{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "wound-medline",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from dbn import SupervisedDBNRegression\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM , Dropout , Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "infinite-simon",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/Equity/NSE50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "southwest-crack",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df.index = df['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "overall-pennsylvania",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df['High']==df['Low']].index , axis=0 , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cardiovascular-albania",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>OI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1995-11-03</th>\n",
       "      <td>NSE50</td>\n",
       "      <td>1995-11-03</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>994.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>993.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>12938015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-11-06</th>\n",
       "      <td>NSE50</td>\n",
       "      <td>1995-11-06</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>1002.0</td>\n",
       "      <td>1002.0</td>\n",
       "      <td>989.0</td>\n",
       "      <td>989.0</td>\n",
       "      <td>9711115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-11-07</th>\n",
       "      <td>NSE50</td>\n",
       "      <td>1995-11-07</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>987.0</td>\n",
       "      <td>987.0</td>\n",
       "      <td>977.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>10985070</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-11-08</th>\n",
       "      <td>NSE50</td>\n",
       "      <td>1995-11-08</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>976.0</td>\n",
       "      <td>976.0</td>\n",
       "      <td>963.0</td>\n",
       "      <td>964.0</td>\n",
       "      <td>7272730</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-11-09</th>\n",
       "      <td>NSE50</td>\n",
       "      <td>1995-11-09</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>960.0</td>\n",
       "      <td>960.0</td>\n",
       "      <td>952.0</td>\n",
       "      <td>953.0</td>\n",
       "      <td>7680380</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Ticker       Date      Time    Open    High    Low   Close  \\\n",
       "Date                                                                    \n",
       "1995-11-03  NSE50 1995-11-03  00:00:00   994.0  1001.0  993.0  1000.0   \n",
       "1995-11-06  NSE50 1995-11-06  00:00:00  1002.0  1002.0  989.0   989.0   \n",
       "1995-11-07  NSE50 1995-11-07  00:00:00   987.0   987.0  977.0   978.0   \n",
       "1995-11-08  NSE50 1995-11-08  00:00:00   976.0   976.0  963.0   964.0   \n",
       "1995-11-09  NSE50 1995-11-09  00:00:00   960.0   960.0  952.0   953.0   \n",
       "\n",
       "              Volume  OI   \n",
       "Date                       \n",
       "1995-11-03  12938015    0  \n",
       "1995-11-06   9711115    0  \n",
       "1995-11-07  10985070    0  \n",
       "1995-11-08   7272730    0  \n",
       "1995-11-09   7680380    0  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "demographic-brick",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Ticker' , 'Date' ,'Time', 'Volume' , 'OI '] , axis=1 , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "studied-religious",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1995-11-03</th>\n",
       "      <td>994.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>993.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-11-06</th>\n",
       "      <td>1002.0</td>\n",
       "      <td>1002.0</td>\n",
       "      <td>989.0</td>\n",
       "      <td>989.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-11-07</th>\n",
       "      <td>987.0</td>\n",
       "      <td>987.0</td>\n",
       "      <td>977.0</td>\n",
       "      <td>978.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-11-08</th>\n",
       "      <td>976.0</td>\n",
       "      <td>976.0</td>\n",
       "      <td>963.0</td>\n",
       "      <td>964.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-11-09</th>\n",
       "      <td>960.0</td>\n",
       "      <td>960.0</td>\n",
       "      <td>952.0</td>\n",
       "      <td>953.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open    High    Low   Close\n",
       "Date                                     \n",
       "1995-11-03   994.0  1001.0  993.0  1000.0\n",
       "1995-11-06  1002.0  1002.0  989.0   989.0\n",
       "1995-11-07   987.0   987.0  977.0   978.0\n",
       "1995-11-08   976.0   976.0  963.0   964.0\n",
       "1995-11-09   960.0   960.0  952.0   953.0"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "creative-roman",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "selective-google",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and testing data\n",
    "train_size = int(len(data) *0.80)\n",
    "train = data[:train_size]\n",
    "test = data[train_size :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "minute-algeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_close = scaler.fit_transform(np.array(train['Close']).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "respiratory-empire",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_open = scaler.transform(np.array(train['Open']).reshape(-1,1))\n",
    "scaled_high = scaler.transform(np.array(train['High']).reshape(-1,1))\n",
    "scaled_low = scaler.transform(np.array(train['Low']).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "greek-finish",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_list = []\n",
    "close_list = []\n",
    "high_list = []\n",
    "low_list = []\n",
    "for i in range(len(scaled_open)):\n",
    "    open_list.append(scaled_open[i])\n",
    "    high_list.append(scaled_high[i])\n",
    "    low_list.append(scaled_low[i])\n",
    "    close_list.append( scaled_close[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "younger-spiritual",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_arr = np.array(open_list).reshape(-1,1)\n",
    "high_arr = np.array(high_list).reshape(-1,1)\n",
    "low_arr = np.array(low_list).reshape(-1,1)\n",
    "close_arr = np.array(close_list).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "starting-escape",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data = pd.DataFrame(open_arr , columns=['Open'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "viral-plant",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data['High'] = high_arr\n",
    "scaled_data['Low'] = low_arr\n",
    "scaled_data['Close'] = close_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "civic-printer",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train = np.array(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "august-distinction",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for x in range(60,len(scaled_train)-1):\n",
    "    temp = []\n",
    "    for i in scaled_train[x-60 :x,]:\n",
    "        temp.append(i[0] )\n",
    "        temp.append(i[1])\n",
    "        temp.append( i[2])\n",
    "        temp.append(i[3])\n",
    "        \n",
    "    X_train.append(temp)\n",
    "    \n",
    "    y_train.append(scaled_train[x+1][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "instant-visiting",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "sapphire-balance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.02605353, 0.02605353, 0.02446973, 0.02446973, 0.02422607,\n",
       "        0.02422607, 0.02300776, 0.02312959, 0.02288593, 0.02288593,\n",
       "        0.02130213, 0.02142396, 0.02093664, 0.02093664, 0.01996199,\n",
       "        0.02008382, 0.01996199, 0.01996199, 0.019231  , 0.0195965 ,\n",
       "        0.0195965 , 0.0195965 , 0.01557608, 0.01569791, 0.01569791,\n",
       "        0.01569791, 0.01338312, 0.01399228, 0.01374861, 0.01533242,\n",
       "        0.01374861, 0.01521058, 0.01557608, 0.01557608, 0.01374861,\n",
       "        0.01411411, 0.01350495, 0.01362678, 0.01179932, 0.01350495,\n",
       "        0.01313946, 0.01350495, 0.01265214, 0.01277397, 0.01265214,\n",
       "        0.01265214, 0.01070284, 0.01082467, 0.0109465 , 0.0109465 ,\n",
       "        0.00838806, 0.00924087, 0.00826622, 0.00826622, 0.00656059,\n",
       "        0.00753524, 0.00753524, 0.01058101, 0.00753524, 0.01009369,\n",
       "        0.01021552, 0.01106833, 0.00863172, 0.00887538, 0.00802256,\n",
       "        0.00802256, 0.00643876, 0.00680425, 0.00692609, 0.00692609,\n",
       "        0.00424581, 0.00692609, 0.00643876, 0.00924087, 0.00607327,\n",
       "        0.00899721, 0.0097282 , 0.01082467, 0.00948453, 0.01033735,\n",
       "        0.00997186, 0.01033735, 0.00899721, 0.00924087, 0.00875355,\n",
       "        0.0097282 , 0.00802256, 0.00960636, 0.00997186, 0.01106833,\n",
       "        0.0097282 , 0.01106833, 0.01143383, 0.01374861, 0.01143383,\n",
       "        0.01350495, 0.01362678, 0.01460143, 0.01204298, 0.01204298,\n",
       "        0.01155566, 0.01155566, 0.01045918, 0.01082467, 0.01106833,\n",
       "        0.01119017, 0.01058101, 0.01106833, 0.011312  , 0.01228664,\n",
       "        0.011312  , 0.01228664, 0.01253031, 0.01265214, 0.01167749,\n",
       "        0.01167749, 0.01082467, 0.01167749, 0.01058101, 0.01155566,\n",
       "        0.01155566, 0.01167749, 0.011312  , 0.01155566, 0.01143383,\n",
       "        0.01167749, 0.01119017, 0.01167749, 0.01167749, 0.01204298,\n",
       "        0.01167749, 0.01192115, 0.01216481, 0.01374861, 0.01216481,\n",
       "        0.01374861, 0.01374861, 0.0144796 , 0.01350495, 0.01374861,\n",
       "        0.01362678, 0.01435777, 0.01338312, 0.01423594, 0.01472326,\n",
       "        0.01642889, 0.01472326, 0.01630706, 0.01655072, 0.01703805,\n",
       "        0.01533242, 0.01545425, 0.01521058, 0.01521058, 0.01435777,\n",
       "        0.01472326, 0.01521058, 0.01521058, 0.01435777, 0.01460143,\n",
       "        0.0144796 , 0.0144796 , 0.01362678, 0.01362678, 0.01387045,\n",
       "        0.01411411, 0.01301763, 0.01313946, 0.01253031, 0.01253031,\n",
       "        0.01167749, 0.01240847, 0.01216481, 0.01216481, 0.01143383,\n",
       "        0.01179932, 0.01167749, 0.01167749, 0.0097282 , 0.00997186,\n",
       "        0.0093627 , 0.01009369, 0.00838806, 0.00985003, 0.00924087,\n",
       "        0.00985003, 0.00924087, 0.00924087, 0.00911904, 0.01045918,\n",
       "        0.00899721, 0.01033735, 0.01058101, 0.0109465 , 0.01021552,\n",
       "        0.01058101, 0.01106833, 0.01106833, 0.01009369, 0.01009369,\n",
       "        0.01009369, 0.01009369, 0.00960636, 0.00985003, 0.00948453,\n",
       "        0.00948453, 0.00838806, 0.00838806, 0.00790073, 0.00790073,\n",
       "        0.00656059, 0.00741341, 0.00716975, 0.00716975, 0.00631693,\n",
       "        0.00680425, 0.00692609, 0.00716975, 0.00680425, 0.00680425,\n",
       "        0.00704792, 0.00704792, 0.00522045, 0.00546411, 0.00522045,\n",
       "        0.00522045, 0.00339299, 0.00375848, 0.00388031, 0.00388031,\n",
       "        0.00314933, 0.00327116, 0.0030275 , 0.00534228, 0.0030275 ,\n",
       "        0.00522045, 0.00582961, 0.00729158, 0.00582961, 0.00716975]),\n",
       " 0.0072915778316541)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1] , y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "fabulous-regard",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SupervisedDBNRegression(hidden_layers_structure=[500],\n",
    "                                    learning_rate_rbm=0.0001,\n",
    "                                    learning_rate=0.0001,\n",
    "                                    n_epochs_rbm=100,\n",
    "                                    n_iter_backprop=200,\n",
    "                                    batch_size=32,\n",
    "                                    activation_function='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "lined-position",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 34.885635\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 25.566875\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 8.270980\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 0.518628\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 0.463482\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 0.555735\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 0.559351\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 0.558333\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 0.600001\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 0.556194\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 0.551634\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 0.555824\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 0.580976\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 0.558521\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 0.545248\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 0.555689\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 0.535253\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 0.556675\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 0.572025\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 0.549555\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 0.558617\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 0.546950\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 0.529162\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 0.550810\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 0.550327\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 0.565815\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 0.596908\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 0.575197\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 0.583344\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 0.571829\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 0.556775\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 0.561268\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.557182\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.540684\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.526467\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.520211\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.560236\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.587085\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.575746\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.560460\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.551380\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.602202\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.566552\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.572716\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.566908\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.597387\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.614646\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.562958\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.606141\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.567882\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.620649\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.559923\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.557203\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.574164\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.583873\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.580980\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.613971\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.619001\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.598619\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.594406\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.577080\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.636889\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.646329\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.599627\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.583770\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.606317\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.625843\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.582858\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.589093\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.625730\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.632346\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.608231\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.596774\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.609458\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.595013\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.618202\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.589460\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.599603\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.601640\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.627016\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.625448\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.639278\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.616356\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.583399\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.607456\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.582703\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.584875\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.620469\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.637125\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.611717\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.653437\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.626972\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.649074\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.639842\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.633628\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.640721\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.605404\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.597833\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.605442\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.642977\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.031632\n",
      ">> Epoch 2 finished \tANN training loss 0.005453\n",
      ">> Epoch 3 finished \tANN training loss 0.002188\n",
      ">> Epoch 4 finished \tANN training loss 0.001769\n",
      ">> Epoch 5 finished \tANN training loss 0.001696\n",
      ">> Epoch 6 finished \tANN training loss 0.001668\n",
      ">> Epoch 7 finished \tANN training loss 0.001646\n",
      ">> Epoch 8 finished \tANN training loss 0.001625\n",
      ">> Epoch 9 finished \tANN training loss 0.001605\n",
      ">> Epoch 10 finished \tANN training loss 0.001585\n",
      ">> Epoch 11 finished \tANN training loss 0.001566\n",
      ">> Epoch 12 finished \tANN training loss 0.001548\n",
      ">> Epoch 13 finished \tANN training loss 0.001529\n",
      ">> Epoch 14 finished \tANN training loss 0.001512\n",
      ">> Epoch 15 finished \tANN training loss 0.001495\n",
      ">> Epoch 16 finished \tANN training loss 0.001478\n",
      ">> Epoch 17 finished \tANN training loss 0.001462\n",
      ">> Epoch 18 finished \tANN training loss 0.001446\n",
      ">> Epoch 19 finished \tANN training loss 0.001430\n",
      ">> Epoch 20 finished \tANN training loss 0.001415\n",
      ">> Epoch 21 finished \tANN training loss 0.001400\n",
      ">> Epoch 22 finished \tANN training loss 0.001386\n",
      ">> Epoch 23 finished \tANN training loss 0.001372\n",
      ">> Epoch 24 finished \tANN training loss 0.001358\n",
      ">> Epoch 25 finished \tANN training loss 0.001345\n",
      ">> Epoch 26 finished \tANN training loss 0.001332\n",
      ">> Epoch 27 finished \tANN training loss 0.001320\n",
      ">> Epoch 28 finished \tANN training loss 0.001307\n",
      ">> Epoch 29 finished \tANN training loss 0.001295\n",
      ">> Epoch 30 finished \tANN training loss 0.001284\n",
      ">> Epoch 31 finished \tANN training loss 0.001272\n",
      ">> Epoch 32 finished \tANN training loss 0.001261\n",
      ">> Epoch 33 finished \tANN training loss 0.001250\n",
      ">> Epoch 34 finished \tANN training loss 0.001240\n",
      ">> Epoch 35 finished \tANN training loss 0.001229\n",
      ">> Epoch 36 finished \tANN training loss 0.001219\n",
      ">> Epoch 37 finished \tANN training loss 0.001209\n",
      ">> Epoch 38 finished \tANN training loss 0.001200\n",
      ">> Epoch 39 finished \tANN training loss 0.001190\n",
      ">> Epoch 40 finished \tANN training loss 0.001181\n",
      ">> Epoch 41 finished \tANN training loss 0.001173\n",
      ">> Epoch 42 finished \tANN training loss 0.001164\n",
      ">> Epoch 43 finished \tANN training loss 0.001156\n",
      ">> Epoch 44 finished \tANN training loss 0.001148\n",
      ">> Epoch 45 finished \tANN training loss 0.001140\n",
      ">> Epoch 46 finished \tANN training loss 0.001132\n",
      ">> Epoch 47 finished \tANN training loss 0.001125\n",
      ">> Epoch 48 finished \tANN training loss 0.001118\n",
      ">> Epoch 49 finished \tANN training loss 0.001111\n",
      ">> Epoch 50 finished \tANN training loss 0.001104\n",
      ">> Epoch 51 finished \tANN training loss 0.001097\n",
      ">> Epoch 52 finished \tANN training loss 0.001090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 53 finished \tANN training loss 0.001084\n",
      ">> Epoch 54 finished \tANN training loss 0.001078\n",
      ">> Epoch 55 finished \tANN training loss 0.001072\n",
      ">> Epoch 56 finished \tANN training loss 0.001066\n",
      ">> Epoch 57 finished \tANN training loss 0.001060\n",
      ">> Epoch 58 finished \tANN training loss 0.001054\n",
      ">> Epoch 59 finished \tANN training loss 0.001048\n",
      ">> Epoch 60 finished \tANN training loss 0.001043\n",
      ">> Epoch 61 finished \tANN training loss 0.001038\n",
      ">> Epoch 62 finished \tANN training loss 0.001032\n",
      ">> Epoch 63 finished \tANN training loss 0.001027\n",
      ">> Epoch 64 finished \tANN training loss 0.001022\n",
      ">> Epoch 65 finished \tANN training loss 0.001017\n",
      ">> Epoch 66 finished \tANN training loss 0.001013\n",
      ">> Epoch 67 finished \tANN training loss 0.001008\n",
      ">> Epoch 68 finished \tANN training loss 0.001003\n",
      ">> Epoch 69 finished \tANN training loss 0.000999\n",
      ">> Epoch 70 finished \tANN training loss 0.000995\n",
      ">> Epoch 71 finished \tANN training loss 0.000990\n",
      ">> Epoch 72 finished \tANN training loss 0.000986\n",
      ">> Epoch 73 finished \tANN training loss 0.000982\n",
      ">> Epoch 74 finished \tANN training loss 0.000978\n",
      ">> Epoch 75 finished \tANN training loss 0.000975\n",
      ">> Epoch 76 finished \tANN training loss 0.000971\n",
      ">> Epoch 77 finished \tANN training loss 0.000967\n",
      ">> Epoch 78 finished \tANN training loss 0.000964\n",
      ">> Epoch 79 finished \tANN training loss 0.000960\n",
      ">> Epoch 80 finished \tANN training loss 0.000957\n",
      ">> Epoch 81 finished \tANN training loss 0.000953\n",
      ">> Epoch 82 finished \tANN training loss 0.000950\n",
      ">> Epoch 83 finished \tANN training loss 0.000947\n",
      ">> Epoch 84 finished \tANN training loss 0.000944\n",
      ">> Epoch 85 finished \tANN training loss 0.000941\n",
      ">> Epoch 86 finished \tANN training loss 0.000938\n",
      ">> Epoch 87 finished \tANN training loss 0.000935\n",
      ">> Epoch 88 finished \tANN training loss 0.000932\n",
      ">> Epoch 89 finished \tANN training loss 0.000929\n",
      ">> Epoch 90 finished \tANN training loss 0.000926\n",
      ">> Epoch 91 finished \tANN training loss 0.000923\n",
      ">> Epoch 92 finished \tANN training loss 0.000921\n",
      ">> Epoch 93 finished \tANN training loss 0.000918\n",
      ">> Epoch 94 finished \tANN training loss 0.000916\n",
      ">> Epoch 95 finished \tANN training loss 0.000913\n",
      ">> Epoch 96 finished \tANN training loss 0.000910\n",
      ">> Epoch 97 finished \tANN training loss 0.000908\n",
      ">> Epoch 98 finished \tANN training loss 0.000906\n",
      ">> Epoch 99 finished \tANN training loss 0.000903\n",
      ">> Epoch 100 finished \tANN training loss 0.000901\n",
      ">> Epoch 101 finished \tANN training loss 0.000899\n",
      ">> Epoch 102 finished \tANN training loss 0.000897\n",
      ">> Epoch 103 finished \tANN training loss 0.000895\n",
      ">> Epoch 104 finished \tANN training loss 0.000892\n",
      ">> Epoch 105 finished \tANN training loss 0.000891\n",
      ">> Epoch 106 finished \tANN training loss 0.000889\n",
      ">> Epoch 107 finished \tANN training loss 0.000887\n",
      ">> Epoch 108 finished \tANN training loss 0.000885\n",
      ">> Epoch 109 finished \tANN training loss 0.000883\n",
      ">> Epoch 110 finished \tANN training loss 0.000881\n",
      ">> Epoch 111 finished \tANN training loss 0.000880\n",
      ">> Epoch 112 finished \tANN training loss 0.000878\n",
      ">> Epoch 113 finished \tANN training loss 0.000876\n",
      ">> Epoch 114 finished \tANN training loss 0.000875\n",
      ">> Epoch 115 finished \tANN training loss 0.000873\n",
      ">> Epoch 116 finished \tANN training loss 0.000871\n",
      ">> Epoch 117 finished \tANN training loss 0.000870\n",
      ">> Epoch 118 finished \tANN training loss 0.000868\n",
      ">> Epoch 119 finished \tANN training loss 0.000867\n",
      ">> Epoch 120 finished \tANN training loss 0.000865\n",
      ">> Epoch 121 finished \tANN training loss 0.000864\n",
      ">> Epoch 122 finished \tANN training loss 0.000862\n",
      ">> Epoch 123 finished \tANN training loss 0.000861\n",
      ">> Epoch 124 finished \tANN training loss 0.000860\n",
      ">> Epoch 125 finished \tANN training loss 0.000859\n",
      ">> Epoch 126 finished \tANN training loss 0.000857\n",
      ">> Epoch 127 finished \tANN training loss 0.000856\n",
      ">> Epoch 128 finished \tANN training loss 0.000855\n",
      ">> Epoch 129 finished \tANN training loss 0.000853\n",
      ">> Epoch 130 finished \tANN training loss 0.000852\n",
      ">> Epoch 131 finished \tANN training loss 0.000851\n",
      ">> Epoch 132 finished \tANN training loss 0.000850\n",
      ">> Epoch 133 finished \tANN training loss 0.000848\n",
      ">> Epoch 134 finished \tANN training loss 0.000847\n",
      ">> Epoch 135 finished \tANN training loss 0.000846\n",
      ">> Epoch 136 finished \tANN training loss 0.000845\n",
      ">> Epoch 137 finished \tANN training loss 0.000844\n",
      ">> Epoch 138 finished \tANN training loss 0.000843\n",
      ">> Epoch 139 finished \tANN training loss 0.000842\n",
      ">> Epoch 140 finished \tANN training loss 0.000841\n",
      ">> Epoch 141 finished \tANN training loss 0.000839\n",
      ">> Epoch 142 finished \tANN training loss 0.000838\n",
      ">> Epoch 143 finished \tANN training loss 0.000837\n",
      ">> Epoch 144 finished \tANN training loss 0.000836\n",
      ">> Epoch 145 finished \tANN training loss 0.000835\n",
      ">> Epoch 146 finished \tANN training loss 0.000834\n",
      ">> Epoch 147 finished \tANN training loss 0.000833\n",
      ">> Epoch 148 finished \tANN training loss 0.000832\n",
      ">> Epoch 149 finished \tANN training loss 0.000831\n",
      ">> Epoch 150 finished \tANN training loss 0.000830\n",
      ">> Epoch 151 finished \tANN training loss 0.000829\n",
      ">> Epoch 152 finished \tANN training loss 0.000828\n",
      ">> Epoch 153 finished \tANN training loss 0.000827\n",
      ">> Epoch 154 finished \tANN training loss 0.000826\n",
      ">> Epoch 155 finished \tANN training loss 0.000825\n",
      ">> Epoch 156 finished \tANN training loss 0.000824\n",
      ">> Epoch 157 finished \tANN training loss 0.000823\n",
      ">> Epoch 158 finished \tANN training loss 0.000822\n",
      ">> Epoch 159 finished \tANN training loss 0.000822\n",
      ">> Epoch 160 finished \tANN training loss 0.000821\n",
      ">> Epoch 161 finished \tANN training loss 0.000820\n",
      ">> Epoch 162 finished \tANN training loss 0.000819\n",
      ">> Epoch 163 finished \tANN training loss 0.000818\n",
      ">> Epoch 164 finished \tANN training loss 0.000817\n",
      ">> Epoch 165 finished \tANN training loss 0.000816\n",
      ">> Epoch 166 finished \tANN training loss 0.000815\n",
      ">> Epoch 167 finished \tANN training loss 0.000814\n",
      ">> Epoch 168 finished \tANN training loss 0.000813\n",
      ">> Epoch 169 finished \tANN training loss 0.000812\n",
      ">> Epoch 170 finished \tANN training loss 0.000811\n",
      ">> Epoch 171 finished \tANN training loss 0.000811\n",
      ">> Epoch 172 finished \tANN training loss 0.000810\n",
      ">> Epoch 173 finished \tANN training loss 0.000809\n",
      ">> Epoch 174 finished \tANN training loss 0.000808\n",
      ">> Epoch 175 finished \tANN training loss 0.000807\n",
      ">> Epoch 176 finished \tANN training loss 0.000806\n",
      ">> Epoch 177 finished \tANN training loss 0.000805\n",
      ">> Epoch 178 finished \tANN training loss 0.000804\n",
      ">> Epoch 179 finished \tANN training loss 0.000804\n",
      ">> Epoch 180 finished \tANN training loss 0.000803\n",
      ">> Epoch 181 finished \tANN training loss 0.000802\n",
      ">> Epoch 182 finished \tANN training loss 0.000801\n",
      ">> Epoch 183 finished \tANN training loss 0.000800\n",
      ">> Epoch 184 finished \tANN training loss 0.000799\n",
      ">> Epoch 185 finished \tANN training loss 0.000799\n",
      ">> Epoch 186 finished \tANN training loss 0.000798\n",
      ">> Epoch 187 finished \tANN training loss 0.000797\n",
      ">> Epoch 188 finished \tANN training loss 0.000796\n",
      ">> Epoch 189 finished \tANN training loss 0.000796\n",
      ">> Epoch 190 finished \tANN training loss 0.000795\n",
      ">> Epoch 191 finished \tANN training loss 0.000794\n",
      ">> Epoch 192 finished \tANN training loss 0.000794\n",
      ">> Epoch 193 finished \tANN training loss 0.000793\n",
      ">> Epoch 194 finished \tANN training loss 0.000792\n",
      ">> Epoch 195 finished \tANN training loss 0.000792\n",
      ">> Epoch 196 finished \tANN training loss 0.000791\n",
      ">> Epoch 197 finished \tANN training loss 0.000790\n",
      ">> Epoch 198 finished \tANN training loss 0.000790\n",
      ">> Epoch 199 finished \tANN training loss 0.000789\n",
      ">> Epoch 200 finished \tANN training loss 0.000789\n",
      "[END] Fine tuning step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SupervisedDBNRegression()"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "statewide-wedding",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scaled_close = scaler.transform(np.array(test['Close']).reshape(-1,1))\n",
    "test_scaled_open = scaler.transform(np.array(test['Open']).reshape(-1,1))\n",
    "test_scaled_high = scaler.transform(np.array(test['High']).reshape(-1,1))\n",
    "test_scaled_low = scaler.transform(np.array(test['Low']).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "southeast-lightning",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_list = []\n",
    "close_list = []\n",
    "high_list = []\n",
    "low_list = []\n",
    "for i in range(len(test_scaled_open)):\n",
    "    open_list.append(test_scaled_open[i])\n",
    "    high_list.append(test_scaled_high[i])\n",
    "    low_list.append(test_scaled_low[i])\n",
    "    close_list.append( test_scaled_close[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "increasing-stick",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_arr = np.array(open_list).reshape(-1,1)\n",
    "high_arr = np.array(high_list).reshape(-1,1)\n",
    "low_arr = np.array(low_list).reshape(-1,1)\n",
    "close_arr = np.array(close_list).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "loose-shadow",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data = pd.DataFrame(open_arr , columns=['Open'])\n",
    "scaled_data['High'] = high_arr\n",
    "scaled_data['Low'] = low_arr\n",
    "scaled_data['Close'] = close_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "proper-python",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_test = np.array(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "brilliant-tissue",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./models/ohlc25.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "historical-catholic",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for x in range(60,len(scaled_test)-1):\n",
    "    temp = []\n",
    "    for i in scaled_test[x-60 :x,]:\n",
    "        temp.append(i[0] )\n",
    "        temp.append(i[1])\n",
    "        temp.append( i[2])\n",
    "        temp.append(i[3])\n",
    "        \n",
    "    X_test.append(temp)\n",
    "    \n",
    "    y_test.append(scaled_test[x+1][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "worth-genre",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "worthy-vehicle",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "powerful-criticism",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(preds)\n",
    "plt.plot(y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-disney",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
