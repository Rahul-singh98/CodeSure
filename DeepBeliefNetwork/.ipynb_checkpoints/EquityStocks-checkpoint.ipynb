{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "higher-limit",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics._regression import r2_score, mean_squared_error ,mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from dbn import SupervisedDBNRegression\n",
    "import matplotlib.pyplot as plt \n",
    "import os\n",
    "import sys \n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "latest-opportunity",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '/home/rahul/Desktop/data/EQ_daily'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "crude-investing",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = os.listdir(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "informal-election",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_list = []\n",
    "ticker_list = []\n",
    "\n",
    "for i , idx in enumerate(csv_files):\n",
    "    df = pd.read_csv(filepath+'/' + idx)\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df.index = df['Date']\n",
    "    ticker_list.append(idx.split('.')[0])\n",
    "    X = df['Close'].copy()\n",
    "    dataframe_list.append(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "powered-palestinian",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df = []\n",
    "scaler_list = []\n",
    "for i in range(len(dataframe_list)):\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    transformed = scaler.fit_transform(np.array(dataframe_list[i]).reshape(-1,1))\n",
    "    scaler_list.append(scaler)\n",
    "    scaled_df.append(transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "blank-brazilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_data = []\n",
    "Testing_data = []\n",
    "\n",
    "for i in range(len(scaled_df)):\n",
    "    train_size = int(len(scaled_df[i])* 0.80)\n",
    "    train = scaled_df[i][:train_size] \n",
    "    test = scaled_df[i][train_size:]\n",
    "    Training_data.append(train)\n",
    "    Testing_data.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "unknown-nowhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_list = []\n",
    "y_train_list = []\n",
    "\n",
    "periods = 60\n",
    "\n",
    "for i in range(len(Training_data)):\n",
    "    xappend = []\n",
    "    yappend = []\n",
    "    for j in range(periods , len(Training_data[i])):\n",
    "        X_train = Training_data[i][j-periods :j ,0]\n",
    "        y_train = Training_data[i][j ,0]\n",
    "        \n",
    "        xappend.append(X_train)\n",
    "        yappend.append(y_train)\n",
    "        \n",
    "    X_train_list.append(xappend)\n",
    "    y_train_list.append(yappend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "artistic-appreciation",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_list = []\n",
    "y_test_list = []\n",
    "\n",
    "periods = 60\n",
    "\n",
    "for i in range(len(Testing_data)):\n",
    "    xappend = []\n",
    "    yappend = []\n",
    "    for j in range(periods , len(Testing_data[i])):\n",
    "        X_train = Testing_data[i][j-periods :j ,0]\n",
    "        y_train = Testing_data[i][j ,0]\n",
    "        \n",
    "        xappend.append(X_train)\n",
    "        yappend.append(y_train)\n",
    "        \n",
    "    X_test_list.append(xappend)\n",
    "    y_test_list.append(yappend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "further-chapel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### End Training for KOTAKBANKEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 0.522996\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 0.518152\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 0.513415\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 0.508787\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 0.504270\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 0.499859\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 0.495559\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 0.491363\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 0.487263\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 0.483266\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 0.479363\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 0.475549\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 0.471829\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 0.468198\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 0.464652\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 0.461193\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 0.457813\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 0.454523\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 0.451312\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 0.448170\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 0.445097\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 0.442103\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 0.439185\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 0.436337\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 0.433563\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 0.430845\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 0.428188\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 0.425595\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 0.423058\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 0.420586\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 0.418167\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 0.415806\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.413490\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.411231\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.409021\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.406861\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.404742\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.402672\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.400641\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.398659\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.396721\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.394824\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.392969\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.391147\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.389363\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.387615\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.385903\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.384226\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.382581\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.380959\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.379370\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.377815\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.376289\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.374790\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.373321\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.371878\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.370457\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.369060\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.367680\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.366330\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.365002\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.363696\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.362409\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.361139\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.359893\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.358662\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.357454\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.356251\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.355074\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.353908\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.352766\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.351639\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.350521\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.349427\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.348338\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.347260\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.346197\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.345140\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.344101\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.343072\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.342052\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.341040\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.340039\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.339050\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.338067\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.337093\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.336135\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.335179\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.334235\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.333295\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.332358\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.331430\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.330507\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.329589\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.328672\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.327765\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.326863\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.325968\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.325068\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.324184\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.022566\n",
      ">> Epoch 2 finished \tANN training loss 0.021522\n",
      ">> Epoch 3 finished \tANN training loss 0.020536\n",
      ">> Epoch 4 finished \tANN training loss 0.019606\n",
      ">> Epoch 5 finished \tANN training loss 0.018728\n",
      ">> Epoch 6 finished \tANN training loss 0.017900\n",
      ">> Epoch 7 finished \tANN training loss 0.017118\n",
      ">> Epoch 8 finished \tANN training loss 0.016378\n",
      ">> Epoch 9 finished \tANN training loss 0.015679\n",
      ">> Epoch 10 finished \tANN training loss 0.015017\n",
      ">> Epoch 11 finished \tANN training loss 0.014391\n",
      ">> Epoch 12 finished \tANN training loss 0.013800\n",
      ">> Epoch 13 finished \tANN training loss 0.013241\n",
      ">> Epoch 14 finished \tANN training loss 0.012712\n",
      ">> Epoch 15 finished \tANN training loss 0.012212\n",
      ">> Epoch 16 finished \tANN training loss 0.011740\n",
      ">> Epoch 17 finished \tANN training loss 0.011293\n",
      ">> Epoch 18 finished \tANN training loss 0.010872\n",
      ">> Epoch 19 finished \tANN training loss 0.010474\n",
      ">> Epoch 20 finished \tANN training loss 0.010098\n",
      ">> Epoch 21 finished \tANN training loss 0.009743\n",
      ">> Epoch 22 finished \tANN training loss 0.009407\n",
      ">> Epoch 23 finished \tANN training loss 0.009089\n",
      ">> Epoch 24 finished \tANN training loss 0.008788\n",
      ">> Epoch 25 finished \tANN training loss 0.008503\n",
      ">> Epoch 26 finished \tANN training loss 0.008232\n",
      ">> Epoch 27 finished \tANN training loss 0.007976\n",
      ">> Epoch 28 finished \tANN training loss 0.007733\n",
      ">> Epoch 29 finished \tANN training loss 0.007502\n",
      ">> Epoch 30 finished \tANN training loss 0.007283\n",
      ">> Epoch 31 finished \tANN training loss 0.007075\n",
      ">> Epoch 32 finished \tANN training loss 0.006878\n",
      ">> Epoch 33 finished \tANN training loss 0.006690\n",
      ">> Epoch 34 finished \tANN training loss 0.006511\n",
      ">> Epoch 35 finished \tANN training loss 0.006341\n",
      ">> Epoch 36 finished \tANN training loss 0.006180\n",
      ">> Epoch 37 finished \tANN training loss 0.006026\n",
      ">> Epoch 38 finished \tANN training loss 0.005879\n",
      ">> Epoch 39 finished \tANN training loss 0.005739\n",
      ">> Epoch 40 finished \tANN training loss 0.005606\n",
      ">> Epoch 41 finished \tANN training loss 0.005478\n",
      ">> Epoch 42 finished \tANN training loss 0.005357\n",
      ">> Epoch 43 finished \tANN training loss 0.005240\n",
      ">> Epoch 44 finished \tANN training loss 0.005129\n",
      ">> Epoch 45 finished \tANN training loss 0.005023\n",
      ">> Epoch 46 finished \tANN training loss 0.004921\n",
      ">> Epoch 47 finished \tANN training loss 0.004823\n",
      ">> Epoch 48 finished \tANN training loss 0.004730\n",
      ">> Epoch 49 finished \tANN training loss 0.004640\n",
      ">> Epoch 50 finished \tANN training loss 0.004554\n",
      ">> Epoch 51 finished \tANN training loss 0.004471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 52 finished \tANN training loss 0.004392\n",
      ">> Epoch 53 finished \tANN training loss 0.004316\n",
      ">> Epoch 54 finished \tANN training loss 0.004242\n",
      ">> Epoch 55 finished \tANN training loss 0.004171\n",
      ">> Epoch 56 finished \tANN training loss 0.004103\n",
      ">> Epoch 57 finished \tANN training loss 0.004037\n",
      ">> Epoch 58 finished \tANN training loss 0.003974\n",
      ">> Epoch 59 finished \tANN training loss 0.003912\n",
      ">> Epoch 60 finished \tANN training loss 0.003853\n",
      ">> Epoch 61 finished \tANN training loss 0.003796\n",
      ">> Epoch 62 finished \tANN training loss 0.003740\n",
      ">> Epoch 63 finished \tANN training loss 0.003687\n",
      ">> Epoch 64 finished \tANN training loss 0.003635\n",
      ">> Epoch 65 finished \tANN training loss 0.003584\n",
      ">> Epoch 66 finished \tANN training loss 0.003535\n",
      ">> Epoch 67 finished \tANN training loss 0.003487\n",
      ">> Epoch 68 finished \tANN training loss 0.003441\n",
      ">> Epoch 69 finished \tANN training loss 0.003396\n",
      ">> Epoch 70 finished \tANN training loss 0.003352\n",
      ">> Epoch 71 finished \tANN training loss 0.003309\n",
      ">> Epoch 72 finished \tANN training loss 0.003268\n",
      ">> Epoch 73 finished \tANN training loss 0.003227\n",
      ">> Epoch 74 finished \tANN training loss 0.003188\n",
      ">> Epoch 75 finished \tANN training loss 0.003149\n",
      ">> Epoch 76 finished \tANN training loss 0.003111\n",
      ">> Epoch 77 finished \tANN training loss 0.003075\n",
      ">> Epoch 78 finished \tANN training loss 0.003039\n",
      ">> Epoch 79 finished \tANN training loss 0.003003\n",
      ">> Epoch 80 finished \tANN training loss 0.002969\n",
      ">> Epoch 81 finished \tANN training loss 0.002935\n",
      ">> Epoch 82 finished \tANN training loss 0.002902\n",
      ">> Epoch 83 finished \tANN training loss 0.002870\n",
      ">> Epoch 84 finished \tANN training loss 0.002838\n",
      ">> Epoch 85 finished \tANN training loss 0.002807\n",
      ">> Epoch 86 finished \tANN training loss 0.002776\n",
      ">> Epoch 87 finished \tANN training loss 0.002746\n",
      ">> Epoch 88 finished \tANN training loss 0.002717\n",
      ">> Epoch 89 finished \tANN training loss 0.002688\n",
      ">> Epoch 90 finished \tANN training loss 0.002660\n",
      ">> Epoch 91 finished \tANN training loss 0.002632\n",
      ">> Epoch 92 finished \tANN training loss 0.002604\n",
      ">> Epoch 93 finished \tANN training loss 0.002577\n",
      ">> Epoch 94 finished \tANN training loss 0.002551\n",
      ">> Epoch 95 finished \tANN training loss 0.002524\n",
      ">> Epoch 96 finished \tANN training loss 0.002499\n",
      ">> Epoch 97 finished \tANN training loss 0.002473\n",
      ">> Epoch 98 finished \tANN training loss 0.002448\n",
      ">> Epoch 99 finished \tANN training loss 0.002424\n",
      ">> Epoch 100 finished \tANN training loss 0.002399\n",
      ">> Epoch 101 finished \tANN training loss 0.002375\n",
      ">> Epoch 102 finished \tANN training loss 0.002352\n",
      ">> Epoch 103 finished \tANN training loss 0.002328\n",
      ">> Epoch 104 finished \tANN training loss 0.002305\n",
      ">> Epoch 105 finished \tANN training loss 0.002283\n",
      ">> Epoch 106 finished \tANN training loss 0.002260\n",
      ">> Epoch 107 finished \tANN training loss 0.002238\n",
      ">> Epoch 108 finished \tANN training loss 0.002216\n",
      ">> Epoch 109 finished \tANN training loss 0.002195\n",
      ">> Epoch 110 finished \tANN training loss 0.002173\n",
      ">> Epoch 111 finished \tANN training loss 0.002152\n",
      ">> Epoch 112 finished \tANN training loss 0.002131\n",
      ">> Epoch 113 finished \tANN training loss 0.002111\n",
      ">> Epoch 114 finished \tANN training loss 0.002090\n",
      ">> Epoch 115 finished \tANN training loss 0.002070\n",
      ">> Epoch 116 finished \tANN training loss 0.002050\n",
      ">> Epoch 117 finished \tANN training loss 0.002031\n",
      ">> Epoch 118 finished \tANN training loss 0.002011\n",
      ">> Epoch 119 finished \tANN training loss 0.001992\n",
      ">> Epoch 120 finished \tANN training loss 0.001973\n",
      ">> Epoch 121 finished \tANN training loss 0.001954\n",
      ">> Epoch 122 finished \tANN training loss 0.001935\n",
      ">> Epoch 123 finished \tANN training loss 0.001917\n",
      ">> Epoch 124 finished \tANN training loss 0.001899\n",
      ">> Epoch 125 finished \tANN training loss 0.001881\n",
      ">> Epoch 126 finished \tANN training loss 0.001863\n",
      ">> Epoch 127 finished \tANN training loss 0.001845\n",
      ">> Epoch 128 finished \tANN training loss 0.001827\n",
      ">> Epoch 129 finished \tANN training loss 0.001810\n",
      ">> Epoch 130 finished \tANN training loss 0.001793\n",
      ">> Epoch 131 finished \tANN training loss 0.001776\n",
      ">> Epoch 132 finished \tANN training loss 0.001759\n",
      ">> Epoch 133 finished \tANN training loss 0.001743\n",
      ">> Epoch 134 finished \tANN training loss 0.001726\n",
      ">> Epoch 135 finished \tANN training loss 0.001710\n",
      ">> Epoch 136 finished \tANN training loss 0.001694\n",
      ">> Epoch 137 finished \tANN training loss 0.001678\n",
      ">> Epoch 138 finished \tANN training loss 0.001663\n",
      ">> Epoch 139 finished \tANN training loss 0.001647\n",
      ">> Epoch 140 finished \tANN training loss 0.001632\n",
      ">> Epoch 141 finished \tANN training loss 0.001616\n",
      ">> Epoch 142 finished \tANN training loss 0.001601\n",
      ">> Epoch 143 finished \tANN training loss 0.001587\n",
      ">> Epoch 144 finished \tANN training loss 0.001572\n",
      ">> Epoch 145 finished \tANN training loss 0.001557\n",
      ">> Epoch 146 finished \tANN training loss 0.001543\n",
      ">> Epoch 147 finished \tANN training loss 0.001529\n",
      ">> Epoch 148 finished \tANN training loss 0.001514\n",
      ">> Epoch 149 finished \tANN training loss 0.001500\n",
      ">> Epoch 150 finished \tANN training loss 0.001487\n",
      "[END] Fine tuning step\n",
      "############### End Training for KOTAKBANKEQ #####################\n",
      "############### End Training for GLENMARKEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 4.084265\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 4.008198\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 3.930597\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 3.851210\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 3.769709\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 3.685888\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 3.599315\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 3.509760\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 3.417054\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 3.320615\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 3.220318\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 3.116036\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 3.007432\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 2.894346\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 2.776592\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 2.654061\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 2.527260\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 2.396430\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 2.261609\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 2.123696\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 1.982936\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 1.841325\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 1.699213\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 1.557769\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 1.420230\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 1.286147\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 1.157867\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 1.036517\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 0.923871\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 0.820782\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 0.727986\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 0.645581\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.574627\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.513126\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.460109\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.416917\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.380714\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.350911\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.326198\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.304948\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.287751\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.273743\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.262742\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.253138\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.244754\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.238162\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.231824\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.226421\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.221807\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.217765\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.213993\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.210433\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.207348\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.204122\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.201057\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.198205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 57 finished \tRBM Reconstruction error 0.195402\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.192670\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.190449\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.188353\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.186029\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.183557\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.181386\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.179150\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.177045\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.174948\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.173037\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.171069\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.169169\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.167530\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.165600\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.163824\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.162051\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.160171\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.158326\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.156601\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.155084\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.153313\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.151698\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.149964\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.148268\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.146563\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.144865\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.143200\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.141980\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.140656\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.139088\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.137611\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.136093\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.134522\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.133280\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.131758\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.130533\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.129157\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.127680\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.126232\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.125055\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.123876\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.122602\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.121285\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.001259\n",
      ">> Epoch 2 finished \tANN training loss 0.001255\n",
      ">> Epoch 3 finished \tANN training loss 0.001251\n",
      ">> Epoch 4 finished \tANN training loss 0.001248\n",
      ">> Epoch 5 finished \tANN training loss 0.001244\n",
      ">> Epoch 6 finished \tANN training loss 0.001241\n",
      ">> Epoch 7 finished \tANN training loss 0.001237\n",
      ">> Epoch 8 finished \tANN training loss 0.001234\n",
      ">> Epoch 9 finished \tANN training loss 0.001231\n",
      ">> Epoch 10 finished \tANN training loss 0.001228\n",
      ">> Epoch 11 finished \tANN training loss 0.001225\n",
      ">> Epoch 12 finished \tANN training loss 0.001222\n",
      ">> Epoch 13 finished \tANN training loss 0.001219\n",
      ">> Epoch 14 finished \tANN training loss 0.001216\n",
      ">> Epoch 15 finished \tANN training loss 0.001213\n",
      ">> Epoch 16 finished \tANN training loss 0.001210\n",
      ">> Epoch 17 finished \tANN training loss 0.001207\n",
      ">> Epoch 18 finished \tANN training loss 0.001205\n",
      ">> Epoch 19 finished \tANN training loss 0.001202\n",
      ">> Epoch 20 finished \tANN training loss 0.001200\n",
      ">> Epoch 21 finished \tANN training loss 0.001197\n",
      ">> Epoch 22 finished \tANN training loss 0.001194\n",
      ">> Epoch 23 finished \tANN training loss 0.001192\n",
      ">> Epoch 24 finished \tANN training loss 0.001190\n",
      ">> Epoch 25 finished \tANN training loss 0.001187\n",
      ">> Epoch 26 finished \tANN training loss 0.001185\n",
      ">> Epoch 27 finished \tANN training loss 0.001182\n",
      ">> Epoch 28 finished \tANN training loss 0.001180\n",
      ">> Epoch 29 finished \tANN training loss 0.001178\n",
      ">> Epoch 30 finished \tANN training loss 0.001176\n",
      ">> Epoch 31 finished \tANN training loss 0.001174\n",
      ">> Epoch 32 finished \tANN training loss 0.001171\n",
      ">> Epoch 33 finished \tANN training loss 0.001169\n",
      ">> Epoch 34 finished \tANN training loss 0.001167\n",
      ">> Epoch 35 finished \tANN training loss 0.001165\n",
      ">> Epoch 36 finished \tANN training loss 0.001163\n",
      ">> Epoch 37 finished \tANN training loss 0.001161\n",
      ">> Epoch 38 finished \tANN training loss 0.001159\n",
      ">> Epoch 39 finished \tANN training loss 0.001157\n",
      ">> Epoch 40 finished \tANN training loss 0.001155\n",
      ">> Epoch 41 finished \tANN training loss 0.001153\n",
      ">> Epoch 42 finished \tANN training loss 0.001152\n",
      ">> Epoch 43 finished \tANN training loss 0.001150\n",
      ">> Epoch 44 finished \tANN training loss 0.001148\n",
      ">> Epoch 45 finished \tANN training loss 0.001146\n",
      ">> Epoch 46 finished \tANN training loss 0.001144\n",
      ">> Epoch 47 finished \tANN training loss 0.001143\n",
      ">> Epoch 48 finished \tANN training loss 0.001141\n",
      ">> Epoch 49 finished \tANN training loss 0.001139\n",
      ">> Epoch 50 finished \tANN training loss 0.001138\n",
      ">> Epoch 51 finished \tANN training loss 0.001136\n",
      ">> Epoch 52 finished \tANN training loss 0.001135\n",
      ">> Epoch 53 finished \tANN training loss 0.001133\n",
      ">> Epoch 54 finished \tANN training loss 0.001131\n",
      ">> Epoch 55 finished \tANN training loss 0.001130\n",
      ">> Epoch 56 finished \tANN training loss 0.001128\n",
      ">> Epoch 57 finished \tANN training loss 0.001127\n",
      ">> Epoch 58 finished \tANN training loss 0.001125\n",
      ">> Epoch 59 finished \tANN training loss 0.001124\n",
      ">> Epoch 60 finished \tANN training loss 0.001123\n",
      ">> Epoch 61 finished \tANN training loss 0.001121\n",
      ">> Epoch 62 finished \tANN training loss 0.001120\n",
      ">> Epoch 63 finished \tANN training loss 0.001118\n",
      ">> Epoch 64 finished \tANN training loss 0.001117\n",
      ">> Epoch 65 finished \tANN training loss 0.001116\n",
      ">> Epoch 66 finished \tANN training loss 0.001115\n",
      ">> Epoch 67 finished \tANN training loss 0.001113\n",
      ">> Epoch 68 finished \tANN training loss 0.001112\n",
      ">> Epoch 69 finished \tANN training loss 0.001111\n",
      ">> Epoch 70 finished \tANN training loss 0.001109\n",
      ">> Epoch 71 finished \tANN training loss 0.001108\n",
      ">> Epoch 72 finished \tANN training loss 0.001107\n",
      ">> Epoch 73 finished \tANN training loss 0.001106\n",
      ">> Epoch 74 finished \tANN training loss 0.001105\n",
      ">> Epoch 75 finished \tANN training loss 0.001104\n",
      ">> Epoch 76 finished \tANN training loss 0.001102\n",
      ">> Epoch 77 finished \tANN training loss 0.001101\n",
      ">> Epoch 78 finished \tANN training loss 0.001100\n",
      ">> Epoch 79 finished \tANN training loss 0.001099\n",
      ">> Epoch 80 finished \tANN training loss 0.001098\n",
      ">> Epoch 81 finished \tANN training loss 0.001097\n",
      ">> Epoch 82 finished \tANN training loss 0.001096\n",
      ">> Epoch 83 finished \tANN training loss 0.001095\n",
      ">> Epoch 84 finished \tANN training loss 0.001094\n",
      ">> Epoch 85 finished \tANN training loss 0.001093\n",
      ">> Epoch 86 finished \tANN training loss 0.001092\n",
      ">> Epoch 87 finished \tANN training loss 0.001091\n",
      ">> Epoch 88 finished \tANN training loss 0.001090\n",
      ">> Epoch 89 finished \tANN training loss 0.001089\n",
      ">> Epoch 90 finished \tANN training loss 0.001088\n",
      ">> Epoch 91 finished \tANN training loss 0.001087\n",
      ">> Epoch 92 finished \tANN training loss 0.001086\n",
      ">> Epoch 93 finished \tANN training loss 0.001085\n",
      ">> Epoch 94 finished \tANN training loss 0.001084\n",
      ">> Epoch 95 finished \tANN training loss 0.001084\n",
      ">> Epoch 96 finished \tANN training loss 0.001083\n",
      ">> Epoch 97 finished \tANN training loss 0.001082\n",
      ">> Epoch 98 finished \tANN training loss 0.001081\n",
      ">> Epoch 99 finished \tANN training loss 0.001080\n",
      ">> Epoch 100 finished \tANN training loss 0.001079\n",
      ">> Epoch 101 finished \tANN training loss 0.001078\n",
      ">> Epoch 102 finished \tANN training loss 0.001078\n",
      ">> Epoch 103 finished \tANN training loss 0.001077\n",
      ">> Epoch 104 finished \tANN training loss 0.001076\n",
      ">> Epoch 105 finished \tANN training loss 0.001075\n",
      ">> Epoch 106 finished \tANN training loss 0.001074\n",
      ">> Epoch 107 finished \tANN training loss 0.001074\n",
      ">> Epoch 108 finished \tANN training loss 0.001073\n",
      ">> Epoch 109 finished \tANN training loss 0.001072\n",
      ">> Epoch 110 finished \tANN training loss 0.001071\n",
      ">> Epoch 111 finished \tANN training loss 0.001071\n",
      ">> Epoch 112 finished \tANN training loss 0.001070\n",
      ">> Epoch 113 finished \tANN training loss 0.001069\n",
      ">> Epoch 114 finished \tANN training loss 0.001069\n",
      ">> Epoch 115 finished \tANN training loss 0.001068\n",
      ">> Epoch 116 finished \tANN training loss 0.001067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 117 finished \tANN training loss 0.001067\n",
      ">> Epoch 118 finished \tANN training loss 0.001066\n",
      ">> Epoch 119 finished \tANN training loss 0.001065\n",
      ">> Epoch 120 finished \tANN training loss 0.001065\n",
      ">> Epoch 121 finished \tANN training loss 0.001064\n",
      ">> Epoch 122 finished \tANN training loss 0.001063\n",
      ">> Epoch 123 finished \tANN training loss 0.001063\n",
      ">> Epoch 124 finished \tANN training loss 0.001062\n",
      ">> Epoch 125 finished \tANN training loss 0.001061\n",
      ">> Epoch 126 finished \tANN training loss 0.001061\n",
      ">> Epoch 127 finished \tANN training loss 0.001060\n",
      ">> Epoch 128 finished \tANN training loss 0.001060\n",
      ">> Epoch 129 finished \tANN training loss 0.001059\n",
      ">> Epoch 130 finished \tANN training loss 0.001058\n",
      ">> Epoch 131 finished \tANN training loss 0.001058\n",
      ">> Epoch 132 finished \tANN training loss 0.001057\n",
      ">> Epoch 133 finished \tANN training loss 0.001057\n",
      ">> Epoch 134 finished \tANN training loss 0.001056\n",
      ">> Epoch 135 finished \tANN training loss 0.001056\n",
      ">> Epoch 136 finished \tANN training loss 0.001055\n",
      ">> Epoch 137 finished \tANN training loss 0.001054\n",
      ">> Epoch 138 finished \tANN training loss 0.001054\n",
      ">> Epoch 139 finished \tANN training loss 0.001053\n",
      ">> Epoch 140 finished \tANN training loss 0.001053\n",
      ">> Epoch 141 finished \tANN training loss 0.001052\n",
      ">> Epoch 142 finished \tANN training loss 0.001052\n",
      ">> Epoch 143 finished \tANN training loss 0.001051\n",
      ">> Epoch 144 finished \tANN training loss 0.001051\n",
      ">> Epoch 145 finished \tANN training loss 0.001050\n",
      ">> Epoch 146 finished \tANN training loss 0.001050\n",
      ">> Epoch 147 finished \tANN training loss 0.001049\n",
      ">> Epoch 148 finished \tANN training loss 0.001049\n",
      ">> Epoch 149 finished \tANN training loss 0.001048\n",
      ">> Epoch 150 finished \tANN training loss 0.001048\n",
      "[END] Fine tuning step\n",
      "############### End Training for GLENMARKEQ #####################\n",
      "############### End Training for WOCKPHARMAEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 3.568917\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 3.522248\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 3.475136\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 3.427484\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 3.379189\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 3.330133\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 3.280214\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 3.229293\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 3.177193\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 3.123772\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 3.068956\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 3.012542\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 2.954395\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 2.894329\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 2.832323\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 2.768182\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 2.701735\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 2.632859\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 2.561563\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 2.487629\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 2.411064\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 2.331938\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 2.250177\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 2.166044\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 2.079604\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 1.990921\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 1.900310\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 1.808243\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 1.715008\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 1.621711\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 1.528053\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 1.434610\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 1.342682\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 1.252516\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 1.164659\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 1.080766\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 1.000801\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.924893\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.853843\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.786852\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.726071\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.670226\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.620182\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.574957\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.535260\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.499527\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.468733\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.441725\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.418415\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.397635\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.379538\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.364191\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.351282\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.339934\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.329927\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.320770\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.313051\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.305771\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.299384\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.293574\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.288191\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.283281\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.278461\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.274088\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.269731\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.265657\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.261827\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.258213\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.254623\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.251186\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.247788\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.244505\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.241308\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.238213\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.235160\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.232162\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.229257\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.226417\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.223623\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.220839\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.218187\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.215437\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.212777\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.210225\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.207696\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.205143\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.202785\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.200360\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.198103\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.195857\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.193572\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.191398\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.189301\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.187094\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.185070\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.183133\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.181144\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.179077\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.177196\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.175380\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.140517\n",
      ">> Epoch 2 finished \tANN training loss 0.122438\n",
      ">> Epoch 3 finished \tANN training loss 0.106834\n",
      ">> Epoch 4 finished \tANN training loss 0.093345\n",
      ">> Epoch 5 finished \tANN training loss 0.081670\n",
      ">> Epoch 6 finished \tANN training loss 0.071576\n",
      ">> Epoch 7 finished \tANN training loss 0.062841\n",
      ">> Epoch 8 finished \tANN training loss 0.055279\n",
      ">> Epoch 9 finished \tANN training loss 0.048736\n",
      ">> Epoch 10 finished \tANN training loss 0.043075\n",
      ">> Epoch 11 finished \tANN training loss 0.038179\n",
      ">> Epoch 12 finished \tANN training loss 0.033943\n",
      ">> Epoch 13 finished \tANN training loss 0.030272\n",
      ">> Epoch 14 finished \tANN training loss 0.027090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 15 finished \tANN training loss 0.024326\n",
      ">> Epoch 16 finished \tANN training loss 0.021923\n",
      ">> Epoch 17 finished \tANN training loss 0.019835\n",
      ">> Epoch 18 finished \tANN training loss 0.018016\n",
      ">> Epoch 19 finished \tANN training loss 0.016432\n",
      ">> Epoch 20 finished \tANN training loss 0.015051\n",
      ">> Epoch 21 finished \tANN training loss 0.013847\n",
      ">> Epoch 22 finished \tANN training loss 0.012797\n",
      ">> Epoch 23 finished \tANN training loss 0.011878\n",
      ">> Epoch 24 finished \tANN training loss 0.011074\n",
      ">> Epoch 25 finished \tANN training loss 0.010369\n",
      ">> Epoch 26 finished \tANN training loss 0.009750\n",
      ">> Epoch 27 finished \tANN training loss 0.009206\n",
      ">> Epoch 28 finished \tANN training loss 0.008728\n",
      ">> Epoch 29 finished \tANN training loss 0.008305\n",
      ">> Epoch 30 finished \tANN training loss 0.007931\n",
      ">> Epoch 31 finished \tANN training loss 0.007600\n",
      ">> Epoch 32 finished \tANN training loss 0.007306\n",
      ">> Epoch 33 finished \tANN training loss 0.007044\n",
      ">> Epoch 34 finished \tANN training loss 0.006810\n",
      ">> Epoch 35 finished \tANN training loss 0.006600\n",
      ">> Epoch 36 finished \tANN training loss 0.006412\n",
      ">> Epoch 37 finished \tANN training loss 0.006243\n",
      ">> Epoch 38 finished \tANN training loss 0.006089\n",
      ">> Epoch 39 finished \tANN training loss 0.005950\n",
      ">> Epoch 40 finished \tANN training loss 0.005822\n",
      ">> Epoch 41 finished \tANN training loss 0.005706\n",
      ">> Epoch 42 finished \tANN training loss 0.005599\n",
      ">> Epoch 43 finished \tANN training loss 0.005501\n",
      ">> Epoch 44 finished \tANN training loss 0.005410\n",
      ">> Epoch 45 finished \tANN training loss 0.005325\n",
      ">> Epoch 46 finished \tANN training loss 0.005246\n",
      ">> Epoch 47 finished \tANN training loss 0.005173\n",
      ">> Epoch 48 finished \tANN training loss 0.005103\n",
      ">> Epoch 49 finished \tANN training loss 0.005038\n",
      ">> Epoch 50 finished \tANN training loss 0.004976\n",
      ">> Epoch 51 finished \tANN training loss 0.004917\n",
      ">> Epoch 52 finished \tANN training loss 0.004861\n",
      ">> Epoch 53 finished \tANN training loss 0.004808\n",
      ">> Epoch 54 finished \tANN training loss 0.004757\n",
      ">> Epoch 55 finished \tANN training loss 0.004708\n",
      ">> Epoch 56 finished \tANN training loss 0.004661\n",
      ">> Epoch 57 finished \tANN training loss 0.004616\n",
      ">> Epoch 58 finished \tANN training loss 0.004572\n",
      ">> Epoch 59 finished \tANN training loss 0.004529\n",
      ">> Epoch 60 finished \tANN training loss 0.004488\n",
      ">> Epoch 61 finished \tANN training loss 0.004448\n",
      ">> Epoch 62 finished \tANN training loss 0.004410\n",
      ">> Epoch 63 finished \tANN training loss 0.004372\n",
      ">> Epoch 64 finished \tANN training loss 0.004335\n",
      ">> Epoch 65 finished \tANN training loss 0.004300\n",
      ">> Epoch 66 finished \tANN training loss 0.004265\n",
      ">> Epoch 67 finished \tANN training loss 0.004231\n",
      ">> Epoch 68 finished \tANN training loss 0.004198\n",
      ">> Epoch 69 finished \tANN training loss 0.004166\n",
      ">> Epoch 70 finished \tANN training loss 0.004134\n",
      ">> Epoch 71 finished \tANN training loss 0.004103\n",
      ">> Epoch 72 finished \tANN training loss 0.004073\n",
      ">> Epoch 73 finished \tANN training loss 0.004043\n",
      ">> Epoch 74 finished \tANN training loss 0.004014\n",
      ">> Epoch 75 finished \tANN training loss 0.003986\n",
      ">> Epoch 76 finished \tANN training loss 0.003958\n",
      ">> Epoch 77 finished \tANN training loss 0.003931\n",
      ">> Epoch 78 finished \tANN training loss 0.003904\n",
      ">> Epoch 79 finished \tANN training loss 0.003878\n",
      ">> Epoch 80 finished \tANN training loss 0.003852\n",
      ">> Epoch 81 finished \tANN training loss 0.003827\n",
      ">> Epoch 82 finished \tANN training loss 0.003802\n",
      ">> Epoch 83 finished \tANN training loss 0.003778\n",
      ">> Epoch 84 finished \tANN training loss 0.003755\n",
      ">> Epoch 85 finished \tANN training loss 0.003731\n",
      ">> Epoch 86 finished \tANN training loss 0.003709\n",
      ">> Epoch 87 finished \tANN training loss 0.003686\n",
      ">> Epoch 88 finished \tANN training loss 0.003664\n",
      ">> Epoch 89 finished \tANN training loss 0.003643\n",
      ">> Epoch 90 finished \tANN training loss 0.003622\n",
      ">> Epoch 91 finished \tANN training loss 0.003601\n",
      ">> Epoch 92 finished \tANN training loss 0.003581\n",
      ">> Epoch 93 finished \tANN training loss 0.003561\n",
      ">> Epoch 94 finished \tANN training loss 0.003542\n",
      ">> Epoch 95 finished \tANN training loss 0.003523\n",
      ">> Epoch 96 finished \tANN training loss 0.003504\n",
      ">> Epoch 97 finished \tANN training loss 0.003485\n",
      ">> Epoch 98 finished \tANN training loss 0.003467\n",
      ">> Epoch 99 finished \tANN training loss 0.003450\n",
      ">> Epoch 100 finished \tANN training loss 0.003432\n",
      ">> Epoch 101 finished \tANN training loss 0.003415\n",
      ">> Epoch 102 finished \tANN training loss 0.003398\n",
      ">> Epoch 103 finished \tANN training loss 0.003382\n",
      ">> Epoch 104 finished \tANN training loss 0.003366\n",
      ">> Epoch 105 finished \tANN training loss 0.003350\n",
      ">> Epoch 106 finished \tANN training loss 0.003334\n",
      ">> Epoch 107 finished \tANN training loss 0.003319\n",
      ">> Epoch 108 finished \tANN training loss 0.003304\n",
      ">> Epoch 109 finished \tANN training loss 0.003289\n",
      ">> Epoch 110 finished \tANN training loss 0.003275\n",
      ">> Epoch 111 finished \tANN training loss 0.003260\n",
      ">> Epoch 112 finished \tANN training loss 0.003246\n",
      ">> Epoch 113 finished \tANN training loss 0.003233\n",
      ">> Epoch 114 finished \tANN training loss 0.003219\n",
      ">> Epoch 115 finished \tANN training loss 0.003206\n",
      ">> Epoch 116 finished \tANN training loss 0.003193\n",
      ">> Epoch 117 finished \tANN training loss 0.003180\n",
      ">> Epoch 118 finished \tANN training loss 0.003167\n",
      ">> Epoch 119 finished \tANN training loss 0.003155\n",
      ">> Epoch 120 finished \tANN training loss 0.003143\n",
      ">> Epoch 121 finished \tANN training loss 0.003131\n",
      ">> Epoch 122 finished \tANN training loss 0.003119\n",
      ">> Epoch 123 finished \tANN training loss 0.003108\n",
      ">> Epoch 124 finished \tANN training loss 0.003097\n",
      ">> Epoch 125 finished \tANN training loss 0.003086\n",
      ">> Epoch 126 finished \tANN training loss 0.003075\n",
      ">> Epoch 127 finished \tANN training loss 0.003064\n",
      ">> Epoch 128 finished \tANN training loss 0.003054\n",
      ">> Epoch 129 finished \tANN training loss 0.003043\n",
      ">> Epoch 130 finished \tANN training loss 0.003033\n",
      ">> Epoch 131 finished \tANN training loss 0.003023\n",
      ">> Epoch 132 finished \tANN training loss 0.003013\n",
      ">> Epoch 133 finished \tANN training loss 0.003004\n",
      ">> Epoch 134 finished \tANN training loss 0.002994\n",
      ">> Epoch 135 finished \tANN training loss 0.002985\n",
      ">> Epoch 136 finished \tANN training loss 0.002976\n",
      ">> Epoch 137 finished \tANN training loss 0.002967\n",
      ">> Epoch 138 finished \tANN training loss 0.002958\n",
      ">> Epoch 139 finished \tANN training loss 0.002949\n",
      ">> Epoch 140 finished \tANN training loss 0.002941\n",
      ">> Epoch 141 finished \tANN training loss 0.002932\n",
      ">> Epoch 142 finished \tANN training loss 0.002924\n",
      ">> Epoch 143 finished \tANN training loss 0.002916\n",
      ">> Epoch 144 finished \tANN training loss 0.002908\n",
      ">> Epoch 145 finished \tANN training loss 0.002900\n",
      ">> Epoch 146 finished \tANN training loss 0.002892\n",
      ">> Epoch 147 finished \tANN training loss 0.002884\n",
      ">> Epoch 148 finished \tANN training loss 0.002877\n",
      ">> Epoch 149 finished \tANN training loss 0.002870\n",
      ">> Epoch 150 finished \tANN training loss 0.002862\n",
      "[END] Fine tuning step\n",
      "############### End Training for WOCKPHARMAEQ #####################\n",
      "############### End Training for PIDILITINDEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 0.309517\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 0.307302\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 0.305137\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 0.303028\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 0.300973\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 0.298967\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 0.297009\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 0.295099\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 0.293241\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 0.291428\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 0.289657\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 0.287932\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 0.286244\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 0.284603\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 0.282995\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 0.281436\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 0.279911\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 0.278421\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 0.276969\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 0.275554\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 0.274182\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 0.272839\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 0.271532\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 0.270255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 25 finished \tRBM Reconstruction error 0.269006\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 0.267791\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 0.266608\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 0.265451\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 0.264327\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 0.263227\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 0.262156\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 0.261109\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.260092\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.259101\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.258131\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.257187\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.256262\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.255361\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.254484\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.253629\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.252793\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.251977\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.251178\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.250402\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.249644\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.248904\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.248177\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.247471\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.246781\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.246106\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.245444\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.244801\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.244170\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.243554\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.242954\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.242364\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.241790\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.241227\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.240679\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.240141\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.239617\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.239102\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.238599\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.238107\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.237624\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.237154\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.236692\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.236237\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.235791\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.235353\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.234927\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.234507\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.234095\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.233692\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.233295\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.232904\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.232525\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.232153\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.231784\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.231420\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.231062\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.230713\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.230368\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.230029\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.229694\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.229370\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.229047\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.228729\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.228412\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.228103\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.227799\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.227500\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.227204\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.226912\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.226625\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.226342\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.226062\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.225787\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.225511\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.225240\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.008263\n",
      ">> Epoch 2 finished \tANN training loss 0.008085\n",
      ">> Epoch 3 finished \tANN training loss 0.007916\n",
      ">> Epoch 4 finished \tANN training loss 0.007755\n",
      ">> Epoch 5 finished \tANN training loss 0.007602\n",
      ">> Epoch 6 finished \tANN training loss 0.007456\n",
      ">> Epoch 7 finished \tANN training loss 0.007317\n",
      ">> Epoch 8 finished \tANN training loss 0.007184\n",
      ">> Epoch 9 finished \tANN training loss 0.007057\n",
      ">> Epoch 10 finished \tANN training loss 0.006936\n",
      ">> Epoch 11 finished \tANN training loss 0.006820\n",
      ">> Epoch 12 finished \tANN training loss 0.006709\n",
      ">> Epoch 13 finished \tANN training loss 0.006603\n",
      ">> Epoch 14 finished \tANN training loss 0.006501\n",
      ">> Epoch 15 finished \tANN training loss 0.006404\n",
      ">> Epoch 16 finished \tANN training loss 0.006310\n",
      ">> Epoch 17 finished \tANN training loss 0.006220\n",
      ">> Epoch 18 finished \tANN training loss 0.006134\n",
      ">> Epoch 19 finished \tANN training loss 0.006051\n",
      ">> Epoch 20 finished \tANN training loss 0.005971\n",
      ">> Epoch 21 finished \tANN training loss 0.005894\n",
      ">> Epoch 22 finished \tANN training loss 0.005820\n",
      ">> Epoch 23 finished \tANN training loss 0.005748\n",
      ">> Epoch 24 finished \tANN training loss 0.005679\n",
      ">> Epoch 25 finished \tANN training loss 0.005612\n",
      ">> Epoch 26 finished \tANN training loss 0.005548\n",
      ">> Epoch 27 finished \tANN training loss 0.005485\n",
      ">> Epoch 28 finished \tANN training loss 0.005425\n",
      ">> Epoch 29 finished \tANN training loss 0.005366\n",
      ">> Epoch 30 finished \tANN training loss 0.005309\n",
      ">> Epoch 31 finished \tANN training loss 0.005254\n",
      ">> Epoch 32 finished \tANN training loss 0.005200\n",
      ">> Epoch 33 finished \tANN training loss 0.005148\n",
      ">> Epoch 34 finished \tANN training loss 0.005097\n",
      ">> Epoch 35 finished \tANN training loss 0.005048\n",
      ">> Epoch 36 finished \tANN training loss 0.004999\n",
      ">> Epoch 37 finished \tANN training loss 0.004952\n",
      ">> Epoch 38 finished \tANN training loss 0.004907\n",
      ">> Epoch 39 finished \tANN training loss 0.004862\n",
      ">> Epoch 40 finished \tANN training loss 0.004818\n",
      ">> Epoch 41 finished \tANN training loss 0.004775\n",
      ">> Epoch 42 finished \tANN training loss 0.004734\n",
      ">> Epoch 43 finished \tANN training loss 0.004693\n",
      ">> Epoch 44 finished \tANN training loss 0.004653\n",
      ">> Epoch 45 finished \tANN training loss 0.004613\n",
      ">> Epoch 46 finished \tANN training loss 0.004575\n",
      ">> Epoch 47 finished \tANN training loss 0.004537\n",
      ">> Epoch 48 finished \tANN training loss 0.004500\n",
      ">> Epoch 49 finished \tANN training loss 0.004463\n",
      ">> Epoch 50 finished \tANN training loss 0.004427\n",
      ">> Epoch 51 finished \tANN training loss 0.004392\n",
      ">> Epoch 52 finished \tANN training loss 0.004357\n",
      ">> Epoch 53 finished \tANN training loss 0.004323\n",
      ">> Epoch 54 finished \tANN training loss 0.004289\n",
      ">> Epoch 55 finished \tANN training loss 0.004256\n",
      ">> Epoch 56 finished \tANN training loss 0.004223\n",
      ">> Epoch 57 finished \tANN training loss 0.004191\n",
      ">> Epoch 58 finished \tANN training loss 0.004159\n",
      ">> Epoch 59 finished \tANN training loss 0.004128\n",
      ">> Epoch 60 finished \tANN training loss 0.004097\n",
      ">> Epoch 61 finished \tANN training loss 0.004066\n",
      ">> Epoch 62 finished \tANN training loss 0.004036\n",
      ">> Epoch 63 finished \tANN training loss 0.004006\n",
      ">> Epoch 64 finished \tANN training loss 0.003977\n",
      ">> Epoch 65 finished \tANN training loss 0.003948\n",
      ">> Epoch 66 finished \tANN training loss 0.003919\n",
      ">> Epoch 67 finished \tANN training loss 0.003891\n",
      ">> Epoch 68 finished \tANN training loss 0.003863\n",
      ">> Epoch 69 finished \tANN training loss 0.003835\n",
      ">> Epoch 70 finished \tANN training loss 0.003808\n",
      ">> Epoch 71 finished \tANN training loss 0.003781\n",
      ">> Epoch 72 finished \tANN training loss 0.003754\n",
      ">> Epoch 73 finished \tANN training loss 0.003728\n",
      ">> Epoch 74 finished \tANN training loss 0.003702\n",
      ">> Epoch 75 finished \tANN training loss 0.003676\n",
      ">> Epoch 76 finished \tANN training loss 0.003650\n",
      ">> Epoch 77 finished \tANN training loss 0.003625\n",
      ">> Epoch 78 finished \tANN training loss 0.003599\n",
      ">> Epoch 79 finished \tANN training loss 0.003575\n",
      ">> Epoch 80 finished \tANN training loss 0.003550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 81 finished \tANN training loss 0.003526\n",
      ">> Epoch 82 finished \tANN training loss 0.003501\n",
      ">> Epoch 83 finished \tANN training loss 0.003477\n",
      ">> Epoch 84 finished \tANN training loss 0.003454\n",
      ">> Epoch 85 finished \tANN training loss 0.003430\n",
      ">> Epoch 86 finished \tANN training loss 0.003407\n",
      ">> Epoch 87 finished \tANN training loss 0.003384\n",
      ">> Epoch 88 finished \tANN training loss 0.003361\n",
      ">> Epoch 89 finished \tANN training loss 0.003338\n",
      ">> Epoch 90 finished \tANN training loss 0.003315\n",
      ">> Epoch 91 finished \tANN training loss 0.003293\n",
      ">> Epoch 92 finished \tANN training loss 0.003271\n",
      ">> Epoch 93 finished \tANN training loss 0.003249\n",
      ">> Epoch 94 finished \tANN training loss 0.003227\n",
      ">> Epoch 95 finished \tANN training loss 0.003205\n",
      ">> Epoch 96 finished \tANN training loss 0.003184\n",
      ">> Epoch 97 finished \tANN training loss 0.003163\n",
      ">> Epoch 98 finished \tANN training loss 0.003142\n",
      ">> Epoch 99 finished \tANN training loss 0.003121\n",
      ">> Epoch 100 finished \tANN training loss 0.003100\n",
      ">> Epoch 101 finished \tANN training loss 0.003079\n",
      ">> Epoch 102 finished \tANN training loss 0.003059\n",
      ">> Epoch 103 finished \tANN training loss 0.003039\n",
      ">> Epoch 104 finished \tANN training loss 0.003019\n",
      ">> Epoch 105 finished \tANN training loss 0.002999\n",
      ">> Epoch 106 finished \tANN training loss 0.002979\n",
      ">> Epoch 107 finished \tANN training loss 0.002959\n",
      ">> Epoch 108 finished \tANN training loss 0.002940\n",
      ">> Epoch 109 finished \tANN training loss 0.002920\n",
      ">> Epoch 110 finished \tANN training loss 0.002901\n",
      ">> Epoch 111 finished \tANN training loss 0.002882\n",
      ">> Epoch 112 finished \tANN training loss 0.002863\n",
      ">> Epoch 113 finished \tANN training loss 0.002844\n",
      ">> Epoch 114 finished \tANN training loss 0.002825\n",
      ">> Epoch 115 finished \tANN training loss 0.002807\n",
      ">> Epoch 116 finished \tANN training loss 0.002789\n",
      ">> Epoch 117 finished \tANN training loss 0.002770\n",
      ">> Epoch 118 finished \tANN training loss 0.002752\n",
      ">> Epoch 119 finished \tANN training loss 0.002734\n",
      ">> Epoch 120 finished \tANN training loss 0.002716\n",
      ">> Epoch 121 finished \tANN training loss 0.002699\n",
      ">> Epoch 122 finished \tANN training loss 0.002681\n",
      ">> Epoch 123 finished \tANN training loss 0.002663\n",
      ">> Epoch 124 finished \tANN training loss 0.002646\n",
      ">> Epoch 125 finished \tANN training loss 0.002629\n",
      ">> Epoch 126 finished \tANN training loss 0.002612\n",
      ">> Epoch 127 finished \tANN training loss 0.002595\n",
      ">> Epoch 128 finished \tANN training loss 0.002578\n",
      ">> Epoch 129 finished \tANN training loss 0.002561\n",
      ">> Epoch 130 finished \tANN training loss 0.002545\n",
      ">> Epoch 131 finished \tANN training loss 0.002528\n",
      ">> Epoch 132 finished \tANN training loss 0.002512\n",
      ">> Epoch 133 finished \tANN training loss 0.002495\n",
      ">> Epoch 134 finished \tANN training loss 0.002479\n",
      ">> Epoch 135 finished \tANN training loss 0.002463\n",
      ">> Epoch 136 finished \tANN training loss 0.002447\n",
      ">> Epoch 137 finished \tANN training loss 0.002431\n",
      ">> Epoch 138 finished \tANN training loss 0.002416\n",
      ">> Epoch 139 finished \tANN training loss 0.002400\n",
      ">> Epoch 140 finished \tANN training loss 0.002385\n",
      ">> Epoch 141 finished \tANN training loss 0.002369\n",
      ">> Epoch 142 finished \tANN training loss 0.002354\n",
      ">> Epoch 143 finished \tANN training loss 0.002339\n",
      ">> Epoch 144 finished \tANN training loss 0.002324\n",
      ">> Epoch 145 finished \tANN training loss 0.002309\n",
      ">> Epoch 146 finished \tANN training loss 0.002294\n",
      ">> Epoch 147 finished \tANN training loss 0.002279\n",
      ">> Epoch 148 finished \tANN training loss 0.002265\n",
      ">> Epoch 149 finished \tANN training loss 0.002250\n",
      ">> Epoch 150 finished \tANN training loss 0.002236\n",
      "[END] Fine tuning step\n",
      "############### End Training for PIDILITINDEQ #####################\n",
      "############### End Training for ICICIPRULIEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 9.172992\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 9.170242\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 9.167482\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 9.164719\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 9.161962\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 9.159200\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 9.156428\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 9.153674\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 9.150907\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 9.148146\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 9.145374\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 9.142598\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 9.139830\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 9.137052\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 9.134281\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 9.131507\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 9.128731\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 9.125959\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 9.123179\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 9.120398\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 9.117623\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 9.114851\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 9.112071\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 9.109293\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 9.106508\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 9.103734\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 9.100955\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 9.098173\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 9.095382\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 9.092589\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 9.089809\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 9.087007\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 9.084211\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 9.081417\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 9.078617\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 9.075825\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 9.073031\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 9.070231\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 9.067429\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 9.064625\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 9.061831\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 9.059035\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 9.056245\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 9.053442\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 9.050639\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 9.047826\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 9.045028\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 9.042215\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 9.039408\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 9.036591\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 9.033789\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 9.030973\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 9.028154\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 9.025334\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 9.022518\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 9.019706\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 9.016892\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 9.014084\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 9.011261\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 9.008440\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 9.005614\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 9.002789\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 8.999972\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 8.997149\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 8.994322\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 8.991493\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 8.988667\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 8.985837\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 8.983019\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 8.980190\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 8.977356\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 8.974528\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 8.971703\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 8.968867\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 8.966035\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 8.963194\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 8.960355\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 8.957519\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 8.954682\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 8.951837\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 8.949000\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 8.946156\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 8.943313\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 8.940473\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 8.937618\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 8.934764\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 8.931912\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 8.929061\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 8.926205\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 8.923355\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 8.920503\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 8.917648\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 8.914778\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 8.911911\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 8.909048\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 8.906182\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 8.903321\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 8.900452\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 8.897584\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 8.894718\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.383959\n",
      ">> Epoch 2 finished \tANN training loss 0.383452\n",
      ">> Epoch 3 finished \tANN training loss 0.382937\n",
      ">> Epoch 4 finished \tANN training loss 0.382426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 5 finished \tANN training loss 0.381929\n",
      ">> Epoch 6 finished \tANN training loss 0.381418\n",
      ">> Epoch 7 finished \tANN training loss 0.380908\n",
      ">> Epoch 8 finished \tANN training loss 0.380408\n",
      ">> Epoch 9 finished \tANN training loss 0.379913\n",
      ">> Epoch 10 finished \tANN training loss 0.379407\n",
      ">> Epoch 11 finished \tANN training loss 0.378915\n",
      ">> Epoch 12 finished \tANN training loss 0.378396\n",
      ">> Epoch 13 finished \tANN training loss 0.377895\n",
      ">> Epoch 14 finished \tANN training loss 0.377389\n",
      ">> Epoch 15 finished \tANN training loss 0.376896\n",
      ">> Epoch 16 finished \tANN training loss 0.376394\n",
      ">> Epoch 17 finished \tANN training loss 0.375897\n",
      ">> Epoch 18 finished \tANN training loss 0.375410\n",
      ">> Epoch 19 finished \tANN training loss 0.374901\n",
      ">> Epoch 20 finished \tANN training loss 0.374418\n",
      ">> Epoch 21 finished \tANN training loss 0.373927\n",
      ">> Epoch 22 finished \tANN training loss 0.373438\n",
      ">> Epoch 23 finished \tANN training loss 0.372926\n",
      ">> Epoch 24 finished \tANN training loss 0.372435\n",
      ">> Epoch 25 finished \tANN training loss 0.371959\n",
      ">> Epoch 26 finished \tANN training loss 0.371453\n",
      ">> Epoch 27 finished \tANN training loss 0.370976\n",
      ">> Epoch 28 finished \tANN training loss 0.370487\n",
      ">> Epoch 29 finished \tANN training loss 0.369996\n",
      ">> Epoch 30 finished \tANN training loss 0.369497\n",
      ">> Epoch 31 finished \tANN training loss 0.369010\n",
      ">> Epoch 32 finished \tANN training loss 0.368525\n",
      ">> Epoch 33 finished \tANN training loss 0.368046\n",
      ">> Epoch 34 finished \tANN training loss 0.367545\n",
      ">> Epoch 35 finished \tANN training loss 0.367076\n",
      ">> Epoch 36 finished \tANN training loss 0.366584\n",
      ">> Epoch 37 finished \tANN training loss 0.366110\n",
      ">> Epoch 38 finished \tANN training loss 0.365627\n",
      ">> Epoch 39 finished \tANN training loss 0.365138\n",
      ">> Epoch 40 finished \tANN training loss 0.364658\n",
      ">> Epoch 41 finished \tANN training loss 0.364166\n",
      ">> Epoch 42 finished \tANN training loss 0.363690\n",
      ">> Epoch 43 finished \tANN training loss 0.363223\n",
      ">> Epoch 44 finished \tANN training loss 0.362737\n",
      ">> Epoch 45 finished \tANN training loss 0.362251\n",
      ">> Epoch 46 finished \tANN training loss 0.361784\n",
      ">> Epoch 47 finished \tANN training loss 0.361283\n",
      ">> Epoch 48 finished \tANN training loss 0.360803\n",
      ">> Epoch 49 finished \tANN training loss 0.360338\n",
      ">> Epoch 50 finished \tANN training loss 0.359847\n",
      ">> Epoch 51 finished \tANN training loss 0.359364\n",
      ">> Epoch 52 finished \tANN training loss 0.358900\n",
      ">> Epoch 53 finished \tANN training loss 0.358425\n",
      ">> Epoch 54 finished \tANN training loss 0.357944\n",
      ">> Epoch 55 finished \tANN training loss 0.357459\n",
      ">> Epoch 56 finished \tANN training loss 0.356983\n",
      ">> Epoch 57 finished \tANN training loss 0.356509\n",
      ">> Epoch 58 finished \tANN training loss 0.356030\n",
      ">> Epoch 59 finished \tANN training loss 0.355557\n",
      ">> Epoch 60 finished \tANN training loss 0.355090\n",
      ">> Epoch 61 finished \tANN training loss 0.354608\n",
      ">> Epoch 62 finished \tANN training loss 0.354141\n",
      ">> Epoch 63 finished \tANN training loss 0.353681\n",
      ">> Epoch 64 finished \tANN training loss 0.353196\n",
      ">> Epoch 65 finished \tANN training loss 0.352716\n",
      ">> Epoch 66 finished \tANN training loss 0.352271\n",
      ">> Epoch 67 finished \tANN training loss 0.351794\n",
      ">> Epoch 68 finished \tANN training loss 0.351332\n",
      ">> Epoch 69 finished \tANN training loss 0.350848\n",
      ">> Epoch 70 finished \tANN training loss 0.350375\n",
      ">> Epoch 71 finished \tANN training loss 0.349909\n",
      ">> Epoch 72 finished \tANN training loss 0.349441\n",
      ">> Epoch 73 finished \tANN training loss 0.348979\n",
      ">> Epoch 74 finished \tANN training loss 0.348512\n",
      ">> Epoch 75 finished \tANN training loss 0.348044\n",
      ">> Epoch 76 finished \tANN training loss 0.347582\n",
      ">> Epoch 77 finished \tANN training loss 0.347117\n",
      ">> Epoch 78 finished \tANN training loss 0.346657\n",
      ">> Epoch 79 finished \tANN training loss 0.346192\n",
      ">> Epoch 80 finished \tANN training loss 0.345722\n",
      ">> Epoch 81 finished \tANN training loss 0.345258\n",
      ">> Epoch 82 finished \tANN training loss 0.344808\n",
      ">> Epoch 83 finished \tANN training loss 0.344343\n",
      ">> Epoch 84 finished \tANN training loss 0.343892\n",
      ">> Epoch 85 finished \tANN training loss 0.343432\n",
      ">> Epoch 86 finished \tANN training loss 0.342979\n",
      ">> Epoch 87 finished \tANN training loss 0.342520\n",
      ">> Epoch 88 finished \tANN training loss 0.342054\n",
      ">> Epoch 89 finished \tANN training loss 0.341618\n",
      ">> Epoch 90 finished \tANN training loss 0.341157\n",
      ">> Epoch 91 finished \tANN training loss 0.340698\n",
      ">> Epoch 92 finished \tANN training loss 0.340257\n",
      ">> Epoch 93 finished \tANN training loss 0.339796\n",
      ">> Epoch 94 finished \tANN training loss 0.339359\n",
      ">> Epoch 95 finished \tANN training loss 0.338906\n",
      ">> Epoch 96 finished \tANN training loss 0.338452\n",
      ">> Epoch 97 finished \tANN training loss 0.338023\n",
      ">> Epoch 98 finished \tANN training loss 0.337558\n",
      ">> Epoch 99 finished \tANN training loss 0.337122\n",
      ">> Epoch 100 finished \tANN training loss 0.336665\n",
      ">> Epoch 101 finished \tANN training loss 0.336227\n",
      ">> Epoch 102 finished \tANN training loss 0.335766\n",
      ">> Epoch 103 finished \tANN training loss 0.335320\n",
      ">> Epoch 104 finished \tANN training loss 0.334888\n",
      ">> Epoch 105 finished \tANN training loss 0.334445\n",
      ">> Epoch 106 finished \tANN training loss 0.334016\n",
      ">> Epoch 107 finished \tANN training loss 0.333562\n",
      ">> Epoch 108 finished \tANN training loss 0.333115\n",
      ">> Epoch 109 finished \tANN training loss 0.332672\n",
      ">> Epoch 110 finished \tANN training loss 0.332232\n",
      ">> Epoch 111 finished \tANN training loss 0.331808\n",
      ">> Epoch 112 finished \tANN training loss 0.331348\n",
      ">> Epoch 113 finished \tANN training loss 0.330907\n",
      ">> Epoch 114 finished \tANN training loss 0.330488\n",
      ">> Epoch 115 finished \tANN training loss 0.330035\n",
      ">> Epoch 116 finished \tANN training loss 0.329607\n",
      ">> Epoch 117 finished \tANN training loss 0.329159\n",
      ">> Epoch 118 finished \tANN training loss 0.328731\n",
      ">> Epoch 119 finished \tANN training loss 0.328292\n",
      ">> Epoch 120 finished \tANN training loss 0.327856\n",
      ">> Epoch 121 finished \tANN training loss 0.327436\n",
      ">> Epoch 122 finished \tANN training loss 0.326984\n",
      ">> Epoch 123 finished \tANN training loss 0.326555\n",
      ">> Epoch 124 finished \tANN training loss 0.326131\n",
      ">> Epoch 125 finished \tANN training loss 0.325696\n",
      ">> Epoch 126 finished \tANN training loss 0.325277\n",
      ">> Epoch 127 finished \tANN training loss 0.324841\n",
      ">> Epoch 128 finished \tANN training loss 0.324422\n",
      ">> Epoch 129 finished \tANN training loss 0.323984\n",
      ">> Epoch 130 finished \tANN training loss 0.323566\n",
      ">> Epoch 131 finished \tANN training loss 0.323134\n",
      ">> Epoch 132 finished \tANN training loss 0.322704\n",
      ">> Epoch 133 finished \tANN training loss 0.322268\n",
      ">> Epoch 134 finished \tANN training loss 0.321852\n",
      ">> Epoch 135 finished \tANN training loss 0.321443\n",
      ">> Epoch 136 finished \tANN training loss 0.320998\n",
      ">> Epoch 137 finished \tANN training loss 0.320576\n",
      ">> Epoch 138 finished \tANN training loss 0.320166\n",
      ">> Epoch 139 finished \tANN training loss 0.319726\n",
      ">> Epoch 140 finished \tANN training loss 0.319310\n",
      ">> Epoch 141 finished \tANN training loss 0.318895\n",
      ">> Epoch 142 finished \tANN training loss 0.318468\n",
      ">> Epoch 143 finished \tANN training loss 0.318054\n",
      ">> Epoch 144 finished \tANN training loss 0.317634\n",
      ">> Epoch 145 finished \tANN training loss 0.317213\n",
      ">> Epoch 146 finished \tANN training loss 0.316791\n",
      ">> Epoch 147 finished \tANN training loss 0.316382\n",
      ">> Epoch 148 finished \tANN training loss 0.315967\n",
      ">> Epoch 149 finished \tANN training loss 0.315536\n",
      ">> Epoch 150 finished \tANN training loss 0.315121\n",
      "[END] Fine tuning step\n",
      "############### End Training for ICICIPRULIEQ #####################\n",
      "############### End Training for COALINDIAEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 15.777640\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 15.520940\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 15.244548\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 14.945170\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 14.618902\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 14.261162\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 13.866721\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 13.430049\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 12.945701\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 12.406788\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 11.808279\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 11.145329\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 10.414869\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 9.616887\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 8.753271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 16 finished \tRBM Reconstruction error 7.832778\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 6.872366\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 5.896216\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 4.932474\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 4.018663\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 3.181463\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 2.448957\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 1.846974\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 1.368481\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 1.010461\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 0.758540\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 0.593439\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 0.491267\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 0.434416\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 0.407065\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 0.397593\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 0.397875\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.403459\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.410336\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.417061\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.425433\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.433229\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.436797\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.440056\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.444228\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.447605\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.447442\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.447995\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.448452\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.446546\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.447675\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.450382\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.452077\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.453558\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.452243\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.454364\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.454830\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.453965\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.454773\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.454494\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.451814\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.453155\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.455312\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.456984\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.455192\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.454201\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.455194\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.453720\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.452695\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.452709\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.453851\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.452766\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.451369\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.450500\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.450016\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.453270\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.452267\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.454948\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.454966\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.456212\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.455782\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.456902\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.459497\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.456813\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.454744\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.453147\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.455564\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.455930\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.456509\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.456861\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.455196\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.454454\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.455769\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.452791\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.448397\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.445685\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.448239\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.449007\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.451326\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.450108\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.451388\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.452895\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.449187\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.450633\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.452627\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.011889\n",
      ">> Epoch 2 finished \tANN training loss 0.011563\n",
      ">> Epoch 3 finished \tANN training loss 0.011317\n",
      ">> Epoch 4 finished \tANN training loss 0.011130\n",
      ">> Epoch 5 finished \tANN training loss 0.010989\n",
      ">> Epoch 6 finished \tANN training loss 0.010881\n",
      ">> Epoch 7 finished \tANN training loss 0.010798\n",
      ">> Epoch 8 finished \tANN training loss 0.010734\n",
      ">> Epoch 9 finished \tANN training loss 0.010684\n",
      ">> Epoch 10 finished \tANN training loss 0.010646\n",
      ">> Epoch 11 finished \tANN training loss 0.010614\n",
      ">> Epoch 12 finished \tANN training loss 0.010588\n",
      ">> Epoch 13 finished \tANN training loss 0.010567\n",
      ">> Epoch 14 finished \tANN training loss 0.010549\n",
      ">> Epoch 15 finished \tANN training loss 0.010534\n",
      ">> Epoch 16 finished \tANN training loss 0.010520\n",
      ">> Epoch 17 finished \tANN training loss 0.010508\n",
      ">> Epoch 18 finished \tANN training loss 0.010496\n",
      ">> Epoch 19 finished \tANN training loss 0.010485\n",
      ">> Epoch 20 finished \tANN training loss 0.010475\n",
      ">> Epoch 21 finished \tANN training loss 0.010465\n",
      ">> Epoch 22 finished \tANN training loss 0.010456\n",
      ">> Epoch 23 finished \tANN training loss 0.010448\n",
      ">> Epoch 24 finished \tANN training loss 0.010438\n",
      ">> Epoch 25 finished \tANN training loss 0.010430\n",
      ">> Epoch 26 finished \tANN training loss 0.010421\n",
      ">> Epoch 27 finished \tANN training loss 0.010413\n",
      ">> Epoch 28 finished \tANN training loss 0.010404\n",
      ">> Epoch 29 finished \tANN training loss 0.010396\n",
      ">> Epoch 30 finished \tANN training loss 0.010387\n",
      ">> Epoch 31 finished \tANN training loss 0.010379\n",
      ">> Epoch 32 finished \tANN training loss 0.010371\n",
      ">> Epoch 33 finished \tANN training loss 0.010363\n",
      ">> Epoch 34 finished \tANN training loss 0.010355\n",
      ">> Epoch 35 finished \tANN training loss 0.010347\n",
      ">> Epoch 36 finished \tANN training loss 0.010338\n",
      ">> Epoch 37 finished \tANN training loss 0.010330\n",
      ">> Epoch 38 finished \tANN training loss 0.010322\n",
      ">> Epoch 39 finished \tANN training loss 0.010314\n",
      ">> Epoch 40 finished \tANN training loss 0.010306\n",
      ">> Epoch 41 finished \tANN training loss 0.010298\n",
      ">> Epoch 42 finished \tANN training loss 0.010289\n",
      ">> Epoch 43 finished \tANN training loss 0.010281\n",
      ">> Epoch 44 finished \tANN training loss 0.010273\n",
      ">> Epoch 45 finished \tANN training loss 0.010265\n",
      ">> Epoch 46 finished \tANN training loss 0.010257\n",
      ">> Epoch 47 finished \tANN training loss 0.010249\n",
      ">> Epoch 48 finished \tANN training loss 0.010241\n",
      ">> Epoch 49 finished \tANN training loss 0.010233\n",
      ">> Epoch 50 finished \tANN training loss 0.010225\n",
      ">> Epoch 51 finished \tANN training loss 0.010217\n",
      ">> Epoch 52 finished \tANN training loss 0.010209\n",
      ">> Epoch 53 finished \tANN training loss 0.010201\n",
      ">> Epoch 54 finished \tANN training loss 0.010193\n",
      ">> Epoch 55 finished \tANN training loss 0.010185\n",
      ">> Epoch 56 finished \tANN training loss 0.010177\n",
      ">> Epoch 57 finished \tANN training loss 0.010169\n",
      ">> Epoch 58 finished \tANN training loss 0.010161\n",
      ">> Epoch 59 finished \tANN training loss 0.010154\n",
      ">> Epoch 60 finished \tANN training loss 0.010146\n",
      ">> Epoch 61 finished \tANN training loss 0.010137\n",
      ">> Epoch 62 finished \tANN training loss 0.010130\n",
      ">> Epoch 63 finished \tANN training loss 0.010122\n",
      ">> Epoch 64 finished \tANN training loss 0.010113\n",
      ">> Epoch 65 finished \tANN training loss 0.010106\n",
      ">> Epoch 66 finished \tANN training loss 0.010098\n",
      ">> Epoch 67 finished \tANN training loss 0.010090\n",
      ">> Epoch 68 finished \tANN training loss 0.010082\n",
      ">> Epoch 69 finished \tANN training loss 0.010075\n",
      ">> Epoch 70 finished \tANN training loss 0.010066\n",
      ">> Epoch 71 finished \tANN training loss 0.010059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 72 finished \tANN training loss 0.010051\n",
      ">> Epoch 73 finished \tANN training loss 0.010043\n",
      ">> Epoch 74 finished \tANN training loss 0.010035\n",
      ">> Epoch 75 finished \tANN training loss 0.010027\n",
      ">> Epoch 76 finished \tANN training loss 0.010020\n",
      ">> Epoch 77 finished \tANN training loss 0.010012\n",
      ">> Epoch 78 finished \tANN training loss 0.010004\n",
      ">> Epoch 79 finished \tANN training loss 0.009996\n",
      ">> Epoch 80 finished \tANN training loss 0.009988\n",
      ">> Epoch 81 finished \tANN training loss 0.009980\n",
      ">> Epoch 82 finished \tANN training loss 0.009973\n",
      ">> Epoch 83 finished \tANN training loss 0.009965\n",
      ">> Epoch 84 finished \tANN training loss 0.009957\n",
      ">> Epoch 85 finished \tANN training loss 0.009950\n",
      ">> Epoch 86 finished \tANN training loss 0.009942\n",
      ">> Epoch 87 finished \tANN training loss 0.009934\n",
      ">> Epoch 88 finished \tANN training loss 0.009927\n",
      ">> Epoch 89 finished \tANN training loss 0.009919\n",
      ">> Epoch 90 finished \tANN training loss 0.009911\n",
      ">> Epoch 91 finished \tANN training loss 0.009904\n",
      ">> Epoch 92 finished \tANN training loss 0.009896\n",
      ">> Epoch 93 finished \tANN training loss 0.009889\n",
      ">> Epoch 94 finished \tANN training loss 0.009881\n",
      ">> Epoch 95 finished \tANN training loss 0.009873\n",
      ">> Epoch 96 finished \tANN training loss 0.009866\n",
      ">> Epoch 97 finished \tANN training loss 0.009859\n",
      ">> Epoch 98 finished \tANN training loss 0.009851\n",
      ">> Epoch 99 finished \tANN training loss 0.009843\n",
      ">> Epoch 100 finished \tANN training loss 0.009836\n",
      ">> Epoch 101 finished \tANN training loss 0.009828\n",
      ">> Epoch 102 finished \tANN training loss 0.009820\n",
      ">> Epoch 103 finished \tANN training loss 0.009813\n",
      ">> Epoch 104 finished \tANN training loss 0.009806\n",
      ">> Epoch 105 finished \tANN training loss 0.009798\n",
      ">> Epoch 106 finished \tANN training loss 0.009791\n",
      ">> Epoch 107 finished \tANN training loss 0.009783\n",
      ">> Epoch 108 finished \tANN training loss 0.009776\n",
      ">> Epoch 109 finished \tANN training loss 0.009768\n",
      ">> Epoch 110 finished \tANN training loss 0.009761\n",
      ">> Epoch 111 finished \tANN training loss 0.009754\n",
      ">> Epoch 112 finished \tANN training loss 0.009746\n",
      ">> Epoch 113 finished \tANN training loss 0.009739\n",
      ">> Epoch 114 finished \tANN training loss 0.009731\n",
      ">> Epoch 115 finished \tANN training loss 0.009725\n",
      ">> Epoch 116 finished \tANN training loss 0.009717\n",
      ">> Epoch 117 finished \tANN training loss 0.009709\n",
      ">> Epoch 118 finished \tANN training loss 0.009702\n",
      ">> Epoch 119 finished \tANN training loss 0.009695\n",
      ">> Epoch 120 finished \tANN training loss 0.009688\n",
      ">> Epoch 121 finished \tANN training loss 0.009680\n",
      ">> Epoch 122 finished \tANN training loss 0.009673\n",
      ">> Epoch 123 finished \tANN training loss 0.009666\n",
      ">> Epoch 124 finished \tANN training loss 0.009659\n",
      ">> Epoch 125 finished \tANN training loss 0.009651\n",
      ">> Epoch 126 finished \tANN training loss 0.009644\n",
      ">> Epoch 127 finished \tANN training loss 0.009637\n",
      ">> Epoch 128 finished \tANN training loss 0.009630\n",
      ">> Epoch 129 finished \tANN training loss 0.009622\n",
      ">> Epoch 130 finished \tANN training loss 0.009616\n",
      ">> Epoch 131 finished \tANN training loss 0.009608\n",
      ">> Epoch 132 finished \tANN training loss 0.009601\n",
      ">> Epoch 133 finished \tANN training loss 0.009594\n",
      ">> Epoch 134 finished \tANN training loss 0.009587\n",
      ">> Epoch 135 finished \tANN training loss 0.009580\n",
      ">> Epoch 136 finished \tANN training loss 0.009573\n",
      ">> Epoch 137 finished \tANN training loss 0.009566\n",
      ">> Epoch 138 finished \tANN training loss 0.009559\n",
      ">> Epoch 139 finished \tANN training loss 0.009552\n",
      ">> Epoch 140 finished \tANN training loss 0.009545\n",
      ">> Epoch 141 finished \tANN training loss 0.009538\n",
      ">> Epoch 142 finished \tANN training loss 0.009531\n",
      ">> Epoch 143 finished \tANN training loss 0.009524\n",
      ">> Epoch 144 finished \tANN training loss 0.009517\n",
      ">> Epoch 145 finished \tANN training loss 0.009510\n",
      ">> Epoch 146 finished \tANN training loss 0.009503\n",
      ">> Epoch 147 finished \tANN training loss 0.009496\n",
      ">> Epoch 148 finished \tANN training loss 0.009489\n",
      ">> Epoch 149 finished \tANN training loss 0.009482\n",
      ">> Epoch 150 finished \tANN training loss 0.009475\n",
      "[END] Fine tuning step\n",
      "############### End Training for COALINDIAEQ #####################\n",
      "############### End Training for INDIGOEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 5.574373\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 5.572566\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 5.570761\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 5.568951\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 5.567135\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 5.565330\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 5.563519\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 5.561705\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 5.559899\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 5.558087\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 5.556276\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 5.554466\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 5.552663\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 5.550854\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 5.549045\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 5.547239\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 5.545428\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 5.543617\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 5.541809\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 5.539997\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 5.538191\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 5.536382\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 5.534572\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 5.532762\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 5.530952\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 5.529141\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 5.527329\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 5.525513\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 5.523703\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 5.521891\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 5.520070\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 5.518255\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 5.516438\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 5.514626\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 5.512809\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 5.510996\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 5.509186\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 5.507376\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 5.505567\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 5.503751\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 5.501939\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 5.500124\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 5.498315\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 5.496496\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 5.494684\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 5.492867\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 5.491053\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 5.489239\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 5.487423\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 5.485606\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 5.483790\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 5.481978\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 5.480168\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 5.478350\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 5.476540\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 5.474724\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 5.472904\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 5.471097\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 5.469287\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 5.467475\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 5.465663\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 5.463849\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 5.462028\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 5.460215\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 5.458396\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 5.456575\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 5.454763\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 5.452945\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 5.451122\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 5.449302\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 5.447482\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 5.445663\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 5.443846\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 5.442021\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 5.440203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 76 finished \tRBM Reconstruction error 5.438382\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 5.436566\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 5.434745\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 5.432932\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 5.431110\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 5.429291\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 5.427466\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 5.425647\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 5.423828\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 5.422002\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 5.420186\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 5.418362\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 5.416543\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 5.414731\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 5.412910\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 5.411083\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 5.409262\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 5.407434\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 5.405605\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 5.403783\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 5.401956\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 5.400126\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 5.398311\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 5.396489\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 5.394662\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.259424\n",
      ">> Epoch 2 finished \tANN training loss 0.259061\n",
      ">> Epoch 3 finished \tANN training loss 0.258702\n",
      ">> Epoch 4 finished \tANN training loss 0.258342\n",
      ">> Epoch 5 finished \tANN training loss 0.257973\n",
      ">> Epoch 6 finished \tANN training loss 0.257618\n",
      ">> Epoch 7 finished \tANN training loss 0.257261\n",
      ">> Epoch 8 finished \tANN training loss 0.256910\n",
      ">> Epoch 9 finished \tANN training loss 0.256550\n",
      ">> Epoch 10 finished \tANN training loss 0.256193\n",
      ">> Epoch 11 finished \tANN training loss 0.255832\n",
      ">> Epoch 12 finished \tANN training loss 0.255478\n",
      ">> Epoch 13 finished \tANN training loss 0.255125\n",
      ">> Epoch 14 finished \tANN training loss 0.254769\n",
      ">> Epoch 15 finished \tANN training loss 0.254409\n",
      ">> Epoch 16 finished \tANN training loss 0.254061\n",
      ">> Epoch 17 finished \tANN training loss 0.253707\n",
      ">> Epoch 18 finished \tANN training loss 0.253348\n",
      ">> Epoch 19 finished \tANN training loss 0.252998\n",
      ">> Epoch 20 finished \tANN training loss 0.252643\n",
      ">> Epoch 21 finished \tANN training loss 0.252299\n",
      ">> Epoch 22 finished \tANN training loss 0.251940\n",
      ">> Epoch 23 finished \tANN training loss 0.251589\n",
      ">> Epoch 24 finished \tANN training loss 0.251244\n",
      ">> Epoch 25 finished \tANN training loss 0.250894\n",
      ">> Epoch 26 finished \tANN training loss 0.250550\n",
      ">> Epoch 27 finished \tANN training loss 0.250203\n",
      ">> Epoch 28 finished \tANN training loss 0.249855\n",
      ">> Epoch 29 finished \tANN training loss 0.249517\n",
      ">> Epoch 30 finished \tANN training loss 0.249166\n",
      ">> Epoch 31 finished \tANN training loss 0.248820\n",
      ">> Epoch 32 finished \tANN training loss 0.248476\n",
      ">> Epoch 33 finished \tANN training loss 0.248130\n",
      ">> Epoch 34 finished \tANN training loss 0.247780\n",
      ">> Epoch 35 finished \tANN training loss 0.247440\n",
      ">> Epoch 36 finished \tANN training loss 0.247096\n",
      ">> Epoch 37 finished \tANN training loss 0.246757\n",
      ">> Epoch 38 finished \tANN training loss 0.246413\n",
      ">> Epoch 39 finished \tANN training loss 0.246077\n",
      ">> Epoch 40 finished \tANN training loss 0.245742\n",
      ">> Epoch 41 finished \tANN training loss 0.245395\n",
      ">> Epoch 42 finished \tANN training loss 0.245060\n",
      ">> Epoch 43 finished \tANN training loss 0.244718\n",
      ">> Epoch 44 finished \tANN training loss 0.244382\n",
      ">> Epoch 45 finished \tANN training loss 0.244044\n",
      ">> Epoch 46 finished \tANN training loss 0.243709\n",
      ">> Epoch 47 finished \tANN training loss 0.243369\n",
      ">> Epoch 48 finished \tANN training loss 0.243029\n",
      ">> Epoch 49 finished \tANN training loss 0.242688\n",
      ">> Epoch 50 finished \tANN training loss 0.242366\n",
      ">> Epoch 51 finished \tANN training loss 0.242018\n",
      ">> Epoch 52 finished \tANN training loss 0.241684\n",
      ">> Epoch 53 finished \tANN training loss 0.241355\n",
      ">> Epoch 54 finished \tANN training loss 0.241018\n",
      ">> Epoch 55 finished \tANN training loss 0.240687\n",
      ">> Epoch 56 finished \tANN training loss 0.240349\n",
      ">> Epoch 57 finished \tANN training loss 0.240019\n",
      ">> Epoch 58 finished \tANN training loss 0.239689\n",
      ">> Epoch 59 finished \tANN training loss 0.239360\n",
      ">> Epoch 60 finished \tANN training loss 0.239028\n",
      ">> Epoch 61 finished \tANN training loss 0.238696\n",
      ">> Epoch 62 finished \tANN training loss 0.238372\n",
      ">> Epoch 63 finished \tANN training loss 0.238040\n",
      ">> Epoch 64 finished \tANN training loss 0.237711\n",
      ">> Epoch 65 finished \tANN training loss 0.237386\n",
      ">> Epoch 66 finished \tANN training loss 0.237057\n",
      ">> Epoch 67 finished \tANN training loss 0.236737\n",
      ">> Epoch 68 finished \tANN training loss 0.236404\n",
      ">> Epoch 69 finished \tANN training loss 0.236084\n",
      ">> Epoch 70 finished \tANN training loss 0.235760\n",
      ">> Epoch 71 finished \tANN training loss 0.235438\n",
      ">> Epoch 72 finished \tANN training loss 0.235114\n",
      ">> Epoch 73 finished \tANN training loss 0.234789\n",
      ">> Epoch 74 finished \tANN training loss 0.234474\n",
      ">> Epoch 75 finished \tANN training loss 0.234149\n",
      ">> Epoch 76 finished \tANN training loss 0.233822\n",
      ">> Epoch 77 finished \tANN training loss 0.233507\n",
      ">> Epoch 78 finished \tANN training loss 0.233191\n",
      ">> Epoch 79 finished \tANN training loss 0.232866\n",
      ">> Epoch 80 finished \tANN training loss 0.232549\n",
      ">> Epoch 81 finished \tANN training loss 0.232228\n",
      ">> Epoch 82 finished \tANN training loss 0.231914\n",
      ">> Epoch 83 finished \tANN training loss 0.231594\n",
      ">> Epoch 84 finished \tANN training loss 0.231271\n",
      ">> Epoch 85 finished \tANN training loss 0.230955\n",
      ">> Epoch 86 finished \tANN training loss 0.230642\n",
      ">> Epoch 87 finished \tANN training loss 0.230323\n",
      ">> Epoch 88 finished \tANN training loss 0.230015\n",
      ">> Epoch 89 finished \tANN training loss 0.229694\n",
      ">> Epoch 90 finished \tANN training loss 0.229385\n",
      ">> Epoch 91 finished \tANN training loss 0.229069\n",
      ">> Epoch 92 finished \tANN training loss 0.228754\n",
      ">> Epoch 93 finished \tANN training loss 0.228436\n",
      ">> Epoch 94 finished \tANN training loss 0.228121\n",
      ">> Epoch 95 finished \tANN training loss 0.227819\n",
      ">> Epoch 96 finished \tANN training loss 0.227503\n",
      ">> Epoch 97 finished \tANN training loss 0.227185\n",
      ">> Epoch 98 finished \tANN training loss 0.226875\n",
      ">> Epoch 99 finished \tANN training loss 0.226570\n",
      ">> Epoch 100 finished \tANN training loss 0.226255\n",
      ">> Epoch 101 finished \tANN training loss 0.225947\n",
      ">> Epoch 102 finished \tANN training loss 0.225634\n",
      ">> Epoch 103 finished \tANN training loss 0.225325\n",
      ">> Epoch 104 finished \tANN training loss 0.225018\n",
      ">> Epoch 105 finished \tANN training loss 0.224710\n",
      ">> Epoch 106 finished \tANN training loss 0.224408\n",
      ">> Epoch 107 finished \tANN training loss 0.224100\n",
      ">> Epoch 108 finished \tANN training loss 0.223802\n",
      ">> Epoch 109 finished \tANN training loss 0.223489\n",
      ">> Epoch 110 finished \tANN training loss 0.223197\n",
      ">> Epoch 111 finished \tANN training loss 0.222885\n",
      ">> Epoch 112 finished \tANN training loss 0.222574\n",
      ">> Epoch 113 finished \tANN training loss 0.222270\n",
      ">> Epoch 114 finished \tANN training loss 0.221972\n",
      ">> Epoch 115 finished \tANN training loss 0.221678\n",
      ">> Epoch 116 finished \tANN training loss 0.221374\n",
      ">> Epoch 117 finished \tANN training loss 0.221068\n",
      ">> Epoch 118 finished \tANN training loss 0.220762\n",
      ">> Epoch 119 finished \tANN training loss 0.220465\n",
      ">> Epoch 120 finished \tANN training loss 0.220169\n",
      ">> Epoch 121 finished \tANN training loss 0.219869\n",
      ">> Epoch 122 finished \tANN training loss 0.219566\n",
      ">> Epoch 123 finished \tANN training loss 0.219267\n",
      ">> Epoch 124 finished \tANN training loss 0.218965\n",
      ">> Epoch 125 finished \tANN training loss 0.218675\n",
      ">> Epoch 126 finished \tANN training loss 0.218375\n",
      ">> Epoch 127 finished \tANN training loss 0.218072\n",
      ">> Epoch 128 finished \tANN training loss 0.217777\n",
      ">> Epoch 129 finished \tANN training loss 0.217491\n",
      ">> Epoch 130 finished \tANN training loss 0.217196\n",
      ">> Epoch 131 finished \tANN training loss 0.216899\n",
      ">> Epoch 132 finished \tANN training loss 0.216612\n",
      ">> Epoch 133 finished \tANN training loss 0.216313\n",
      ">> Epoch 134 finished \tANN training loss 0.216023\n",
      ">> Epoch 135 finished \tANN training loss 0.215733\n",
      ">> Epoch 136 finished \tANN training loss 0.215436\n",
      ">> Epoch 137 finished \tANN training loss 0.215145\n",
      ">> Epoch 138 finished \tANN training loss 0.214856\n",
      ">> Epoch 139 finished \tANN training loss 0.214571\n",
      ">> Epoch 140 finished \tANN training loss 0.214281\n",
      ">> Epoch 141 finished \tANN training loss 0.213984\n",
      ">> Epoch 142 finished \tANN training loss 0.213703\n",
      ">> Epoch 143 finished \tANN training loss 0.213416\n",
      ">> Epoch 144 finished \tANN training loss 0.213123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 145 finished \tANN training loss 0.212840\n",
      ">> Epoch 146 finished \tANN training loss 0.212550\n",
      ">> Epoch 147 finished \tANN training loss 0.212269\n",
      ">> Epoch 148 finished \tANN training loss 0.211976\n",
      ">> Epoch 149 finished \tANN training loss 0.211692\n",
      ">> Epoch 150 finished \tANN training loss 0.211413\n",
      "[END] Fine tuning step\n",
      "############### End Training for INDIGOEQ #####################\n",
      "############### End Training for PCJEWELLEREQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 4.147811\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 4.122159\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 4.096442\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 4.070631\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 4.044706\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 4.018667\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 3.992529\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 3.966237\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 3.939818\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 3.913249\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 3.886551\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 3.859663\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 3.832584\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 3.805362\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 3.777932\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 3.750354\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 3.722531\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 3.694462\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 3.666200\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 3.637700\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 3.608948\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 3.579960\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 3.550747\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 3.521229\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 3.491419\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 3.461345\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 3.431030\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 3.400348\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 3.369349\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 3.337979\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 3.306371\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 3.274417\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 3.242072\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 3.209368\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 3.176310\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 3.142917\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 3.109098\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 3.074924\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 3.040292\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 3.005310\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 2.969958\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 2.934141\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 2.897958\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 2.861401\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 2.824438\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 2.787007\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 2.749175\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 2.710903\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 2.672277\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 2.633186\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 2.593785\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 2.553794\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 2.513510\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 2.472918\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 2.431856\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 2.390517\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 2.348922\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 2.306876\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 2.264547\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 2.221954\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 2.179001\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 2.136037\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 2.092529\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 2.048828\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 2.005064\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 1.960937\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 1.916793\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 1.872886\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 1.828778\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 1.784726\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 1.740541\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 1.696530\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 1.652835\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 1.608890\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 1.565466\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 1.522446\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 1.479562\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 1.437014\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 1.395042\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 1.353461\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 1.312394\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 1.271760\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 1.231431\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 1.191850\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 1.152913\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 1.114637\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 1.077023\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 1.040755\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 1.004615\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.969419\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.935554\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.902354\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.870139\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.839076\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.809285\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.780268\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.752493\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.725484\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.699716\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.674330\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.426990\n",
      ">> Epoch 2 finished \tANN training loss 0.403529\n",
      ">> Epoch 3 finished \tANN training loss 0.381482\n",
      ">> Epoch 4 finished \tANN training loss 0.360764\n",
      ">> Epoch 5 finished \tANN training loss 0.341304\n",
      ">> Epoch 6 finished \tANN training loss 0.323004\n",
      ">> Epoch 7 finished \tANN training loss 0.305771\n",
      ">> Epoch 8 finished \tANN training loss 0.289537\n",
      ">> Epoch 9 finished \tANN training loss 0.274250\n",
      ">> Epoch 10 finished \tANN training loss 0.259853\n",
      ">> Epoch 11 finished \tANN training loss 0.246286\n",
      ">> Epoch 12 finished \tANN training loss 0.233485\n",
      ">> Epoch 13 finished \tANN training loss 0.221411\n",
      ">> Epoch 14 finished \tANN training loss 0.210016\n",
      ">> Epoch 15 finished \tANN training loss 0.199252\n",
      ">> Epoch 16 finished \tANN training loss 0.189087\n",
      ">> Epoch 17 finished \tANN training loss 0.179493\n",
      ">> Epoch 18 finished \tANN training loss 0.170422\n",
      ">> Epoch 19 finished \tANN training loss 0.161847\n",
      ">> Epoch 20 finished \tANN training loss 0.153744\n",
      ">> Epoch 21 finished \tANN training loss 0.146083\n",
      ">> Epoch 22 finished \tANN training loss 0.138841\n",
      ">> Epoch 23 finished \tANN training loss 0.131994\n",
      ">> Epoch 24 finished \tANN training loss 0.125529\n",
      ">> Epoch 25 finished \tANN training loss 0.119417\n",
      ">> Epoch 26 finished \tANN training loss 0.113647\n",
      ">> Epoch 27 finished \tANN training loss 0.108194\n",
      ">> Epoch 28 finished \tANN training loss 0.103039\n",
      ">> Epoch 29 finished \tANN training loss 0.098162\n",
      ">> Epoch 30 finished \tANN training loss 0.093550\n",
      ">> Epoch 31 finished \tANN training loss 0.089183\n",
      ">> Epoch 32 finished \tANN training loss 0.085055\n",
      ">> Epoch 33 finished \tANN training loss 0.081143\n",
      ">> Epoch 34 finished \tANN training loss 0.077440\n",
      ">> Epoch 35 finished \tANN training loss 0.073933\n",
      ">> Epoch 36 finished \tANN training loss 0.070612\n",
      ">> Epoch 37 finished \tANN training loss 0.067465\n",
      ">> Epoch 38 finished \tANN training loss 0.064485\n",
      ">> Epoch 39 finished \tANN training loss 0.061661\n",
      ">> Epoch 40 finished \tANN training loss 0.058985\n",
      ">> Epoch 41 finished \tANN training loss 0.056448\n",
      ">> Epoch 42 finished \tANN training loss 0.054045\n",
      ">> Epoch 43 finished \tANN training loss 0.051766\n",
      ">> Epoch 44 finished \tANN training loss 0.049606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 45 finished \tANN training loss 0.047561\n",
      ">> Epoch 46 finished \tANN training loss 0.045620\n",
      ">> Epoch 47 finished \tANN training loss 0.043780\n",
      ">> Epoch 48 finished \tANN training loss 0.042035\n",
      ">> Epoch 49 finished \tANN training loss 0.040380\n",
      ">> Epoch 50 finished \tANN training loss 0.038811\n",
      ">> Epoch 51 finished \tANN training loss 0.037323\n",
      ">> Epoch 52 finished \tANN training loss 0.035911\n",
      ">> Epoch 53 finished \tANN training loss 0.034573\n",
      ">> Epoch 54 finished \tANN training loss 0.033302\n",
      ">> Epoch 55 finished \tANN training loss 0.032097\n",
      ">> Epoch 56 finished \tANN training loss 0.030954\n",
      ">> Epoch 57 finished \tANN training loss 0.029868\n",
      ">> Epoch 58 finished \tANN training loss 0.028838\n",
      ">> Epoch 59 finished \tANN training loss 0.027861\n",
      ">> Epoch 60 finished \tANN training loss 0.026933\n",
      ">> Epoch 61 finished \tANN training loss 0.026052\n",
      ">> Epoch 62 finished \tANN training loss 0.025215\n",
      ">> Epoch 63 finished \tANN training loss 0.024420\n",
      ">> Epoch 64 finished \tANN training loss 0.023666\n",
      ">> Epoch 65 finished \tANN training loss 0.022948\n",
      ">> Epoch 66 finished \tANN training loss 0.022268\n",
      ">> Epoch 67 finished \tANN training loss 0.021621\n",
      ">> Epoch 68 finished \tANN training loss 0.021007\n",
      ">> Epoch 69 finished \tANN training loss 0.020423\n",
      ">> Epoch 70 finished \tANN training loss 0.019868\n",
      ">> Epoch 71 finished \tANN training loss 0.019341\n",
      ">> Epoch 72 finished \tANN training loss 0.018840\n",
      ">> Epoch 73 finished \tANN training loss 0.018362\n",
      ">> Epoch 74 finished \tANN training loss 0.017909\n",
      ">> Epoch 75 finished \tANN training loss 0.017477\n",
      ">> Epoch 76 finished \tANN training loss 0.017067\n",
      ">> Epoch 77 finished \tANN training loss 0.016677\n",
      ">> Epoch 78 finished \tANN training loss 0.016306\n",
      ">> Epoch 79 finished \tANN training loss 0.015952\n",
      ">> Epoch 80 finished \tANN training loss 0.015615\n",
      ">> Epoch 81 finished \tANN training loss 0.015294\n",
      ">> Epoch 82 finished \tANN training loss 0.014989\n",
      ">> Epoch 83 finished \tANN training loss 0.014697\n",
      ">> Epoch 84 finished \tANN training loss 0.014420\n",
      ">> Epoch 85 finished \tANN training loss 0.014155\n",
      ">> Epoch 86 finished \tANN training loss 0.013902\n",
      ">> Epoch 87 finished \tANN training loss 0.013662\n",
      ">> Epoch 88 finished \tANN training loss 0.013432\n",
      ">> Epoch 89 finished \tANN training loss 0.013213\n",
      ">> Epoch 90 finished \tANN training loss 0.013003\n",
      ">> Epoch 91 finished \tANN training loss 0.012803\n",
      ">> Epoch 92 finished \tANN training loss 0.012612\n",
      ">> Epoch 93 finished \tANN training loss 0.012429\n",
      ">> Epoch 94 finished \tANN training loss 0.012254\n",
      ">> Epoch 95 finished \tANN training loss 0.012087\n",
      ">> Epoch 96 finished \tANN training loss 0.011927\n",
      ">> Epoch 97 finished \tANN training loss 0.011773\n",
      ">> Epoch 98 finished \tANN training loss 0.011626\n",
      ">> Epoch 99 finished \tANN training loss 0.011486\n",
      ">> Epoch 100 finished \tANN training loss 0.011351\n",
      ">> Epoch 101 finished \tANN training loss 0.011221\n",
      ">> Epoch 102 finished \tANN training loss 0.011097\n",
      ">> Epoch 103 finished \tANN training loss 0.010978\n",
      ">> Epoch 104 finished \tANN training loss 0.010864\n",
      ">> Epoch 105 finished \tANN training loss 0.010754\n",
      ">> Epoch 106 finished \tANN training loss 0.010648\n",
      ">> Epoch 107 finished \tANN training loss 0.010546\n",
      ">> Epoch 108 finished \tANN training loss 0.010449\n",
      ">> Epoch 109 finished \tANN training loss 0.010354\n",
      ">> Epoch 110 finished \tANN training loss 0.010263\n",
      ">> Epoch 111 finished \tANN training loss 0.010175\n",
      ">> Epoch 112 finished \tANN training loss 0.010091\n",
      ">> Epoch 113 finished \tANN training loss 0.010009\n",
      ">> Epoch 114 finished \tANN training loss 0.009930\n",
      ">> Epoch 115 finished \tANN training loss 0.009854\n",
      ">> Epoch 116 finished \tANN training loss 0.009780\n",
      ">> Epoch 117 finished \tANN training loss 0.009709\n",
      ">> Epoch 118 finished \tANN training loss 0.009640\n",
      ">> Epoch 119 finished \tANN training loss 0.009573\n",
      ">> Epoch 120 finished \tANN training loss 0.009508\n",
      ">> Epoch 121 finished \tANN training loss 0.009445\n",
      ">> Epoch 122 finished \tANN training loss 0.009384\n",
      ">> Epoch 123 finished \tANN training loss 0.009325\n",
      ">> Epoch 124 finished \tANN training loss 0.009267\n",
      ">> Epoch 125 finished \tANN training loss 0.009211\n",
      ">> Epoch 126 finished \tANN training loss 0.009156\n",
      ">> Epoch 127 finished \tANN training loss 0.009103\n",
      ">> Epoch 128 finished \tANN training loss 0.009051\n",
      ">> Epoch 129 finished \tANN training loss 0.009001\n",
      ">> Epoch 130 finished \tANN training loss 0.008951\n",
      ">> Epoch 131 finished \tANN training loss 0.008903\n",
      ">> Epoch 132 finished \tANN training loss 0.008856\n",
      ">> Epoch 133 finished \tANN training loss 0.008810\n",
      ">> Epoch 134 finished \tANN training loss 0.008765\n",
      ">> Epoch 135 finished \tANN training loss 0.008721\n",
      ">> Epoch 136 finished \tANN training loss 0.008678\n",
      ">> Epoch 137 finished \tANN training loss 0.008636\n",
      ">> Epoch 138 finished \tANN training loss 0.008595\n",
      ">> Epoch 139 finished \tANN training loss 0.008554\n",
      ">> Epoch 140 finished \tANN training loss 0.008514\n",
      ">> Epoch 141 finished \tANN training loss 0.008475\n",
      ">> Epoch 142 finished \tANN training loss 0.008437\n",
      ">> Epoch 143 finished \tANN training loss 0.008399\n",
      ">> Epoch 144 finished \tANN training loss 0.008362\n",
      ">> Epoch 145 finished \tANN training loss 0.008326\n",
      ">> Epoch 146 finished \tANN training loss 0.008290\n",
      ">> Epoch 147 finished \tANN training loss 0.008254\n",
      ">> Epoch 148 finished \tANN training loss 0.008220\n",
      ">> Epoch 149 finished \tANN training loss 0.008185\n",
      ">> Epoch 150 finished \tANN training loss 0.008152\n",
      "[END] Fine tuning step\n",
      "############### End Training for PCJEWELLEREQ #####################\n",
      "############### End Training for STAREQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 2.829527\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 2.806295\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 2.783045\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 2.759784\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 2.736459\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 2.713032\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 2.689514\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 2.665854\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 2.642035\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 2.617997\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 2.593729\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 2.569189\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 2.544349\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 2.519144\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 2.493557\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 2.467553\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 2.441095\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 2.414090\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 2.386564\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 2.358405\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 2.329633\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 2.300194\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 2.270038\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 2.239093\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 2.207315\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 2.174698\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 2.141247\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 2.106796\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 2.071430\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 2.035096\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 1.997725\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 1.959274\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 1.919886\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 1.879394\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 1.837885\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 1.795208\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 1.751621\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 1.707078\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 1.661491\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 1.615201\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 1.567977\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 1.519931\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 1.471196\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 1.421931\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 1.372252\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 1.322317\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 1.272163\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 1.221848\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 1.171714\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 1.122178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 51 finished \tRBM Reconstruction error 1.072975\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 1.024449\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.976876\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.929800\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.884085\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.839580\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.796293\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.754216\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.714583\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.676305\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.640039\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.605852\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.573629\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.543509\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.515314\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.488775\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.463894\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.440943\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.419501\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.399482\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.380806\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.363657\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.348624\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.334448\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.321661\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.309670\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.298366\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.287894\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.278544\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.269582\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.261235\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.253737\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.246694\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.239997\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.233750\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.227695\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.222025\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.216603\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.211608\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.206741\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.202076\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.197598\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.193294\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.189158\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.185147\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.181257\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.177509\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.173852\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.170298\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.166850\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.035858\n",
      ">> Epoch 2 finished \tANN training loss 0.032373\n",
      ">> Epoch 3 finished \tANN training loss 0.029265\n",
      ">> Epoch 4 finished \tANN training loss 0.026492\n",
      ">> Epoch 5 finished \tANN training loss 0.024018\n",
      ">> Epoch 6 finished \tANN training loss 0.021809\n",
      ">> Epoch 7 finished \tANN training loss 0.019836\n",
      ">> Epoch 8 finished \tANN training loss 0.018073\n",
      ">> Epoch 9 finished \tANN training loss 0.016496\n",
      ">> Epoch 10 finished \tANN training loss 0.015087\n",
      ">> Epoch 11 finished \tANN training loss 0.013824\n",
      ">> Epoch 12 finished \tANN training loss 0.012693\n",
      ">> Epoch 13 finished \tANN training loss 0.011681\n",
      ">> Epoch 14 finished \tANN training loss 0.010772\n",
      ">> Epoch 15 finished \tANN training loss 0.009957\n",
      ">> Epoch 16 finished \tANN training loss 0.009225\n",
      ">> Epoch 17 finished \tANN training loss 0.008566\n",
      ">> Epoch 18 finished \tANN training loss 0.007974\n",
      ">> Epoch 19 finished \tANN training loss 0.007441\n",
      ">> Epoch 20 finished \tANN training loss 0.006960\n",
      ">> Epoch 21 finished \tANN training loss 0.006525\n",
      ">> Epoch 22 finished \tANN training loss 0.006133\n",
      ">> Epoch 23 finished \tANN training loss 0.005777\n",
      ">> Epoch 24 finished \tANN training loss 0.005455\n",
      ">> Epoch 25 finished \tANN training loss 0.005163\n",
      ">> Epoch 26 finished \tANN training loss 0.004897\n",
      ">> Epoch 27 finished \tANN training loss 0.004655\n",
      ">> Epoch 28 finished \tANN training loss 0.004434\n",
      ">> Epoch 29 finished \tANN training loss 0.004232\n",
      ">> Epoch 30 finished \tANN training loss 0.004047\n",
      ">> Epoch 31 finished \tANN training loss 0.003878\n",
      ">> Epoch 32 finished \tANN training loss 0.003722\n",
      ">> Epoch 33 finished \tANN training loss 0.003578\n",
      ">> Epoch 34 finished \tANN training loss 0.003446\n",
      ">> Epoch 35 finished \tANN training loss 0.003323\n",
      ">> Epoch 36 finished \tANN training loss 0.003209\n",
      ">> Epoch 37 finished \tANN training loss 0.003104\n",
      ">> Epoch 38 finished \tANN training loss 0.003005\n",
      ">> Epoch 39 finished \tANN training loss 0.002913\n",
      ">> Epoch 40 finished \tANN training loss 0.002827\n",
      ">> Epoch 41 finished \tANN training loss 0.002747\n",
      ">> Epoch 42 finished \tANN training loss 0.002671\n",
      ">> Epoch 43 finished \tANN training loss 0.002600\n",
      ">> Epoch 44 finished \tANN training loss 0.002532\n",
      ">> Epoch 45 finished \tANN training loss 0.002469\n",
      ">> Epoch 46 finished \tANN training loss 0.002408\n",
      ">> Epoch 47 finished \tANN training loss 0.002351\n",
      ">> Epoch 48 finished \tANN training loss 0.002297\n",
      ">> Epoch 49 finished \tANN training loss 0.002245\n",
      ">> Epoch 50 finished \tANN training loss 0.002195\n",
      ">> Epoch 51 finished \tANN training loss 0.002148\n",
      ">> Epoch 52 finished \tANN training loss 0.002103\n",
      ">> Epoch 53 finished \tANN training loss 0.002059\n",
      ">> Epoch 54 finished \tANN training loss 0.002018\n",
      ">> Epoch 55 finished \tANN training loss 0.001977\n",
      ">> Epoch 56 finished \tANN training loss 0.001939\n",
      ">> Epoch 57 finished \tANN training loss 0.001902\n",
      ">> Epoch 58 finished \tANN training loss 0.001866\n",
      ">> Epoch 59 finished \tANN training loss 0.001831\n",
      ">> Epoch 60 finished \tANN training loss 0.001798\n",
      ">> Epoch 61 finished \tANN training loss 0.001766\n",
      ">> Epoch 62 finished \tANN training loss 0.001734\n",
      ">> Epoch 63 finished \tANN training loss 0.001704\n",
      ">> Epoch 64 finished \tANN training loss 0.001675\n",
      ">> Epoch 65 finished \tANN training loss 0.001646\n",
      ">> Epoch 66 finished \tANN training loss 0.001619\n",
      ">> Epoch 67 finished \tANN training loss 0.001592\n",
      ">> Epoch 68 finished \tANN training loss 0.001566\n",
      ">> Epoch 69 finished \tANN training loss 0.001541\n",
      ">> Epoch 70 finished \tANN training loss 0.001516\n",
      ">> Epoch 71 finished \tANN training loss 0.001492\n",
      ">> Epoch 72 finished \tANN training loss 0.001469\n",
      ">> Epoch 73 finished \tANN training loss 0.001446\n",
      ">> Epoch 74 finished \tANN training loss 0.001424\n",
      ">> Epoch 75 finished \tANN training loss 0.001403\n",
      ">> Epoch 76 finished \tANN training loss 0.001382\n",
      ">> Epoch 77 finished \tANN training loss 0.001362\n",
      ">> Epoch 78 finished \tANN training loss 0.001342\n",
      ">> Epoch 79 finished \tANN training loss 0.001322\n",
      ">> Epoch 80 finished \tANN training loss 0.001304\n",
      ">> Epoch 81 finished \tANN training loss 0.001285\n",
      ">> Epoch 82 finished \tANN training loss 0.001267\n",
      ">> Epoch 83 finished \tANN training loss 0.001250\n",
      ">> Epoch 84 finished \tANN training loss 0.001233\n",
      ">> Epoch 85 finished \tANN training loss 0.001216\n",
      ">> Epoch 86 finished \tANN training loss 0.001200\n",
      ">> Epoch 87 finished \tANN training loss 0.001184\n",
      ">> Epoch 88 finished \tANN training loss 0.001169\n",
      ">> Epoch 89 finished \tANN training loss 0.001154\n",
      ">> Epoch 90 finished \tANN training loss 0.001139\n",
      ">> Epoch 91 finished \tANN training loss 0.001125\n",
      ">> Epoch 92 finished \tANN training loss 0.001111\n",
      ">> Epoch 93 finished \tANN training loss 0.001097\n",
      ">> Epoch 94 finished \tANN training loss 0.001084\n",
      ">> Epoch 95 finished \tANN training loss 0.001071\n",
      ">> Epoch 96 finished \tANN training loss 0.001058\n",
      ">> Epoch 97 finished \tANN training loss 0.001046\n",
      ">> Epoch 98 finished \tANN training loss 0.001033\n",
      ">> Epoch 99 finished \tANN training loss 0.001022\n",
      ">> Epoch 100 finished \tANN training loss 0.001010\n",
      ">> Epoch 101 finished \tANN training loss 0.000999\n",
      ">> Epoch 102 finished \tANN training loss 0.000988\n",
      ">> Epoch 103 finished \tANN training loss 0.000977\n",
      ">> Epoch 104 finished \tANN training loss 0.000967\n",
      ">> Epoch 105 finished \tANN training loss 0.000956\n",
      ">> Epoch 106 finished \tANN training loss 0.000946\n",
      ">> Epoch 107 finished \tANN training loss 0.000937\n",
      ">> Epoch 108 finished \tANN training loss 0.000927\n",
      ">> Epoch 109 finished \tANN training loss 0.000918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 110 finished \tANN training loss 0.000909\n",
      ">> Epoch 111 finished \tANN training loss 0.000900\n",
      ">> Epoch 112 finished \tANN training loss 0.000891\n",
      ">> Epoch 113 finished \tANN training loss 0.000883\n",
      ">> Epoch 114 finished \tANN training loss 0.000874\n",
      ">> Epoch 115 finished \tANN training loss 0.000866\n",
      ">> Epoch 116 finished \tANN training loss 0.000859\n",
      ">> Epoch 117 finished \tANN training loss 0.000851\n",
      ">> Epoch 118 finished \tANN training loss 0.000843\n",
      ">> Epoch 119 finished \tANN training loss 0.000836\n",
      ">> Epoch 120 finished \tANN training loss 0.000829\n",
      ">> Epoch 121 finished \tANN training loss 0.000822\n",
      ">> Epoch 122 finished \tANN training loss 0.000815\n",
      ">> Epoch 123 finished \tANN training loss 0.000808\n",
      ">> Epoch 124 finished \tANN training loss 0.000802\n",
      ">> Epoch 125 finished \tANN training loss 0.000795\n",
      ">> Epoch 126 finished \tANN training loss 0.000789\n",
      ">> Epoch 127 finished \tANN training loss 0.000783\n",
      ">> Epoch 128 finished \tANN training loss 0.000777\n",
      ">> Epoch 129 finished \tANN training loss 0.000771\n",
      ">> Epoch 130 finished \tANN training loss 0.000766\n",
      ">> Epoch 131 finished \tANN training loss 0.000760\n",
      ">> Epoch 132 finished \tANN training loss 0.000755\n",
      ">> Epoch 133 finished \tANN training loss 0.000749\n",
      ">> Epoch 134 finished \tANN training loss 0.000744\n",
      ">> Epoch 135 finished \tANN training loss 0.000739\n",
      ">> Epoch 136 finished \tANN training loss 0.000734\n",
      ">> Epoch 137 finished \tANN training loss 0.000729\n",
      ">> Epoch 138 finished \tANN training loss 0.000725\n",
      ">> Epoch 139 finished \tANN training loss 0.000720\n",
      ">> Epoch 140 finished \tANN training loss 0.000716\n",
      ">> Epoch 141 finished \tANN training loss 0.000711\n",
      ">> Epoch 142 finished \tANN training loss 0.000707\n",
      ">> Epoch 143 finished \tANN training loss 0.000703\n",
      ">> Epoch 144 finished \tANN training loss 0.000699\n",
      ">> Epoch 145 finished \tANN training loss 0.000695\n",
      ">> Epoch 146 finished \tANN training loss 0.000691\n",
      ">> Epoch 147 finished \tANN training loss 0.000687\n",
      ">> Epoch 148 finished \tANN training loss 0.000683\n",
      ">> Epoch 149 finished \tANN training loss 0.000680\n",
      ">> Epoch 150 finished \tANN training loss 0.000676\n",
      "[END] Fine tuning step\n",
      "############### End Training for STAREQ #####################\n",
      "############### End Training for KSCLEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 6.922422\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 6.855926\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 6.787116\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 6.715740\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 6.641431\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 6.563840\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 6.482611\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 6.397267\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 6.307567\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 6.212965\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 6.113179\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 6.007586\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 5.895602\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 5.776823\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 5.650580\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 5.516626\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 5.374163\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 5.223143\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 5.062409\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 4.891974\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 4.711844\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 4.521917\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 4.321172\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 4.111641\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 3.892470\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 3.665469\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 3.431154\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 3.191634\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 2.948434\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 2.705159\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 2.463860\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 2.227288\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 1.998138\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 1.778354\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 1.572786\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 1.381952\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 1.208464\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 1.052343\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.915965\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.795584\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.695120\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.608790\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.537547\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.481058\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.433930\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.396175\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.366232\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.342688\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.323271\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.308768\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.297263\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.288104\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.280477\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.273819\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.268554\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.264149\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.260352\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.256936\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.253888\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.251042\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.248398\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.246080\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.243787\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.241727\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.239442\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.237293\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.235360\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.233059\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.231115\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.229338\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.227238\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.225037\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.223085\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.221379\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.219530\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.217419\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.215713\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.213686\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.212053\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.210451\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.208760\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.207365\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.205290\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.203185\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.201586\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.199799\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.198371\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.196734\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.195448\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.193807\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.193032\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.191516\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.190165\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.188801\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.187554\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.186201\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.185044\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.183535\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.182103\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.181008\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.085596\n",
      ">> Epoch 2 finished \tANN training loss 0.073942\n",
      ">> Epoch 3 finished \tANN training loss 0.063926\n",
      ">> Epoch 4 finished \tANN training loss 0.055316\n",
      ">> Epoch 5 finished \tANN training loss 0.047917\n",
      ">> Epoch 6 finished \tANN training loss 0.041556\n",
      ">> Epoch 7 finished \tANN training loss 0.036090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 8 finished \tANN training loss 0.031394\n",
      ">> Epoch 9 finished \tANN training loss 0.027364\n",
      ">> Epoch 10 finished \tANN training loss 0.023907\n",
      ">> Epoch 11 finished \tANN training loss 0.020942\n",
      ">> Epoch 12 finished \tANN training loss 0.018396\n",
      ">> Epoch 13 finished \tANN training loss 0.016211\n",
      ">> Epoch 14 finished \tANN training loss 0.014335\n",
      ">> Epoch 15 finished \tANN training loss 0.012724\n",
      ">> Epoch 16 finished \tANN training loss 0.011341\n",
      ">> Epoch 17 finished \tANN training loss 0.010153\n",
      ">> Epoch 18 finished \tANN training loss 0.009131\n",
      ">> Epoch 19 finished \tANN training loss 0.008254\n",
      ">> Epoch 20 finished \tANN training loss 0.007500\n",
      ">> Epoch 21 finished \tANN training loss 0.006853\n",
      ">> Epoch 22 finished \tANN training loss 0.006296\n",
      ">> Epoch 23 finished \tANN training loss 0.005817\n",
      ">> Epoch 24 finished \tANN training loss 0.005406\n",
      ">> Epoch 25 finished \tANN training loss 0.005053\n",
      ">> Epoch 26 finished \tANN training loss 0.004749\n",
      ">> Epoch 27 finished \tANN training loss 0.004488\n",
      ">> Epoch 28 finished \tANN training loss 0.004264\n",
      ">> Epoch 29 finished \tANN training loss 0.004071\n",
      ">> Epoch 30 finished \tANN training loss 0.003904\n",
      ">> Epoch 31 finished \tANN training loss 0.003761\n",
      ">> Epoch 32 finished \tANN training loss 0.003638\n",
      ">> Epoch 33 finished \tANN training loss 0.003532\n",
      ">> Epoch 34 finished \tANN training loss 0.003440\n",
      ">> Epoch 35 finished \tANN training loss 0.003361\n",
      ">> Epoch 36 finished \tANN training loss 0.003293\n",
      ">> Epoch 37 finished \tANN training loss 0.003234\n",
      ">> Epoch 38 finished \tANN training loss 0.003183\n",
      ">> Epoch 39 finished \tANN training loss 0.003139\n",
      ">> Epoch 40 finished \tANN training loss 0.003100\n",
      ">> Epoch 41 finished \tANN training loss 0.003067\n",
      ">> Epoch 42 finished \tANN training loss 0.003038\n",
      ">> Epoch 43 finished \tANN training loss 0.003013\n",
      ">> Epoch 44 finished \tANN training loss 0.002991\n",
      ">> Epoch 45 finished \tANN training loss 0.002971\n",
      ">> Epoch 46 finished \tANN training loss 0.002954\n",
      ">> Epoch 47 finished \tANN training loss 0.002939\n",
      ">> Epoch 48 finished \tANN training loss 0.002926\n",
      ">> Epoch 49 finished \tANN training loss 0.002914\n",
      ">> Epoch 50 finished \tANN training loss 0.002904\n",
      ">> Epoch 51 finished \tANN training loss 0.002895\n",
      ">> Epoch 52 finished \tANN training loss 0.002886\n",
      ">> Epoch 53 finished \tANN training loss 0.002879\n",
      ">> Epoch 54 finished \tANN training loss 0.002872\n",
      ">> Epoch 55 finished \tANN training loss 0.002865\n",
      ">> Epoch 56 finished \tANN training loss 0.002860\n",
      ">> Epoch 57 finished \tANN training loss 0.002854\n",
      ">> Epoch 58 finished \tANN training loss 0.002849\n",
      ">> Epoch 59 finished \tANN training loss 0.002845\n",
      ">> Epoch 60 finished \tANN training loss 0.002841\n",
      ">> Epoch 61 finished \tANN training loss 0.002837\n",
      ">> Epoch 62 finished \tANN training loss 0.002833\n",
      ">> Epoch 63 finished \tANN training loss 0.002829\n",
      ">> Epoch 64 finished \tANN training loss 0.002826\n",
      ">> Epoch 65 finished \tANN training loss 0.002822\n",
      ">> Epoch 66 finished \tANN training loss 0.002819\n",
      ">> Epoch 67 finished \tANN training loss 0.002816\n",
      ">> Epoch 68 finished \tANN training loss 0.002813\n",
      ">> Epoch 69 finished \tANN training loss 0.002810\n",
      ">> Epoch 70 finished \tANN training loss 0.002807\n",
      ">> Epoch 71 finished \tANN training loss 0.002804\n",
      ">> Epoch 72 finished \tANN training loss 0.002802\n",
      ">> Epoch 73 finished \tANN training loss 0.002799\n",
      ">> Epoch 74 finished \tANN training loss 0.002796\n",
      ">> Epoch 75 finished \tANN training loss 0.002794\n",
      ">> Epoch 76 finished \tANN training loss 0.002791\n",
      ">> Epoch 77 finished \tANN training loss 0.002789\n",
      ">> Epoch 78 finished \tANN training loss 0.002786\n",
      ">> Epoch 79 finished \tANN training loss 0.002784\n",
      ">> Epoch 80 finished \tANN training loss 0.002781\n",
      ">> Epoch 81 finished \tANN training loss 0.002779\n",
      ">> Epoch 82 finished \tANN training loss 0.002777\n",
      ">> Epoch 83 finished \tANN training loss 0.002774\n",
      ">> Epoch 84 finished \tANN training loss 0.002772\n",
      ">> Epoch 85 finished \tANN training loss 0.002770\n",
      ">> Epoch 86 finished \tANN training loss 0.002767\n",
      ">> Epoch 87 finished \tANN training loss 0.002765\n",
      ">> Epoch 88 finished \tANN training loss 0.002763\n",
      ">> Epoch 89 finished \tANN training loss 0.002761\n",
      ">> Epoch 90 finished \tANN training loss 0.002759\n",
      ">> Epoch 91 finished \tANN training loss 0.002756\n",
      ">> Epoch 92 finished \tANN training loss 0.002754\n",
      ">> Epoch 93 finished \tANN training loss 0.002752\n",
      ">> Epoch 94 finished \tANN training loss 0.002750\n",
      ">> Epoch 95 finished \tANN training loss 0.002748\n",
      ">> Epoch 96 finished \tANN training loss 0.002746\n",
      ">> Epoch 97 finished \tANN training loss 0.002744\n",
      ">> Epoch 98 finished \tANN training loss 0.002742\n",
      ">> Epoch 99 finished \tANN training loss 0.002740\n",
      ">> Epoch 100 finished \tANN training loss 0.002738\n",
      ">> Epoch 101 finished \tANN training loss 0.002736\n",
      ">> Epoch 102 finished \tANN training loss 0.002734\n",
      ">> Epoch 103 finished \tANN training loss 0.002732\n",
      ">> Epoch 104 finished \tANN training loss 0.002730\n",
      ">> Epoch 105 finished \tANN training loss 0.002728\n",
      ">> Epoch 106 finished \tANN training loss 0.002726\n",
      ">> Epoch 107 finished \tANN training loss 0.002725\n",
      ">> Epoch 108 finished \tANN training loss 0.002723\n",
      ">> Epoch 109 finished \tANN training loss 0.002721\n",
      ">> Epoch 110 finished \tANN training loss 0.002719\n",
      ">> Epoch 111 finished \tANN training loss 0.002717\n",
      ">> Epoch 112 finished \tANN training loss 0.002716\n",
      ">> Epoch 113 finished \tANN training loss 0.002714\n",
      ">> Epoch 114 finished \tANN training loss 0.002712\n",
      ">> Epoch 115 finished \tANN training loss 0.002710\n",
      ">> Epoch 116 finished \tANN training loss 0.002709\n",
      ">> Epoch 117 finished \tANN training loss 0.002707\n",
      ">> Epoch 118 finished \tANN training loss 0.002705\n",
      ">> Epoch 119 finished \tANN training loss 0.002704\n",
      ">> Epoch 120 finished \tANN training loss 0.002702\n",
      ">> Epoch 121 finished \tANN training loss 0.002701\n",
      ">> Epoch 122 finished \tANN training loss 0.002699\n",
      ">> Epoch 123 finished \tANN training loss 0.002697\n",
      ">> Epoch 124 finished \tANN training loss 0.002696\n",
      ">> Epoch 125 finished \tANN training loss 0.002694\n",
      ">> Epoch 126 finished \tANN training loss 0.002693\n",
      ">> Epoch 127 finished \tANN training loss 0.002691\n",
      ">> Epoch 128 finished \tANN training loss 0.002690\n",
      ">> Epoch 129 finished \tANN training loss 0.002688\n",
      ">> Epoch 130 finished \tANN training loss 0.002687\n",
      ">> Epoch 131 finished \tANN training loss 0.002685\n",
      ">> Epoch 132 finished \tANN training loss 0.002684\n",
      ">> Epoch 133 finished \tANN training loss 0.002682\n",
      ">> Epoch 134 finished \tANN training loss 0.002681\n",
      ">> Epoch 135 finished \tANN training loss 0.002679\n",
      ">> Epoch 136 finished \tANN training loss 0.002678\n",
      ">> Epoch 137 finished \tANN training loss 0.002676\n",
      ">> Epoch 138 finished \tANN training loss 0.002675\n",
      ">> Epoch 139 finished \tANN training loss 0.002673\n",
      ">> Epoch 140 finished \tANN training loss 0.002672\n",
      ">> Epoch 141 finished \tANN training loss 0.002671\n",
      ">> Epoch 142 finished \tANN training loss 0.002669\n",
      ">> Epoch 143 finished \tANN training loss 0.002668\n",
      ">> Epoch 144 finished \tANN training loss 0.002667\n",
      ">> Epoch 145 finished \tANN training loss 0.002665\n",
      ">> Epoch 146 finished \tANN training loss 0.002664\n",
      ">> Epoch 147 finished \tANN training loss 0.002663\n",
      ">> Epoch 148 finished \tANN training loss 0.002661\n",
      ">> Epoch 149 finished \tANN training loss 0.002660\n",
      ">> Epoch 150 finished \tANN training loss 0.002659\n",
      "[END] Fine tuning step\n",
      "############### End Training for KSCLEQ #####################\n",
      "############### End Training for BHELEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 8.338455\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 8.150539\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 7.941828\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 7.705958\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 7.435408\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 7.121147\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 6.752972\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 6.320001\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 5.813961\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 5.228977\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 4.566592\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 3.842907\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 3.091819\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 2.359611\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 1.702571\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 1.168767\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 0.782646\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 0.531655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 19 finished \tRBM Reconstruction error 0.385570\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 0.310193\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 0.275383\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 0.261660\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 0.257170\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 0.255239\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 0.253931\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 0.253094\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 0.251694\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 0.250086\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 0.245851\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 0.242947\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 0.240848\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 0.237903\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.233414\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.230256\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.227244\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.225167\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.221651\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.220026\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.215803\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.211982\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.209938\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.208054\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.209183\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.207418\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.205338\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.202510\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.199653\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.198055\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.196796\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.194642\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.193143\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.193355\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.190798\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.189963\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.188272\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.187654\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.183938\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.187243\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.182783\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.183030\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.182182\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.179775\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.177293\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.176839\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.173761\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.171007\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.170499\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.172378\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.171240\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.170596\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.169093\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.165801\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.165729\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.164639\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.163810\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.163292\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.163803\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.161958\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.162581\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.161474\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.162063\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.161197\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.160103\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.159147\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.161922\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.162309\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.160664\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.162503\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.163232\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.160111\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.159870\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.157800\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.158145\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.157510\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.159389\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.158957\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.158341\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.157434\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.157114\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.157353\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.431578\n",
      ">> Epoch 2 finished \tANN training loss 0.275227\n",
      ">> Epoch 3 finished \tANN training loss 0.176627\n",
      ">> Epoch 4 finished \tANN training loss 0.114063\n",
      ">> Epoch 5 finished \tANN training loss 0.073915\n",
      ">> Epoch 6 finished \tANN training loss 0.048119\n",
      ">> Epoch 7 finished \tANN training loss 0.031542\n",
      ">> Epoch 8 finished \tANN training loss 0.020895\n",
      ">> Epoch 9 finished \tANN training loss 0.014058\n",
      ">> Epoch 10 finished \tANN training loss 0.009674\n",
      ">> Epoch 11 finished \tANN training loss 0.006868\n",
      ">> Epoch 12 finished \tANN training loss 0.005073\n",
      ">> Epoch 13 finished \tANN training loss 0.003926\n",
      ">> Epoch 14 finished \tANN training loss 0.003193\n",
      ">> Epoch 15 finished \tANN training loss 0.002723\n",
      ">> Epoch 16 finished \tANN training loss 0.002421\n",
      ">> Epoch 17 finished \tANN training loss 0.002228\n",
      ">> Epoch 18 finished \tANN training loss 0.002103\n",
      ">> Epoch 19 finished \tANN training loss 0.002022\n",
      ">> Epoch 20 finished \tANN training loss 0.001970\n",
      ">> Epoch 21 finished \tANN training loss 0.001935\n",
      ">> Epoch 22 finished \tANN training loss 0.001912\n",
      ">> Epoch 23 finished \tANN training loss 0.001896\n",
      ">> Epoch 24 finished \tANN training loss 0.001884\n",
      ">> Epoch 25 finished \tANN training loss 0.001876\n",
      ">> Epoch 26 finished \tANN training loss 0.001870\n",
      ">> Epoch 27 finished \tANN training loss 0.001864\n",
      ">> Epoch 28 finished \tANN training loss 0.001860\n",
      ">> Epoch 29 finished \tANN training loss 0.001857\n",
      ">> Epoch 30 finished \tANN training loss 0.001853\n",
      ">> Epoch 31 finished \tANN training loss 0.001850\n",
      ">> Epoch 32 finished \tANN training loss 0.001847\n",
      ">> Epoch 33 finished \tANN training loss 0.001844\n",
      ">> Epoch 34 finished \tANN training loss 0.001842\n",
      ">> Epoch 35 finished \tANN training loss 0.001839\n",
      ">> Epoch 36 finished \tANN training loss 0.001837\n",
      ">> Epoch 37 finished \tANN training loss 0.001834\n",
      ">> Epoch 38 finished \tANN training loss 0.001832\n",
      ">> Epoch 39 finished \tANN training loss 0.001830\n",
      ">> Epoch 40 finished \tANN training loss 0.001827\n",
      ">> Epoch 41 finished \tANN training loss 0.001825\n",
      ">> Epoch 42 finished \tANN training loss 0.001823\n",
      ">> Epoch 43 finished \tANN training loss 0.001820\n",
      ">> Epoch 44 finished \tANN training loss 0.001818\n",
      ">> Epoch 45 finished \tANN training loss 0.001816\n",
      ">> Epoch 46 finished \tANN training loss 0.001814\n",
      ">> Epoch 47 finished \tANN training loss 0.001812\n",
      ">> Epoch 48 finished \tANN training loss 0.001809\n",
      ">> Epoch 49 finished \tANN training loss 0.001807\n",
      ">> Epoch 50 finished \tANN training loss 0.001805\n",
      ">> Epoch 51 finished \tANN training loss 0.001803\n",
      ">> Epoch 52 finished \tANN training loss 0.001801\n",
      ">> Epoch 53 finished \tANN training loss 0.001799\n",
      ">> Epoch 54 finished \tANN training loss 0.001797\n",
      ">> Epoch 55 finished \tANN training loss 0.001795\n",
      ">> Epoch 56 finished \tANN training loss 0.001793\n",
      ">> Epoch 57 finished \tANN training loss 0.001791\n",
      ">> Epoch 58 finished \tANN training loss 0.001789\n",
      ">> Epoch 59 finished \tANN training loss 0.001787\n",
      ">> Epoch 60 finished \tANN training loss 0.001785\n",
      ">> Epoch 61 finished \tANN training loss 0.001783\n",
      ">> Epoch 62 finished \tANN training loss 0.001781\n",
      ">> Epoch 63 finished \tANN training loss 0.001779\n",
      ">> Epoch 64 finished \tANN training loss 0.001777\n",
      ">> Epoch 65 finished \tANN training loss 0.001774\n",
      ">> Epoch 66 finished \tANN training loss 0.001772\n",
      ">> Epoch 67 finished \tANN training loss 0.001770\n",
      ">> Epoch 68 finished \tANN training loss 0.001768\n",
      ">> Epoch 69 finished \tANN training loss 0.001766\n",
      ">> Epoch 70 finished \tANN training loss 0.001764\n",
      ">> Epoch 71 finished \tANN training loss 0.001761\n",
      ">> Epoch 72 finished \tANN training loss 0.001759\n",
      ">> Epoch 73 finished \tANN training loss 0.001757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 74 finished \tANN training loss 0.001755\n",
      ">> Epoch 75 finished \tANN training loss 0.001752\n",
      ">> Epoch 76 finished \tANN training loss 0.001750\n",
      ">> Epoch 77 finished \tANN training loss 0.001747\n",
      ">> Epoch 78 finished \tANN training loss 0.001745\n",
      ">> Epoch 79 finished \tANN training loss 0.001742\n",
      ">> Epoch 80 finished \tANN training loss 0.001740\n",
      ">> Epoch 81 finished \tANN training loss 0.001737\n",
      ">> Epoch 82 finished \tANN training loss 0.001735\n",
      ">> Epoch 83 finished \tANN training loss 0.001732\n",
      ">> Epoch 84 finished \tANN training loss 0.001730\n",
      ">> Epoch 85 finished \tANN training loss 0.001727\n",
      ">> Epoch 86 finished \tANN training loss 0.001725\n",
      ">> Epoch 87 finished \tANN training loss 0.001722\n",
      ">> Epoch 88 finished \tANN training loss 0.001719\n",
      ">> Epoch 89 finished \tANN training loss 0.001717\n",
      ">> Epoch 90 finished \tANN training loss 0.001715\n",
      ">> Epoch 91 finished \tANN training loss 0.001712\n",
      ">> Epoch 92 finished \tANN training loss 0.001710\n",
      ">> Epoch 93 finished \tANN training loss 0.001708\n",
      ">> Epoch 94 finished \tANN training loss 0.001706\n",
      ">> Epoch 95 finished \tANN training loss 0.001704\n",
      ">> Epoch 96 finished \tANN training loss 0.001702\n",
      ">> Epoch 97 finished \tANN training loss 0.001700\n",
      ">> Epoch 98 finished \tANN training loss 0.001698\n",
      ">> Epoch 99 finished \tANN training loss 0.001696\n",
      ">> Epoch 100 finished \tANN training loss 0.001694\n",
      ">> Epoch 101 finished \tANN training loss 0.001693\n",
      ">> Epoch 102 finished \tANN training loss 0.001691\n",
      ">> Epoch 103 finished \tANN training loss 0.001690\n",
      ">> Epoch 104 finished \tANN training loss 0.001688\n",
      ">> Epoch 105 finished \tANN training loss 0.001686\n",
      ">> Epoch 106 finished \tANN training loss 0.001685\n",
      ">> Epoch 107 finished \tANN training loss 0.001683\n",
      ">> Epoch 108 finished \tANN training loss 0.001682\n",
      ">> Epoch 109 finished \tANN training loss 0.001681\n",
      ">> Epoch 110 finished \tANN training loss 0.001679\n",
      ">> Epoch 111 finished \tANN training loss 0.001678\n",
      ">> Epoch 112 finished \tANN training loss 0.001676\n",
      ">> Epoch 113 finished \tANN training loss 0.001675\n",
      ">> Epoch 114 finished \tANN training loss 0.001674\n",
      ">> Epoch 115 finished \tANN training loss 0.001672\n",
      ">> Epoch 116 finished \tANN training loss 0.001671\n",
      ">> Epoch 117 finished \tANN training loss 0.001669\n",
      ">> Epoch 118 finished \tANN training loss 0.001668\n",
      ">> Epoch 119 finished \tANN training loss 0.001667\n",
      ">> Epoch 120 finished \tANN training loss 0.001666\n",
      ">> Epoch 121 finished \tANN training loss 0.001664\n",
      ">> Epoch 122 finished \tANN training loss 0.001663\n",
      ">> Epoch 123 finished \tANN training loss 0.001662\n",
      ">> Epoch 124 finished \tANN training loss 0.001661\n",
      ">> Epoch 125 finished \tANN training loss 0.001659\n",
      ">> Epoch 126 finished \tANN training loss 0.001658\n",
      ">> Epoch 127 finished \tANN training loss 0.001657\n",
      ">> Epoch 128 finished \tANN training loss 0.001656\n",
      ">> Epoch 129 finished \tANN training loss 0.001654\n",
      ">> Epoch 130 finished \tANN training loss 0.001653\n",
      ">> Epoch 131 finished \tANN training loss 0.001652\n",
      ">> Epoch 132 finished \tANN training loss 0.001651\n",
      ">> Epoch 133 finished \tANN training loss 0.001650\n",
      ">> Epoch 134 finished \tANN training loss 0.001648\n",
      ">> Epoch 135 finished \tANN training loss 0.001647\n",
      ">> Epoch 136 finished \tANN training loss 0.001646\n",
      ">> Epoch 137 finished \tANN training loss 0.001645\n",
      ">> Epoch 138 finished \tANN training loss 0.001644\n",
      ">> Epoch 139 finished \tANN training loss 0.001643\n",
      ">> Epoch 140 finished \tANN training loss 0.001641\n",
      ">> Epoch 141 finished \tANN training loss 0.001640\n",
      ">> Epoch 142 finished \tANN training loss 0.001639\n",
      ">> Epoch 143 finished \tANN training loss 0.001638\n",
      ">> Epoch 144 finished \tANN training loss 0.001637\n",
      ">> Epoch 145 finished \tANN training loss 0.001636\n",
      ">> Epoch 146 finished \tANN training loss 0.001635\n",
      ">> Epoch 147 finished \tANN training loss 0.001634\n",
      ">> Epoch 148 finished \tANN training loss 0.001633\n",
      ">> Epoch 149 finished \tANN training loss 0.001632\n",
      ">> Epoch 150 finished \tANN training loss 0.001632\n",
      "[END] Fine tuning step\n",
      "############### End Training for BHELEQ #####################\n",
      "############### End Training for YESBANKEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 1.997727\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 1.975256\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 1.952932\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 1.930800\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 1.908791\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 1.886917\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 1.865197\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 1.843631\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 1.822192\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 1.800873\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 1.779682\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 1.758614\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 1.737648\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 1.716765\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 1.696003\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 1.675316\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 1.654710\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 1.634185\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 1.613715\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 1.593344\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 1.573013\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 1.552759\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 1.532538\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 1.512331\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 1.492163\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 1.472081\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 1.451973\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 1.431914\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 1.411860\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 1.391847\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 1.371846\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 1.351802\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 1.331820\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 1.311830\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 1.291896\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 1.271946\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 1.251944\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 1.232044\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 1.212150\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 1.192213\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 1.172299\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 1.152386\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 1.132459\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 1.112552\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 1.092699\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 1.072958\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 1.053270\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 1.033638\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 1.014028\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.994518\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.975090\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.955671\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.936336\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.917052\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.898004\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.879119\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.860279\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.841554\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.823066\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.804809\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.786623\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.768711\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.750891\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.733365\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.715993\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.699004\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.682383\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.665894\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.649809\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.633932\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.618293\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.603174\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.588242\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.573611\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.559418\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.545406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 77 finished \tRBM Reconstruction error 0.532061\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.518952\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.506348\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.493989\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.482105\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.470267\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.459005\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.448270\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.437983\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.427800\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.418221\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.408768\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.399892\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.391153\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.383056\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.375178\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.367349\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.360079\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.353001\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.346317\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.340024\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.333989\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.328439\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.322897\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.109096\n",
      ">> Epoch 2 finished \tANN training loss 0.103695\n",
      ">> Epoch 3 finished \tANN training loss 0.098476\n",
      ">> Epoch 4 finished \tANN training loss 0.093537\n",
      ">> Epoch 5 finished \tANN training loss 0.088886\n",
      ">> Epoch 6 finished \tANN training loss 0.084505\n",
      ">> Epoch 7 finished \tANN training loss 0.080379\n",
      ">> Epoch 8 finished \tANN training loss 0.076492\n",
      ">> Epoch 9 finished \tANN training loss 0.072829\n",
      ">> Epoch 10 finished \tANN training loss 0.069376\n",
      ">> Epoch 11 finished \tANN training loss 0.066121\n",
      ">> Epoch 12 finished \tANN training loss 0.063051\n",
      ">> Epoch 13 finished \tANN training loss 0.060157\n",
      ">> Epoch 14 finished \tANN training loss 0.057426\n",
      ">> Epoch 15 finished \tANN training loss 0.054850\n",
      ">> Epoch 16 finished \tANN training loss 0.052419\n",
      ">> Epoch 17 finished \tANN training loss 0.050125\n",
      ">> Epoch 18 finished \tANN training loss 0.047959\n",
      ">> Epoch 19 finished \tANN training loss 0.045915\n",
      ">> Epoch 20 finished \tANN training loss 0.043985\n",
      ">> Epoch 21 finished \tANN training loss 0.042161\n",
      ">> Epoch 22 finished \tANN training loss 0.040439\n",
      ">> Epoch 23 finished \tANN training loss 0.038812\n",
      ">> Epoch 24 finished \tANN training loss 0.037274\n",
      ">> Epoch 25 finished \tANN training loss 0.035821\n",
      ">> Epoch 26 finished \tANN training loss 0.034446\n",
      ">> Epoch 27 finished \tANN training loss 0.033147\n",
      ">> Epoch 28 finished \tANN training loss 0.031919\n",
      ">> Epoch 29 finished \tANN training loss 0.030757\n",
      ">> Epoch 30 finished \tANN training loss 0.029657\n",
      ">> Epoch 31 finished \tANN training loss 0.028617\n",
      ">> Epoch 32 finished \tANN training loss 0.027632\n",
      ">> Epoch 33 finished \tANN training loss 0.026700\n",
      ">> Epoch 34 finished \tANN training loss 0.025818\n",
      ">> Epoch 35 finished \tANN training loss 0.024982\n",
      ">> Epoch 36 finished \tANN training loss 0.024190\n",
      ">> Epoch 37 finished \tANN training loss 0.023440\n",
      ">> Epoch 38 finished \tANN training loss 0.022728\n",
      ">> Epoch 39 finished \tANN training loss 0.022054\n",
      ">> Epoch 40 finished \tANN training loss 0.021415\n",
      ">> Epoch 41 finished \tANN training loss 0.020808\n",
      ">> Epoch 42 finished \tANN training loss 0.020232\n",
      ">> Epoch 43 finished \tANN training loss 0.019685\n",
      ">> Epoch 44 finished \tANN training loss 0.019166\n",
      ">> Epoch 45 finished \tANN training loss 0.018673\n",
      ">> Epoch 46 finished \tANN training loss 0.018204\n",
      ">> Epoch 47 finished \tANN training loss 0.017759\n",
      ">> Epoch 48 finished \tANN training loss 0.017335\n",
      ">> Epoch 49 finished \tANN training loss 0.016932\n",
      ">> Epoch 50 finished \tANN training loss 0.016549\n",
      ">> Epoch 51 finished \tANN training loss 0.016184\n",
      ">> Epoch 52 finished \tANN training loss 0.015836\n",
      ">> Epoch 53 finished \tANN training loss 0.015504\n",
      ">> Epoch 54 finished \tANN training loss 0.015188\n",
      ">> Epoch 55 finished \tANN training loss 0.014886\n",
      ">> Epoch 56 finished \tANN training loss 0.014599\n",
      ">> Epoch 57 finished \tANN training loss 0.014324\n",
      ">> Epoch 58 finished \tANN training loss 0.014061\n",
      ">> Epoch 59 finished \tANN training loss 0.013811\n",
      ">> Epoch 60 finished \tANN training loss 0.013571\n",
      ">> Epoch 61 finished \tANN training loss 0.013341\n",
      ">> Epoch 62 finished \tANN training loss 0.013121\n",
      ">> Epoch 63 finished \tANN training loss 0.012910\n",
      ">> Epoch 64 finished \tANN training loss 0.012709\n",
      ">> Epoch 65 finished \tANN training loss 0.012515\n",
      ">> Epoch 66 finished \tANN training loss 0.012329\n",
      ">> Epoch 67 finished \tANN training loss 0.012151\n",
      ">> Epoch 68 finished \tANN training loss 0.011979\n",
      ">> Epoch 69 finished \tANN training loss 0.011814\n",
      ">> Epoch 70 finished \tANN training loss 0.011656\n",
      ">> Epoch 71 finished \tANN training loss 0.011503\n",
      ">> Epoch 72 finished \tANN training loss 0.011356\n",
      ">> Epoch 73 finished \tANN training loss 0.011214\n",
      ">> Epoch 74 finished \tANN training loss 0.011077\n",
      ">> Epoch 75 finished \tANN training loss 0.010945\n",
      ">> Epoch 76 finished \tANN training loss 0.010818\n",
      ">> Epoch 77 finished \tANN training loss 0.010694\n",
      ">> Epoch 78 finished \tANN training loss 0.010575\n",
      ">> Epoch 79 finished \tANN training loss 0.010459\n",
      ">> Epoch 80 finished \tANN training loss 0.010347\n",
      ">> Epoch 81 finished \tANN training loss 0.010239\n",
      ">> Epoch 82 finished \tANN training loss 0.010134\n",
      ">> Epoch 83 finished \tANN training loss 0.010032\n",
      ">> Epoch 84 finished \tANN training loss 0.009932\n",
      ">> Epoch 85 finished \tANN training loss 0.009836\n",
      ">> Epoch 86 finished \tANN training loss 0.009742\n",
      ">> Epoch 87 finished \tANN training loss 0.009651\n",
      ">> Epoch 88 finished \tANN training loss 0.009562\n",
      ">> Epoch 89 finished \tANN training loss 0.009475\n",
      ">> Epoch 90 finished \tANN training loss 0.009391\n",
      ">> Epoch 91 finished \tANN training loss 0.009308\n",
      ">> Epoch 92 finished \tANN training loss 0.009228\n",
      ">> Epoch 93 finished \tANN training loss 0.009149\n",
      ">> Epoch 94 finished \tANN training loss 0.009072\n",
      ">> Epoch 95 finished \tANN training loss 0.008997\n",
      ">> Epoch 96 finished \tANN training loss 0.008924\n",
      ">> Epoch 97 finished \tANN training loss 0.008852\n",
      ">> Epoch 98 finished \tANN training loss 0.008781\n",
      ">> Epoch 99 finished \tANN training loss 0.008712\n",
      ">> Epoch 100 finished \tANN training loss 0.008644\n",
      ">> Epoch 101 finished \tANN training loss 0.008577\n",
      ">> Epoch 102 finished \tANN training loss 0.008512\n",
      ">> Epoch 103 finished \tANN training loss 0.008448\n",
      ">> Epoch 104 finished \tANN training loss 0.008385\n",
      ">> Epoch 105 finished \tANN training loss 0.008323\n",
      ">> Epoch 106 finished \tANN training loss 0.008262\n",
      ">> Epoch 107 finished \tANN training loss 0.008202\n",
      ">> Epoch 108 finished \tANN training loss 0.008142\n",
      ">> Epoch 109 finished \tANN training loss 0.008084\n",
      ">> Epoch 110 finished \tANN training loss 0.008027\n",
      ">> Epoch 111 finished \tANN training loss 0.007970\n",
      ">> Epoch 112 finished \tANN training loss 0.007915\n",
      ">> Epoch 113 finished \tANN training loss 0.007860\n",
      ">> Epoch 114 finished \tANN training loss 0.007806\n",
      ">> Epoch 115 finished \tANN training loss 0.007752\n",
      ">> Epoch 116 finished \tANN training loss 0.007699\n",
      ">> Epoch 117 finished \tANN training loss 0.007647\n",
      ">> Epoch 118 finished \tANN training loss 0.007596\n",
      ">> Epoch 119 finished \tANN training loss 0.007545\n",
      ">> Epoch 120 finished \tANN training loss 0.007495\n",
      ">> Epoch 121 finished \tANN training loss 0.007445\n",
      ">> Epoch 122 finished \tANN training loss 0.007396\n",
      ">> Epoch 123 finished \tANN training loss 0.007348\n",
      ">> Epoch 124 finished \tANN training loss 0.007300\n",
      ">> Epoch 125 finished \tANN training loss 0.007252\n",
      ">> Epoch 126 finished \tANN training loss 0.007205\n",
      ">> Epoch 127 finished \tANN training loss 0.007159\n",
      ">> Epoch 128 finished \tANN training loss 0.007113\n",
      ">> Epoch 129 finished \tANN training loss 0.007067\n",
      ">> Epoch 130 finished \tANN training loss 0.007022\n",
      ">> Epoch 131 finished \tANN training loss 0.006977\n",
      ">> Epoch 132 finished \tANN training loss 0.006933\n",
      ">> Epoch 133 finished \tANN training loss 0.006889\n",
      ">> Epoch 134 finished \tANN training loss 0.006846\n",
      ">> Epoch 135 finished \tANN training loss 0.006803\n",
      ">> Epoch 136 finished \tANN training loss 0.006760\n",
      ">> Epoch 137 finished \tANN training loss 0.006718\n",
      ">> Epoch 138 finished \tANN training loss 0.006676\n",
      ">> Epoch 139 finished \tANN training loss 0.006634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 140 finished \tANN training loss 0.006593\n",
      ">> Epoch 141 finished \tANN training loss 0.006552\n",
      ">> Epoch 142 finished \tANN training loss 0.006512\n",
      ">> Epoch 143 finished \tANN training loss 0.006472\n",
      ">> Epoch 144 finished \tANN training loss 0.006432\n",
      ">> Epoch 145 finished \tANN training loss 0.006392\n",
      ">> Epoch 146 finished \tANN training loss 0.006353\n",
      ">> Epoch 147 finished \tANN training loss 0.006314\n",
      ">> Epoch 148 finished \tANN training loss 0.006275\n",
      ">> Epoch 149 finished \tANN training loss 0.006237\n",
      ">> Epoch 150 finished \tANN training loss 0.006199\n",
      "[END] Fine tuning step\n",
      "############### End Training for YESBANKEQ #####################\n",
      "############### End Training for SREINFRAEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 17.199421\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 17.192425\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 17.185414\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 17.178390\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 17.171345\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 17.164297\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 17.157232\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 17.150165\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 17.143078\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 17.135981\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 17.128856\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 17.121731\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 17.114579\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 17.107428\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 17.100260\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 17.093095\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 17.085908\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 17.078705\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 17.071494\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 17.064267\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 17.057016\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 17.049754\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 17.042504\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 17.035224\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 17.027930\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 17.020634\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 17.013329\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 17.005994\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 16.998651\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 16.991298\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 16.983943\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 16.976569\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 16.969179\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 16.961777\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 16.954365\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 16.946923\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 16.939480\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 16.932029\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 16.924546\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 16.917038\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 16.909523\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 16.902007\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 16.894479\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 16.886939\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 16.879364\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 16.871801\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 16.864210\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 16.856601\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 16.848977\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 16.841344\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 16.833701\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 16.826044\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 16.818359\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 16.810679\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 16.802967\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 16.795252\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 16.787510\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 16.779775\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 16.772007\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 16.764237\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 16.756460\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 16.748651\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 16.740838\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 16.733015\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 16.725155\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 16.717289\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 16.709418\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 16.701529\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 16.693612\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 16.685687\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 16.677766\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 16.669805\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 16.661833\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 16.653838\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 16.645832\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 16.637802\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 16.629759\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 16.621691\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 16.613613\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 16.605525\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 16.597439\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 16.589329\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 16.581200\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 16.573053\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 16.564878\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 16.556686\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 16.548490\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 16.540283\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 16.532051\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 16.523792\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 16.515502\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 16.507196\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 16.498881\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 16.490554\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 16.482220\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 16.473867\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 16.465511\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 16.457129\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 16.448706\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 16.440274\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.148497\n",
      ">> Epoch 2 finished \tANN training loss 0.148116\n",
      ">> Epoch 3 finished \tANN training loss 0.147740\n",
      ">> Epoch 4 finished \tANN training loss 0.147354\n",
      ">> Epoch 5 finished \tANN training loss 0.146982\n",
      ">> Epoch 6 finished \tANN training loss 0.146603\n",
      ">> Epoch 7 finished \tANN training loss 0.146238\n",
      ">> Epoch 8 finished \tANN training loss 0.145869\n",
      ">> Epoch 9 finished \tANN training loss 0.145487\n",
      ">> Epoch 10 finished \tANN training loss 0.145117\n",
      ">> Epoch 11 finished \tANN training loss 0.144749\n",
      ">> Epoch 12 finished \tANN training loss 0.144380\n",
      ">> Epoch 13 finished \tANN training loss 0.144010\n",
      ">> Epoch 14 finished \tANN training loss 0.143646\n",
      ">> Epoch 15 finished \tANN training loss 0.143291\n",
      ">> Epoch 16 finished \tANN training loss 0.142926\n",
      ">> Epoch 17 finished \tANN training loss 0.142559\n",
      ">> Epoch 18 finished \tANN training loss 0.142195\n",
      ">> Epoch 19 finished \tANN training loss 0.141852\n",
      ">> Epoch 20 finished \tANN training loss 0.141488\n",
      ">> Epoch 21 finished \tANN training loss 0.141131\n",
      ">> Epoch 22 finished \tANN training loss 0.140772\n",
      ">> Epoch 23 finished \tANN training loss 0.140422\n",
      ">> Epoch 24 finished \tANN training loss 0.140072\n",
      ">> Epoch 25 finished \tANN training loss 0.139723\n",
      ">> Epoch 26 finished \tANN training loss 0.139369\n",
      ">> Epoch 27 finished \tANN training loss 0.139020\n",
      ">> Epoch 28 finished \tANN training loss 0.138669\n",
      ">> Epoch 29 finished \tANN training loss 0.138325\n",
      ">> Epoch 30 finished \tANN training loss 0.137981\n",
      ">> Epoch 31 finished \tANN training loss 0.137629\n",
      ">> Epoch 32 finished \tANN training loss 0.137299\n",
      ">> Epoch 33 finished \tANN training loss 0.136946\n",
      ">> Epoch 34 finished \tANN training loss 0.136601\n",
      ">> Epoch 35 finished \tANN training loss 0.136267\n",
      ">> Epoch 36 finished \tANN training loss 0.135921\n",
      ">> Epoch 37 finished \tANN training loss 0.135586\n",
      ">> Epoch 38 finished \tANN training loss 0.135251\n",
      ">> Epoch 39 finished \tANN training loss 0.134909\n",
      ">> Epoch 40 finished \tANN training loss 0.134582\n",
      ">> Epoch 41 finished \tANN training loss 0.134246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 42 finished \tANN training loss 0.133912\n",
      ">> Epoch 43 finished \tANN training loss 0.133578\n",
      ">> Epoch 44 finished \tANN training loss 0.133242\n",
      ">> Epoch 45 finished \tANN training loss 0.132921\n",
      ">> Epoch 46 finished \tANN training loss 0.132583\n",
      ">> Epoch 47 finished \tANN training loss 0.132260\n",
      ">> Epoch 48 finished \tANN training loss 0.131928\n",
      ">> Epoch 49 finished \tANN training loss 0.131614\n",
      ">> Epoch 50 finished \tANN training loss 0.131287\n",
      ">> Epoch 51 finished \tANN training loss 0.130967\n",
      ">> Epoch 52 finished \tANN training loss 0.130635\n",
      ">> Epoch 53 finished \tANN training loss 0.130317\n",
      ">> Epoch 54 finished \tANN training loss 0.130009\n",
      ">> Epoch 55 finished \tANN training loss 0.129681\n",
      ">> Epoch 56 finished \tANN training loss 0.129365\n",
      ">> Epoch 57 finished \tANN training loss 0.129053\n",
      ">> Epoch 58 finished \tANN training loss 0.128735\n",
      ">> Epoch 59 finished \tANN training loss 0.128421\n",
      ">> Epoch 60 finished \tANN training loss 0.128105\n",
      ">> Epoch 61 finished \tANN training loss 0.127793\n",
      ">> Epoch 62 finished \tANN training loss 0.127485\n",
      ">> Epoch 63 finished \tANN training loss 0.127182\n",
      ">> Epoch 64 finished \tANN training loss 0.126868\n",
      ">> Epoch 65 finished \tANN training loss 0.126557\n",
      ">> Epoch 66 finished \tANN training loss 0.126256\n",
      ">> Epoch 67 finished \tANN training loss 0.125956\n",
      ">> Epoch 68 finished \tANN training loss 0.125651\n",
      ">> Epoch 69 finished \tANN training loss 0.125349\n",
      ">> Epoch 70 finished \tANN training loss 0.125049\n",
      ">> Epoch 71 finished \tANN training loss 0.124756\n",
      ">> Epoch 72 finished \tANN training loss 0.124468\n",
      ">> Epoch 73 finished \tANN training loss 0.124163\n",
      ">> Epoch 74 finished \tANN training loss 0.123873\n",
      ">> Epoch 75 finished \tANN training loss 0.123578\n",
      ">> Epoch 76 finished \tANN training loss 0.123285\n",
      ">> Epoch 77 finished \tANN training loss 0.122992\n",
      ">> Epoch 78 finished \tANN training loss 0.122717\n",
      ">> Epoch 79 finished \tANN training loss 0.122416\n",
      ">> Epoch 80 finished \tANN training loss 0.122126\n",
      ">> Epoch 81 finished \tANN training loss 0.121842\n",
      ">> Epoch 82 finished \tANN training loss 0.121552\n",
      ">> Epoch 83 finished \tANN training loss 0.121260\n",
      ">> Epoch 84 finished \tANN training loss 0.120983\n",
      ">> Epoch 85 finished \tANN training loss 0.120700\n",
      ">> Epoch 86 finished \tANN training loss 0.120414\n",
      ">> Epoch 87 finished \tANN training loss 0.120134\n",
      ">> Epoch 88 finished \tANN training loss 0.119857\n",
      ">> Epoch 89 finished \tANN training loss 0.119574\n",
      ">> Epoch 90 finished \tANN training loss 0.119291\n",
      ">> Epoch 91 finished \tANN training loss 0.119010\n",
      ">> Epoch 92 finished \tANN training loss 0.118736\n",
      ">> Epoch 93 finished \tANN training loss 0.118457\n",
      ">> Epoch 94 finished \tANN training loss 0.118182\n",
      ">> Epoch 95 finished \tANN training loss 0.117916\n",
      ">> Epoch 96 finished \tANN training loss 0.117641\n",
      ">> Epoch 97 finished \tANN training loss 0.117370\n",
      ">> Epoch 98 finished \tANN training loss 0.117105\n",
      ">> Epoch 99 finished \tANN training loss 0.116832\n",
      ">> Epoch 100 finished \tANN training loss 0.116565\n",
      ">> Epoch 101 finished \tANN training loss 0.116302\n",
      ">> Epoch 102 finished \tANN training loss 0.116029\n",
      ">> Epoch 103 finished \tANN training loss 0.115767\n",
      ">> Epoch 104 finished \tANN training loss 0.115502\n",
      ">> Epoch 105 finished \tANN training loss 0.115239\n",
      ">> Epoch 106 finished \tANN training loss 0.114970\n",
      ">> Epoch 107 finished \tANN training loss 0.114713\n",
      ">> Epoch 108 finished \tANN training loss 0.114456\n",
      ">> Epoch 109 finished \tANN training loss 0.114189\n",
      ">> Epoch 110 finished \tANN training loss 0.113932\n",
      ">> Epoch 111 finished \tANN training loss 0.113675\n",
      ">> Epoch 112 finished \tANN training loss 0.113413\n",
      ">> Epoch 113 finished \tANN training loss 0.113165\n",
      ">> Epoch 114 finished \tANN training loss 0.112903\n",
      ">> Epoch 115 finished \tANN training loss 0.112655\n",
      ">> Epoch 116 finished \tANN training loss 0.112403\n",
      ">> Epoch 117 finished \tANN training loss 0.112147\n",
      ">> Epoch 118 finished \tANN training loss 0.111903\n",
      ">> Epoch 119 finished \tANN training loss 0.111654\n",
      ">> Epoch 120 finished \tANN training loss 0.111408\n",
      ">> Epoch 121 finished \tANN training loss 0.111159\n",
      ">> Epoch 122 finished \tANN training loss 0.110914\n",
      ">> Epoch 123 finished \tANN training loss 0.110669\n",
      ">> Epoch 124 finished \tANN training loss 0.110421\n",
      ">> Epoch 125 finished \tANN training loss 0.110187\n",
      ">> Epoch 126 finished \tANN training loss 0.109934\n",
      ">> Epoch 127 finished \tANN training loss 0.109693\n",
      ">> Epoch 128 finished \tANN training loss 0.109457\n",
      ">> Epoch 129 finished \tANN training loss 0.109217\n",
      ">> Epoch 130 finished \tANN training loss 0.108972\n",
      ">> Epoch 131 finished \tANN training loss 0.108735\n",
      ">> Epoch 132 finished \tANN training loss 0.108495\n",
      ">> Epoch 133 finished \tANN training loss 0.108254\n",
      ">> Epoch 134 finished \tANN training loss 0.108020\n",
      ">> Epoch 135 finished \tANN training loss 0.107782\n",
      ">> Epoch 136 finished \tANN training loss 0.107550\n",
      ">> Epoch 137 finished \tANN training loss 0.107321\n",
      ">> Epoch 138 finished \tANN training loss 0.107081\n",
      ">> Epoch 139 finished \tANN training loss 0.106853\n",
      ">> Epoch 140 finished \tANN training loss 0.106620\n",
      ">> Epoch 141 finished \tANN training loss 0.106391\n",
      ">> Epoch 142 finished \tANN training loss 0.106160\n",
      ">> Epoch 143 finished \tANN training loss 0.105929\n",
      ">> Epoch 144 finished \tANN training loss 0.105706\n",
      ">> Epoch 145 finished \tANN training loss 0.105487\n",
      ">> Epoch 146 finished \tANN training loss 0.105261\n",
      ">> Epoch 147 finished \tANN training loss 0.105034\n",
      ">> Epoch 148 finished \tANN training loss 0.104810\n",
      ">> Epoch 149 finished \tANN training loss 0.104590\n",
      ">> Epoch 150 finished \tANN training loss 0.104364\n",
      "[END] Fine tuning step\n",
      "############### End Training for SREINFRAEQ #####################\n",
      "############### End Training for BHARATFORGEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 0.901550\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 0.887499\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 0.873755\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 0.860301\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 0.847144\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 0.834285\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 0.821715\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 0.809394\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 0.797363\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 0.785600\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 0.774110\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 0.762846\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 0.751848\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 0.741086\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 0.730564\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 0.720260\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 0.710174\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 0.700313\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 0.690644\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 0.681186\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 0.671918\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 0.662853\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 0.653968\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 0.645260\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 0.636738\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 0.628354\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 0.620136\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 0.612084\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 0.604200\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 0.596489\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 0.588906\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 0.581490\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.574189\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.567000\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.559984\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.553097\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.546329\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.539692\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.533167\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.526769\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.520501\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.514354\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.508287\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.502331\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.496466\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.490717\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.485100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 48 finished \tRBM Reconstruction error 0.479554\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.474076\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.468692\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.463397\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.458197\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.453097\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.448094\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.443162\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.438317\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.433547\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.428853\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.424267\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.419772\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.415312\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.410914\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.406597\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.402378\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.398236\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.394189\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.390179\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.386218\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.382325\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.378502\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.374745\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.371061\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.367449\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.363907\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.360406\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.356964\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.353588\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.350268\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.346986\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.343762\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.340603\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.337498\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.334426\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.331424\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.328493\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.325625\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.322792\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.320053\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.317289\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.314577\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.311927\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.309342\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.306770\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.304228\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.301765\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.299306\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.296884\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.294546\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.292199\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.289913\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.092036\n",
      ">> Epoch 2 finished \tANN training loss 0.085267\n",
      ">> Epoch 3 finished \tANN training loss 0.079025\n",
      ">> Epoch 4 finished \tANN training loss 0.073267\n",
      ">> Epoch 5 finished \tANN training loss 0.067954\n",
      ">> Epoch 6 finished \tANN training loss 0.063048\n",
      ">> Epoch 7 finished \tANN training loss 0.058515\n",
      ">> Epoch 8 finished \tANN training loss 0.054320\n",
      ">> Epoch 9 finished \tANN training loss 0.050429\n",
      ">> Epoch 10 finished \tANN training loss 0.046818\n",
      ">> Epoch 11 finished \tANN training loss 0.043472\n",
      ">> Epoch 12 finished \tANN training loss 0.040381\n",
      ">> Epoch 13 finished \tANN training loss 0.037530\n",
      ">> Epoch 14 finished \tANN training loss 0.034900\n",
      ">> Epoch 15 finished \tANN training loss 0.032473\n",
      ">> Epoch 16 finished \tANN training loss 0.030235\n",
      ">> Epoch 17 finished \tANN training loss 0.028171\n",
      ">> Epoch 18 finished \tANN training loss 0.026266\n",
      ">> Epoch 19 finished \tANN training loss 0.024509\n",
      ">> Epoch 20 finished \tANN training loss 0.022887\n",
      ">> Epoch 21 finished \tANN training loss 0.021390\n",
      ">> Epoch 22 finished \tANN training loss 0.020007\n",
      ">> Epoch 23 finished \tANN training loss 0.018731\n",
      ">> Epoch 24 finished \tANN training loss 0.017552\n",
      ">> Epoch 25 finished \tANN training loss 0.016463\n",
      ">> Epoch 26 finished \tANN training loss 0.015457\n",
      ">> Epoch 27 finished \tANN training loss 0.014527\n",
      ">> Epoch 28 finished \tANN training loss 0.013668\n",
      ">> Epoch 29 finished \tANN training loss 0.012874\n",
      ">> Epoch 30 finished \tANN training loss 0.012140\n",
      ">> Epoch 31 finished \tANN training loss 0.011460\n",
      ">> Epoch 32 finished \tANN training loss 0.010832\n",
      ">> Epoch 33 finished \tANN training loss 0.010250\n",
      ">> Epoch 34 finished \tANN training loss 0.009712\n",
      ">> Epoch 35 finished \tANN training loss 0.009213\n",
      ">> Epoch 36 finished \tANN training loss 0.008751\n",
      ">> Epoch 37 finished \tANN training loss 0.008323\n",
      ">> Epoch 38 finished \tANN training loss 0.007927\n",
      ">> Epoch 39 finished \tANN training loss 0.007559\n",
      ">> Epoch 40 finished \tANN training loss 0.007217\n",
      ">> Epoch 41 finished \tANN training loss 0.006900\n",
      ">> Epoch 42 finished \tANN training loss 0.006605\n",
      ">> Epoch 43 finished \tANN training loss 0.006330\n",
      ">> Epoch 44 finished \tANN training loss 0.006074\n",
      ">> Epoch 45 finished \tANN training loss 0.005836\n",
      ">> Epoch 46 finished \tANN training loss 0.005614\n",
      ">> Epoch 47 finished \tANN training loss 0.005407\n",
      ">> Epoch 48 finished \tANN training loss 0.005214\n",
      ">> Epoch 49 finished \tANN training loss 0.005033\n",
      ">> Epoch 50 finished \tANN training loss 0.004865\n",
      ">> Epoch 51 finished \tANN training loss 0.004708\n",
      ">> Epoch 52 finished \tANN training loss 0.004561\n",
      ">> Epoch 53 finished \tANN training loss 0.004423\n",
      ">> Epoch 54 finished \tANN training loss 0.004294\n",
      ">> Epoch 55 finished \tANN training loss 0.004173\n",
      ">> Epoch 56 finished \tANN training loss 0.004059\n",
      ">> Epoch 57 finished \tANN training loss 0.003953\n",
      ">> Epoch 58 finished \tANN training loss 0.003852\n",
      ">> Epoch 59 finished \tANN training loss 0.003758\n",
      ">> Epoch 60 finished \tANN training loss 0.003669\n",
      ">> Epoch 61 finished \tANN training loss 0.003585\n",
      ">> Epoch 62 finished \tANN training loss 0.003505\n",
      ">> Epoch 63 finished \tANN training loss 0.003430\n",
      ">> Epoch 64 finished \tANN training loss 0.003359\n",
      ">> Epoch 65 finished \tANN training loss 0.003291\n",
      ">> Epoch 66 finished \tANN training loss 0.003227\n",
      ">> Epoch 67 finished \tANN training loss 0.003166\n",
      ">> Epoch 68 finished \tANN training loss 0.003108\n",
      ">> Epoch 69 finished \tANN training loss 0.003053\n",
      ">> Epoch 70 finished \tANN training loss 0.003000\n",
      ">> Epoch 71 finished \tANN training loss 0.002950\n",
      ">> Epoch 72 finished \tANN training loss 0.002902\n",
      ">> Epoch 73 finished \tANN training loss 0.002855\n",
      ">> Epoch 74 finished \tANN training loss 0.002811\n",
      ">> Epoch 75 finished \tANN training loss 0.002769\n",
      ">> Epoch 76 finished \tANN training loss 0.002728\n",
      ">> Epoch 77 finished \tANN training loss 0.002689\n",
      ">> Epoch 78 finished \tANN training loss 0.002651\n",
      ">> Epoch 79 finished \tANN training loss 0.002615\n",
      ">> Epoch 80 finished \tANN training loss 0.002580\n",
      ">> Epoch 81 finished \tANN training loss 0.002546\n",
      ">> Epoch 82 finished \tANN training loss 0.002513\n",
      ">> Epoch 83 finished \tANN training loss 0.002482\n",
      ">> Epoch 84 finished \tANN training loss 0.002452\n",
      ">> Epoch 85 finished \tANN training loss 0.002423\n",
      ">> Epoch 86 finished \tANN training loss 0.002395\n",
      ">> Epoch 87 finished \tANN training loss 0.002368\n",
      ">> Epoch 88 finished \tANN training loss 0.002342\n",
      ">> Epoch 89 finished \tANN training loss 0.002316\n",
      ">> Epoch 90 finished \tANN training loss 0.002292\n",
      ">> Epoch 91 finished \tANN training loss 0.002268\n",
      ">> Epoch 92 finished \tANN training loss 0.002244\n",
      ">> Epoch 93 finished \tANN training loss 0.002221\n",
      ">> Epoch 94 finished \tANN training loss 0.002199\n",
      ">> Epoch 95 finished \tANN training loss 0.002177\n",
      ">> Epoch 96 finished \tANN training loss 0.002155\n",
      ">> Epoch 97 finished \tANN training loss 0.002134\n",
      ">> Epoch 98 finished \tANN training loss 0.002114\n",
      ">> Epoch 99 finished \tANN training loss 0.002093\n",
      ">> Epoch 100 finished \tANN training loss 0.002074\n",
      ">> Epoch 101 finished \tANN training loss 0.002054\n",
      ">> Epoch 102 finished \tANN training loss 0.002035\n",
      ">> Epoch 103 finished \tANN training loss 0.002016\n",
      ">> Epoch 104 finished \tANN training loss 0.001997\n",
      ">> Epoch 105 finished \tANN training loss 0.001979\n",
      ">> Epoch 106 finished \tANN training loss 0.001961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 107 finished \tANN training loss 0.001943\n",
      ">> Epoch 108 finished \tANN training loss 0.001926\n",
      ">> Epoch 109 finished \tANN training loss 0.001909\n",
      ">> Epoch 110 finished \tANN training loss 0.001892\n",
      ">> Epoch 111 finished \tANN training loss 0.001875\n",
      ">> Epoch 112 finished \tANN training loss 0.001859\n",
      ">> Epoch 113 finished \tANN training loss 0.001843\n",
      ">> Epoch 114 finished \tANN training loss 0.001827\n",
      ">> Epoch 115 finished \tANN training loss 0.001811\n",
      ">> Epoch 116 finished \tANN training loss 0.001795\n",
      ">> Epoch 117 finished \tANN training loss 0.001780\n",
      ">> Epoch 118 finished \tANN training loss 0.001765\n",
      ">> Epoch 119 finished \tANN training loss 0.001750\n",
      ">> Epoch 120 finished \tANN training loss 0.001735\n",
      ">> Epoch 121 finished \tANN training loss 0.001720\n",
      ">> Epoch 122 finished \tANN training loss 0.001706\n",
      ">> Epoch 123 finished \tANN training loss 0.001691\n",
      ">> Epoch 124 finished \tANN training loss 0.001677\n",
      ">> Epoch 125 finished \tANN training loss 0.001663\n",
      ">> Epoch 126 finished \tANN training loss 0.001649\n",
      ">> Epoch 127 finished \tANN training loss 0.001636\n",
      ">> Epoch 128 finished \tANN training loss 0.001622\n",
      ">> Epoch 129 finished \tANN training loss 0.001609\n",
      ">> Epoch 130 finished \tANN training loss 0.001596\n",
      ">> Epoch 131 finished \tANN training loss 0.001583\n",
      ">> Epoch 132 finished \tANN training loss 0.001570\n",
      ">> Epoch 133 finished \tANN training loss 0.001557\n",
      ">> Epoch 134 finished \tANN training loss 0.001545\n",
      ">> Epoch 135 finished \tANN training loss 0.001532\n",
      ">> Epoch 136 finished \tANN training loss 0.001520\n",
      ">> Epoch 137 finished \tANN training loss 0.001508\n",
      ">> Epoch 138 finished \tANN training loss 0.001496\n",
      ">> Epoch 139 finished \tANN training loss 0.001484\n",
      ">> Epoch 140 finished \tANN training loss 0.001472\n",
      ">> Epoch 141 finished \tANN training loss 0.001461\n",
      ">> Epoch 142 finished \tANN training loss 0.001449\n",
      ">> Epoch 143 finished \tANN training loss 0.001438\n",
      ">> Epoch 144 finished \tANN training loss 0.001427\n",
      ">> Epoch 145 finished \tANN training loss 0.001416\n",
      ">> Epoch 146 finished \tANN training loss 0.001405\n",
      ">> Epoch 147 finished \tANN training loss 0.001394\n",
      ">> Epoch 148 finished \tANN training loss 0.001383\n",
      ">> Epoch 149 finished \tANN training loss 0.001372\n",
      ">> Epoch 150 finished \tANN training loss 0.001362\n",
      "[END] Fine tuning step\n",
      "############### End Training for BHARATFORGEQ #####################\n",
      "############### End Training for BHARTIARTLEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 15.161584\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 14.721633\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 14.206777\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 13.587338\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 12.825727\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 11.877396\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 10.697762\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 9.252935\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 7.549208\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 5.678693\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 3.827801\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 2.239674\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 1.115159\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 0.494474\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 0.254673\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 0.231395\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 0.296491\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 0.375310\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 0.444102\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 0.498262\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 0.530329\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 0.554649\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 0.565210\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 0.571055\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 0.582204\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 0.586871\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 0.589847\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 0.596894\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 0.601214\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 0.598651\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 0.596543\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 0.603647\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.599351\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.603554\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.604508\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.605469\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.606936\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.609727\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.610637\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.612315\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.610164\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.607947\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.604837\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.613958\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.616323\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.618778\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.617323\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.617646\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.618404\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.611734\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.612618\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.611215\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.615331\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.620955\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.620566\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.620249\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.620411\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.617853\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.614869\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.627078\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.620199\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.621349\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.616622\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.616966\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.614745\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.623686\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.624543\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.624124\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.625198\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.628425\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.633509\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.631255\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.633933\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.634306\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.642434\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.641182\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.635759\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.636767\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.636409\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.636318\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.643729\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.638549\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.635590\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.627114\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.624937\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.630199\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.629240\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.628076\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.627728\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.630612\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.632235\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.635016\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.637116\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.642675\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.644504\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.640268\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.640240\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.643847\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.652533\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.650678\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.050633\n",
      ">> Epoch 2 finished \tANN training loss 0.029428\n",
      ">> Epoch 3 finished \tANN training loss 0.017401\n",
      ">> Epoch 4 finished \tANN training loss 0.010631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 5 finished \tANN training loss 0.006835\n",
      ">> Epoch 6 finished \tANN training loss 0.004708\n",
      ">> Epoch 7 finished \tANN training loss 0.003517\n",
      ">> Epoch 8 finished \tANN training loss 0.002851\n",
      ">> Epoch 9 finished \tANN training loss 0.002478\n",
      ">> Epoch 10 finished \tANN training loss 0.002270\n",
      ">> Epoch 11 finished \tANN training loss 0.002153\n",
      ">> Epoch 12 finished \tANN training loss 0.002087\n",
      ">> Epoch 13 finished \tANN training loss 0.002051\n",
      ">> Epoch 14 finished \tANN training loss 0.002029\n",
      ">> Epoch 15 finished \tANN training loss 0.002017\n",
      ">> Epoch 16 finished \tANN training loss 0.002009\n",
      ">> Epoch 17 finished \tANN training loss 0.002004\n",
      ">> Epoch 18 finished \tANN training loss 0.002001\n",
      ">> Epoch 19 finished \tANN training loss 0.001999\n",
      ">> Epoch 20 finished \tANN training loss 0.001997\n",
      ">> Epoch 21 finished \tANN training loss 0.001995\n",
      ">> Epoch 22 finished \tANN training loss 0.001994\n",
      ">> Epoch 23 finished \tANN training loss 0.001992\n",
      ">> Epoch 24 finished \tANN training loss 0.001991\n",
      ">> Epoch 25 finished \tANN training loss 0.001990\n",
      ">> Epoch 26 finished \tANN training loss 0.001988\n",
      ">> Epoch 27 finished \tANN training loss 0.001987\n",
      ">> Epoch 28 finished \tANN training loss 0.001986\n",
      ">> Epoch 29 finished \tANN training loss 0.001985\n",
      ">> Epoch 30 finished \tANN training loss 0.001983\n",
      ">> Epoch 31 finished \tANN training loss 0.001982\n",
      ">> Epoch 32 finished \tANN training loss 0.001981\n",
      ">> Epoch 33 finished \tANN training loss 0.001980\n",
      ">> Epoch 34 finished \tANN training loss 0.001979\n",
      ">> Epoch 35 finished \tANN training loss 0.001977\n",
      ">> Epoch 36 finished \tANN training loss 0.001976\n",
      ">> Epoch 37 finished \tANN training loss 0.001975\n",
      ">> Epoch 38 finished \tANN training loss 0.001974\n",
      ">> Epoch 39 finished \tANN training loss 0.001973\n",
      ">> Epoch 40 finished \tANN training loss 0.001972\n",
      ">> Epoch 41 finished \tANN training loss 0.001970\n",
      ">> Epoch 42 finished \tANN training loss 0.001969\n",
      ">> Epoch 43 finished \tANN training loss 0.001968\n",
      ">> Epoch 44 finished \tANN training loss 0.001967\n",
      ">> Epoch 45 finished \tANN training loss 0.001966\n",
      ">> Epoch 46 finished \tANN training loss 0.001965\n",
      ">> Epoch 47 finished \tANN training loss 0.001964\n",
      ">> Epoch 48 finished \tANN training loss 0.001963\n",
      ">> Epoch 49 finished \tANN training loss 0.001962\n",
      ">> Epoch 50 finished \tANN training loss 0.001961\n",
      ">> Epoch 51 finished \tANN training loss 0.001959\n",
      ">> Epoch 52 finished \tANN training loss 0.001958\n",
      ">> Epoch 53 finished \tANN training loss 0.001957\n",
      ">> Epoch 54 finished \tANN training loss 0.001956\n",
      ">> Epoch 55 finished \tANN training loss 0.001955\n",
      ">> Epoch 56 finished \tANN training loss 0.001954\n",
      ">> Epoch 57 finished \tANN training loss 0.001953\n",
      ">> Epoch 58 finished \tANN training loss 0.001952\n",
      ">> Epoch 59 finished \tANN training loss 0.001951\n",
      ">> Epoch 60 finished \tANN training loss 0.001950\n",
      ">> Epoch 61 finished \tANN training loss 0.001949\n",
      ">> Epoch 62 finished \tANN training loss 0.001948\n",
      ">> Epoch 63 finished \tANN training loss 0.001947\n",
      ">> Epoch 64 finished \tANN training loss 0.001946\n",
      ">> Epoch 65 finished \tANN training loss 0.001945\n",
      ">> Epoch 66 finished \tANN training loss 0.001944\n",
      ">> Epoch 67 finished \tANN training loss 0.001943\n",
      ">> Epoch 68 finished \tANN training loss 0.001942\n",
      ">> Epoch 69 finished \tANN training loss 0.001941\n",
      ">> Epoch 70 finished \tANN training loss 0.001940\n",
      ">> Epoch 71 finished \tANN training loss 0.001939\n",
      ">> Epoch 72 finished \tANN training loss 0.001938\n",
      ">> Epoch 73 finished \tANN training loss 0.001937\n",
      ">> Epoch 74 finished \tANN training loss 0.001936\n",
      ">> Epoch 75 finished \tANN training loss 0.001935\n",
      ">> Epoch 76 finished \tANN training loss 0.001935\n",
      ">> Epoch 77 finished \tANN training loss 0.001934\n",
      ">> Epoch 78 finished \tANN training loss 0.001933\n",
      ">> Epoch 79 finished \tANN training loss 0.001932\n",
      ">> Epoch 80 finished \tANN training loss 0.001931\n",
      ">> Epoch 81 finished \tANN training loss 0.001930\n",
      ">> Epoch 82 finished \tANN training loss 0.001929\n",
      ">> Epoch 83 finished \tANN training loss 0.001928\n",
      ">> Epoch 84 finished \tANN training loss 0.001927\n",
      ">> Epoch 85 finished \tANN training loss 0.001926\n",
      ">> Epoch 86 finished \tANN training loss 0.001925\n",
      ">> Epoch 87 finished \tANN training loss 0.001925\n",
      ">> Epoch 88 finished \tANN training loss 0.001924\n",
      ">> Epoch 89 finished \tANN training loss 0.001923\n",
      ">> Epoch 90 finished \tANN training loss 0.001922\n",
      ">> Epoch 91 finished \tANN training loss 0.001921\n",
      ">> Epoch 92 finished \tANN training loss 0.001920\n",
      ">> Epoch 93 finished \tANN training loss 0.001919\n",
      ">> Epoch 94 finished \tANN training loss 0.001918\n",
      ">> Epoch 95 finished \tANN training loss 0.001918\n",
      ">> Epoch 96 finished \tANN training loss 0.001917\n",
      ">> Epoch 97 finished \tANN training loss 0.001916\n",
      ">> Epoch 98 finished \tANN training loss 0.001915\n",
      ">> Epoch 99 finished \tANN training loss 0.001914\n",
      ">> Epoch 100 finished \tANN training loss 0.001913\n",
      ">> Epoch 101 finished \tANN training loss 0.001912\n",
      ">> Epoch 102 finished \tANN training loss 0.001912\n",
      ">> Epoch 103 finished \tANN training loss 0.001911\n",
      ">> Epoch 104 finished \tANN training loss 0.001910\n",
      ">> Epoch 105 finished \tANN training loss 0.001909\n",
      ">> Epoch 106 finished \tANN training loss 0.001908\n",
      ">> Epoch 107 finished \tANN training loss 0.001908\n",
      ">> Epoch 108 finished \tANN training loss 0.001907\n",
      ">> Epoch 109 finished \tANN training loss 0.001906\n",
      ">> Epoch 110 finished \tANN training loss 0.001905\n",
      ">> Epoch 111 finished \tANN training loss 0.001904\n",
      ">> Epoch 112 finished \tANN training loss 0.001904\n",
      ">> Epoch 113 finished \tANN training loss 0.001903\n",
      ">> Epoch 114 finished \tANN training loss 0.001902\n",
      ">> Epoch 115 finished \tANN training loss 0.001901\n",
      ">> Epoch 116 finished \tANN training loss 0.001900\n",
      ">> Epoch 117 finished \tANN training loss 0.001900\n",
      ">> Epoch 118 finished \tANN training loss 0.001899\n",
      ">> Epoch 119 finished \tANN training loss 0.001898\n",
      ">> Epoch 120 finished \tANN training loss 0.001897\n",
      ">> Epoch 121 finished \tANN training loss 0.001897\n",
      ">> Epoch 122 finished \tANN training loss 0.001896\n",
      ">> Epoch 123 finished \tANN training loss 0.001895\n",
      ">> Epoch 124 finished \tANN training loss 0.001894\n",
      ">> Epoch 125 finished \tANN training loss 0.001894\n",
      ">> Epoch 126 finished \tANN training loss 0.001893\n",
      ">> Epoch 127 finished \tANN training loss 0.001892\n",
      ">> Epoch 128 finished \tANN training loss 0.001891\n",
      ">> Epoch 129 finished \tANN training loss 0.001891\n",
      ">> Epoch 130 finished \tANN training loss 0.001890\n",
      ">> Epoch 131 finished \tANN training loss 0.001889\n",
      ">> Epoch 132 finished \tANN training loss 0.001889\n",
      ">> Epoch 133 finished \tANN training loss 0.001888\n",
      ">> Epoch 134 finished \tANN training loss 0.001887\n",
      ">> Epoch 135 finished \tANN training loss 0.001886\n",
      ">> Epoch 136 finished \tANN training loss 0.001886\n",
      ">> Epoch 137 finished \tANN training loss 0.001885\n",
      ">> Epoch 138 finished \tANN training loss 0.001884\n",
      ">> Epoch 139 finished \tANN training loss 0.001884\n",
      ">> Epoch 140 finished \tANN training loss 0.001883\n",
      ">> Epoch 141 finished \tANN training loss 0.001882\n",
      ">> Epoch 142 finished \tANN training loss 0.001881\n",
      ">> Epoch 143 finished \tANN training loss 0.001881\n",
      ">> Epoch 144 finished \tANN training loss 0.001880\n",
      ">> Epoch 145 finished \tANN training loss 0.001879\n",
      ">> Epoch 146 finished \tANN training loss 0.001879\n",
      ">> Epoch 147 finished \tANN training loss 0.001878\n",
      ">> Epoch 148 finished \tANN training loss 0.001877\n",
      ">> Epoch 149 finished \tANN training loss 0.001877\n",
      ">> Epoch 150 finished \tANN training loss 0.001876\n",
      "[END] Fine tuning step\n",
      "############### End Training for BHARTIARTLEQ #####################\n",
      "############### End Training for RAMCOCEMEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 4.275589\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 4.274479\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 4.273370\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 4.272252\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 4.271137\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 4.270021\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 4.268909\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 4.267793\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 4.266683\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 4.265575\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 4.264462\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 4.263349\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 4.262235\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 4.261123\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 4.260005\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 4.258893\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 4.257783\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 4.256670\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 4.255560\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 4.254447\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 4.253338\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 4.252224\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 4.251112\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 4.250001\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 4.248890\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 4.247776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 27 finished \tRBM Reconstruction error 4.246663\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 4.245548\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 4.244431\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 4.243322\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 4.242216\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 4.241103\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 4.239992\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 4.238882\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 4.237776\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 4.236667\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 4.235561\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 4.234455\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 4.233343\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 4.232228\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 4.231118\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 4.230008\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 4.228894\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 4.227779\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 4.226667\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 4.225558\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 4.224452\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 4.223341\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 4.222232\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 4.221124\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 4.220010\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 4.218896\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 4.217785\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 4.216672\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 4.215558\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 4.214449\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 4.213333\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 4.212225\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 4.211116\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 4.210003\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 4.208896\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 4.207787\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 4.206677\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 4.205564\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 4.204456\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 4.203349\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 4.202238\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 4.201131\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 4.200026\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 4.198910\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 4.197801\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 4.196689\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 4.195579\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 4.194471\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 4.193364\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 4.192255\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 4.191142\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 4.190032\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 4.188923\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 4.187817\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 4.186706\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 4.185600\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 4.184494\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 4.183383\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 4.182277\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 4.181168\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 4.180061\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 4.178949\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 4.177844\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 4.176729\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 4.175622\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 4.174516\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 4.173408\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 4.172299\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 4.171193\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 4.170084\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 4.168978\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 4.167878\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 4.166767\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 4.165661\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.306417\n",
      ">> Epoch 2 finished \tANN training loss 0.306057\n",
      ">> Epoch 3 finished \tANN training loss 0.305709\n",
      ">> Epoch 4 finished \tANN training loss 0.305355\n",
      ">> Epoch 5 finished \tANN training loss 0.305009\n",
      ">> Epoch 6 finished \tANN training loss 0.304665\n",
      ">> Epoch 7 finished \tANN training loss 0.304301\n",
      ">> Epoch 8 finished \tANN training loss 0.303959\n",
      ">> Epoch 9 finished \tANN training loss 0.303606\n",
      ">> Epoch 10 finished \tANN training loss 0.303259\n",
      ">> Epoch 11 finished \tANN training loss 0.302906\n",
      ">> Epoch 12 finished \tANN training loss 0.302567\n",
      ">> Epoch 13 finished \tANN training loss 0.302207\n",
      ">> Epoch 14 finished \tANN training loss 0.301863\n",
      ">> Epoch 15 finished \tANN training loss 0.301517\n",
      ">> Epoch 16 finished \tANN training loss 0.301174\n",
      ">> Epoch 17 finished \tANN training loss 0.300824\n",
      ">> Epoch 18 finished \tANN training loss 0.300479\n",
      ">> Epoch 19 finished \tANN training loss 0.300135\n",
      ">> Epoch 20 finished \tANN training loss 0.299789\n",
      ">> Epoch 21 finished \tANN training loss 0.299436\n",
      ">> Epoch 22 finished \tANN training loss 0.299092\n",
      ">> Epoch 23 finished \tANN training loss 0.298754\n",
      ">> Epoch 24 finished \tANN training loss 0.298406\n",
      ">> Epoch 25 finished \tANN training loss 0.298083\n",
      ">> Epoch 26 finished \tANN training loss 0.297721\n",
      ">> Epoch 27 finished \tANN training loss 0.297390\n",
      ">> Epoch 28 finished \tANN training loss 0.297038\n",
      ">> Epoch 29 finished \tANN training loss 0.296696\n",
      ">> Epoch 30 finished \tANN training loss 0.296348\n",
      ">> Epoch 31 finished \tANN training loss 0.296013\n",
      ">> Epoch 32 finished \tANN training loss 0.295660\n",
      ">> Epoch 33 finished \tANN training loss 0.295322\n",
      ">> Epoch 34 finished \tANN training loss 0.294986\n",
      ">> Epoch 35 finished \tANN training loss 0.294644\n",
      ">> Epoch 36 finished \tANN training loss 0.294307\n",
      ">> Epoch 37 finished \tANN training loss 0.293978\n",
      ">> Epoch 38 finished \tANN training loss 0.293639\n",
      ">> Epoch 39 finished \tANN training loss 0.293303\n",
      ">> Epoch 40 finished \tANN training loss 0.292952\n",
      ">> Epoch 41 finished \tANN training loss 0.292619\n",
      ">> Epoch 42 finished \tANN training loss 0.292295\n",
      ">> Epoch 43 finished \tANN training loss 0.291949\n",
      ">> Epoch 44 finished \tANN training loss 0.291617\n",
      ">> Epoch 45 finished \tANN training loss 0.291284\n",
      ">> Epoch 46 finished \tANN training loss 0.290948\n",
      ">> Epoch 47 finished \tANN training loss 0.290607\n",
      ">> Epoch 48 finished \tANN training loss 0.290273\n",
      ">> Epoch 49 finished \tANN training loss 0.289939\n",
      ">> Epoch 50 finished \tANN training loss 0.289609\n",
      ">> Epoch 51 finished \tANN training loss 0.289282\n",
      ">> Epoch 52 finished \tANN training loss 0.288948\n",
      ">> Epoch 53 finished \tANN training loss 0.288611\n",
      ">> Epoch 54 finished \tANN training loss 0.288280\n",
      ">> Epoch 55 finished \tANN training loss 0.287951\n",
      ">> Epoch 56 finished \tANN training loss 0.287637\n",
      ">> Epoch 57 finished \tANN training loss 0.287291\n",
      ">> Epoch 58 finished \tANN training loss 0.286954\n",
      ">> Epoch 59 finished \tANN training loss 0.286631\n",
      ">> Epoch 60 finished \tANN training loss 0.286301\n",
      ">> Epoch 61 finished \tANN training loss 0.285967\n",
      ">> Epoch 62 finished \tANN training loss 0.285637\n",
      ">> Epoch 63 finished \tANN training loss 0.285312\n",
      ">> Epoch 64 finished \tANN training loss 0.284977\n",
      ">> Epoch 65 finished \tANN training loss 0.284653\n",
      ">> Epoch 66 finished \tANN training loss 0.284337\n",
      ">> Epoch 67 finished \tANN training loss 0.284006\n",
      ">> Epoch 68 finished \tANN training loss 0.283673\n",
      ">> Epoch 69 finished \tANN training loss 0.283359\n",
      ">> Epoch 70 finished \tANN training loss 0.283021\n",
      ">> Epoch 71 finished \tANN training loss 0.282703\n",
      ">> Epoch 72 finished \tANN training loss 0.282370\n",
      ">> Epoch 73 finished \tANN training loss 0.282045\n",
      ">> Epoch 74 finished \tANN training loss 0.281728\n",
      ">> Epoch 75 finished \tANN training loss 0.281403\n",
      ">> Epoch 76 finished \tANN training loss 0.281076\n",
      ">> Epoch 77 finished \tANN training loss 0.280762\n",
      ">> Epoch 78 finished \tANN training loss 0.280427\n",
      ">> Epoch 79 finished \tANN training loss 0.280111\n",
      ">> Epoch 80 finished \tANN training loss 0.279800\n",
      ">> Epoch 81 finished \tANN training loss 0.279463\n",
      ">> Epoch 82 finished \tANN training loss 0.279146\n",
      ">> Epoch 83 finished \tANN training loss 0.278823\n",
      ">> Epoch 84 finished \tANN training loss 0.278509\n",
      ">> Epoch 85 finished \tANN training loss 0.278187\n",
      ">> Epoch 86 finished \tANN training loss 0.277866\n",
      ">> Epoch 87 finished \tANN training loss 0.277550\n",
      ">> Epoch 88 finished \tANN training loss 0.277230\n",
      ">> Epoch 89 finished \tANN training loss 0.276921\n",
      ">> Epoch 90 finished \tANN training loss 0.276599\n",
      ">> Epoch 91 finished \tANN training loss 0.276270\n",
      ">> Epoch 92 finished \tANN training loss 0.275969\n",
      ">> Epoch 93 finished \tANN training loss 0.275640\n",
      ">> Epoch 94 finished \tANN training loss 0.275326\n",
      ">> Epoch 95 finished \tANN training loss 0.275018\n",
      ">> Epoch 96 finished \tANN training loss 0.274693\n",
      ">> Epoch 97 finished \tANN training loss 0.274380\n",
      ">> Epoch 98 finished \tANN training loss 0.274069\n",
      ">> Epoch 99 finished \tANN training loss 0.273754\n",
      ">> Epoch 100 finished \tANN training loss 0.273440\n",
      ">> Epoch 101 finished \tANN training loss 0.273124\n",
      ">> Epoch 102 finished \tANN training loss 0.272810\n",
      ">> Epoch 103 finished \tANN training loss 0.272492\n",
      ">> Epoch 104 finished \tANN training loss 0.272190\n",
      ">> Epoch 105 finished \tANN training loss 0.271872\n",
      ">> Epoch 106 finished \tANN training loss 0.271567\n",
      ">> Epoch 107 finished \tANN training loss 0.271257\n",
      ">> Epoch 108 finished \tANN training loss 0.270948\n",
      ">> Epoch 109 finished \tANN training loss 0.270625\n",
      ">> Epoch 110 finished \tANN training loss 0.270311\n",
      ">> Epoch 111 finished \tANN training loss 0.270008\n",
      ">> Epoch 112 finished \tANN training loss 0.269700\n",
      ">> Epoch 113 finished \tANN training loss 0.269398\n",
      ">> Epoch 114 finished \tANN training loss 0.269074\n",
      ">> Epoch 115 finished \tANN training loss 0.268774\n",
      ">> Epoch 116 finished \tANN training loss 0.268471\n",
      ">> Epoch 117 finished \tANN training loss 0.268150\n",
      ">> Epoch 118 finished \tANN training loss 0.267852\n",
      ">> Epoch 119 finished \tANN training loss 0.267551\n",
      ">> Epoch 120 finished \tANN training loss 0.267234\n",
      ">> Epoch 121 finished \tANN training loss 0.266938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 122 finished \tANN training loss 0.266620\n",
      ">> Epoch 123 finished \tANN training loss 0.266325\n",
      ">> Epoch 124 finished \tANN training loss 0.266014\n",
      ">> Epoch 125 finished \tANN training loss 0.265702\n",
      ">> Epoch 126 finished \tANN training loss 0.265408\n",
      ">> Epoch 127 finished \tANN training loss 0.265103\n",
      ">> Epoch 128 finished \tANN training loss 0.264798\n",
      ">> Epoch 129 finished \tANN training loss 0.264495\n",
      ">> Epoch 130 finished \tANN training loss 0.264194\n",
      ">> Epoch 131 finished \tANN training loss 0.263892\n",
      ">> Epoch 132 finished \tANN training loss 0.263592\n",
      ">> Epoch 133 finished \tANN training loss 0.263291\n",
      ">> Epoch 134 finished \tANN training loss 0.262993\n",
      ">> Epoch 135 finished \tANN training loss 0.262702\n",
      ">> Epoch 136 finished \tANN training loss 0.262392\n",
      ">> Epoch 137 finished \tANN training loss 0.262100\n",
      ">> Epoch 138 finished \tANN training loss 0.261797\n",
      ">> Epoch 139 finished \tANN training loss 0.261500\n",
      ">> Epoch 140 finished \tANN training loss 0.261205\n",
      ">> Epoch 141 finished \tANN training loss 0.260902\n",
      ">> Epoch 142 finished \tANN training loss 0.260605\n",
      ">> Epoch 143 finished \tANN training loss 0.260306\n",
      ">> Epoch 144 finished \tANN training loss 0.260024\n",
      ">> Epoch 145 finished \tANN training loss 0.259727\n",
      ">> Epoch 146 finished \tANN training loss 0.259419\n",
      ">> Epoch 147 finished \tANN training loss 0.259122\n",
      ">> Epoch 148 finished \tANN training loss 0.258830\n",
      ">> Epoch 149 finished \tANN training loss 0.258548\n",
      ">> Epoch 150 finished \tANN training loss 0.258243\n",
      "[END] Fine tuning step\n",
      "############### End Training for RAMCOCEMEQ #####################\n",
      "############### End Training for IDBIEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 7.326633\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 7.110966\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 6.879053\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 6.626546\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 6.348097\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 6.037973\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 5.690401\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 5.299335\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 4.860687\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 4.373947\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 3.842884\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 3.279507\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 2.704096\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 2.145619\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 1.637446\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 1.211016\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 0.877797\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 0.639786\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 0.480791\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 0.384170\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 0.327280\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 0.294921\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 0.276792\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 0.265877\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 0.258958\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 0.254147\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 0.250448\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 0.247388\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 0.244427\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 0.241833\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 0.239585\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 0.237379\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.235245\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.233262\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.230850\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.229270\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.227439\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.225270\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.223474\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.221628\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.220184\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.218597\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.216793\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.215534\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.213692\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.211987\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.210437\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.208852\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.207410\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.206008\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.204908\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.203686\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.202205\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.200776\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.199594\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.198303\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.196806\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.195282\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.193511\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.192044\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.191158\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.189975\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.188940\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.187671\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.186838\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.185638\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.184560\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.183056\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.181746\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.181114\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.180305\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.178870\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.177969\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.177122\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.175775\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.174760\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.173859\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.172612\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.171489\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.170011\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.169449\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.167641\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.166649\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.165916\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.165653\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.164724\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.164308\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.163531\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.162567\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.161390\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.160416\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.159206\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.158305\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.157780\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.157006\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.156328\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.156138\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.154687\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.153903\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.153552\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.322736\n",
      ">> Epoch 2 finished \tANN training loss 0.224462\n",
      ">> Epoch 3 finished \tANN training loss 0.156461\n",
      ">> Epoch 4 finished \tANN training loss 0.109271\n",
      ">> Epoch 5 finished \tANN training loss 0.076489\n",
      ">> Epoch 6 finished \tANN training loss 0.053776\n",
      ">> Epoch 7 finished \tANN training loss 0.038063\n",
      ">> Epoch 8 finished \tANN training loss 0.027204\n",
      ">> Epoch 9 finished \tANN training loss 0.019702\n",
      ">> Epoch 10 finished \tANN training loss 0.014521\n",
      ">> Epoch 11 finished \tANN training loss 0.010944\n",
      ">> Epoch 12 finished \tANN training loss 0.008481\n",
      ">> Epoch 13 finished \tANN training loss 0.006782\n",
      ">> Epoch 14 finished \tANN training loss 0.005610\n",
      ">> Epoch 15 finished \tANN training loss 0.004803\n",
      ">> Epoch 16 finished \tANN training loss 0.004248\n",
      ">> Epoch 17 finished \tANN training loss 0.003866\n",
      ">> Epoch 18 finished \tANN training loss 0.003601\n",
      ">> Epoch 19 finished \tANN training loss 0.003419\n",
      ">> Epoch 20 finished \tANN training loss 0.003293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 21 finished \tANN training loss 0.003205\n",
      ">> Epoch 22 finished \tANN training loss 0.003145\n",
      ">> Epoch 23 finished \tANN training loss 0.003102\n",
      ">> Epoch 24 finished \tANN training loss 0.003072\n",
      ">> Epoch 25 finished \tANN training loss 0.003051\n",
      ">> Epoch 26 finished \tANN training loss 0.003035\n",
      ">> Epoch 27 finished \tANN training loss 0.003024\n",
      ">> Epoch 28 finished \tANN training loss 0.003015\n",
      ">> Epoch 29 finished \tANN training loss 0.003009\n",
      ">> Epoch 30 finished \tANN training loss 0.003003\n",
      ">> Epoch 31 finished \tANN training loss 0.002999\n",
      ">> Epoch 32 finished \tANN training loss 0.002995\n",
      ">> Epoch 33 finished \tANN training loss 0.002992\n",
      ">> Epoch 34 finished \tANN training loss 0.002989\n",
      ">> Epoch 35 finished \tANN training loss 0.002986\n",
      ">> Epoch 36 finished \tANN training loss 0.002983\n",
      ">> Epoch 37 finished \tANN training loss 0.002980\n",
      ">> Epoch 38 finished \tANN training loss 0.002978\n",
      ">> Epoch 39 finished \tANN training loss 0.002975\n",
      ">> Epoch 40 finished \tANN training loss 0.002973\n",
      ">> Epoch 41 finished \tANN training loss 0.002970\n",
      ">> Epoch 42 finished \tANN training loss 0.002968\n",
      ">> Epoch 43 finished \tANN training loss 0.002966\n",
      ">> Epoch 44 finished \tANN training loss 0.002963\n",
      ">> Epoch 45 finished \tANN training loss 0.002961\n",
      ">> Epoch 46 finished \tANN training loss 0.002958\n",
      ">> Epoch 47 finished \tANN training loss 0.002956\n",
      ">> Epoch 48 finished \tANN training loss 0.002954\n",
      ">> Epoch 49 finished \tANN training loss 0.002951\n",
      ">> Epoch 50 finished \tANN training loss 0.002949\n",
      ">> Epoch 51 finished \tANN training loss 0.002947\n",
      ">> Epoch 52 finished \tANN training loss 0.002944\n",
      ">> Epoch 53 finished \tANN training loss 0.002942\n",
      ">> Epoch 54 finished \tANN training loss 0.002940\n",
      ">> Epoch 55 finished \tANN training loss 0.002937\n",
      ">> Epoch 56 finished \tANN training loss 0.002935\n",
      ">> Epoch 57 finished \tANN training loss 0.002932\n",
      ">> Epoch 58 finished \tANN training loss 0.002930\n",
      ">> Epoch 59 finished \tANN training loss 0.002928\n",
      ">> Epoch 60 finished \tANN training loss 0.002925\n",
      ">> Epoch 61 finished \tANN training loss 0.002923\n",
      ">> Epoch 62 finished \tANN training loss 0.002921\n",
      ">> Epoch 63 finished \tANN training loss 0.002919\n",
      ">> Epoch 64 finished \tANN training loss 0.002916\n",
      ">> Epoch 65 finished \tANN training loss 0.002914\n",
      ">> Epoch 66 finished \tANN training loss 0.002912\n",
      ">> Epoch 67 finished \tANN training loss 0.002909\n",
      ">> Epoch 68 finished \tANN training loss 0.002907\n",
      ">> Epoch 69 finished \tANN training loss 0.002905\n",
      ">> Epoch 70 finished \tANN training loss 0.002902\n",
      ">> Epoch 71 finished \tANN training loss 0.002900\n",
      ">> Epoch 72 finished \tANN training loss 0.002898\n",
      ">> Epoch 73 finished \tANN training loss 0.002895\n",
      ">> Epoch 74 finished \tANN training loss 0.002893\n",
      ">> Epoch 75 finished \tANN training loss 0.002891\n",
      ">> Epoch 76 finished \tANN training loss 0.002888\n",
      ">> Epoch 77 finished \tANN training loss 0.002886\n",
      ">> Epoch 78 finished \tANN training loss 0.002884\n",
      ">> Epoch 79 finished \tANN training loss 0.002881\n",
      ">> Epoch 80 finished \tANN training loss 0.002879\n",
      ">> Epoch 81 finished \tANN training loss 0.002877\n",
      ">> Epoch 82 finished \tANN training loss 0.002874\n",
      ">> Epoch 83 finished \tANN training loss 0.002872\n",
      ">> Epoch 84 finished \tANN training loss 0.002870\n",
      ">> Epoch 85 finished \tANN training loss 0.002867\n",
      ">> Epoch 86 finished \tANN training loss 0.002865\n",
      ">> Epoch 87 finished \tANN training loss 0.002863\n",
      ">> Epoch 88 finished \tANN training loss 0.002860\n",
      ">> Epoch 89 finished \tANN training loss 0.002858\n",
      ">> Epoch 90 finished \tANN training loss 0.002856\n",
      ">> Epoch 91 finished \tANN training loss 0.002853\n",
      ">> Epoch 92 finished \tANN training loss 0.002851\n",
      ">> Epoch 93 finished \tANN training loss 0.002849\n",
      ">> Epoch 94 finished \tANN training loss 0.002846\n",
      ">> Epoch 95 finished \tANN training loss 0.002844\n",
      ">> Epoch 96 finished \tANN training loss 0.002841\n",
      ">> Epoch 97 finished \tANN training loss 0.002839\n",
      ">> Epoch 98 finished \tANN training loss 0.002837\n",
      ">> Epoch 99 finished \tANN training loss 0.002834\n",
      ">> Epoch 100 finished \tANN training loss 0.002832\n",
      ">> Epoch 101 finished \tANN training loss 0.002830\n",
      ">> Epoch 102 finished \tANN training loss 0.002827\n",
      ">> Epoch 103 finished \tANN training loss 0.002825\n",
      ">> Epoch 104 finished \tANN training loss 0.002822\n",
      ">> Epoch 105 finished \tANN training loss 0.002820\n",
      ">> Epoch 106 finished \tANN training loss 0.002818\n",
      ">> Epoch 107 finished \tANN training loss 0.002815\n",
      ">> Epoch 108 finished \tANN training loss 0.002813\n",
      ">> Epoch 109 finished \tANN training loss 0.002810\n",
      ">> Epoch 110 finished \tANN training loss 0.002808\n",
      ">> Epoch 111 finished \tANN training loss 0.002806\n",
      ">> Epoch 112 finished \tANN training loss 0.002803\n",
      ">> Epoch 113 finished \tANN training loss 0.002801\n",
      ">> Epoch 114 finished \tANN training loss 0.002798\n",
      ">> Epoch 115 finished \tANN training loss 0.002796\n",
      ">> Epoch 116 finished \tANN training loss 0.002794\n",
      ">> Epoch 117 finished \tANN training loss 0.002791\n",
      ">> Epoch 118 finished \tANN training loss 0.002789\n",
      ">> Epoch 119 finished \tANN training loss 0.002786\n",
      ">> Epoch 120 finished \tANN training loss 0.002784\n",
      ">> Epoch 121 finished \tANN training loss 0.002782\n",
      ">> Epoch 122 finished \tANN training loss 0.002779\n",
      ">> Epoch 123 finished \tANN training loss 0.002777\n",
      ">> Epoch 124 finished \tANN training loss 0.002775\n",
      ">> Epoch 125 finished \tANN training loss 0.002772\n",
      ">> Epoch 126 finished \tANN training loss 0.002770\n",
      ">> Epoch 127 finished \tANN training loss 0.002768\n",
      ">> Epoch 128 finished \tANN training loss 0.002765\n",
      ">> Epoch 129 finished \tANN training loss 0.002763\n",
      ">> Epoch 130 finished \tANN training loss 0.002761\n",
      ">> Epoch 131 finished \tANN training loss 0.002759\n",
      ">> Epoch 132 finished \tANN training loss 0.002756\n",
      ">> Epoch 133 finished \tANN training loss 0.002754\n",
      ">> Epoch 134 finished \tANN training loss 0.002752\n",
      ">> Epoch 135 finished \tANN training loss 0.002750\n",
      ">> Epoch 136 finished \tANN training loss 0.002748\n",
      ">> Epoch 137 finished \tANN training loss 0.002745\n",
      ">> Epoch 138 finished \tANN training loss 0.002743\n",
      ">> Epoch 139 finished \tANN training loss 0.002741\n",
      ">> Epoch 140 finished \tANN training loss 0.002739\n",
      ">> Epoch 141 finished \tANN training loss 0.002737\n",
      ">> Epoch 142 finished \tANN training loss 0.002735\n",
      ">> Epoch 143 finished \tANN training loss 0.002732\n",
      ">> Epoch 144 finished \tANN training loss 0.002730\n",
      ">> Epoch 145 finished \tANN training loss 0.002728\n",
      ">> Epoch 146 finished \tANN training loss 0.002726\n",
      ">> Epoch 147 finished \tANN training loss 0.002724\n",
      ">> Epoch 148 finished \tANN training loss 0.002722\n",
      ">> Epoch 149 finished \tANN training loss 0.002720\n",
      ">> Epoch 150 finished \tANN training loss 0.002718\n",
      "[END] Fine tuning step\n",
      "############### End Training for IDBIEQ #####################\n",
      "############### End Training for NATIONALUMEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 17.029990\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 17.023135\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 17.016265\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 17.009374\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 17.002484\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 16.995572\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 16.988656\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 16.981724\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 16.974782\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 16.967828\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 16.960875\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 16.953902\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 16.946922\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 16.939922\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 16.932921\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 16.925899\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 16.918864\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 16.911824\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 16.904778\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 16.897709\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 16.890629\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 16.883547\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 16.876451\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 16.869342\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 16.862238\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 16.855094\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 16.847945\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 16.840785\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 16.833606\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 16.826430\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 16.819227\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 16.812020\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 16.804800\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 16.797567\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 16.790325\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 16.783074\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 16.775797\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 16.768516\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 16.761223\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 16.753907\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 16.746584\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 16.739250\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 16.731903\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 16.724530\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 16.717159\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 16.709772\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 16.702382\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 16.694978\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 16.687543\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 16.680089\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 16.672633\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 16.665162\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 16.657683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 54 finished \tRBM Reconstruction error 16.650189\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 16.642674\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 16.635152\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 16.627616\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 16.620067\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 16.612484\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 16.604914\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 16.597316\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 16.589709\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 16.582070\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 16.574420\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 16.566771\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 16.559103\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 16.551407\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 16.543694\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 16.535970\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 16.528223\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 16.520482\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 16.512728\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 16.504944\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 16.497145\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 16.489339\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 16.481527\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 16.473672\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 16.465833\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 16.457961\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 16.450080\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 16.442176\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 16.434239\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 16.426300\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 16.418351\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 16.410365\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 16.402385\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 16.394376\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 16.386359\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 16.378338\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 16.370290\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 16.362220\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 16.354138\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 16.346037\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 16.337933\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 16.329801\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 16.321639\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 16.313480\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 16.305287\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 16.297078\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 16.288848\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.022187\n",
      ">> Epoch 2 finished \tANN training loss 0.022185\n",
      ">> Epoch 3 finished \tANN training loss 0.022185\n",
      ">> Epoch 4 finished \tANN training loss 0.022183\n",
      ">> Epoch 5 finished \tANN training loss 0.022183\n",
      ">> Epoch 6 finished \tANN training loss 0.022181\n",
      ">> Epoch 7 finished \tANN training loss 0.022180\n",
      ">> Epoch 8 finished \tANN training loss 0.022179\n",
      ">> Epoch 9 finished \tANN training loss 0.022178\n",
      ">> Epoch 10 finished \tANN training loss 0.022176\n",
      ">> Epoch 11 finished \tANN training loss 0.022175\n",
      ">> Epoch 12 finished \tANN training loss 0.022175\n",
      ">> Epoch 13 finished \tANN training loss 0.022173\n",
      ">> Epoch 14 finished \tANN training loss 0.022172\n",
      ">> Epoch 15 finished \tANN training loss 0.022171\n",
      ">> Epoch 16 finished \tANN training loss 0.022170\n",
      ">> Epoch 17 finished \tANN training loss 0.022169\n",
      ">> Epoch 18 finished \tANN training loss 0.022169\n",
      ">> Epoch 19 finished \tANN training loss 0.022168\n",
      ">> Epoch 20 finished \tANN training loss 0.022166\n",
      ">> Epoch 21 finished \tANN training loss 0.022165\n",
      ">> Epoch 22 finished \tANN training loss 0.022164\n",
      ">> Epoch 23 finished \tANN training loss 0.022164\n",
      ">> Epoch 24 finished \tANN training loss 0.022162\n",
      ">> Epoch 25 finished \tANN training loss 0.022161\n",
      ">> Epoch 26 finished \tANN training loss 0.022160\n",
      ">> Epoch 27 finished \tANN training loss 0.022159\n",
      ">> Epoch 28 finished \tANN training loss 0.022159\n",
      ">> Epoch 29 finished \tANN training loss 0.022157\n",
      ">> Epoch 30 finished \tANN training loss 0.022156\n",
      ">> Epoch 31 finished \tANN training loss 0.022155\n",
      ">> Epoch 32 finished \tANN training loss 0.022154\n",
      ">> Epoch 33 finished \tANN training loss 0.022153\n",
      ">> Epoch 34 finished \tANN training loss 0.022152\n",
      ">> Epoch 35 finished \tANN training loss 0.022151\n",
      ">> Epoch 36 finished \tANN training loss 0.022150\n",
      ">> Epoch 37 finished \tANN training loss 0.022148\n",
      ">> Epoch 38 finished \tANN training loss 0.022147\n",
      ">> Epoch 39 finished \tANN training loss 0.022146\n",
      ">> Epoch 40 finished \tANN training loss 0.022145\n",
      ">> Epoch 41 finished \tANN training loss 0.022144\n",
      ">> Epoch 42 finished \tANN training loss 0.022145\n",
      ">> Epoch 43 finished \tANN training loss 0.022143\n",
      ">> Epoch 44 finished \tANN training loss 0.022141\n",
      ">> Epoch 45 finished \tANN training loss 0.022142\n",
      ">> Epoch 46 finished \tANN training loss 0.022139\n",
      ">> Epoch 47 finished \tANN training loss 0.022138\n",
      ">> Epoch 48 finished \tANN training loss 0.022137\n",
      ">> Epoch 49 finished \tANN training loss 0.022136\n",
      ">> Epoch 50 finished \tANN training loss 0.022136\n",
      ">> Epoch 51 finished \tANN training loss 0.022134\n",
      ">> Epoch 52 finished \tANN training loss 0.022133\n",
      ">> Epoch 53 finished \tANN training loss 0.022132\n",
      ">> Epoch 54 finished \tANN training loss 0.022131\n",
      ">> Epoch 55 finished \tANN training loss 0.022130\n",
      ">> Epoch 56 finished \tANN training loss 0.022129\n",
      ">> Epoch 57 finished \tANN training loss 0.022128\n",
      ">> Epoch 58 finished \tANN training loss 0.022127\n",
      ">> Epoch 59 finished \tANN training loss 0.022126\n",
      ">> Epoch 60 finished \tANN training loss 0.022124\n",
      ">> Epoch 61 finished \tANN training loss 0.022123\n",
      ">> Epoch 62 finished \tANN training loss 0.022122\n",
      ">> Epoch 63 finished \tANN training loss 0.022121\n",
      ">> Epoch 64 finished \tANN training loss 0.022120\n",
      ">> Epoch 65 finished \tANN training loss 0.022119\n",
      ">> Epoch 66 finished \tANN training loss 0.022118\n",
      ">> Epoch 67 finished \tANN training loss 0.022117\n",
      ">> Epoch 68 finished \tANN training loss 0.022116\n",
      ">> Epoch 69 finished \tANN training loss 0.022115\n",
      ">> Epoch 70 finished \tANN training loss 0.022114\n",
      ">> Epoch 71 finished \tANN training loss 0.022112\n",
      ">> Epoch 72 finished \tANN training loss 0.022112\n",
      ">> Epoch 73 finished \tANN training loss 0.022110\n",
      ">> Epoch 74 finished \tANN training loss 0.022111\n",
      ">> Epoch 75 finished \tANN training loss 0.022108\n",
      ">> Epoch 76 finished \tANN training loss 0.022107\n",
      ">> Epoch 77 finished \tANN training loss 0.022106\n",
      ">> Epoch 78 finished \tANN training loss 0.022105\n",
      ">> Epoch 79 finished \tANN training loss 0.022104\n",
      ">> Epoch 80 finished \tANN training loss 0.022103\n",
      ">> Epoch 81 finished \tANN training loss 0.022102\n",
      ">> Epoch 82 finished \tANN training loss 0.022100\n",
      ">> Epoch 83 finished \tANN training loss 0.022099\n",
      ">> Epoch 84 finished \tANN training loss 0.022100\n",
      ">> Epoch 85 finished \tANN training loss 0.022100\n",
      ">> Epoch 86 finished \tANN training loss 0.022097\n",
      ">> Epoch 87 finished \tANN training loss 0.022095\n",
      ">> Epoch 88 finished \tANN training loss 0.022095\n",
      ">> Epoch 89 finished \tANN training loss 0.022094\n",
      ">> Epoch 90 finished \tANN training loss 0.022093\n",
      ">> Epoch 91 finished \tANN training loss 0.022091\n",
      ">> Epoch 92 finished \tANN training loss 0.022091\n",
      ">> Epoch 93 finished \tANN training loss 0.022089\n",
      ">> Epoch 94 finished \tANN training loss 0.022088\n",
      ">> Epoch 95 finished \tANN training loss 0.022087\n",
      ">> Epoch 96 finished \tANN training loss 0.022087\n",
      ">> Epoch 97 finished \tANN training loss 0.022085\n",
      ">> Epoch 98 finished \tANN training loss 0.022085\n",
      ">> Epoch 99 finished \tANN training loss 0.022083\n",
      ">> Epoch 100 finished \tANN training loss 0.022082\n",
      ">> Epoch 101 finished \tANN training loss 0.022082\n",
      ">> Epoch 102 finished \tANN training loss 0.022082\n",
      ">> Epoch 103 finished \tANN training loss 0.022079\n",
      ">> Epoch 104 finished \tANN training loss 0.022079\n",
      ">> Epoch 105 finished \tANN training loss 0.022077\n",
      ">> Epoch 106 finished \tANN training loss 0.022076\n",
      ">> Epoch 107 finished \tANN training loss 0.022075\n",
      ">> Epoch 108 finished \tANN training loss 0.022075\n",
      ">> Epoch 109 finished \tANN training loss 0.022076\n",
      ">> Epoch 110 finished \tANN training loss 0.022072\n",
      ">> Epoch 111 finished \tANN training loss 0.022072\n",
      ">> Epoch 112 finished \tANN training loss 0.022070\n",
      ">> Epoch 113 finished \tANN training loss 0.022070\n",
      ">> Epoch 114 finished \tANN training loss 0.022069\n",
      ">> Epoch 115 finished \tANN training loss 0.022068\n",
      ">> Epoch 116 finished \tANN training loss 0.022067\n",
      ">> Epoch 117 finished \tANN training loss 0.022067\n",
      ">> Epoch 118 finished \tANN training loss 0.022068\n",
      ">> Epoch 119 finished \tANN training loss 0.022064\n",
      ">> Epoch 120 finished \tANN training loss 0.022063\n",
      ">> Epoch 121 finished \tANN training loss 0.022063\n",
      ">> Epoch 122 finished \tANN training loss 0.022063\n",
      ">> Epoch 123 finished \tANN training loss 0.022060\n",
      ">> Epoch 124 finished \tANN training loss 0.022059\n",
      ">> Epoch 125 finished \tANN training loss 0.022059\n",
      ">> Epoch 126 finished \tANN training loss 0.022057\n",
      ">> Epoch 127 finished \tANN training loss 0.022057\n",
      ">> Epoch 128 finished \tANN training loss 0.022057\n",
      ">> Epoch 129 finished \tANN training loss 0.022055\n",
      ">> Epoch 130 finished \tANN training loss 0.022054\n",
      ">> Epoch 131 finished \tANN training loss 0.022054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 132 finished \tANN training loss 0.022052\n",
      ">> Epoch 133 finished \tANN training loss 0.022051\n",
      ">> Epoch 134 finished \tANN training loss 0.022051\n",
      ">> Epoch 135 finished \tANN training loss 0.022049\n",
      ">> Epoch 136 finished \tANN training loss 0.022049\n",
      ">> Epoch 137 finished \tANN training loss 0.022047\n",
      ">> Epoch 138 finished \tANN training loss 0.022046\n",
      ">> Epoch 139 finished \tANN training loss 0.022046\n",
      ">> Epoch 140 finished \tANN training loss 0.022045\n",
      ">> Epoch 141 finished \tANN training loss 0.022043\n",
      ">> Epoch 142 finished \tANN training loss 0.022043\n",
      ">> Epoch 143 finished \tANN training loss 0.022042\n",
      ">> Epoch 144 finished \tANN training loss 0.022041\n",
      ">> Epoch 145 finished \tANN training loss 0.022040\n",
      ">> Epoch 146 finished \tANN training loss 0.022039\n",
      ">> Epoch 147 finished \tANN training loss 0.022038\n",
      ">> Epoch 148 finished \tANN training loss 0.022037\n",
      ">> Epoch 149 finished \tANN training loss 0.022036\n",
      ">> Epoch 150 finished \tANN training loss 0.022035\n",
      "[END] Fine tuning step\n",
      "############### End Training for NATIONALUMEQ #####################\n",
      "############### End Training for TATASTEELEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 7.220116\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 7.033256\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 6.831265\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 6.609985\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 6.364556\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 6.089751\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 5.779986\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 5.429415\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 5.033192\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 4.589008\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 4.097903\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 3.566663\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 3.010456\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 2.455668\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 1.928847\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 1.465315\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 1.084491\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 0.798313\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 0.597912\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 0.467964\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 0.384834\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 0.335901\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 0.306689\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 0.289244\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 0.277962\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 0.269292\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 0.262780\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 0.257587\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 0.252986\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 0.248876\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 0.245134\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 0.241591\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.238367\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.235212\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.232082\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.229032\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.226097\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.223382\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.220735\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.218029\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.215326\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.212937\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.210575\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.207934\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.205582\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.203539\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.201403\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.199078\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.196730\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.194575\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.192728\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.191044\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.188556\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.186684\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.184860\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.182999\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.180882\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.179002\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.177328\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.175561\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.173702\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.171732\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.170105\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.168693\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.167120\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.165649\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.164033\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.162357\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.160674\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.159364\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.157722\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.156083\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.154677\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.153626\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.152252\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.150727\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.149529\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.148318\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.147110\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.145862\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.145090\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.143637\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.142592\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.141358\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.140062\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.139017\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.138195\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.137213\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.136429\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.135544\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.134834\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.133719\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.132712\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.131357\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.130954\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.130291\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.128752\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.128198\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.127977\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.127169\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.295888\n",
      ">> Epoch 2 finished \tANN training loss 0.207584\n",
      ">> Epoch 3 finished \tANN training loss 0.148075\n",
      ">> Epoch 4 finished \tANN training loss 0.107809\n",
      ">> Epoch 5 finished \tANN training loss 0.080459\n",
      ">> Epoch 6 finished \tANN training loss 0.061827\n",
      ">> Epoch 7 finished \tANN training loss 0.049079\n",
      ">> Epoch 8 finished \tANN training loss 0.040310\n",
      ">> Epoch 9 finished \tANN training loss 0.034242\n",
      ">> Epoch 10 finished \tANN training loss 0.029995\n",
      ">> Epoch 11 finished \tANN training loss 0.026987\n",
      ">> Epoch 12 finished \tANN training loss 0.024822\n",
      ">> Epoch 13 finished \tANN training loss 0.023226\n",
      ">> Epoch 14 finished \tANN training loss 0.022018\n",
      ">> Epoch 15 finished \tANN training loss 0.021077\n",
      ">> Epoch 16 finished \tANN training loss 0.020316\n",
      ">> Epoch 17 finished \tANN training loss 0.019683\n",
      ">> Epoch 18 finished \tANN training loss 0.019138\n",
      ">> Epoch 19 finished \tANN training loss 0.018654\n",
      ">> Epoch 20 finished \tANN training loss 0.018214\n",
      ">> Epoch 21 finished \tANN training loss 0.017807\n",
      ">> Epoch 22 finished \tANN training loss 0.017424\n",
      ">> Epoch 23 finished \tANN training loss 0.017060\n",
      ">> Epoch 24 finished \tANN training loss 0.016712\n",
      ">> Epoch 25 finished \tANN training loss 0.016375\n",
      ">> Epoch 26 finished \tANN training loss 0.016049\n",
      ">> Epoch 27 finished \tANN training loss 0.015732\n",
      ">> Epoch 28 finished \tANN training loss 0.015424\n",
      ">> Epoch 29 finished \tANN training loss 0.015123\n",
      ">> Epoch 30 finished \tANN training loss 0.014829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 31 finished \tANN training loss 0.014543\n",
      ">> Epoch 32 finished \tANN training loss 0.014264\n",
      ">> Epoch 33 finished \tANN training loss 0.013991\n",
      ">> Epoch 34 finished \tANN training loss 0.013725\n",
      ">> Epoch 35 finished \tANN training loss 0.013464\n",
      ">> Epoch 36 finished \tANN training loss 0.013211\n",
      ">> Epoch 37 finished \tANN training loss 0.012963\n",
      ">> Epoch 38 finished \tANN training loss 0.012721\n",
      ">> Epoch 39 finished \tANN training loss 0.012485\n",
      ">> Epoch 40 finished \tANN training loss 0.012255\n",
      ">> Epoch 41 finished \tANN training loss 0.012030\n",
      ">> Epoch 42 finished \tANN training loss 0.011810\n",
      ">> Epoch 43 finished \tANN training loss 0.011596\n",
      ">> Epoch 44 finished \tANN training loss 0.011386\n",
      ">> Epoch 45 finished \tANN training loss 0.011181\n",
      ">> Epoch 46 finished \tANN training loss 0.010981\n",
      ">> Epoch 47 finished \tANN training loss 0.010786\n",
      ">> Epoch 48 finished \tANN training loss 0.010595\n",
      ">> Epoch 49 finished \tANN training loss 0.010408\n",
      ">> Epoch 50 finished \tANN training loss 0.010226\n",
      ">> Epoch 51 finished \tANN training loss 0.010047\n",
      ">> Epoch 52 finished \tANN training loss 0.009873\n",
      ">> Epoch 53 finished \tANN training loss 0.009703\n",
      ">> Epoch 54 finished \tANN training loss 0.009536\n",
      ">> Epoch 55 finished \tANN training loss 0.009373\n",
      ">> Epoch 56 finished \tANN training loss 0.009214\n",
      ">> Epoch 57 finished \tANN training loss 0.009058\n",
      ">> Epoch 58 finished \tANN training loss 0.008906\n",
      ">> Epoch 59 finished \tANN training loss 0.008757\n",
      ">> Epoch 60 finished \tANN training loss 0.008612\n",
      ">> Epoch 61 finished \tANN training loss 0.008469\n",
      ">> Epoch 62 finished \tANN training loss 0.008330\n",
      ">> Epoch 63 finished \tANN training loss 0.008194\n",
      ">> Epoch 64 finished \tANN training loss 0.008061\n",
      ">> Epoch 65 finished \tANN training loss 0.007930\n",
      ">> Epoch 66 finished \tANN training loss 0.007803\n",
      ">> Epoch 67 finished \tANN training loss 0.007678\n",
      ">> Epoch 68 finished \tANN training loss 0.007556\n",
      ">> Epoch 69 finished \tANN training loss 0.007437\n",
      ">> Epoch 70 finished \tANN training loss 0.007320\n",
      ">> Epoch 71 finished \tANN training loss 0.007206\n",
      ">> Epoch 72 finished \tANN training loss 0.007094\n",
      ">> Epoch 73 finished \tANN training loss 0.006985\n",
      ">> Epoch 74 finished \tANN training loss 0.006879\n",
      ">> Epoch 75 finished \tANN training loss 0.006774\n",
      ">> Epoch 76 finished \tANN training loss 0.006672\n",
      ">> Epoch 77 finished \tANN training loss 0.006573\n",
      ">> Epoch 78 finished \tANN training loss 0.006475\n",
      ">> Epoch 79 finished \tANN training loss 0.006380\n",
      ">> Epoch 80 finished \tANN training loss 0.006286\n",
      ">> Epoch 81 finished \tANN training loss 0.006195\n",
      ">> Epoch 82 finished \tANN training loss 0.006106\n",
      ">> Epoch 83 finished \tANN training loss 0.006019\n",
      ">> Epoch 84 finished \tANN training loss 0.005934\n",
      ">> Epoch 85 finished \tANN training loss 0.005851\n",
      ">> Epoch 86 finished \tANN training loss 0.005769\n",
      ">> Epoch 87 finished \tANN training loss 0.005689\n",
      ">> Epoch 88 finished \tANN training loss 0.005611\n",
      ">> Epoch 89 finished \tANN training loss 0.005535\n",
      ">> Epoch 90 finished \tANN training loss 0.005460\n",
      ">> Epoch 91 finished \tANN training loss 0.005387\n",
      ">> Epoch 92 finished \tANN training loss 0.005315\n",
      ">> Epoch 93 finished \tANN training loss 0.005245\n",
      ">> Epoch 94 finished \tANN training loss 0.005177\n",
      ">> Epoch 95 finished \tANN training loss 0.005110\n",
      ">> Epoch 96 finished \tANN training loss 0.005044\n",
      ">> Epoch 97 finished \tANN training loss 0.004980\n",
      ">> Epoch 98 finished \tANN training loss 0.004917\n",
      ">> Epoch 99 finished \tANN training loss 0.004856\n",
      ">> Epoch 100 finished \tANN training loss 0.004796\n",
      ">> Epoch 101 finished \tANN training loss 0.004737\n",
      ">> Epoch 102 finished \tANN training loss 0.004679\n",
      ">> Epoch 103 finished \tANN training loss 0.004623\n",
      ">> Epoch 104 finished \tANN training loss 0.004568\n",
      ">> Epoch 105 finished \tANN training loss 0.004514\n",
      ">> Epoch 106 finished \tANN training loss 0.004462\n",
      ">> Epoch 107 finished \tANN training loss 0.004410\n",
      ">> Epoch 108 finished \tANN training loss 0.004360\n",
      ">> Epoch 109 finished \tANN training loss 0.004311\n",
      ">> Epoch 110 finished \tANN training loss 0.004262\n",
      ">> Epoch 111 finished \tANN training loss 0.004215\n",
      ">> Epoch 112 finished \tANN training loss 0.004169\n",
      ">> Epoch 113 finished \tANN training loss 0.004124\n",
      ">> Epoch 114 finished \tANN training loss 0.004080\n",
      ">> Epoch 115 finished \tANN training loss 0.004037\n",
      ">> Epoch 116 finished \tANN training loss 0.003995\n",
      ">> Epoch 117 finished \tANN training loss 0.003953\n",
      ">> Epoch 118 finished \tANN training loss 0.003913\n",
      ">> Epoch 119 finished \tANN training loss 0.003873\n",
      ">> Epoch 120 finished \tANN training loss 0.003835\n",
      ">> Epoch 121 finished \tANN training loss 0.003797\n",
      ">> Epoch 122 finished \tANN training loss 0.003760\n",
      ">> Epoch 123 finished \tANN training loss 0.003724\n",
      ">> Epoch 124 finished \tANN training loss 0.003689\n",
      ">> Epoch 125 finished \tANN training loss 0.003654\n",
      ">> Epoch 126 finished \tANN training loss 0.003620\n",
      ">> Epoch 127 finished \tANN training loss 0.003587\n",
      ">> Epoch 128 finished \tANN training loss 0.003554\n",
      ">> Epoch 129 finished \tANN training loss 0.003522\n",
      ">> Epoch 130 finished \tANN training loss 0.003491\n",
      ">> Epoch 131 finished \tANN training loss 0.003461\n",
      ">> Epoch 132 finished \tANN training loss 0.003431\n",
      ">> Epoch 133 finished \tANN training loss 0.003402\n",
      ">> Epoch 134 finished \tANN training loss 0.003373\n",
      ">> Epoch 135 finished \tANN training loss 0.003345\n",
      ">> Epoch 136 finished \tANN training loss 0.003317\n",
      ">> Epoch 137 finished \tANN training loss 0.003291\n",
      ">> Epoch 138 finished \tANN training loss 0.003264\n",
      ">> Epoch 139 finished \tANN training loss 0.003239\n",
      ">> Epoch 140 finished \tANN training loss 0.003213\n",
      ">> Epoch 141 finished \tANN training loss 0.003189\n",
      ">> Epoch 142 finished \tANN training loss 0.003164\n",
      ">> Epoch 143 finished \tANN training loss 0.003141\n",
      ">> Epoch 144 finished \tANN training loss 0.003117\n",
      ">> Epoch 145 finished \tANN training loss 0.003095\n",
      ">> Epoch 146 finished \tANN training loss 0.003072\n",
      ">> Epoch 147 finished \tANN training loss 0.003051\n",
      ">> Epoch 148 finished \tANN training loss 0.003029\n",
      ">> Epoch 149 finished \tANN training loss 0.003008\n",
      ">> Epoch 150 finished \tANN training loss 0.002988\n",
      "[END] Fine tuning step\n",
      "############### End Training for TATASTEELEQ #####################\n",
      "############### End Training for CENTURYTEXEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 2.727628\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 2.679934\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 2.632311\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 2.584761\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 2.537204\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 2.489470\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 2.441486\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 2.393218\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 2.344508\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 2.295311\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 2.245592\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 2.195171\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 2.144024\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 2.091938\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 2.038965\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 1.984983\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 1.929850\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 1.873737\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 1.816374\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 1.757995\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 1.698442\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 1.637796\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 1.576116\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 1.513633\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 1.450363\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 1.386545\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 1.322439\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 1.258090\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 1.193874\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 1.130348\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 1.067981\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 1.006457\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.946278\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.888190\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.832349\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.778939\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.728738\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.681310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 39 finished \tRBM Reconstruction error 0.636458\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.594737\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.556918\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.522028\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.490664\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.462534\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.437622\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.414293\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.393502\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.375061\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.358894\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.344239\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.331397\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.319927\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.309761\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.300615\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.292193\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.284721\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.277686\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.271472\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.265494\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.260438\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.255695\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.250891\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.246391\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.242106\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.238100\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.234367\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.230642\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.227128\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.223656\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.220301\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.217148\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.214154\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.211064\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.208182\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.205280\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.202460\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.199624\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.196897\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.194235\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.191552\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.189015\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.186342\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.183772\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.181242\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.178845\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.176459\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.174059\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.171680\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.169317\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.167129\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.164877\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.162666\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.160460\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.158359\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.156303\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.154257\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.152244\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.150255\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.148256\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.146303\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.122746\n",
      ">> Epoch 2 finished \tANN training loss 0.105632\n",
      ">> Epoch 3 finished \tANN training loss 0.091003\n",
      ">> Epoch 4 finished \tANN training loss 0.078459\n",
      ">> Epoch 5 finished \tANN training loss 0.067679\n",
      ">> Epoch 6 finished \tANN training loss 0.058404\n",
      ">> Epoch 7 finished \tANN training loss 0.050418\n",
      ">> Epoch 8 finished \tANN training loss 0.043542\n",
      ">> Epoch 9 finished \tANN training loss 0.037626\n",
      ">> Epoch 10 finished \tANN training loss 0.032538\n",
      ">> Epoch 11 finished \tANN training loss 0.028166\n",
      ">> Epoch 12 finished \tANN training loss 0.024410\n",
      ">> Epoch 13 finished \tANN training loss 0.021186\n",
      ">> Epoch 14 finished \tANN training loss 0.018421\n",
      ">> Epoch 15 finished \tANN training loss 0.016051\n",
      ">> Epoch 16 finished \tANN training loss 0.014022\n",
      ">> Epoch 17 finished \tANN training loss 0.012288\n",
      ">> Epoch 18 finished \tANN training loss 0.010804\n",
      ">> Epoch 19 finished \tANN training loss 0.009532\n",
      ">> Epoch 20 finished \tANN training loss 0.008440\n",
      ">> Epoch 21 finished \tANN training loss 0.007502\n",
      ">> Epoch 22 finished \tANN training loss 0.006694\n",
      ">> Epoch 23 finished \tANN training loss 0.006000\n",
      ">> Epoch 24 finished \tANN training loss 0.005402\n",
      ">> Epoch 25 finished \tANN training loss 0.004887\n",
      ">> Epoch 26 finished \tANN training loss 0.004444\n",
      ">> Epoch 27 finished \tANN training loss 0.004063\n",
      ">> Epoch 28 finished \tANN training loss 0.003734\n",
      ">> Epoch 29 finished \tANN training loss 0.003451\n",
      ">> Epoch 30 finished \tANN training loss 0.003207\n",
      ">> Epoch 31 finished \tANN training loss 0.002997\n",
      ">> Epoch 32 finished \tANN training loss 0.002816\n",
      ">> Epoch 33 finished \tANN training loss 0.002661\n",
      ">> Epoch 34 finished \tANN training loss 0.002526\n",
      ">> Epoch 35 finished \tANN training loss 0.002410\n",
      ">> Epoch 36 finished \tANN training loss 0.002310\n",
      ">> Epoch 37 finished \tANN training loss 0.002223\n",
      ">> Epoch 38 finished \tANN training loss 0.002148\n",
      ">> Epoch 39 finished \tANN training loss 0.002084\n",
      ">> Epoch 40 finished \tANN training loss 0.002028\n",
      ">> Epoch 41 finished \tANN training loss 0.001979\n",
      ">> Epoch 42 finished \tANN training loss 0.001937\n",
      ">> Epoch 43 finished \tANN training loss 0.001900\n",
      ">> Epoch 44 finished \tANN training loss 0.001868\n",
      ">> Epoch 45 finished \tANN training loss 0.001841\n",
      ">> Epoch 46 finished \tANN training loss 0.001816\n",
      ">> Epoch 47 finished \tANN training loss 0.001795\n",
      ">> Epoch 48 finished \tANN training loss 0.001776\n",
      ">> Epoch 49 finished \tANN training loss 0.001760\n",
      ">> Epoch 50 finished \tANN training loss 0.001745\n",
      ">> Epoch 51 finished \tANN training loss 0.001732\n",
      ">> Epoch 52 finished \tANN training loss 0.001721\n",
      ">> Epoch 53 finished \tANN training loss 0.001710\n",
      ">> Epoch 54 finished \tANN training loss 0.001701\n",
      ">> Epoch 55 finished \tANN training loss 0.001693\n",
      ">> Epoch 56 finished \tANN training loss 0.001686\n",
      ">> Epoch 57 finished \tANN training loss 0.001679\n",
      ">> Epoch 58 finished \tANN training loss 0.001673\n",
      ">> Epoch 59 finished \tANN training loss 0.001667\n",
      ">> Epoch 60 finished \tANN training loss 0.001662\n",
      ">> Epoch 61 finished \tANN training loss 0.001657\n",
      ">> Epoch 62 finished \tANN training loss 0.001653\n",
      ">> Epoch 63 finished \tANN training loss 0.001648\n",
      ">> Epoch 64 finished \tANN training loss 0.001645\n",
      ">> Epoch 65 finished \tANN training loss 0.001641\n",
      ">> Epoch 66 finished \tANN training loss 0.001637\n",
      ">> Epoch 67 finished \tANN training loss 0.001634\n",
      ">> Epoch 68 finished \tANN training loss 0.001631\n",
      ">> Epoch 69 finished \tANN training loss 0.001628\n",
      ">> Epoch 70 finished \tANN training loss 0.001625\n",
      ">> Epoch 71 finished \tANN training loss 0.001622\n",
      ">> Epoch 72 finished \tANN training loss 0.001620\n",
      ">> Epoch 73 finished \tANN training loss 0.001617\n",
      ">> Epoch 74 finished \tANN training loss 0.001615\n",
      ">> Epoch 75 finished \tANN training loss 0.001612\n",
      ">> Epoch 76 finished \tANN training loss 0.001610\n",
      ">> Epoch 77 finished \tANN training loss 0.001608\n",
      ">> Epoch 78 finished \tANN training loss 0.001605\n",
      ">> Epoch 79 finished \tANN training loss 0.001603\n",
      ">> Epoch 80 finished \tANN training loss 0.001601\n",
      ">> Epoch 81 finished \tANN training loss 0.001599\n",
      ">> Epoch 82 finished \tANN training loss 0.001597\n",
      ">> Epoch 83 finished \tANN training loss 0.001595\n",
      ">> Epoch 84 finished \tANN training loss 0.001593\n",
      ">> Epoch 85 finished \tANN training loss 0.001591\n",
      ">> Epoch 86 finished \tANN training loss 0.001589\n",
      ">> Epoch 87 finished \tANN training loss 0.001587\n",
      ">> Epoch 88 finished \tANN training loss 0.001585\n",
      ">> Epoch 89 finished \tANN training loss 0.001584\n",
      ">> Epoch 90 finished \tANN training loss 0.001582\n",
      ">> Epoch 91 finished \tANN training loss 0.001580\n",
      ">> Epoch 92 finished \tANN training loss 0.001579\n",
      ">> Epoch 93 finished \tANN training loss 0.001577\n",
      ">> Epoch 94 finished \tANN training loss 0.001575\n",
      ">> Epoch 95 finished \tANN training loss 0.001574\n",
      ">> Epoch 96 finished \tANN training loss 0.001572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 97 finished \tANN training loss 0.001570\n",
      ">> Epoch 98 finished \tANN training loss 0.001569\n",
      ">> Epoch 99 finished \tANN training loss 0.001567\n",
      ">> Epoch 100 finished \tANN training loss 0.001566\n",
      ">> Epoch 101 finished \tANN training loss 0.001564\n",
      ">> Epoch 102 finished \tANN training loss 0.001563\n",
      ">> Epoch 103 finished \tANN training loss 0.001561\n",
      ">> Epoch 104 finished \tANN training loss 0.001560\n",
      ">> Epoch 105 finished \tANN training loss 0.001559\n",
      ">> Epoch 106 finished \tANN training loss 0.001557\n",
      ">> Epoch 107 finished \tANN training loss 0.001556\n",
      ">> Epoch 108 finished \tANN training loss 0.001554\n",
      ">> Epoch 109 finished \tANN training loss 0.001553\n",
      ">> Epoch 110 finished \tANN training loss 0.001552\n",
      ">> Epoch 111 finished \tANN training loss 0.001550\n",
      ">> Epoch 112 finished \tANN training loss 0.001549\n",
      ">> Epoch 113 finished \tANN training loss 0.001548\n",
      ">> Epoch 114 finished \tANN training loss 0.001547\n",
      ">> Epoch 115 finished \tANN training loss 0.001545\n",
      ">> Epoch 116 finished \tANN training loss 0.001544\n",
      ">> Epoch 117 finished \tANN training loss 0.001543\n",
      ">> Epoch 118 finished \tANN training loss 0.001542\n",
      ">> Epoch 119 finished \tANN training loss 0.001540\n",
      ">> Epoch 120 finished \tANN training loss 0.001539\n",
      ">> Epoch 121 finished \tANN training loss 0.001538\n",
      ">> Epoch 122 finished \tANN training loss 0.001537\n",
      ">> Epoch 123 finished \tANN training loss 0.001536\n",
      ">> Epoch 124 finished \tANN training loss 0.001535\n",
      ">> Epoch 125 finished \tANN training loss 0.001533\n",
      ">> Epoch 126 finished \tANN training loss 0.001532\n",
      ">> Epoch 127 finished \tANN training loss 0.001531\n",
      ">> Epoch 128 finished \tANN training loss 0.001530\n",
      ">> Epoch 129 finished \tANN training loss 0.001529\n",
      ">> Epoch 130 finished \tANN training loss 0.001528\n",
      ">> Epoch 131 finished \tANN training loss 0.001527\n",
      ">> Epoch 132 finished \tANN training loss 0.001526\n",
      ">> Epoch 133 finished \tANN training loss 0.001525\n",
      ">> Epoch 134 finished \tANN training loss 0.001524\n",
      ">> Epoch 135 finished \tANN training loss 0.001523\n",
      ">> Epoch 136 finished \tANN training loss 0.001522\n",
      ">> Epoch 137 finished \tANN training loss 0.001521\n",
      ">> Epoch 138 finished \tANN training loss 0.001520\n",
      ">> Epoch 139 finished \tANN training loss 0.001519\n",
      ">> Epoch 140 finished \tANN training loss 0.001518\n",
      ">> Epoch 141 finished \tANN training loss 0.001517\n",
      ">> Epoch 142 finished \tANN training loss 0.001516\n",
      ">> Epoch 143 finished \tANN training loss 0.001515\n",
      ">> Epoch 144 finished \tANN training loss 0.001514\n",
      ">> Epoch 145 finished \tANN training loss 0.001513\n",
      ">> Epoch 146 finished \tANN training loss 0.001512\n",
      ">> Epoch 147 finished \tANN training loss 0.001511\n",
      ">> Epoch 148 finished \tANN training loss 0.001510\n",
      ">> Epoch 149 finished \tANN training loss 0.001509\n",
      ">> Epoch 150 finished \tANN training loss 0.001508\n",
      "[END] Fine tuning step\n",
      "############### End Training for CENTURYTEXEQ #####################\n",
      "############### End Training for MARUTIEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 1.301121\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 1.286787\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 1.272676\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 1.258738\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 1.244997\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 1.231441\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 1.218038\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 1.204831\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 1.191788\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 1.178904\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 1.166189\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 1.153640\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 1.141237\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 1.129009\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 1.116928\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 1.105009\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 1.093229\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 1.081581\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 1.070065\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 1.058692\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 1.047441\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 1.036324\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 1.025331\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 1.014469\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 1.003718\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 0.993090\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 0.982585\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 0.972179\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 0.961898\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 0.951694\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 0.941605\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 0.931591\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.921700\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.911915\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.902176\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.892555\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.882998\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.873547\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.864164\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.854863\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.845636\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.836495\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.827436\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.818483\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.809561\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.800723\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.791971\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.783281\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.774661\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.766106\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.757584\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.749168\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.740817\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.732546\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.724327\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.716188\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.708060\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.700056\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.692064\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.684134\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.676310\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.668539\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.660826\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.653160\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.645578\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.638069\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.630603\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.623167\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.615831\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.608548\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.601370\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.594292\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.587184\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.580174\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.573232\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.566343\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.559539\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.552797\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.546152\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.539550\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.533040\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.526593\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.520250\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.514022\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.507821\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.501670\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.495619\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.489632\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.483724\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.477897\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.472178\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.466581\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.461055\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.455562\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.450136\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.444845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 97 finished \tRBM Reconstruction error 0.439626\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.434451\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.429445\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.424403\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.005170\n",
      ">> Epoch 2 finished \tANN training loss 0.005097\n",
      ">> Epoch 3 finished \tANN training loss 0.005027\n",
      ">> Epoch 4 finished \tANN training loss 0.004958\n",
      ">> Epoch 5 finished \tANN training loss 0.004892\n",
      ">> Epoch 6 finished \tANN training loss 0.004828\n",
      ">> Epoch 7 finished \tANN training loss 0.004766\n",
      ">> Epoch 8 finished \tANN training loss 0.004706\n",
      ">> Epoch 9 finished \tANN training loss 0.004648\n",
      ">> Epoch 10 finished \tANN training loss 0.004591\n",
      ">> Epoch 11 finished \tANN training loss 0.004536\n",
      ">> Epoch 12 finished \tANN training loss 0.004482\n",
      ">> Epoch 13 finished \tANN training loss 0.004430\n",
      ">> Epoch 14 finished \tANN training loss 0.004379\n",
      ">> Epoch 15 finished \tANN training loss 0.004330\n",
      ">> Epoch 16 finished \tANN training loss 0.004281\n",
      ">> Epoch 17 finished \tANN training loss 0.004234\n",
      ">> Epoch 18 finished \tANN training loss 0.004189\n",
      ">> Epoch 19 finished \tANN training loss 0.004144\n",
      ">> Epoch 20 finished \tANN training loss 0.004100\n",
      ">> Epoch 21 finished \tANN training loss 0.004057\n",
      ">> Epoch 22 finished \tANN training loss 0.004015\n",
      ">> Epoch 23 finished \tANN training loss 0.003974\n",
      ">> Epoch 24 finished \tANN training loss 0.003934\n",
      ">> Epoch 25 finished \tANN training loss 0.003895\n",
      ">> Epoch 26 finished \tANN training loss 0.003856\n",
      ">> Epoch 27 finished \tANN training loss 0.003818\n",
      ">> Epoch 28 finished \tANN training loss 0.003781\n",
      ">> Epoch 29 finished \tANN training loss 0.003745\n",
      ">> Epoch 30 finished \tANN training loss 0.003709\n",
      ">> Epoch 31 finished \tANN training loss 0.003674\n",
      ">> Epoch 32 finished \tANN training loss 0.003640\n",
      ">> Epoch 33 finished \tANN training loss 0.003606\n",
      ">> Epoch 34 finished \tANN training loss 0.003572\n",
      ">> Epoch 35 finished \tANN training loss 0.003540\n",
      ">> Epoch 36 finished \tANN training loss 0.003507\n",
      ">> Epoch 37 finished \tANN training loss 0.003476\n",
      ">> Epoch 38 finished \tANN training loss 0.003444\n",
      ">> Epoch 39 finished \tANN training loss 0.003413\n",
      ">> Epoch 40 finished \tANN training loss 0.003383\n",
      ">> Epoch 41 finished \tANN training loss 0.003353\n",
      ">> Epoch 42 finished \tANN training loss 0.003324\n",
      ">> Epoch 43 finished \tANN training loss 0.003295\n",
      ">> Epoch 44 finished \tANN training loss 0.003266\n",
      ">> Epoch 45 finished \tANN training loss 0.003237\n",
      ">> Epoch 46 finished \tANN training loss 0.003209\n",
      ">> Epoch 47 finished \tANN training loss 0.003182\n",
      ">> Epoch 48 finished \tANN training loss 0.003155\n",
      ">> Epoch 49 finished \tANN training loss 0.003128\n",
      ">> Epoch 50 finished \tANN training loss 0.003101\n",
      ">> Epoch 51 finished \tANN training loss 0.003075\n",
      ">> Epoch 52 finished \tANN training loss 0.003049\n",
      ">> Epoch 53 finished \tANN training loss 0.003023\n",
      ">> Epoch 54 finished \tANN training loss 0.002998\n",
      ">> Epoch 55 finished \tANN training loss 0.002973\n",
      ">> Epoch 56 finished \tANN training loss 0.002948\n",
      ">> Epoch 57 finished \tANN training loss 0.002924\n",
      ">> Epoch 58 finished \tANN training loss 0.002900\n",
      ">> Epoch 59 finished \tANN training loss 0.002876\n",
      ">> Epoch 60 finished \tANN training loss 0.002852\n",
      ">> Epoch 61 finished \tANN training loss 0.002829\n",
      ">> Epoch 62 finished \tANN training loss 0.002806\n",
      ">> Epoch 63 finished \tANN training loss 0.002783\n",
      ">> Epoch 64 finished \tANN training loss 0.002760\n",
      ">> Epoch 65 finished \tANN training loss 0.002738\n",
      ">> Epoch 66 finished \tANN training loss 0.002715\n",
      ">> Epoch 67 finished \tANN training loss 0.002693\n",
      ">> Epoch 68 finished \tANN training loss 0.002672\n",
      ">> Epoch 69 finished \tANN training loss 0.002650\n",
      ">> Epoch 70 finished \tANN training loss 0.002629\n",
      ">> Epoch 71 finished \tANN training loss 0.002608\n",
      ">> Epoch 72 finished \tANN training loss 0.002587\n",
      ">> Epoch 73 finished \tANN training loss 0.002566\n",
      ">> Epoch 74 finished \tANN training loss 0.002546\n",
      ">> Epoch 75 finished \tANN training loss 0.002525\n",
      ">> Epoch 76 finished \tANN training loss 0.002505\n",
      ">> Epoch 77 finished \tANN training loss 0.002485\n",
      ">> Epoch 78 finished \tANN training loss 0.002466\n",
      ">> Epoch 79 finished \tANN training loss 0.002446\n",
      ">> Epoch 80 finished \tANN training loss 0.002427\n",
      ">> Epoch 81 finished \tANN training loss 0.002408\n",
      ">> Epoch 82 finished \tANN training loss 0.002389\n",
      ">> Epoch 83 finished \tANN training loss 0.002370\n",
      ">> Epoch 84 finished \tANN training loss 0.002351\n",
      ">> Epoch 85 finished \tANN training loss 0.002333\n",
      ">> Epoch 86 finished \tANN training loss 0.002315\n",
      ">> Epoch 87 finished \tANN training loss 0.002296\n",
      ">> Epoch 88 finished \tANN training loss 0.002278\n",
      ">> Epoch 89 finished \tANN training loss 0.002261\n",
      ">> Epoch 90 finished \tANN training loss 0.002243\n",
      ">> Epoch 91 finished \tANN training loss 0.002225\n",
      ">> Epoch 92 finished \tANN training loss 0.002208\n",
      ">> Epoch 93 finished \tANN training loss 0.002191\n",
      ">> Epoch 94 finished \tANN training loss 0.002174\n",
      ">> Epoch 95 finished \tANN training loss 0.002157\n",
      ">> Epoch 96 finished \tANN training loss 0.002140\n",
      ">> Epoch 97 finished \tANN training loss 0.002124\n",
      ">> Epoch 98 finished \tANN training loss 0.002107\n",
      ">> Epoch 99 finished \tANN training loss 0.002091\n",
      ">> Epoch 100 finished \tANN training loss 0.002075\n",
      ">> Epoch 101 finished \tANN training loss 0.002059\n",
      ">> Epoch 102 finished \tANN training loss 0.002043\n",
      ">> Epoch 103 finished \tANN training loss 0.002027\n",
      ">> Epoch 104 finished \tANN training loss 0.002011\n",
      ">> Epoch 105 finished \tANN training loss 0.001996\n",
      ">> Epoch 106 finished \tANN training loss 0.001981\n",
      ">> Epoch 107 finished \tANN training loss 0.001965\n",
      ">> Epoch 108 finished \tANN training loss 0.001950\n",
      ">> Epoch 109 finished \tANN training loss 0.001936\n",
      ">> Epoch 110 finished \tANN training loss 0.001921\n",
      ">> Epoch 111 finished \tANN training loss 0.001906\n",
      ">> Epoch 112 finished \tANN training loss 0.001892\n",
      ">> Epoch 113 finished \tANN training loss 0.001877\n",
      ">> Epoch 114 finished \tANN training loss 0.001863\n",
      ">> Epoch 115 finished \tANN training loss 0.001849\n",
      ">> Epoch 116 finished \tANN training loss 0.001835\n",
      ">> Epoch 117 finished \tANN training loss 0.001821\n",
      ">> Epoch 118 finished \tANN training loss 0.001807\n",
      ">> Epoch 119 finished \tANN training loss 0.001793\n",
      ">> Epoch 120 finished \tANN training loss 0.001780\n",
      ">> Epoch 121 finished \tANN training loss 0.001766\n",
      ">> Epoch 122 finished \tANN training loss 0.001753\n",
      ">> Epoch 123 finished \tANN training loss 0.001740\n",
      ">> Epoch 124 finished \tANN training loss 0.001727\n",
      ">> Epoch 125 finished \tANN training loss 0.001714\n",
      ">> Epoch 126 finished \tANN training loss 0.001701\n",
      ">> Epoch 127 finished \tANN training loss 0.001688\n",
      ">> Epoch 128 finished \tANN training loss 0.001676\n",
      ">> Epoch 129 finished \tANN training loss 0.001663\n",
      ">> Epoch 130 finished \tANN training loss 0.001651\n",
      ">> Epoch 131 finished \tANN training loss 0.001639\n",
      ">> Epoch 132 finished \tANN training loss 0.001626\n",
      ">> Epoch 133 finished \tANN training loss 0.001614\n",
      ">> Epoch 134 finished \tANN training loss 0.001602\n",
      ">> Epoch 135 finished \tANN training loss 0.001591\n",
      ">> Epoch 136 finished \tANN training loss 0.001579\n",
      ">> Epoch 137 finished \tANN training loss 0.001567\n",
      ">> Epoch 138 finished \tANN training loss 0.001556\n",
      ">> Epoch 139 finished \tANN training loss 0.001544\n",
      ">> Epoch 140 finished \tANN training loss 0.001533\n",
      ">> Epoch 141 finished \tANN training loss 0.001522\n",
      ">> Epoch 142 finished \tANN training loss 0.001511\n",
      ">> Epoch 143 finished \tANN training loss 0.001500\n",
      ">> Epoch 144 finished \tANN training loss 0.001489\n",
      ">> Epoch 145 finished \tANN training loss 0.001478\n",
      ">> Epoch 146 finished \tANN training loss 0.001467\n",
      ">> Epoch 147 finished \tANN training loss 0.001457\n",
      ">> Epoch 148 finished \tANN training loss 0.001446\n",
      ">> Epoch 149 finished \tANN training loss 0.001436\n",
      ">> Epoch 150 finished \tANN training loss 0.001425\n",
      "[END] Fine tuning step\n",
      "############### End Training for MARUTIEQ #####################\n",
      "############### End Training for TCSEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 4.025759\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 3.971248\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 3.915891\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 3.859710\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 3.802664\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 3.744559\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 3.685442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 8 finished \tRBM Reconstruction error 3.625062\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 3.563336\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 3.500148\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 3.435438\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 3.369025\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 3.300839\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 3.230757\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 3.158550\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 3.084187\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 3.007643\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 2.928785\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 2.847568\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 2.763787\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 2.677564\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 2.588895\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 2.497815\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 2.404508\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 2.309250\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 2.211779\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 2.112639\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 2.011810\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 1.910287\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 1.808330\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 1.705579\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 1.603396\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 1.502791\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 1.403334\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 1.305553\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 1.210431\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 1.119297\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 1.032084\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.949177\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.871042\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.797078\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.729522\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.667184\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.610734\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.559740\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.512908\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.472513\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.437158\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.405528\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.378343\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.354759\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.334056\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.316056\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.300175\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.286157\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.273800\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.263265\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.254018\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.246185\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.238809\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.232503\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.227093\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.222125\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.217650\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.213468\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.209190\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.205532\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.202151\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.198942\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.196152\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.193351\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.190938\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.188507\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.186203\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.183920\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.181875\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.179784\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.177712\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.175690\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.173683\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.171827\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.169849\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.168129\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.166207\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.164446\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.162803\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.161129\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.159562\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.157976\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.156551\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.155014\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.153345\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.151767\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.150283\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.148764\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.147376\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.145823\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.144427\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.143080\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.141757\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.093408\n",
      ">> Epoch 2 finished \tANN training loss 0.081491\n",
      ">> Epoch 3 finished \tANN training loss 0.071109\n",
      ">> Epoch 4 finished \tANN training loss 0.062063\n",
      ">> Epoch 5 finished \tANN training loss 0.054177\n",
      ">> Epoch 6 finished \tANN training loss 0.047305\n",
      ">> Epoch 7 finished \tANN training loss 0.041316\n",
      ">> Epoch 8 finished \tANN training loss 0.036097\n",
      ">> Epoch 9 finished \tANN training loss 0.031550\n",
      ">> Epoch 10 finished \tANN training loss 0.027591\n",
      ">> Epoch 11 finished \tANN training loss 0.024143\n",
      ">> Epoch 12 finished \tANN training loss 0.021140\n",
      ">> Epoch 13 finished \tANN training loss 0.018526\n",
      ">> Epoch 14 finished \tANN training loss 0.016250\n",
      ">> Epoch 15 finished \tANN training loss 0.014265\n",
      ">> Epoch 16 finished \tANN training loss 0.012533\n",
      ">> Epoch 17 finished \tANN training loss 0.011018\n",
      ">> Epoch 18 finished \tANN training loss 0.009691\n",
      ">> Epoch 19 finished \tANN training loss 0.008530\n",
      ">> Epoch 20 finished \tANN training loss 0.007521\n",
      ">> Epoch 21 finished \tANN training loss 0.006648\n",
      ">> Epoch 22 finished \tANN training loss 0.005892\n",
      ">> Epoch 23 finished \tANN training loss 0.005238\n",
      ">> Epoch 24 finished \tANN training loss 0.004671\n",
      ">> Epoch 25 finished \tANN training loss 0.004181\n",
      ">> Epoch 26 finished \tANN training loss 0.003756\n",
      ">> Epoch 27 finished \tANN training loss 0.003388\n",
      ">> Epoch 28 finished \tANN training loss 0.003068\n",
      ">> Epoch 29 finished \tANN training loss 0.002791\n",
      ">> Epoch 30 finished \tANN training loss 0.002551\n",
      ">> Epoch 31 finished \tANN training loss 0.002342\n",
      ">> Epoch 32 finished \tANN training loss 0.002160\n",
      ">> Epoch 33 finished \tANN training loss 0.002002\n",
      ">> Epoch 34 finished \tANN training loss 0.001864\n",
      ">> Epoch 35 finished \tANN training loss 0.001744\n",
      ">> Epoch 36 finished \tANN training loss 0.001639\n",
      ">> Epoch 37 finished \tANN training loss 0.001547\n",
      ">> Epoch 38 finished \tANN training loss 0.001466\n",
      ">> Epoch 39 finished \tANN training loss 0.001395\n",
      ">> Epoch 40 finished \tANN training loss 0.001333\n",
      ">> Epoch 41 finished \tANN training loss 0.001278\n",
      ">> Epoch 42 finished \tANN training loss 0.001230\n",
      ">> Epoch 43 finished \tANN training loss 0.001187\n",
      ">> Epoch 44 finished \tANN training loss 0.001148\n",
      ">> Epoch 45 finished \tANN training loss 0.001114\n",
      ">> Epoch 46 finished \tANN training loss 0.001083\n",
      ">> Epoch 47 finished \tANN training loss 0.001056\n",
      ">> Epoch 48 finished \tANN training loss 0.001031\n",
      ">> Epoch 49 finished \tANN training loss 0.001008\n",
      ">> Epoch 50 finished \tANN training loss 0.000988\n",
      ">> Epoch 51 finished \tANN training loss 0.000969\n",
      ">> Epoch 52 finished \tANN training loss 0.000952\n",
      ">> Epoch 53 finished \tANN training loss 0.000936\n",
      ">> Epoch 54 finished \tANN training loss 0.000921\n",
      ">> Epoch 55 finished \tANN training loss 0.000907\n",
      ">> Epoch 56 finished \tANN training loss 0.000894\n",
      ">> Epoch 57 finished \tANN training loss 0.000882\n",
      ">> Epoch 58 finished \tANN training loss 0.000871\n",
      ">> Epoch 59 finished \tANN training loss 0.000860\n",
      ">> Epoch 60 finished \tANN training loss 0.000850\n",
      ">> Epoch 61 finished \tANN training loss 0.000840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 62 finished \tANN training loss 0.000831\n",
      ">> Epoch 63 finished \tANN training loss 0.000822\n",
      ">> Epoch 64 finished \tANN training loss 0.000813\n",
      ">> Epoch 65 finished \tANN training loss 0.000805\n",
      ">> Epoch 66 finished \tANN training loss 0.000797\n",
      ">> Epoch 67 finished \tANN training loss 0.000789\n",
      ">> Epoch 68 finished \tANN training loss 0.000781\n",
      ">> Epoch 69 finished \tANN training loss 0.000774\n",
      ">> Epoch 70 finished \tANN training loss 0.000767\n",
      ">> Epoch 71 finished \tANN training loss 0.000760\n",
      ">> Epoch 72 finished \tANN training loss 0.000753\n",
      ">> Epoch 73 finished \tANN training loss 0.000746\n",
      ">> Epoch 74 finished \tANN training loss 0.000740\n",
      ">> Epoch 75 finished \tANN training loss 0.000733\n",
      ">> Epoch 76 finished \tANN training loss 0.000727\n",
      ">> Epoch 77 finished \tANN training loss 0.000721\n",
      ">> Epoch 78 finished \tANN training loss 0.000715\n",
      ">> Epoch 79 finished \tANN training loss 0.000709\n",
      ">> Epoch 80 finished \tANN training loss 0.000703\n",
      ">> Epoch 81 finished \tANN training loss 0.000697\n",
      ">> Epoch 82 finished \tANN training loss 0.000692\n",
      ">> Epoch 83 finished \tANN training loss 0.000686\n",
      ">> Epoch 84 finished \tANN training loss 0.000681\n",
      ">> Epoch 85 finished \tANN training loss 0.000675\n",
      ">> Epoch 86 finished \tANN training loss 0.000670\n",
      ">> Epoch 87 finished \tANN training loss 0.000665\n",
      ">> Epoch 88 finished \tANN training loss 0.000660\n",
      ">> Epoch 89 finished \tANN training loss 0.000655\n",
      ">> Epoch 90 finished \tANN training loss 0.000650\n",
      ">> Epoch 91 finished \tANN training loss 0.000645\n",
      ">> Epoch 92 finished \tANN training loss 0.000640\n",
      ">> Epoch 93 finished \tANN training loss 0.000635\n",
      ">> Epoch 94 finished \tANN training loss 0.000630\n",
      ">> Epoch 95 finished \tANN training loss 0.000626\n",
      ">> Epoch 96 finished \tANN training loss 0.000621\n",
      ">> Epoch 97 finished \tANN training loss 0.000616\n",
      ">> Epoch 98 finished \tANN training loss 0.000612\n",
      ">> Epoch 99 finished \tANN training loss 0.000608\n",
      ">> Epoch 100 finished \tANN training loss 0.000603\n",
      ">> Epoch 101 finished \tANN training loss 0.000599\n",
      ">> Epoch 102 finished \tANN training loss 0.000595\n",
      ">> Epoch 103 finished \tANN training loss 0.000591\n",
      ">> Epoch 104 finished \tANN training loss 0.000586\n",
      ">> Epoch 105 finished \tANN training loss 0.000582\n",
      ">> Epoch 106 finished \tANN training loss 0.000578\n",
      ">> Epoch 107 finished \tANN training loss 0.000574\n",
      ">> Epoch 108 finished \tANN training loss 0.000571\n",
      ">> Epoch 109 finished \tANN training loss 0.000567\n",
      ">> Epoch 110 finished \tANN training loss 0.000563\n",
      ">> Epoch 111 finished \tANN training loss 0.000559\n",
      ">> Epoch 112 finished \tANN training loss 0.000556\n",
      ">> Epoch 113 finished \tANN training loss 0.000552\n",
      ">> Epoch 114 finished \tANN training loss 0.000548\n",
      ">> Epoch 115 finished \tANN training loss 0.000545\n",
      ">> Epoch 116 finished \tANN training loss 0.000541\n",
      ">> Epoch 117 finished \tANN training loss 0.000538\n",
      ">> Epoch 118 finished \tANN training loss 0.000534\n",
      ">> Epoch 119 finished \tANN training loss 0.000531\n",
      ">> Epoch 120 finished \tANN training loss 0.000528\n",
      ">> Epoch 121 finished \tANN training loss 0.000525\n",
      ">> Epoch 122 finished \tANN training loss 0.000521\n",
      ">> Epoch 123 finished \tANN training loss 0.000518\n",
      ">> Epoch 124 finished \tANN training loss 0.000515\n",
      ">> Epoch 125 finished \tANN training loss 0.000512\n",
      ">> Epoch 126 finished \tANN training loss 0.000509\n",
      ">> Epoch 127 finished \tANN training loss 0.000506\n",
      ">> Epoch 128 finished \tANN training loss 0.000503\n",
      ">> Epoch 129 finished \tANN training loss 0.000500\n",
      ">> Epoch 130 finished \tANN training loss 0.000497\n",
      ">> Epoch 131 finished \tANN training loss 0.000494\n",
      ">> Epoch 132 finished \tANN training loss 0.000491\n",
      ">> Epoch 133 finished \tANN training loss 0.000489\n",
      ">> Epoch 134 finished \tANN training loss 0.000486\n",
      ">> Epoch 135 finished \tANN training loss 0.000483\n",
      ">> Epoch 136 finished \tANN training loss 0.000481\n",
      ">> Epoch 137 finished \tANN training loss 0.000478\n",
      ">> Epoch 138 finished \tANN training loss 0.000475\n",
      ">> Epoch 139 finished \tANN training loss 0.000473\n",
      ">> Epoch 140 finished \tANN training loss 0.000470\n",
      ">> Epoch 141 finished \tANN training loss 0.000468\n",
      ">> Epoch 142 finished \tANN training loss 0.000465\n",
      ">> Epoch 143 finished \tANN training loss 0.000463\n",
      ">> Epoch 144 finished \tANN training loss 0.000460\n",
      ">> Epoch 145 finished \tANN training loss 0.000458\n",
      ">> Epoch 146 finished \tANN training loss 0.000456\n",
      ">> Epoch 147 finished \tANN training loss 0.000453\n",
      ">> Epoch 148 finished \tANN training loss 0.000451\n",
      ">> Epoch 149 finished \tANN training loss 0.000449\n",
      ">> Epoch 150 finished \tANN training loss 0.000447\n",
      "[END] Fine tuning step\n",
      "############### End Training for TCSEQ #####################\n",
      "############### End Training for BPCLEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 0.651689\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 0.639954\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 0.628482\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 0.617292\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 0.606374\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 0.595722\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 0.585321\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 0.575170\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 0.565273\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 0.555628\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 0.546230\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 0.537064\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 0.528129\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 0.519402\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 0.510907\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 0.502622\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 0.494536\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 0.486651\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 0.478979\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 0.471504\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 0.464207\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 0.457102\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 0.450162\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 0.443403\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 0.436802\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 0.430375\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 0.424115\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 0.418018\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 0.412051\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 0.406243\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 0.400579\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 0.395045\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.389666\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.384413\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.379292\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.374303\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.369452\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.364700\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.360057\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.355545\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.351131\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.346832\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.342647\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.338552\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.334575\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.330685\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.326907\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.323196\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.319612\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.316094\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.312687\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.309344\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.306069\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.302873\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.299789\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.296749\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.293810\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.290921\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.288106\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.285349\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.282674\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.280063\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.277512\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.275032\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.272609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 66 finished \tRBM Reconstruction error 0.270257\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.267939\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.265678\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.263468\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.261325\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.259210\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.257172\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.255192\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.253242\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.251339\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.249488\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.247669\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.245910\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.244162\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.242471\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.240829\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.239219\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.237660\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.236127\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.234635\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.233164\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.231732\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.230327\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.228958\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.227620\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.226293\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.225005\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.223750\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.222526\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.221344\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.220162\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.219006\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.217888\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.216797\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.215727\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.008636\n",
      ">> Epoch 2 finished \tANN training loss 0.008297\n",
      ">> Epoch 3 finished \tANN training loss 0.007979\n",
      ">> Epoch 4 finished \tANN training loss 0.007681\n",
      ">> Epoch 5 finished \tANN training loss 0.007401\n",
      ">> Epoch 6 finished \tANN training loss 0.007138\n",
      ">> Epoch 7 finished \tANN training loss 0.006892\n",
      ">> Epoch 8 finished \tANN training loss 0.006660\n",
      ">> Epoch 9 finished \tANN training loss 0.006442\n",
      ">> Epoch 10 finished \tANN training loss 0.006238\n",
      ">> Epoch 11 finished \tANN training loss 0.006046\n",
      ">> Epoch 12 finished \tANN training loss 0.005865\n",
      ">> Epoch 13 finished \tANN training loss 0.005695\n",
      ">> Epoch 14 finished \tANN training loss 0.005535\n",
      ">> Epoch 15 finished \tANN training loss 0.005384\n",
      ">> Epoch 16 finished \tANN training loss 0.005242\n",
      ">> Epoch 17 finished \tANN training loss 0.005109\n",
      ">> Epoch 18 finished \tANN training loss 0.004982\n",
      ">> Epoch 19 finished \tANN training loss 0.004864\n",
      ">> Epoch 20 finished \tANN training loss 0.004752\n",
      ">> Epoch 21 finished \tANN training loss 0.004646\n",
      ">> Epoch 22 finished \tANN training loss 0.004546\n",
      ">> Epoch 23 finished \tANN training loss 0.004451\n",
      ">> Epoch 24 finished \tANN training loss 0.004362\n",
      ">> Epoch 25 finished \tANN training loss 0.004277\n",
      ">> Epoch 26 finished \tANN training loss 0.004198\n",
      ">> Epoch 27 finished \tANN training loss 0.004122\n",
      ">> Epoch 28 finished \tANN training loss 0.004050\n",
      ">> Epoch 29 finished \tANN training loss 0.003982\n",
      ">> Epoch 30 finished \tANN training loss 0.003917\n",
      ">> Epoch 31 finished \tANN training loss 0.003856\n",
      ">> Epoch 32 finished \tANN training loss 0.003797\n",
      ">> Epoch 33 finished \tANN training loss 0.003741\n",
      ">> Epoch 34 finished \tANN training loss 0.003688\n",
      ">> Epoch 35 finished \tANN training loss 0.003638\n",
      ">> Epoch 36 finished \tANN training loss 0.003590\n",
      ">> Epoch 37 finished \tANN training loss 0.003544\n",
      ">> Epoch 38 finished \tANN training loss 0.003500\n",
      ">> Epoch 39 finished \tANN training loss 0.003458\n",
      ">> Epoch 40 finished \tANN training loss 0.003418\n",
      ">> Epoch 41 finished \tANN training loss 0.003379\n",
      ">> Epoch 42 finished \tANN training loss 0.003342\n",
      ">> Epoch 43 finished \tANN training loss 0.003306\n",
      ">> Epoch 44 finished \tANN training loss 0.003272\n",
      ">> Epoch 45 finished \tANN training loss 0.003239\n",
      ">> Epoch 46 finished \tANN training loss 0.003208\n",
      ">> Epoch 47 finished \tANN training loss 0.003177\n",
      ">> Epoch 48 finished \tANN training loss 0.003148\n",
      ">> Epoch 49 finished \tANN training loss 0.003119\n",
      ">> Epoch 50 finished \tANN training loss 0.003091\n",
      ">> Epoch 51 finished \tANN training loss 0.003065\n",
      ">> Epoch 52 finished \tANN training loss 0.003039\n",
      ">> Epoch 53 finished \tANN training loss 0.003014\n",
      ">> Epoch 54 finished \tANN training loss 0.002989\n",
      ">> Epoch 55 finished \tANN training loss 0.002966\n",
      ">> Epoch 56 finished \tANN training loss 0.002943\n",
      ">> Epoch 57 finished \tANN training loss 0.002920\n",
      ">> Epoch 58 finished \tANN training loss 0.002898\n",
      ">> Epoch 59 finished \tANN training loss 0.002877\n",
      ">> Epoch 60 finished \tANN training loss 0.002856\n",
      ">> Epoch 61 finished \tANN training loss 0.002836\n",
      ">> Epoch 62 finished \tANN training loss 0.002816\n",
      ">> Epoch 63 finished \tANN training loss 0.002796\n",
      ">> Epoch 64 finished \tANN training loss 0.002777\n",
      ">> Epoch 65 finished \tANN training loss 0.002759\n",
      ">> Epoch 66 finished \tANN training loss 0.002740\n",
      ">> Epoch 67 finished \tANN training loss 0.002722\n",
      ">> Epoch 68 finished \tANN training loss 0.002705\n",
      ">> Epoch 69 finished \tANN training loss 0.002687\n",
      ">> Epoch 70 finished \tANN training loss 0.002670\n",
      ">> Epoch 71 finished \tANN training loss 0.002653\n",
      ">> Epoch 72 finished \tANN training loss 0.002637\n",
      ">> Epoch 73 finished \tANN training loss 0.002621\n",
      ">> Epoch 74 finished \tANN training loss 0.002604\n",
      ">> Epoch 75 finished \tANN training loss 0.002589\n",
      ">> Epoch 76 finished \tANN training loss 0.002573\n",
      ">> Epoch 77 finished \tANN training loss 0.002558\n",
      ">> Epoch 78 finished \tANN training loss 0.002543\n",
      ">> Epoch 79 finished \tANN training loss 0.002528\n",
      ">> Epoch 80 finished \tANN training loss 0.002513\n",
      ">> Epoch 81 finished \tANN training loss 0.002498\n",
      ">> Epoch 82 finished \tANN training loss 0.002484\n",
      ">> Epoch 83 finished \tANN training loss 0.002469\n",
      ">> Epoch 84 finished \tANN training loss 0.002455\n",
      ">> Epoch 85 finished \tANN training loss 0.002441\n",
      ">> Epoch 86 finished \tANN training loss 0.002427\n",
      ">> Epoch 87 finished \tANN training loss 0.002414\n",
      ">> Epoch 88 finished \tANN training loss 0.002400\n",
      ">> Epoch 89 finished \tANN training loss 0.002387\n",
      ">> Epoch 90 finished \tANN training loss 0.002373\n",
      ">> Epoch 91 finished \tANN training loss 0.002360\n",
      ">> Epoch 92 finished \tANN training loss 0.002347\n",
      ">> Epoch 93 finished \tANN training loss 0.002334\n",
      ">> Epoch 94 finished \tANN training loss 0.002321\n",
      ">> Epoch 95 finished \tANN training loss 0.002309\n",
      ">> Epoch 96 finished \tANN training loss 0.002296\n",
      ">> Epoch 97 finished \tANN training loss 0.002284\n",
      ">> Epoch 98 finished \tANN training loss 0.002271\n",
      ">> Epoch 99 finished \tANN training loss 0.002259\n",
      ">> Epoch 100 finished \tANN training loss 0.002247\n",
      ">> Epoch 101 finished \tANN training loss 0.002235\n",
      ">> Epoch 102 finished \tANN training loss 0.002223\n",
      ">> Epoch 103 finished \tANN training loss 0.002211\n",
      ">> Epoch 104 finished \tANN training loss 0.002199\n",
      ">> Epoch 105 finished \tANN training loss 0.002187\n",
      ">> Epoch 106 finished \tANN training loss 0.002175\n",
      ">> Epoch 107 finished \tANN training loss 0.002164\n",
      ">> Epoch 108 finished \tANN training loss 0.002152\n",
      ">> Epoch 109 finished \tANN training loss 0.002141\n",
      ">> Epoch 110 finished \tANN training loss 0.002130\n",
      ">> Epoch 111 finished \tANN training loss 0.002119\n",
      ">> Epoch 112 finished \tANN training loss 0.002107\n",
      ">> Epoch 113 finished \tANN training loss 0.002096\n",
      ">> Epoch 114 finished \tANN training loss 0.002085\n",
      ">> Epoch 115 finished \tANN training loss 0.002074\n",
      ">> Epoch 116 finished \tANN training loss 0.002064\n",
      ">> Epoch 117 finished \tANN training loss 0.002053\n",
      ">> Epoch 118 finished \tANN training loss 0.002042\n",
      ">> Epoch 119 finished \tANN training loss 0.002031\n",
      ">> Epoch 120 finished \tANN training loss 0.002021\n",
      ">> Epoch 121 finished \tANN training loss 0.002010\n",
      ">> Epoch 122 finished \tANN training loss 0.002000\n",
      ">> Epoch 123 finished \tANN training loss 0.001990\n",
      ">> Epoch 124 finished \tANN training loss 0.001979\n",
      ">> Epoch 125 finished \tANN training loss 0.001969\n",
      ">> Epoch 126 finished \tANN training loss 0.001959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 127 finished \tANN training loss 0.001949\n",
      ">> Epoch 128 finished \tANN training loss 0.001939\n",
      ">> Epoch 129 finished \tANN training loss 0.001929\n",
      ">> Epoch 130 finished \tANN training loss 0.001919\n",
      ">> Epoch 131 finished \tANN training loss 0.001909\n",
      ">> Epoch 132 finished \tANN training loss 0.001900\n",
      ">> Epoch 133 finished \tANN training loss 0.001890\n",
      ">> Epoch 134 finished \tANN training loss 0.001880\n",
      ">> Epoch 135 finished \tANN training loss 0.001871\n",
      ">> Epoch 136 finished \tANN training loss 0.001861\n",
      ">> Epoch 137 finished \tANN training loss 0.001852\n",
      ">> Epoch 138 finished \tANN training loss 0.001842\n",
      ">> Epoch 139 finished \tANN training loss 0.001833\n",
      ">> Epoch 140 finished \tANN training loss 0.001824\n",
      ">> Epoch 141 finished \tANN training loss 0.001815\n",
      ">> Epoch 142 finished \tANN training loss 0.001805\n",
      ">> Epoch 143 finished \tANN training loss 0.001796\n",
      ">> Epoch 144 finished \tANN training loss 0.001787\n",
      ">> Epoch 145 finished \tANN training loss 0.001778\n",
      ">> Epoch 146 finished \tANN training loss 0.001769\n",
      ">> Epoch 147 finished \tANN training loss 0.001761\n",
      ">> Epoch 148 finished \tANN training loss 0.001752\n",
      ">> Epoch 149 finished \tANN training loss 0.001743\n",
      ">> Epoch 150 finished \tANN training loss 0.001734\n",
      "[END] Fine tuning step\n",
      "############### End Training for BPCLEQ #####################\n",
      "############### End Training for JUSTDIALEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 12.339441\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 12.229446\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 12.114491\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 11.994250\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 11.868304\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 11.735974\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 11.596843\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 11.450171\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 11.295242\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 11.131671\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 10.958592\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 10.775394\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 10.581104\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 10.375283\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 10.156776\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 9.925316\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 9.679803\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 9.419876\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 9.144933\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 8.853912\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 8.547106\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 8.224765\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 7.885591\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 7.531160\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 7.162425\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 6.779521\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 6.385261\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 5.978873\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 5.566666\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 5.149561\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 4.735310\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 4.322435\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 3.914375\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 3.517795\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 3.137213\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 2.775630\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 2.438365\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 2.127424\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 1.841422\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 1.587291\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 1.364934\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 1.170024\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 1.005176\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.866280\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.752024\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.660471\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.587028\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.530367\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.487858\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.456283\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.433378\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.417963\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.408975\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.404282\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.402627\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.403495\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.405740\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.409304\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.413796\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.418044\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.422637\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.426332\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.429095\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.432875\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.437398\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.439978\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.442577\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.445156\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.447280\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.450359\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.451507\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.451634\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.452924\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.453706\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.453801\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.453519\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.454867\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.455720\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.456943\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.457358\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.458617\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.458128\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.457797\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.459067\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.459460\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.459311\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.459323\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.459263\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.460065\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.459784\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.458673\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.458767\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.456064\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.456158\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.456539\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.456225\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.458395\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.457757\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.457375\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.457014\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.640092\n",
      ">> Epoch 2 finished \tANN training loss 0.554101\n",
      ">> Epoch 3 finished \tANN training loss 0.480065\n",
      ">> Epoch 4 finished \tANN training loss 0.416280\n",
      ">> Epoch 5 finished \tANN training loss 0.361235\n",
      ">> Epoch 6 finished \tANN training loss 0.313754\n",
      ">> Epoch 7 finished \tANN training loss 0.272818\n",
      ">> Epoch 8 finished \tANN training loss 0.237515\n",
      ">> Epoch 9 finished \tANN training loss 0.207020\n",
      ">> Epoch 10 finished \tANN training loss 0.180670\n",
      ">> Epoch 11 finished \tANN training loss 0.157907\n",
      ">> Epoch 12 finished \tANN training loss 0.138224\n",
      ">> Epoch 13 finished \tANN training loss 0.121196\n",
      ">> Epoch 14 finished \tANN training loss 0.106471\n",
      ">> Epoch 15 finished \tANN training loss 0.093728\n",
      ">> Epoch 16 finished \tANN training loss 0.082701\n",
      ">> Epoch 17 finished \tANN training loss 0.073154\n",
      ">> Epoch 18 finished \tANN training loss 0.064893\n",
      ">> Epoch 19 finished \tANN training loss 0.057739\n",
      ">> Epoch 20 finished \tANN training loss 0.051549\n",
      ">> Epoch 21 finished \tANN training loss 0.046189\n",
      ">> Epoch 22 finished \tANN training loss 0.041553\n",
      ">> Epoch 23 finished \tANN training loss 0.037541\n",
      ">> Epoch 24 finished \tANN training loss 0.034068\n",
      ">> Epoch 25 finished \tANN training loss 0.031058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 26 finished \tANN training loss 0.028456\n",
      ">> Epoch 27 finished \tANN training loss 0.026203\n",
      ">> Epoch 28 finished \tANN training loss 0.024251\n",
      ">> Epoch 29 finished \tANN training loss 0.022561\n",
      ">> Epoch 30 finished \tANN training loss 0.021099\n",
      ">> Epoch 31 finished \tANN training loss 0.019832\n",
      ">> Epoch 32 finished \tANN training loss 0.018737\n",
      ">> Epoch 33 finished \tANN training loss 0.017788\n",
      ">> Epoch 34 finished \tANN training loss 0.016964\n",
      ">> Epoch 35 finished \tANN training loss 0.016251\n",
      ">> Epoch 36 finished \tANN training loss 0.015632\n",
      ">> Epoch 37 finished \tANN training loss 0.015097\n",
      ">> Epoch 38 finished \tANN training loss 0.014632\n",
      ">> Epoch 39 finished \tANN training loss 0.014228\n",
      ">> Epoch 40 finished \tANN training loss 0.013878\n",
      ">> Epoch 41 finished \tANN training loss 0.013572\n",
      ">> Epoch 42 finished \tANN training loss 0.013305\n",
      ">> Epoch 43 finished \tANN training loss 0.013073\n",
      ">> Epoch 44 finished \tANN training loss 0.012871\n",
      ">> Epoch 45 finished \tANN training loss 0.012693\n",
      ">> Epoch 46 finished \tANN training loss 0.012537\n",
      ">> Epoch 47 finished \tANN training loss 0.012401\n",
      ">> Epoch 48 finished \tANN training loss 0.012280\n",
      ">> Epoch 49 finished \tANN training loss 0.012174\n",
      ">> Epoch 50 finished \tANN training loss 0.012081\n",
      ">> Epoch 51 finished \tANN training loss 0.011998\n",
      ">> Epoch 52 finished \tANN training loss 0.011924\n",
      ">> Epoch 53 finished \tANN training loss 0.011857\n",
      ">> Epoch 54 finished \tANN training loss 0.011798\n",
      ">> Epoch 55 finished \tANN training loss 0.011743\n",
      ">> Epoch 56 finished \tANN training loss 0.011695\n",
      ">> Epoch 57 finished \tANN training loss 0.011651\n",
      ">> Epoch 58 finished \tANN training loss 0.011610\n",
      ">> Epoch 59 finished \tANN training loss 0.011573\n",
      ">> Epoch 60 finished \tANN training loss 0.011538\n",
      ">> Epoch 61 finished \tANN training loss 0.011507\n",
      ">> Epoch 62 finished \tANN training loss 0.011477\n",
      ">> Epoch 63 finished \tANN training loss 0.011449\n",
      ">> Epoch 64 finished \tANN training loss 0.011423\n",
      ">> Epoch 65 finished \tANN training loss 0.011398\n",
      ">> Epoch 66 finished \tANN training loss 0.011374\n",
      ">> Epoch 67 finished \tANN training loss 0.011351\n",
      ">> Epoch 68 finished \tANN training loss 0.011330\n",
      ">> Epoch 69 finished \tANN training loss 0.011309\n",
      ">> Epoch 70 finished \tANN training loss 0.011288\n",
      ">> Epoch 71 finished \tANN training loss 0.011269\n",
      ">> Epoch 72 finished \tANN training loss 0.011249\n",
      ">> Epoch 73 finished \tANN training loss 0.011231\n",
      ">> Epoch 74 finished \tANN training loss 0.011213\n",
      ">> Epoch 75 finished \tANN training loss 0.011195\n",
      ">> Epoch 76 finished \tANN training loss 0.011177\n",
      ">> Epoch 77 finished \tANN training loss 0.011160\n",
      ">> Epoch 78 finished \tANN training loss 0.011143\n",
      ">> Epoch 79 finished \tANN training loss 0.011126\n",
      ">> Epoch 80 finished \tANN training loss 0.011109\n",
      ">> Epoch 81 finished \tANN training loss 0.011093\n",
      ">> Epoch 82 finished \tANN training loss 0.011076\n",
      ">> Epoch 83 finished \tANN training loss 0.011060\n",
      ">> Epoch 84 finished \tANN training loss 0.011044\n",
      ">> Epoch 85 finished \tANN training loss 0.011029\n",
      ">> Epoch 86 finished \tANN training loss 0.011013\n",
      ">> Epoch 87 finished \tANN training loss 0.010997\n",
      ">> Epoch 88 finished \tANN training loss 0.010982\n",
      ">> Epoch 89 finished \tANN training loss 0.010966\n",
      ">> Epoch 90 finished \tANN training loss 0.010951\n",
      ">> Epoch 91 finished \tANN training loss 0.010936\n",
      ">> Epoch 92 finished \tANN training loss 0.010920\n",
      ">> Epoch 93 finished \tANN training loss 0.010905\n",
      ">> Epoch 94 finished \tANN training loss 0.010890\n",
      ">> Epoch 95 finished \tANN training loss 0.010875\n",
      ">> Epoch 96 finished \tANN training loss 0.010860\n",
      ">> Epoch 97 finished \tANN training loss 0.010845\n",
      ">> Epoch 98 finished \tANN training loss 0.010830\n",
      ">> Epoch 99 finished \tANN training loss 0.010816\n",
      ">> Epoch 100 finished \tANN training loss 0.010801\n",
      ">> Epoch 101 finished \tANN training loss 0.010787\n",
      ">> Epoch 102 finished \tANN training loss 0.010772\n",
      ">> Epoch 103 finished \tANN training loss 0.010757\n",
      ">> Epoch 104 finished \tANN training loss 0.010743\n",
      ">> Epoch 105 finished \tANN training loss 0.010729\n",
      ">> Epoch 106 finished \tANN training loss 0.010714\n",
      ">> Epoch 107 finished \tANN training loss 0.010700\n",
      ">> Epoch 108 finished \tANN training loss 0.010685\n",
      ">> Epoch 109 finished \tANN training loss 0.010672\n",
      ">> Epoch 110 finished \tANN training loss 0.010657\n",
      ">> Epoch 111 finished \tANN training loss 0.010643\n",
      ">> Epoch 112 finished \tANN training loss 0.010629\n",
      ">> Epoch 113 finished \tANN training loss 0.010615\n",
      ">> Epoch 114 finished \tANN training loss 0.010601\n",
      ">> Epoch 115 finished \tANN training loss 0.010587\n",
      ">> Epoch 116 finished \tANN training loss 0.010573\n",
      ">> Epoch 117 finished \tANN training loss 0.010560\n",
      ">> Epoch 118 finished \tANN training loss 0.010545\n",
      ">> Epoch 119 finished \tANN training loss 0.010532\n",
      ">> Epoch 120 finished \tANN training loss 0.010518\n",
      ">> Epoch 121 finished \tANN training loss 0.010504\n",
      ">> Epoch 122 finished \tANN training loss 0.010490\n",
      ">> Epoch 123 finished \tANN training loss 0.010477\n",
      ">> Epoch 124 finished \tANN training loss 0.010463\n",
      ">> Epoch 125 finished \tANN training loss 0.010449\n",
      ">> Epoch 126 finished \tANN training loss 0.010436\n",
      ">> Epoch 127 finished \tANN training loss 0.010423\n",
      ">> Epoch 128 finished \tANN training loss 0.010409\n",
      ">> Epoch 129 finished \tANN training loss 0.010396\n",
      ">> Epoch 130 finished \tANN training loss 0.010383\n",
      ">> Epoch 131 finished \tANN training loss 0.010370\n",
      ">> Epoch 132 finished \tANN training loss 0.010356\n",
      ">> Epoch 133 finished \tANN training loss 0.010343\n",
      ">> Epoch 134 finished \tANN training loss 0.010330\n",
      ">> Epoch 135 finished \tANN training loss 0.010317\n",
      ">> Epoch 136 finished \tANN training loss 0.010304\n",
      ">> Epoch 137 finished \tANN training loss 0.010291\n",
      ">> Epoch 138 finished \tANN training loss 0.010278\n",
      ">> Epoch 139 finished \tANN training loss 0.010265\n",
      ">> Epoch 140 finished \tANN training loss 0.010252\n",
      ">> Epoch 141 finished \tANN training loss 0.010239\n",
      ">> Epoch 142 finished \tANN training loss 0.010227\n",
      ">> Epoch 143 finished \tANN training loss 0.010214\n",
      ">> Epoch 144 finished \tANN training loss 0.010201\n",
      ">> Epoch 145 finished \tANN training loss 0.010189\n",
      ">> Epoch 146 finished \tANN training loss 0.010176\n",
      ">> Epoch 147 finished \tANN training loss 0.010164\n",
      ">> Epoch 148 finished \tANN training loss 0.010151\n",
      ">> Epoch 149 finished \tANN training loss 0.010139\n",
      ">> Epoch 150 finished \tANN training loss 0.010126\n",
      "[END] Fine tuning step\n",
      "############### End Training for JUSTDIALEQ #####################\n",
      "############### End Training for AUROPHARMAEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 0.322899\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 0.320209\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 0.317587\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 0.315023\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 0.312520\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 0.310073\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 0.307687\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 0.305359\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 0.303089\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 0.300868\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 0.298703\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 0.296593\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 0.294534\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 0.292517\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 0.290550\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 0.288632\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 0.286759\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 0.284929\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 0.283148\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 0.281407\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 0.279711\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 0.278050\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 0.276428\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 0.274847\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 0.273305\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 0.271800\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 0.270334\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 0.268898\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 0.267498\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 0.266134\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 0.264797\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 0.263494\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.262226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 34 finished \tRBM Reconstruction error 0.260988\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.259778\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.258591\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.257436\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.256309\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.255213\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.254134\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.253083\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.252056\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.251056\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.250075\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.249116\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.248180\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.247271\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.246374\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.245495\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.244630\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.243794\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.242971\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.242167\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.241378\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.240607\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.239853\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.239116\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.238395\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.237686\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.236990\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.236306\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.235637\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.234987\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.234341\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.233714\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.233094\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.232485\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.231887\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.231300\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.230727\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.230158\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.229605\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.229059\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.228521\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.227999\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.227482\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.226974\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.226471\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.225978\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.225496\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.225021\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.224553\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.224090\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.223635\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.223183\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.222740\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.222301\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.221872\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.221448\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.221030\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.220614\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.220203\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.219801\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.219403\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.219009\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.218623\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.218239\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.217855\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.217477\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.217103\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.010356\n",
      ">> Epoch 2 finished \tANN training loss 0.009976\n",
      ">> Epoch 3 finished \tANN training loss 0.009618\n",
      ">> Epoch 4 finished \tANN training loss 0.009279\n",
      ">> Epoch 5 finished \tANN training loss 0.008960\n",
      ">> Epoch 6 finished \tANN training loss 0.008659\n",
      ">> Epoch 7 finished \tANN training loss 0.008374\n",
      ">> Epoch 8 finished \tANN training loss 0.008105\n",
      ">> Epoch 9 finished \tANN training loss 0.007852\n",
      ">> Epoch 10 finished \tANN training loss 0.007612\n",
      ">> Epoch 11 finished \tANN training loss 0.007386\n",
      ">> Epoch 12 finished \tANN training loss 0.007172\n",
      ">> Epoch 13 finished \tANN training loss 0.006969\n",
      ">> Epoch 14 finished \tANN training loss 0.006778\n",
      ">> Epoch 15 finished \tANN training loss 0.006597\n",
      ">> Epoch 16 finished \tANN training loss 0.006425\n",
      ">> Epoch 17 finished \tANN training loss 0.006263\n",
      ">> Epoch 18 finished \tANN training loss 0.006109\n",
      ">> Epoch 19 finished \tANN training loss 0.005964\n",
      ">> Epoch 20 finished \tANN training loss 0.005826\n",
      ">> Epoch 21 finished \tANN training loss 0.005695\n",
      ">> Epoch 22 finished \tANN training loss 0.005571\n",
      ">> Epoch 23 finished \tANN training loss 0.005453\n",
      ">> Epoch 24 finished \tANN training loss 0.005341\n",
      ">> Epoch 25 finished \tANN training loss 0.005234\n",
      ">> Epoch 26 finished \tANN training loss 0.005132\n",
      ">> Epoch 27 finished \tANN training loss 0.005036\n",
      ">> Epoch 28 finished \tANN training loss 0.004944\n",
      ">> Epoch 29 finished \tANN training loss 0.004857\n",
      ">> Epoch 30 finished \tANN training loss 0.004773\n",
      ">> Epoch 31 finished \tANN training loss 0.004694\n",
      ">> Epoch 32 finished \tANN training loss 0.004618\n",
      ">> Epoch 33 finished \tANN training loss 0.004546\n",
      ">> Epoch 34 finished \tANN training loss 0.004477\n",
      ">> Epoch 35 finished \tANN training loss 0.004411\n",
      ">> Epoch 36 finished \tANN training loss 0.004348\n",
      ">> Epoch 37 finished \tANN training loss 0.004287\n",
      ">> Epoch 38 finished \tANN training loss 0.004230\n",
      ">> Epoch 39 finished \tANN training loss 0.004174\n",
      ">> Epoch 40 finished \tANN training loss 0.004121\n",
      ">> Epoch 41 finished \tANN training loss 0.004071\n",
      ">> Epoch 42 finished \tANN training loss 0.004022\n",
      ">> Epoch 43 finished \tANN training loss 0.003975\n",
      ">> Epoch 44 finished \tANN training loss 0.003930\n",
      ">> Epoch 45 finished \tANN training loss 0.003887\n",
      ">> Epoch 46 finished \tANN training loss 0.003845\n",
      ">> Epoch 47 finished \tANN training loss 0.003805\n",
      ">> Epoch 48 finished \tANN training loss 0.003767\n",
      ">> Epoch 49 finished \tANN training loss 0.003729\n",
      ">> Epoch 50 finished \tANN training loss 0.003694\n",
      ">> Epoch 51 finished \tANN training loss 0.003659\n",
      ">> Epoch 52 finished \tANN training loss 0.003626\n",
      ">> Epoch 53 finished \tANN training loss 0.003593\n",
      ">> Epoch 54 finished \tANN training loss 0.003562\n",
      ">> Epoch 55 finished \tANN training loss 0.003532\n",
      ">> Epoch 56 finished \tANN training loss 0.003503\n",
      ">> Epoch 57 finished \tANN training loss 0.003474\n",
      ">> Epoch 58 finished \tANN training loss 0.003447\n",
      ">> Epoch 59 finished \tANN training loss 0.003420\n",
      ">> Epoch 60 finished \tANN training loss 0.003394\n",
      ">> Epoch 61 finished \tANN training loss 0.003369\n",
      ">> Epoch 62 finished \tANN training loss 0.003345\n",
      ">> Epoch 63 finished \tANN training loss 0.003321\n",
      ">> Epoch 64 finished \tANN training loss 0.003298\n",
      ">> Epoch 65 finished \tANN training loss 0.003275\n",
      ">> Epoch 66 finished \tANN training loss 0.003253\n",
      ">> Epoch 67 finished \tANN training loss 0.003232\n",
      ">> Epoch 68 finished \tANN training loss 0.003211\n",
      ">> Epoch 69 finished \tANN training loss 0.003191\n",
      ">> Epoch 70 finished \tANN training loss 0.003171\n",
      ">> Epoch 71 finished \tANN training loss 0.003151\n",
      ">> Epoch 72 finished \tANN training loss 0.003132\n",
      ">> Epoch 73 finished \tANN training loss 0.003113\n",
      ">> Epoch 74 finished \tANN training loss 0.003095\n",
      ">> Epoch 75 finished \tANN training loss 0.003077\n",
      ">> Epoch 76 finished \tANN training loss 0.003060\n",
      ">> Epoch 77 finished \tANN training loss 0.003042\n",
      ">> Epoch 78 finished \tANN training loss 0.003025\n",
      ">> Epoch 79 finished \tANN training loss 0.003009\n",
      ">> Epoch 80 finished \tANN training loss 0.002992\n",
      ">> Epoch 81 finished \tANN training loss 0.002976\n",
      ">> Epoch 82 finished \tANN training loss 0.002960\n",
      ">> Epoch 83 finished \tANN training loss 0.002945\n",
      ">> Epoch 84 finished \tANN training loss 0.002929\n",
      ">> Epoch 85 finished \tANN training loss 0.002914\n",
      ">> Epoch 86 finished \tANN training loss 0.002899\n",
      ">> Epoch 87 finished \tANN training loss 0.002885\n",
      ">> Epoch 88 finished \tANN training loss 0.002870\n",
      ">> Epoch 89 finished \tANN training loss 0.002856\n",
      ">> Epoch 90 finished \tANN training loss 0.002841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 91 finished \tANN training loss 0.002827\n",
      ">> Epoch 92 finished \tANN training loss 0.002813\n",
      ">> Epoch 93 finished \tANN training loss 0.002800\n",
      ">> Epoch 94 finished \tANN training loss 0.002786\n",
      ">> Epoch 95 finished \tANN training loss 0.002773\n",
      ">> Epoch 96 finished \tANN training loss 0.002760\n",
      ">> Epoch 97 finished \tANN training loss 0.002746\n",
      ">> Epoch 98 finished \tANN training loss 0.002733\n",
      ">> Epoch 99 finished \tANN training loss 0.002721\n",
      ">> Epoch 100 finished \tANN training loss 0.002708\n",
      ">> Epoch 101 finished \tANN training loss 0.002695\n",
      ">> Epoch 102 finished \tANN training loss 0.002683\n",
      ">> Epoch 103 finished \tANN training loss 0.002670\n",
      ">> Epoch 104 finished \tANN training loss 0.002658\n",
      ">> Epoch 105 finished \tANN training loss 0.002646\n",
      ">> Epoch 106 finished \tANN training loss 0.002634\n",
      ">> Epoch 107 finished \tANN training loss 0.002622\n",
      ">> Epoch 108 finished \tANN training loss 0.002610\n",
      ">> Epoch 109 finished \tANN training loss 0.002598\n",
      ">> Epoch 110 finished \tANN training loss 0.002586\n",
      ">> Epoch 111 finished \tANN training loss 0.002575\n",
      ">> Epoch 112 finished \tANN training loss 0.002563\n",
      ">> Epoch 113 finished \tANN training loss 0.002552\n",
      ">> Epoch 114 finished \tANN training loss 0.002540\n",
      ">> Epoch 115 finished \tANN training loss 0.002529\n",
      ">> Epoch 116 finished \tANN training loss 0.002518\n",
      ">> Epoch 117 finished \tANN training loss 0.002507\n",
      ">> Epoch 118 finished \tANN training loss 0.002496\n",
      ">> Epoch 119 finished \tANN training loss 0.002485\n",
      ">> Epoch 120 finished \tANN training loss 0.002474\n",
      ">> Epoch 121 finished \tANN training loss 0.002463\n",
      ">> Epoch 122 finished \tANN training loss 0.002452\n",
      ">> Epoch 123 finished \tANN training loss 0.002441\n",
      ">> Epoch 124 finished \tANN training loss 0.002431\n",
      ">> Epoch 125 finished \tANN training loss 0.002420\n",
      ">> Epoch 126 finished \tANN training loss 0.002409\n",
      ">> Epoch 127 finished \tANN training loss 0.002399\n",
      ">> Epoch 128 finished \tANN training loss 0.002389\n",
      ">> Epoch 129 finished \tANN training loss 0.002378\n",
      ">> Epoch 130 finished \tANN training loss 0.002368\n",
      ">> Epoch 131 finished \tANN training loss 0.002358\n",
      ">> Epoch 132 finished \tANN training loss 0.002348\n",
      ">> Epoch 133 finished \tANN training loss 0.002338\n",
      ">> Epoch 134 finished \tANN training loss 0.002327\n",
      ">> Epoch 135 finished \tANN training loss 0.002317\n",
      ">> Epoch 136 finished \tANN training loss 0.002308\n",
      ">> Epoch 137 finished \tANN training loss 0.002298\n",
      ">> Epoch 138 finished \tANN training loss 0.002288\n",
      ">> Epoch 139 finished \tANN training loss 0.002278\n",
      ">> Epoch 140 finished \tANN training loss 0.002268\n",
      ">> Epoch 141 finished \tANN training loss 0.002259\n",
      ">> Epoch 142 finished \tANN training loss 0.002249\n",
      ">> Epoch 143 finished \tANN training loss 0.002239\n",
      ">> Epoch 144 finished \tANN training loss 0.002230\n",
      ">> Epoch 145 finished \tANN training loss 0.002220\n",
      ">> Epoch 146 finished \tANN training loss 0.002211\n",
      ">> Epoch 147 finished \tANN training loss 0.002202\n",
      ">> Epoch 148 finished \tANN training loss 0.002192\n",
      ">> Epoch 149 finished \tANN training loss 0.002183\n",
      ">> Epoch 150 finished \tANN training loss 0.002174\n",
      "[END] Fine tuning step\n",
      "############### End Training for AUROPHARMAEQ #####################\n",
      "############### End Training for BERGEPAINTEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 0.320379\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 0.318233\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 0.316141\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 0.314097\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 0.312106\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 0.310160\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 0.308262\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 0.306410\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 0.304601\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 0.302839\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 0.301114\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 0.299433\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 0.297792\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 0.296189\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 0.294631\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 0.293113\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 0.291632\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 0.290189\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 0.288777\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 0.287402\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 0.286057\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 0.284747\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 0.283471\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 0.282226\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 0.281015\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 0.279829\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 0.278671\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 0.277544\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 0.276448\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 0.275371\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 0.274325\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 0.273304\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.272308\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.271338\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.270390\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.269468\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.268569\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.267692\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.266834\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.265996\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.265175\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.264375\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.263593\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.262832\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.262086\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.261357\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.260644\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.259948\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.259271\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.258606\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.257959\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.257324\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.256704\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.256094\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.255502\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.254922\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.254353\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.253797\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.253253\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.252718\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.252195\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.251686\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.251187\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.250698\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.250217\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.249748\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.249287\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.248835\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.248389\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.247954\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.247527\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.247109\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.246699\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.246298\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.245901\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.245511\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.245128\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.244752\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.244380\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.244019\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.243662\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.243309\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.242962\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.242622\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.242285\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.241955\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.241629\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.241309\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.240994\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.240682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 91 finished \tRBM Reconstruction error 0.240373\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.240072\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.239773\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.239476\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.239183\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.238895\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.238610\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.238330\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.238052\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.237777\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.015524\n",
      ">> Epoch 2 finished \tANN training loss 0.014886\n",
      ">> Epoch 3 finished \tANN training loss 0.014280\n",
      ">> Epoch 4 finished \tANN training loss 0.013706\n",
      ">> Epoch 5 finished \tANN training loss 0.013161\n",
      ">> Epoch 6 finished \tANN training loss 0.012644\n",
      ">> Epoch 7 finished \tANN training loss 0.012154\n",
      ">> Epoch 8 finished \tANN training loss 0.011688\n",
      ">> Epoch 9 finished \tANN training loss 0.011247\n",
      ">> Epoch 10 finished \tANN training loss 0.010829\n",
      ">> Epoch 11 finished \tANN training loss 0.010433\n",
      ">> Epoch 12 finished \tANN training loss 0.010057\n",
      ">> Epoch 13 finished \tANN training loss 0.009701\n",
      ">> Epoch 14 finished \tANN training loss 0.009363\n",
      ">> Epoch 15 finished \tANN training loss 0.009042\n",
      ">> Epoch 16 finished \tANN training loss 0.008737\n",
      ">> Epoch 17 finished \tANN training loss 0.008447\n",
      ">> Epoch 18 finished \tANN training loss 0.008171\n",
      ">> Epoch 19 finished \tANN training loss 0.007909\n",
      ">> Epoch 20 finished \tANN training loss 0.007660\n",
      ">> Epoch 21 finished \tANN training loss 0.007423\n",
      ">> Epoch 22 finished \tANN training loss 0.007198\n",
      ">> Epoch 23 finished \tANN training loss 0.006984\n",
      ">> Epoch 24 finished \tANN training loss 0.006780\n",
      ">> Epoch 25 finished \tANN training loss 0.006585\n",
      ">> Epoch 26 finished \tANN training loss 0.006400\n",
      ">> Epoch 27 finished \tANN training loss 0.006224\n",
      ">> Epoch 28 finished \tANN training loss 0.006057\n",
      ">> Epoch 29 finished \tANN training loss 0.005898\n",
      ">> Epoch 30 finished \tANN training loss 0.005746\n",
      ">> Epoch 31 finished \tANN training loss 0.005601\n",
      ">> Epoch 32 finished \tANN training loss 0.005463\n",
      ">> Epoch 33 finished \tANN training loss 0.005332\n",
      ">> Epoch 34 finished \tANN training loss 0.005206\n",
      ">> Epoch 35 finished \tANN training loss 0.005087\n",
      ">> Epoch 36 finished \tANN training loss 0.004972\n",
      ">> Epoch 37 finished \tANN training loss 0.004863\n",
      ">> Epoch 38 finished \tANN training loss 0.004758\n",
      ">> Epoch 39 finished \tANN training loss 0.004657\n",
      ">> Epoch 40 finished \tANN training loss 0.004562\n",
      ">> Epoch 41 finished \tANN training loss 0.004470\n",
      ">> Epoch 42 finished \tANN training loss 0.004382\n",
      ">> Epoch 43 finished \tANN training loss 0.004298\n",
      ">> Epoch 44 finished \tANN training loss 0.004218\n",
      ">> Epoch 45 finished \tANN training loss 0.004141\n",
      ">> Epoch 46 finished \tANN training loss 0.004067\n",
      ">> Epoch 47 finished \tANN training loss 0.003997\n",
      ">> Epoch 48 finished \tANN training loss 0.003929\n",
      ">> Epoch 49 finished \tANN training loss 0.003864\n",
      ">> Epoch 50 finished \tANN training loss 0.003802\n",
      ">> Epoch 51 finished \tANN training loss 0.003743\n",
      ">> Epoch 52 finished \tANN training loss 0.003686\n",
      ">> Epoch 53 finished \tANN training loss 0.003631\n",
      ">> Epoch 54 finished \tANN training loss 0.003578\n",
      ">> Epoch 55 finished \tANN training loss 0.003528\n",
      ">> Epoch 56 finished \tANN training loss 0.003479\n",
      ">> Epoch 57 finished \tANN training loss 0.003432\n",
      ">> Epoch 58 finished \tANN training loss 0.003387\n",
      ">> Epoch 59 finished \tANN training loss 0.003344\n",
      ">> Epoch 60 finished \tANN training loss 0.003302\n",
      ">> Epoch 61 finished \tANN training loss 0.003262\n",
      ">> Epoch 62 finished \tANN training loss 0.003223\n",
      ">> Epoch 63 finished \tANN training loss 0.003186\n",
      ">> Epoch 64 finished \tANN training loss 0.003150\n",
      ">> Epoch 65 finished \tANN training loss 0.003115\n",
      ">> Epoch 66 finished \tANN training loss 0.003082\n",
      ">> Epoch 67 finished \tANN training loss 0.003049\n",
      ">> Epoch 68 finished \tANN training loss 0.003018\n",
      ">> Epoch 69 finished \tANN training loss 0.002987\n",
      ">> Epoch 70 finished \tANN training loss 0.002958\n",
      ">> Epoch 71 finished \tANN training loss 0.002929\n",
      ">> Epoch 72 finished \tANN training loss 0.002901\n",
      ">> Epoch 73 finished \tANN training loss 0.002874\n",
      ">> Epoch 74 finished \tANN training loss 0.002848\n",
      ">> Epoch 75 finished \tANN training loss 0.002823\n",
      ">> Epoch 76 finished \tANN training loss 0.002798\n",
      ">> Epoch 77 finished \tANN training loss 0.002774\n",
      ">> Epoch 78 finished \tANN training loss 0.002751\n",
      ">> Epoch 79 finished \tANN training loss 0.002728\n",
      ">> Epoch 80 finished \tANN training loss 0.002706\n",
      ">> Epoch 81 finished \tANN training loss 0.002684\n",
      ">> Epoch 82 finished \tANN training loss 0.002663\n",
      ">> Epoch 83 finished \tANN training loss 0.002642\n",
      ">> Epoch 84 finished \tANN training loss 0.002622\n",
      ">> Epoch 85 finished \tANN training loss 0.002602\n",
      ">> Epoch 86 finished \tANN training loss 0.002583\n",
      ">> Epoch 87 finished \tANN training loss 0.002564\n",
      ">> Epoch 88 finished \tANN training loss 0.002546\n",
      ">> Epoch 89 finished \tANN training loss 0.002528\n",
      ">> Epoch 90 finished \tANN training loss 0.002510\n",
      ">> Epoch 91 finished \tANN training loss 0.002493\n",
      ">> Epoch 92 finished \tANN training loss 0.002476\n",
      ">> Epoch 93 finished \tANN training loss 0.002459\n",
      ">> Epoch 94 finished \tANN training loss 0.002443\n",
      ">> Epoch 95 finished \tANN training loss 0.002426\n",
      ">> Epoch 96 finished \tANN training loss 0.002410\n",
      ">> Epoch 97 finished \tANN training loss 0.002395\n",
      ">> Epoch 98 finished \tANN training loss 0.002380\n",
      ">> Epoch 99 finished \tANN training loss 0.002364\n",
      ">> Epoch 100 finished \tANN training loss 0.002350\n",
      ">> Epoch 101 finished \tANN training loss 0.002335\n",
      ">> Epoch 102 finished \tANN training loss 0.002320\n",
      ">> Epoch 103 finished \tANN training loss 0.002306\n",
      ">> Epoch 104 finished \tANN training loss 0.002292\n",
      ">> Epoch 105 finished \tANN training loss 0.002278\n",
      ">> Epoch 106 finished \tANN training loss 0.002265\n",
      ">> Epoch 107 finished \tANN training loss 0.002251\n",
      ">> Epoch 108 finished \tANN training loss 0.002238\n",
      ">> Epoch 109 finished \tANN training loss 0.002225\n",
      ">> Epoch 110 finished \tANN training loss 0.002212\n",
      ">> Epoch 111 finished \tANN training loss 0.002199\n",
      ">> Epoch 112 finished \tANN training loss 0.002186\n",
      ">> Epoch 113 finished \tANN training loss 0.002173\n",
      ">> Epoch 114 finished \tANN training loss 0.002161\n",
      ">> Epoch 115 finished \tANN training loss 0.002149\n",
      ">> Epoch 116 finished \tANN training loss 0.002137\n",
      ">> Epoch 117 finished \tANN training loss 0.002124\n",
      ">> Epoch 118 finished \tANN training loss 0.002113\n",
      ">> Epoch 119 finished \tANN training loss 0.002101\n",
      ">> Epoch 120 finished \tANN training loss 0.002089\n",
      ">> Epoch 121 finished \tANN training loss 0.002077\n",
      ">> Epoch 122 finished \tANN training loss 0.002066\n",
      ">> Epoch 123 finished \tANN training loss 0.002055\n",
      ">> Epoch 124 finished \tANN training loss 0.002043\n",
      ">> Epoch 125 finished \tANN training loss 0.002032\n",
      ">> Epoch 126 finished \tANN training loss 0.002021\n",
      ">> Epoch 127 finished \tANN training loss 0.002010\n",
      ">> Epoch 128 finished \tANN training loss 0.001999\n",
      ">> Epoch 129 finished \tANN training loss 0.001988\n",
      ">> Epoch 130 finished \tANN training loss 0.001978\n",
      ">> Epoch 131 finished \tANN training loss 0.001967\n",
      ">> Epoch 132 finished \tANN training loss 0.001956\n",
      ">> Epoch 133 finished \tANN training loss 0.001946\n",
      ">> Epoch 134 finished \tANN training loss 0.001935\n",
      ">> Epoch 135 finished \tANN training loss 0.001925\n",
      ">> Epoch 136 finished \tANN training loss 0.001915\n",
      ">> Epoch 137 finished \tANN training loss 0.001905\n",
      ">> Epoch 138 finished \tANN training loss 0.001895\n",
      ">> Epoch 139 finished \tANN training loss 0.001885\n",
      ">> Epoch 140 finished \tANN training loss 0.001875\n",
      ">> Epoch 141 finished \tANN training loss 0.001865\n",
      ">> Epoch 142 finished \tANN training loss 0.001855\n",
      ">> Epoch 143 finished \tANN training loss 0.001845\n",
      ">> Epoch 144 finished \tANN training loss 0.001835\n",
      ">> Epoch 145 finished \tANN training loss 0.001826\n",
      ">> Epoch 146 finished \tANN training loss 0.001816\n",
      ">> Epoch 147 finished \tANN training loss 0.001807\n",
      ">> Epoch 148 finished \tANN training loss 0.001797\n",
      ">> Epoch 149 finished \tANN training loss 0.001788\n",
      ">> Epoch 150 finished \tANN training loss 0.001779\n",
      "[END] Fine tuning step\n",
      "############### End Training for BERGEPAINTEQ #####################\n",
      "############### End Training for MRFEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 0.272423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 2 finished \tRBM Reconstruction error 0.270117\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 0.267865\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 0.265661\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 0.263512\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 0.261406\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 0.259365\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 0.257372\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 0.255420\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 0.253519\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 0.251667\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 0.249858\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 0.248096\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 0.246375\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 0.244699\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 0.243065\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 0.241468\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 0.239915\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 0.238396\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 0.236917\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 0.235477\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 0.234067\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 0.232694\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 0.231353\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 0.230050\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 0.228778\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 0.227540\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 0.226332\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 0.225151\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 0.223998\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 0.222878\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 0.221784\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.220718\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.219675\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.218662\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.217677\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.216714\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.215775\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.214855\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.213962\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.213087\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.212233\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.211400\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.210589\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.209795\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.209022\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.208260\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.207522\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.206801\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.206098\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.205413\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.204746\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.204089\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.203450\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.202824\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.202211\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.201611\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.201028\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.200458\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.199896\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.199345\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.198808\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.198289\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.197776\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.197277\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.196785\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.196306\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.195839\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.195377\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.194923\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.194480\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.194048\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.193622\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.193204\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.192795\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.192400\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.192005\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.191626\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.191249\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.190880\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.190519\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.190161\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.189811\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.189466\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.189127\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.188793\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.188469\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.188150\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.187834\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.187522\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.187216\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.186913\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.186617\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.186326\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.186038\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.185755\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.185474\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.185200\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.184927\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.184660\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.012902\n",
      ">> Epoch 2 finished \tANN training loss 0.012380\n",
      ">> Epoch 3 finished \tANN training loss 0.011885\n",
      ">> Epoch 4 finished \tANN training loss 0.011415\n",
      ">> Epoch 5 finished \tANN training loss 0.010968\n",
      ">> Epoch 6 finished \tANN training loss 0.010544\n",
      ">> Epoch 7 finished \tANN training loss 0.010142\n",
      ">> Epoch 8 finished \tANN training loss 0.009760\n",
      ">> Epoch 9 finished \tANN training loss 0.009397\n",
      ">> Epoch 10 finished \tANN training loss 0.009052\n",
      ">> Epoch 11 finished \tANN training loss 0.008724\n",
      ">> Epoch 12 finished \tANN training loss 0.008413\n",
      ">> Epoch 13 finished \tANN training loss 0.008118\n",
      ">> Epoch 14 finished \tANN training loss 0.007837\n",
      ">> Epoch 15 finished \tANN training loss 0.007571\n",
      ">> Epoch 16 finished \tANN training loss 0.007318\n",
      ">> Epoch 17 finished \tANN training loss 0.007078\n",
      ">> Epoch 18 finished \tANN training loss 0.006850\n",
      ">> Epoch 19 finished \tANN training loss 0.006633\n",
      ">> Epoch 20 finished \tANN training loss 0.006427\n",
      ">> Epoch 21 finished \tANN training loss 0.006232\n",
      ">> Epoch 22 finished \tANN training loss 0.006047\n",
      ">> Epoch 23 finished \tANN training loss 0.005870\n",
      ">> Epoch 24 finished \tANN training loss 0.005703\n",
      ">> Epoch 25 finished \tANN training loss 0.005543\n",
      ">> Epoch 26 finished \tANN training loss 0.005392\n",
      ">> Epoch 27 finished \tANN training loss 0.005248\n",
      ">> Epoch 28 finished \tANN training loss 0.005111\n",
      ">> Epoch 29 finished \tANN training loss 0.004981\n",
      ">> Epoch 30 finished \tANN training loss 0.004857\n",
      ">> Epoch 31 finished \tANN training loss 0.004739\n",
      ">> Epoch 32 finished \tANN training loss 0.004627\n",
      ">> Epoch 33 finished \tANN training loss 0.004520\n",
      ">> Epoch 34 finished \tANN training loss 0.004418\n",
      ">> Epoch 35 finished \tANN training loss 0.004322\n",
      ">> Epoch 36 finished \tANN training loss 0.004229\n",
      ">> Epoch 37 finished \tANN training loss 0.004141\n",
      ">> Epoch 38 finished \tANN training loss 0.004058\n",
      ">> Epoch 39 finished \tANN training loss 0.003978\n",
      ">> Epoch 40 finished \tANN training loss 0.003902\n",
      ">> Epoch 41 finished \tANN training loss 0.003830\n",
      ">> Epoch 42 finished \tANN training loss 0.003760\n",
      ">> Epoch 43 finished \tANN training loss 0.003695\n",
      ">> Epoch 44 finished \tANN training loss 0.003632\n",
      ">> Epoch 45 finished \tANN training loss 0.003572\n",
      ">> Epoch 46 finished \tANN training loss 0.003514\n",
      ">> Epoch 47 finished \tANN training loss 0.003459\n",
      ">> Epoch 48 finished \tANN training loss 0.003407\n",
      ">> Epoch 49 finished \tANN training loss 0.003357\n",
      ">> Epoch 50 finished \tANN training loss 0.003309\n",
      ">> Epoch 51 finished \tANN training loss 0.003263\n",
      ">> Epoch 52 finished \tANN training loss 0.003219\n",
      ">> Epoch 53 finished \tANN training loss 0.003177\n",
      ">> Epoch 54 finished \tANN training loss 0.003136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 55 finished \tANN training loss 0.003098\n",
      ">> Epoch 56 finished \tANN training loss 0.003060\n",
      ">> Epoch 57 finished \tANN training loss 0.003025\n",
      ">> Epoch 58 finished \tANN training loss 0.002990\n",
      ">> Epoch 59 finished \tANN training loss 0.002958\n",
      ">> Epoch 60 finished \tANN training loss 0.002926\n",
      ">> Epoch 61 finished \tANN training loss 0.002895\n",
      ">> Epoch 62 finished \tANN training loss 0.002866\n",
      ">> Epoch 63 finished \tANN training loss 0.002838\n",
      ">> Epoch 64 finished \tANN training loss 0.002811\n",
      ">> Epoch 65 finished \tANN training loss 0.002785\n",
      ">> Epoch 66 finished \tANN training loss 0.002759\n",
      ">> Epoch 67 finished \tANN training loss 0.002735\n",
      ">> Epoch 68 finished \tANN training loss 0.002711\n",
      ">> Epoch 69 finished \tANN training loss 0.002689\n",
      ">> Epoch 70 finished \tANN training loss 0.002667\n",
      ">> Epoch 71 finished \tANN training loss 0.002646\n",
      ">> Epoch 72 finished \tANN training loss 0.002625\n",
      ">> Epoch 73 finished \tANN training loss 0.002605\n",
      ">> Epoch 74 finished \tANN training loss 0.002586\n",
      ">> Epoch 75 finished \tANN training loss 0.002567\n",
      ">> Epoch 76 finished \tANN training loss 0.002549\n",
      ">> Epoch 77 finished \tANN training loss 0.002532\n",
      ">> Epoch 78 finished \tANN training loss 0.002515\n",
      ">> Epoch 79 finished \tANN training loss 0.002498\n",
      ">> Epoch 80 finished \tANN training loss 0.002482\n",
      ">> Epoch 81 finished \tANN training loss 0.002466\n",
      ">> Epoch 82 finished \tANN training loss 0.002451\n",
      ">> Epoch 83 finished \tANN training loss 0.002436\n",
      ">> Epoch 84 finished \tANN training loss 0.002421\n",
      ">> Epoch 85 finished \tANN training loss 0.002407\n",
      ">> Epoch 86 finished \tANN training loss 0.002393\n",
      ">> Epoch 87 finished \tANN training loss 0.002380\n",
      ">> Epoch 88 finished \tANN training loss 0.002367\n",
      ">> Epoch 89 finished \tANN training loss 0.002354\n",
      ">> Epoch 90 finished \tANN training loss 0.002341\n",
      ">> Epoch 91 finished \tANN training loss 0.002329\n",
      ">> Epoch 92 finished \tANN training loss 0.002317\n",
      ">> Epoch 93 finished \tANN training loss 0.002305\n",
      ">> Epoch 94 finished \tANN training loss 0.002293\n",
      ">> Epoch 95 finished \tANN training loss 0.002282\n",
      ">> Epoch 96 finished \tANN training loss 0.002270\n",
      ">> Epoch 97 finished \tANN training loss 0.002259\n",
      ">> Epoch 98 finished \tANN training loss 0.002248\n",
      ">> Epoch 99 finished \tANN training loss 0.002238\n",
      ">> Epoch 100 finished \tANN training loss 0.002227\n",
      ">> Epoch 101 finished \tANN training loss 0.002217\n",
      ">> Epoch 102 finished \tANN training loss 0.002207\n",
      ">> Epoch 103 finished \tANN training loss 0.002197\n",
      ">> Epoch 104 finished \tANN training loss 0.002187\n",
      ">> Epoch 105 finished \tANN training loss 0.002177\n",
      ">> Epoch 106 finished \tANN training loss 0.002167\n",
      ">> Epoch 107 finished \tANN training loss 0.002158\n",
      ">> Epoch 108 finished \tANN training loss 0.002149\n",
      ">> Epoch 109 finished \tANN training loss 0.002139\n",
      ">> Epoch 110 finished \tANN training loss 0.002130\n",
      ">> Epoch 111 finished \tANN training loss 0.002121\n",
      ">> Epoch 112 finished \tANN training loss 0.002112\n",
      ">> Epoch 113 finished \tANN training loss 0.002103\n",
      ">> Epoch 114 finished \tANN training loss 0.002095\n",
      ">> Epoch 115 finished \tANN training loss 0.002086\n",
      ">> Epoch 116 finished \tANN training loss 0.002078\n",
      ">> Epoch 117 finished \tANN training loss 0.002069\n",
      ">> Epoch 118 finished \tANN training loss 0.002061\n",
      ">> Epoch 119 finished \tANN training loss 0.002052\n",
      ">> Epoch 120 finished \tANN training loss 0.002044\n",
      ">> Epoch 121 finished \tANN training loss 0.002036\n",
      ">> Epoch 122 finished \tANN training loss 0.002028\n",
      ">> Epoch 123 finished \tANN training loss 0.002020\n",
      ">> Epoch 124 finished \tANN training loss 0.002012\n",
      ">> Epoch 125 finished \tANN training loss 0.002004\n",
      ">> Epoch 126 finished \tANN training loss 0.001996\n",
      ">> Epoch 127 finished \tANN training loss 0.001989\n",
      ">> Epoch 128 finished \tANN training loss 0.001981\n",
      ">> Epoch 129 finished \tANN training loss 0.001973\n",
      ">> Epoch 130 finished \tANN training loss 0.001966\n",
      ">> Epoch 131 finished \tANN training loss 0.001958\n",
      ">> Epoch 132 finished \tANN training loss 0.001951\n",
      ">> Epoch 133 finished \tANN training loss 0.001943\n",
      ">> Epoch 134 finished \tANN training loss 0.001936\n",
      ">> Epoch 135 finished \tANN training loss 0.001929\n",
      ">> Epoch 136 finished \tANN training loss 0.001921\n",
      ">> Epoch 137 finished \tANN training loss 0.001914\n",
      ">> Epoch 138 finished \tANN training loss 0.001907\n",
      ">> Epoch 139 finished \tANN training loss 0.001900\n",
      ">> Epoch 140 finished \tANN training loss 0.001893\n",
      ">> Epoch 141 finished \tANN training loss 0.001886\n",
      ">> Epoch 142 finished \tANN training loss 0.001879\n",
      ">> Epoch 143 finished \tANN training loss 0.001872\n",
      ">> Epoch 144 finished \tANN training loss 0.001865\n",
      ">> Epoch 145 finished \tANN training loss 0.001858\n",
      ">> Epoch 146 finished \tANN training loss 0.001851\n",
      ">> Epoch 147 finished \tANN training loss 0.001845\n",
      ">> Epoch 148 finished \tANN training loss 0.001838\n",
      ">> Epoch 149 finished \tANN training loss 0.001831\n",
      ">> Epoch 150 finished \tANN training loss 0.001824\n",
      "[END] Fine tuning step\n",
      "############### End Training for MRFEQ #####################\n",
      "############### End Training for BHARATFINEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 5.497278\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 5.453037\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 5.408523\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 5.363638\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 5.318381\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 5.272745\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 5.226642\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 5.180058\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 5.132963\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 5.085241\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 5.036835\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 4.987774\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 4.937902\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 4.887249\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 4.835720\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 4.783299\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 4.729845\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 4.675272\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 4.619573\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 4.562711\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 4.504534\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 4.445060\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 4.384207\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 4.321757\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 4.257790\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 4.192229\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 4.124937\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 4.055939\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 3.985035\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 3.912349\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 3.837620\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 3.760912\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 3.682194\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 3.601532\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 3.518763\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 3.434027\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 3.347263\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 3.258490\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 3.168053\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 3.075575\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 2.981383\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 2.885463\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 2.788134\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 2.689900\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 2.590200\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 2.489133\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 2.387806\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 2.285949\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 2.183457\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 2.081500\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 1.980793\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 1.880424\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 1.780653\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 1.683626\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 1.588560\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 1.495884\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 1.406170\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 1.318758\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 1.234196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 60 finished \tRBM Reconstruction error 1.155007\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 1.078882\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 1.007146\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.939915\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.876594\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.817517\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.763248\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.712742\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.666821\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.624969\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.587047\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.552811\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.521830\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.493841\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.468274\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.446055\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.425567\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.407777\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.391746\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.377956\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.366188\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.355933\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.346938\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.338666\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.331727\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.325454\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.319921\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.315179\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.310892\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.307067\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.303508\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.300701\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.298045\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.295627\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.293409\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.291328\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.289514\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.287854\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.286243\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.284724\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.283331\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.155647\n",
      ">> Epoch 2 finished \tANN training loss 0.142553\n",
      ">> Epoch 3 finished \tANN training loss 0.130575\n",
      ">> Epoch 4 finished \tANN training loss 0.119610\n",
      ">> Epoch 5 finished \tANN training loss 0.109569\n",
      ">> Epoch 6 finished \tANN training loss 0.100379\n",
      ">> Epoch 7 finished \tANN training loss 0.091974\n",
      ">> Epoch 8 finished \tANN training loss 0.084290\n",
      ">> Epoch 9 finished \tANN training loss 0.077268\n",
      ">> Epoch 10 finished \tANN training loss 0.070854\n",
      ">> Epoch 11 finished \tANN training loss 0.064999\n",
      ">> Epoch 12 finished \tANN training loss 0.059652\n",
      ">> Epoch 13 finished \tANN training loss 0.054768\n",
      ">> Epoch 14 finished \tANN training loss 0.050310\n",
      ">> Epoch 15 finished \tANN training loss 0.046239\n",
      ">> Epoch 16 finished \tANN training loss 0.042522\n",
      ">> Epoch 17 finished \tANN training loss 0.039128\n",
      ">> Epoch 18 finished \tANN training loss 0.036029\n",
      ">> Epoch 19 finished \tANN training loss 0.033201\n",
      ">> Epoch 20 finished \tANN training loss 0.030619\n",
      ">> Epoch 21 finished \tANN training loss 0.028263\n",
      ">> Epoch 22 finished \tANN training loss 0.026112\n",
      ">> Epoch 23 finished \tANN training loss 0.024149\n",
      ">> Epoch 24 finished \tANN training loss 0.022357\n",
      ">> Epoch 25 finished \tANN training loss 0.020723\n",
      ">> Epoch 26 finished \tANN training loss 0.019230\n",
      ">> Epoch 27 finished \tANN training loss 0.017869\n",
      ">> Epoch 28 finished \tANN training loss 0.016627\n",
      ">> Epoch 29 finished \tANN training loss 0.015493\n",
      ">> Epoch 30 finished \tANN training loss 0.014459\n",
      ">> Epoch 31 finished \tANN training loss 0.013516\n",
      ">> Epoch 32 finished \tANN training loss 0.012655\n",
      ">> Epoch 33 finished \tANN training loss 0.011869\n",
      ">> Epoch 34 finished \tANN training loss 0.011153\n",
      ">> Epoch 35 finished \tANN training loss 0.010499\n",
      ">> Epoch 36 finished \tANN training loss 0.009902\n",
      ">> Epoch 37 finished \tANN training loss 0.009358\n",
      ">> Epoch 38 finished \tANN training loss 0.008861\n",
      ">> Epoch 39 finished \tANN training loss 0.008407\n",
      ">> Epoch 40 finished \tANN training loss 0.007994\n",
      ">> Epoch 41 finished \tANN training loss 0.007616\n",
      ">> Epoch 42 finished \tANN training loss 0.007272\n",
      ">> Epoch 43 finished \tANN training loss 0.006957\n",
      ">> Epoch 44 finished \tANN training loss 0.006670\n",
      ">> Epoch 45 finished \tANN training loss 0.006408\n",
      ">> Epoch 46 finished \tANN training loss 0.006169\n",
      ">> Epoch 47 finished \tANN training loss 0.005951\n",
      ">> Epoch 48 finished \tANN training loss 0.005752\n",
      ">> Epoch 49 finished \tANN training loss 0.005570\n",
      ">> Epoch 50 finished \tANN training loss 0.005405\n",
      ">> Epoch 51 finished \tANN training loss 0.005253\n",
      ">> Epoch 52 finished \tANN training loss 0.005115\n",
      ">> Epoch 53 finished \tANN training loss 0.004989\n",
      ">> Epoch 54 finished \tANN training loss 0.004873\n",
      ">> Epoch 55 finished \tANN training loss 0.004768\n",
      ">> Epoch 56 finished \tANN training loss 0.004672\n",
      ">> Epoch 57 finished \tANN training loss 0.004584\n",
      ">> Epoch 58 finished \tANN training loss 0.004503\n",
      ">> Epoch 59 finished \tANN training loss 0.004430\n",
      ">> Epoch 60 finished \tANN training loss 0.004363\n",
      ">> Epoch 61 finished \tANN training loss 0.004302\n",
      ">> Epoch 62 finished \tANN training loss 0.004246\n",
      ">> Epoch 63 finished \tANN training loss 0.004195\n",
      ">> Epoch 64 finished \tANN training loss 0.004148\n",
      ">> Epoch 65 finished \tANN training loss 0.004105\n",
      ">> Epoch 66 finished \tANN training loss 0.004066\n",
      ">> Epoch 67 finished \tANN training loss 0.004030\n",
      ">> Epoch 68 finished \tANN training loss 0.003998\n",
      ">> Epoch 69 finished \tANN training loss 0.003967\n",
      ">> Epoch 70 finished \tANN training loss 0.003940\n",
      ">> Epoch 71 finished \tANN training loss 0.003915\n",
      ">> Epoch 72 finished \tANN training loss 0.003892\n",
      ">> Epoch 73 finished \tANN training loss 0.003870\n",
      ">> Epoch 74 finished \tANN training loss 0.003851\n",
      ">> Epoch 75 finished \tANN training loss 0.003833\n",
      ">> Epoch 76 finished \tANN training loss 0.003816\n",
      ">> Epoch 77 finished \tANN training loss 0.003801\n",
      ">> Epoch 78 finished \tANN training loss 0.003787\n",
      ">> Epoch 79 finished \tANN training loss 0.003775\n",
      ">> Epoch 80 finished \tANN training loss 0.003763\n",
      ">> Epoch 81 finished \tANN training loss 0.003752\n",
      ">> Epoch 82 finished \tANN training loss 0.003742\n",
      ">> Epoch 83 finished \tANN training loss 0.003732\n",
      ">> Epoch 84 finished \tANN training loss 0.003724\n",
      ">> Epoch 85 finished \tANN training loss 0.003716\n",
      ">> Epoch 86 finished \tANN training loss 0.003708\n",
      ">> Epoch 87 finished \tANN training loss 0.003701\n",
      ">> Epoch 88 finished \tANN training loss 0.003695\n",
      ">> Epoch 89 finished \tANN training loss 0.003689\n",
      ">> Epoch 90 finished \tANN training loss 0.003684\n",
      ">> Epoch 91 finished \tANN training loss 0.003678\n",
      ">> Epoch 92 finished \tANN training loss 0.003673\n",
      ">> Epoch 93 finished \tANN training loss 0.003669\n",
      ">> Epoch 94 finished \tANN training loss 0.003664\n",
      ">> Epoch 95 finished \tANN training loss 0.003660\n",
      ">> Epoch 96 finished \tANN training loss 0.003657\n",
      ">> Epoch 97 finished \tANN training loss 0.003653\n",
      ">> Epoch 98 finished \tANN training loss 0.003650\n",
      ">> Epoch 99 finished \tANN training loss 0.003646\n",
      ">> Epoch 100 finished \tANN training loss 0.003643\n",
      ">> Epoch 101 finished \tANN training loss 0.003640\n",
      ">> Epoch 102 finished \tANN training loss 0.003638\n",
      ">> Epoch 103 finished \tANN training loss 0.003635\n",
      ">> Epoch 104 finished \tANN training loss 0.003632\n",
      ">> Epoch 105 finished \tANN training loss 0.003630\n",
      ">> Epoch 106 finished \tANN training loss 0.003628\n",
      ">> Epoch 107 finished \tANN training loss 0.003625\n",
      ">> Epoch 108 finished \tANN training loss 0.003623\n",
      ">> Epoch 109 finished \tANN training loss 0.003621\n",
      ">> Epoch 110 finished \tANN training loss 0.003619\n",
      ">> Epoch 111 finished \tANN training loss 0.003617\n",
      ">> Epoch 112 finished \tANN training loss 0.003615\n",
      ">> Epoch 113 finished \tANN training loss 0.003613\n",
      ">> Epoch 114 finished \tANN training loss 0.003611\n",
      ">> Epoch 115 finished \tANN training loss 0.003610\n",
      ">> Epoch 116 finished \tANN training loss 0.003608\n",
      ">> Epoch 117 finished \tANN training loss 0.003606\n",
      ">> Epoch 118 finished \tANN training loss 0.003604\n",
      ">> Epoch 119 finished \tANN training loss 0.003603\n",
      ">> Epoch 120 finished \tANN training loss 0.003601\n",
      ">> Epoch 121 finished \tANN training loss 0.003599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 122 finished \tANN training loss 0.003598\n",
      ">> Epoch 123 finished \tANN training loss 0.003596\n",
      ">> Epoch 124 finished \tANN training loss 0.003595\n",
      ">> Epoch 125 finished \tANN training loss 0.003593\n",
      ">> Epoch 126 finished \tANN training loss 0.003592\n",
      ">> Epoch 127 finished \tANN training loss 0.003590\n",
      ">> Epoch 128 finished \tANN training loss 0.003588\n",
      ">> Epoch 129 finished \tANN training loss 0.003587\n",
      ">> Epoch 130 finished \tANN training loss 0.003585\n",
      ">> Epoch 131 finished \tANN training loss 0.003584\n",
      ">> Epoch 132 finished \tANN training loss 0.003582\n",
      ">> Epoch 133 finished \tANN training loss 0.003581\n",
      ">> Epoch 134 finished \tANN training loss 0.003579\n",
      ">> Epoch 135 finished \tANN training loss 0.003578\n",
      ">> Epoch 136 finished \tANN training loss 0.003576\n",
      ">> Epoch 137 finished \tANN training loss 0.003575\n",
      ">> Epoch 138 finished \tANN training loss 0.003574\n",
      ">> Epoch 139 finished \tANN training loss 0.003572\n",
      ">> Epoch 140 finished \tANN training loss 0.003571\n",
      ">> Epoch 141 finished \tANN training loss 0.003569\n",
      ">> Epoch 142 finished \tANN training loss 0.003568\n",
      ">> Epoch 143 finished \tANN training loss 0.003567\n",
      ">> Epoch 144 finished \tANN training loss 0.003565\n",
      ">> Epoch 145 finished \tANN training loss 0.003564\n",
      ">> Epoch 146 finished \tANN training loss 0.003562\n",
      ">> Epoch 147 finished \tANN training loss 0.003561\n",
      ">> Epoch 148 finished \tANN training loss 0.003559\n",
      ">> Epoch 149 finished \tANN training loss 0.003558\n",
      ">> Epoch 150 finished \tANN training loss 0.003557\n",
      "[END] Fine tuning step\n",
      "############### End Training for BHARATFINEQ #####################\n",
      "############### End Training for PTCEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 3.949050\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 3.890489\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 3.831751\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 3.772741\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 3.713391\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 3.653667\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 3.593463\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 3.532783\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 3.471447\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 3.409381\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 3.346544\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 3.282790\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 3.218104\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 3.152310\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 3.085438\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 3.017212\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 2.947683\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 2.876753\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 2.804360\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 2.730421\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 2.654851\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 2.577876\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 2.499360\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 2.419141\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 2.337520\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 2.254610\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 2.170198\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 2.084788\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 1.998319\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 1.910956\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 1.823149\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 1.735328\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 1.647745\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 1.560535\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 1.474282\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 1.389329\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 1.306252\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 1.224837\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 1.146233\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 1.071115\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.999415\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.932161\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.869092\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.810003\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.754539\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.704039\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.658095\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.615943\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.578803\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.545126\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.515409\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.488298\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.464736\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.444405\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.426587\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.410758\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.397641\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.386265\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.375469\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.366206\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.358352\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.351176\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.345138\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.339709\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.334911\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.330570\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.326785\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.323239\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.319821\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.316867\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.314299\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.312091\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.309801\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.307760\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.306059\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.304415\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.302540\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.300890\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.299294\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.297857\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.296632\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.295101\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.293850\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.292631\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.291344\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.290036\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.288883\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.287758\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.286470\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.285433\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.284167\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.283140\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.282128\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.280990\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.279955\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.278948\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.277994\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.276907\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.275885\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.274937\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.266167\n",
      ">> Epoch 2 finished \tANN training loss 0.235851\n",
      ">> Epoch 3 finished \tANN training loss 0.209186\n",
      ">> Epoch 4 finished \tANN training loss 0.185729\n",
      ">> Epoch 5 finished \tANN training loss 0.165059\n",
      ">> Epoch 6 finished \tANN training loss 0.146827\n",
      ">> Epoch 7 finished \tANN training loss 0.130725\n",
      ">> Epoch 8 finished \tANN training loss 0.116485\n",
      ">> Epoch 9 finished \tANN training loss 0.103878\n",
      ">> Epoch 10 finished \tANN training loss 0.092712\n",
      ">> Epoch 11 finished \tANN training loss 0.082821\n",
      ">> Epoch 12 finished \tANN training loss 0.074056\n",
      ">> Epoch 13 finished \tANN training loss 0.066288\n",
      ">> Epoch 14 finished \tANN training loss 0.059403\n",
      ">> Epoch 15 finished \tANN training loss 0.053302\n",
      ">> Epoch 16 finished \tANN training loss 0.047896\n",
      ">> Epoch 17 finished \tANN training loss 0.043108\n",
      ">> Epoch 18 finished \tANN training loss 0.038866\n",
      ">> Epoch 19 finished \tANN training loss 0.035103\n",
      ">> Epoch 20 finished \tANN training loss 0.031769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 21 finished \tANN training loss 0.028816\n",
      ">> Epoch 22 finished \tANN training loss 0.026200\n",
      ">> Epoch 23 finished \tANN training loss 0.023886\n",
      ">> Epoch 24 finished \tANN training loss 0.021839\n",
      ">> Epoch 25 finished \tANN training loss 0.020028\n",
      ">> Epoch 26 finished \tANN training loss 0.018426\n",
      ">> Epoch 27 finished \tANN training loss 0.017010\n",
      ">> Epoch 28 finished \tANN training loss 0.015757\n",
      ">> Epoch 29 finished \tANN training loss 0.014647\n",
      ">> Epoch 30 finished \tANN training loss 0.013665\n",
      ">> Epoch 31 finished \tANN training loss 0.012795\n",
      ">> Epoch 32 finished \tANN training loss 0.012024\n",
      ">> Epoch 33 finished \tANN training loss 0.011342\n",
      ">> Epoch 34 finished \tANN training loss 0.010737\n",
      ">> Epoch 35 finished \tANN training loss 0.010200\n",
      ">> Epoch 36 finished \tANN training loss 0.009724\n",
      ">> Epoch 37 finished \tANN training loss 0.009302\n",
      ">> Epoch 38 finished \tANN training loss 0.008926\n",
      ">> Epoch 39 finished \tANN training loss 0.008592\n",
      ">> Epoch 40 finished \tANN training loss 0.008296\n",
      ">> Epoch 41 finished \tANN training loss 0.008032\n",
      ">> Epoch 42 finished \tANN training loss 0.007796\n",
      ">> Epoch 43 finished \tANN training loss 0.007586\n",
      ">> Epoch 44 finished \tANN training loss 0.007399\n",
      ">> Epoch 45 finished \tANN training loss 0.007232\n",
      ">> Epoch 46 finished \tANN training loss 0.007083\n",
      ">> Epoch 47 finished \tANN training loss 0.006948\n",
      ">> Epoch 48 finished \tANN training loss 0.006828\n",
      ">> Epoch 49 finished \tANN training loss 0.006720\n",
      ">> Epoch 50 finished \tANN training loss 0.006623\n",
      ">> Epoch 51 finished \tANN training loss 0.006535\n",
      ">> Epoch 52 finished \tANN training loss 0.006455\n",
      ">> Epoch 53 finished \tANN training loss 0.006383\n",
      ">> Epoch 54 finished \tANN training loss 0.006318\n",
      ">> Epoch 55 finished \tANN training loss 0.006258\n",
      ">> Epoch 56 finished \tANN training loss 0.006203\n",
      ">> Epoch 57 finished \tANN training loss 0.006153\n",
      ">> Epoch 58 finished \tANN training loss 0.006107\n",
      ">> Epoch 59 finished \tANN training loss 0.006065\n",
      ">> Epoch 60 finished \tANN training loss 0.006025\n",
      ">> Epoch 61 finished \tANN training loss 0.005989\n",
      ">> Epoch 62 finished \tANN training loss 0.005955\n",
      ">> Epoch 63 finished \tANN training loss 0.005923\n",
      ">> Epoch 64 finished \tANN training loss 0.005893\n",
      ">> Epoch 65 finished \tANN training loss 0.005865\n",
      ">> Epoch 66 finished \tANN training loss 0.005838\n",
      ">> Epoch 67 finished \tANN training loss 0.005813\n",
      ">> Epoch 68 finished \tANN training loss 0.005789\n",
      ">> Epoch 69 finished \tANN training loss 0.005766\n",
      ">> Epoch 70 finished \tANN training loss 0.005744\n",
      ">> Epoch 71 finished \tANN training loss 0.005723\n",
      ">> Epoch 72 finished \tANN training loss 0.005702\n",
      ">> Epoch 73 finished \tANN training loss 0.005683\n",
      ">> Epoch 74 finished \tANN training loss 0.005663\n",
      ">> Epoch 75 finished \tANN training loss 0.005645\n",
      ">> Epoch 76 finished \tANN training loss 0.005627\n",
      ">> Epoch 77 finished \tANN training loss 0.005609\n",
      ">> Epoch 78 finished \tANN training loss 0.005592\n",
      ">> Epoch 79 finished \tANN training loss 0.005575\n",
      ">> Epoch 80 finished \tANN training loss 0.005559\n",
      ">> Epoch 81 finished \tANN training loss 0.005543\n",
      ">> Epoch 82 finished \tANN training loss 0.005527\n",
      ">> Epoch 83 finished \tANN training loss 0.005511\n",
      ">> Epoch 84 finished \tANN training loss 0.005496\n",
      ">> Epoch 85 finished \tANN training loss 0.005481\n",
      ">> Epoch 86 finished \tANN training loss 0.005466\n",
      ">> Epoch 87 finished \tANN training loss 0.005451\n",
      ">> Epoch 88 finished \tANN training loss 0.005437\n",
      ">> Epoch 89 finished \tANN training loss 0.005423\n",
      ">> Epoch 90 finished \tANN training loss 0.005408\n",
      ">> Epoch 91 finished \tANN training loss 0.005394\n",
      ">> Epoch 92 finished \tANN training loss 0.005380\n",
      ">> Epoch 93 finished \tANN training loss 0.005366\n",
      ">> Epoch 94 finished \tANN training loss 0.005353\n",
      ">> Epoch 95 finished \tANN training loss 0.005339\n",
      ">> Epoch 96 finished \tANN training loss 0.005326\n",
      ">> Epoch 97 finished \tANN training loss 0.005312\n",
      ">> Epoch 98 finished \tANN training loss 0.005299\n",
      ">> Epoch 99 finished \tANN training loss 0.005286\n",
      ">> Epoch 100 finished \tANN training loss 0.005273\n",
      ">> Epoch 101 finished \tANN training loss 0.005260\n",
      ">> Epoch 102 finished \tANN training loss 0.005247\n",
      ">> Epoch 103 finished \tANN training loss 0.005234\n",
      ">> Epoch 104 finished \tANN training loss 0.005222\n",
      ">> Epoch 105 finished \tANN training loss 0.005209\n",
      ">> Epoch 106 finished \tANN training loss 0.005197\n",
      ">> Epoch 107 finished \tANN training loss 0.005184\n",
      ">> Epoch 108 finished \tANN training loss 0.005172\n",
      ">> Epoch 109 finished \tANN training loss 0.005160\n",
      ">> Epoch 110 finished \tANN training loss 0.005148\n",
      ">> Epoch 111 finished \tANN training loss 0.005135\n",
      ">> Epoch 112 finished \tANN training loss 0.005123\n",
      ">> Epoch 113 finished \tANN training loss 0.005112\n",
      ">> Epoch 114 finished \tANN training loss 0.005100\n",
      ">> Epoch 115 finished \tANN training loss 0.005088\n",
      ">> Epoch 116 finished \tANN training loss 0.005076\n",
      ">> Epoch 117 finished \tANN training loss 0.005065\n",
      ">> Epoch 118 finished \tANN training loss 0.005053\n",
      ">> Epoch 119 finished \tANN training loss 0.005041\n",
      ">> Epoch 120 finished \tANN training loss 0.005030\n",
      ">> Epoch 121 finished \tANN training loss 0.005019\n",
      ">> Epoch 122 finished \tANN training loss 0.005007\n",
      ">> Epoch 123 finished \tANN training loss 0.004996\n",
      ">> Epoch 124 finished \tANN training loss 0.004985\n",
      ">> Epoch 125 finished \tANN training loss 0.004974\n",
      ">> Epoch 126 finished \tANN training loss 0.004963\n",
      ">> Epoch 127 finished \tANN training loss 0.004952\n",
      ">> Epoch 128 finished \tANN training loss 0.004941\n",
      ">> Epoch 129 finished \tANN training loss 0.004930\n",
      ">> Epoch 130 finished \tANN training loss 0.004919\n",
      ">> Epoch 131 finished \tANN training loss 0.004908\n",
      ">> Epoch 132 finished \tANN training loss 0.004898\n",
      ">> Epoch 133 finished \tANN training loss 0.004887\n",
      ">> Epoch 134 finished \tANN training loss 0.004877\n",
      ">> Epoch 135 finished \tANN training loss 0.004866\n",
      ">> Epoch 136 finished \tANN training loss 0.004856\n",
      ">> Epoch 137 finished \tANN training loss 0.004846\n",
      ">> Epoch 138 finished \tANN training loss 0.004835\n",
      ">> Epoch 139 finished \tANN training loss 0.004825\n",
      ">> Epoch 140 finished \tANN training loss 0.004815\n",
      ">> Epoch 141 finished \tANN training loss 0.004805\n",
      ">> Epoch 142 finished \tANN training loss 0.004795\n",
      ">> Epoch 143 finished \tANN training loss 0.004785\n",
      ">> Epoch 144 finished \tANN training loss 0.004775\n",
      ">> Epoch 145 finished \tANN training loss 0.004765\n",
      ">> Epoch 146 finished \tANN training loss 0.004755\n",
      ">> Epoch 147 finished \tANN training loss 0.004746\n",
      ">> Epoch 148 finished \tANN training loss 0.004736\n",
      ">> Epoch 149 finished \tANN training loss 0.004727\n",
      ">> Epoch 150 finished \tANN training loss 0.004717\n",
      "[END] Fine tuning step\n",
      "############### End Training for PTCEQ #####################\n",
      "############### End Training for EQUITASEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 20.674130\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 20.515851\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 20.350781\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 20.178389\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 19.998401\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 19.810046\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 19.613021\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 19.406615\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 19.190002\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 18.962716\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 18.723906\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 18.472908\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 18.209021\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 17.931403\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 17.639245\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 17.331804\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 17.008221\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 16.668449\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 16.310716\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 15.935265\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 15.540908\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 15.127682\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 14.694653\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 14.242071\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 13.769421\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 13.276757\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 12.766164\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 12.236342\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 11.688790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 30 finished \tRBM Reconstruction error 11.125761\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 10.550000\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 9.962282\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 9.364232\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 8.763333\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 8.159504\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 7.554816\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 6.954992\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 6.366394\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 5.794452\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 5.244682\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 4.723217\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 4.222169\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 3.754900\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 3.320591\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 2.919280\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 2.555834\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 2.228952\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 1.936078\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 1.679226\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 1.458008\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 1.271834\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 1.109840\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.972967\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.864569\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.775706\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.702563\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.641505\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.593964\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.556752\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.528139\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.507321\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.491561\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.481005\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.473392\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.468580\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.465992\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.465028\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.465318\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.466014\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.467284\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.470938\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.473275\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.475120\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.477991\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.481887\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.485151\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.487345\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.490021\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.491300\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.493472\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.494865\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.493560\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.494303\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.494254\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.493848\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.494149\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.494671\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.494659\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.496723\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.498648\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.498155\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.499240\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.499922\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.500514\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.500858\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.499995\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.499790\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.501132\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.502620\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.502165\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.562236\n",
      ">> Epoch 2 finished \tANN training loss 0.489123\n",
      ">> Epoch 3 finished \tANN training loss 0.425816\n",
      ">> Epoch 4 finished \tANN training loss 0.371073\n",
      ">> Epoch 5 finished \tANN training loss 0.323807\n",
      ">> Epoch 6 finished \tANN training loss 0.283075\n",
      ">> Epoch 7 finished \tANN training loss 0.247982\n",
      ">> Epoch 8 finished \tANN training loss 0.217617\n",
      ">> Epoch 9 finished \tANN training loss 0.191272\n",
      ">> Epoch 10 finished \tANN training loss 0.168333\n",
      ">> Epoch 11 finished \tANN training loss 0.148343\n",
      ">> Epoch 12 finished \tANN training loss 0.130901\n",
      ">> Epoch 13 finished \tANN training loss 0.115670\n",
      ">> Epoch 14 finished \tANN training loss 0.102373\n",
      ">> Epoch 15 finished \tANN training loss 0.090755\n",
      ">> Epoch 16 finished \tANN training loss 0.080606\n",
      ">> Epoch 17 finished \tANN training loss 0.071739\n",
      ">> Epoch 18 finished \tANN training loss 0.063988\n",
      ">> Epoch 19 finished \tANN training loss 0.057214\n",
      ">> Epoch 20 finished \tANN training loss 0.051298\n",
      ">> Epoch 21 finished \tANN training loss 0.046128\n",
      ">> Epoch 22 finished \tANN training loss 0.041610\n",
      ">> Epoch 23 finished \tANN training loss 0.037666\n",
      ">> Epoch 24 finished \tANN training loss 0.034219\n",
      ">> Epoch 25 finished \tANN training loss 0.031210\n",
      ">> Epoch 26 finished \tANN training loss 0.028579\n",
      ">> Epoch 27 finished \tANN training loss 0.026277\n",
      ">> Epoch 28 finished \tANN training loss 0.024268\n",
      ">> Epoch 29 finished \tANN training loss 0.022514\n",
      ">> Epoch 30 finished \tANN training loss 0.020982\n",
      ">> Epoch 31 finished \tANN training loss 0.019641\n",
      ">> Epoch 32 finished \tANN training loss 0.018471\n",
      ">> Epoch 33 finished \tANN training loss 0.017446\n",
      ">> Epoch 34 finished \tANN training loss 0.016550\n",
      ">> Epoch 35 finished \tANN training loss 0.015766\n",
      ">> Epoch 36 finished \tANN training loss 0.015080\n",
      ">> Epoch 37 finished \tANN training loss 0.014479\n",
      ">> Epoch 38 finished \tANN training loss 0.013954\n",
      ">> Epoch 39 finished \tANN training loss 0.013493\n",
      ">> Epoch 40 finished \tANN training loss 0.013089\n",
      ">> Epoch 41 finished \tANN training loss 0.012736\n",
      ">> Epoch 42 finished \tANN training loss 0.012427\n",
      ">> Epoch 43 finished \tANN training loss 0.012156\n",
      ">> Epoch 44 finished \tANN training loss 0.011918\n",
      ">> Epoch 45 finished \tANN training loss 0.011712\n",
      ">> Epoch 46 finished \tANN training loss 0.011529\n",
      ">> Epoch 47 finished \tANN training loss 0.011369\n",
      ">> Epoch 48 finished \tANN training loss 0.011228\n",
      ">> Epoch 49 finished \tANN training loss 0.011105\n",
      ">> Epoch 50 finished \tANN training loss 0.010998\n",
      ">> Epoch 51 finished \tANN training loss 0.010902\n",
      ">> Epoch 52 finished \tANN training loss 0.010818\n",
      ">> Epoch 53 finished \tANN training loss 0.010745\n",
      ">> Epoch 54 finished \tANN training loss 0.010680\n",
      ">> Epoch 55 finished \tANN training loss 0.010622\n",
      ">> Epoch 56 finished \tANN training loss 0.010572\n",
      ">> Epoch 57 finished \tANN training loss 0.010527\n",
      ">> Epoch 58 finished \tANN training loss 0.010488\n",
      ">> Epoch 59 finished \tANN training loss 0.010454\n",
      ">> Epoch 60 finished \tANN training loss 0.010422\n",
      ">> Epoch 61 finished \tANN training loss 0.010394\n",
      ">> Epoch 62 finished \tANN training loss 0.010370\n",
      ">> Epoch 63 finished \tANN training loss 0.010348\n",
      ">> Epoch 64 finished \tANN training loss 0.010328\n",
      ">> Epoch 65 finished \tANN training loss 0.010311\n",
      ">> Epoch 66 finished \tANN training loss 0.010294\n",
      ">> Epoch 67 finished \tANN training loss 0.010279\n",
      ">> Epoch 68 finished \tANN training loss 0.010266\n",
      ">> Epoch 69 finished \tANN training loss 0.010254\n",
      ">> Epoch 70 finished \tANN training loss 0.010243\n",
      ">> Epoch 71 finished \tANN training loss 0.010233\n",
      ">> Epoch 72 finished \tANN training loss 0.010223\n",
      ">> Epoch 73 finished \tANN training loss 0.010214\n",
      ">> Epoch 74 finished \tANN training loss 0.010206\n",
      ">> Epoch 75 finished \tANN training loss 0.010198\n",
      ">> Epoch 76 finished \tANN training loss 0.010191\n",
      ">> Epoch 77 finished \tANN training loss 0.010183\n",
      ">> Epoch 78 finished \tANN training loss 0.010178\n",
      ">> Epoch 79 finished \tANN training loss 0.010171\n",
      ">> Epoch 80 finished \tANN training loss 0.010164\n",
      ">> Epoch 81 finished \tANN training loss 0.010159\n",
      ">> Epoch 82 finished \tANN training loss 0.010153\n",
      ">> Epoch 83 finished \tANN training loss 0.010147\n",
      ">> Epoch 84 finished \tANN training loss 0.010141\n",
      ">> Epoch 85 finished \tANN training loss 0.010135\n",
      ">> Epoch 86 finished \tANN training loss 0.010130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 87 finished \tANN training loss 0.010124\n",
      ">> Epoch 88 finished \tANN training loss 0.010118\n",
      ">> Epoch 89 finished \tANN training loss 0.010113\n",
      ">> Epoch 90 finished \tANN training loss 0.010107\n",
      ">> Epoch 91 finished \tANN training loss 0.010102\n",
      ">> Epoch 92 finished \tANN training loss 0.010098\n",
      ">> Epoch 93 finished \tANN training loss 0.010091\n",
      ">> Epoch 94 finished \tANN training loss 0.010086\n",
      ">> Epoch 95 finished \tANN training loss 0.010081\n",
      ">> Epoch 96 finished \tANN training loss 0.010075\n",
      ">> Epoch 97 finished \tANN training loss 0.010069\n",
      ">> Epoch 98 finished \tANN training loss 0.010063\n",
      ">> Epoch 99 finished \tANN training loss 0.010058\n",
      ">> Epoch 100 finished \tANN training loss 0.010053\n",
      ">> Epoch 101 finished \tANN training loss 0.010048\n",
      ">> Epoch 102 finished \tANN training loss 0.010042\n",
      ">> Epoch 103 finished \tANN training loss 0.010036\n",
      ">> Epoch 104 finished \tANN training loss 0.010032\n",
      ">> Epoch 105 finished \tANN training loss 0.010026\n",
      ">> Epoch 106 finished \tANN training loss 0.010021\n",
      ">> Epoch 107 finished \tANN training loss 0.010016\n",
      ">> Epoch 108 finished \tANN training loss 0.010009\n",
      ">> Epoch 109 finished \tANN training loss 0.010005\n",
      ">> Epoch 110 finished \tANN training loss 0.009999\n",
      ">> Epoch 111 finished \tANN training loss 0.009994\n",
      ">> Epoch 112 finished \tANN training loss 0.009988\n",
      ">> Epoch 113 finished \tANN training loss 0.009983\n",
      ">> Epoch 114 finished \tANN training loss 0.009977\n",
      ">> Epoch 115 finished \tANN training loss 0.009971\n",
      ">> Epoch 116 finished \tANN training loss 0.009965\n",
      ">> Epoch 117 finished \tANN training loss 0.009961\n",
      ">> Epoch 118 finished \tANN training loss 0.009954\n",
      ">> Epoch 119 finished \tANN training loss 0.009950\n",
      ">> Epoch 120 finished \tANN training loss 0.009944\n",
      ">> Epoch 121 finished \tANN training loss 0.009937\n",
      ">> Epoch 122 finished \tANN training loss 0.009932\n",
      ">> Epoch 123 finished \tANN training loss 0.009927\n",
      ">> Epoch 124 finished \tANN training loss 0.009921\n",
      ">> Epoch 125 finished \tANN training loss 0.009916\n",
      ">> Epoch 126 finished \tANN training loss 0.009912\n",
      ">> Epoch 127 finished \tANN training loss 0.009906\n",
      ">> Epoch 128 finished \tANN training loss 0.009901\n",
      ">> Epoch 129 finished \tANN training loss 0.009895\n",
      ">> Epoch 130 finished \tANN training loss 0.009890\n",
      ">> Epoch 131 finished \tANN training loss 0.009885\n",
      ">> Epoch 132 finished \tANN training loss 0.009880\n",
      ">> Epoch 133 finished \tANN training loss 0.009875\n",
      ">> Epoch 134 finished \tANN training loss 0.009870\n",
      ">> Epoch 135 finished \tANN training loss 0.009864\n",
      ">> Epoch 136 finished \tANN training loss 0.009859\n",
      ">> Epoch 137 finished \tANN training loss 0.009854\n",
      ">> Epoch 138 finished \tANN training loss 0.009849\n",
      ">> Epoch 139 finished \tANN training loss 0.009844\n",
      ">> Epoch 140 finished \tANN training loss 0.009839\n",
      ">> Epoch 141 finished \tANN training loss 0.009834\n",
      ">> Epoch 142 finished \tANN training loss 0.009829\n",
      ">> Epoch 143 finished \tANN training loss 0.009826\n",
      ">> Epoch 144 finished \tANN training loss 0.009821\n",
      ">> Epoch 145 finished \tANN training loss 0.009816\n",
      ">> Epoch 146 finished \tANN training loss 0.009812\n",
      ">> Epoch 147 finished \tANN training loss 0.009807\n",
      ">> Epoch 148 finished \tANN training loss 0.009804\n",
      ">> Epoch 149 finished \tANN training loss 0.009800\n",
      ">> Epoch 150 finished \tANN training loss 0.009795\n",
      "[END] Fine tuning step\n",
      "############### End Training for EQUITASEQ #####################\n",
      "############### End Training for NESTLEINDEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 4.890549\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 4.830115\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 4.769245\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 4.707831\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 4.645904\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 4.583397\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 4.520181\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 4.456296\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 4.391590\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 4.326080\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 4.259656\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 4.192237\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 4.123762\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 4.054217\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 3.983581\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 3.911744\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 3.838594\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 3.764102\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 3.688141\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 3.610683\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 3.531941\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 3.451526\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 3.369717\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 3.286377\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 3.201379\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 3.114751\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 3.026428\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 2.936579\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 2.845472\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 2.752916\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 2.659021\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 2.564101\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 2.468081\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 2.370782\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 2.273159\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 2.174399\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 2.075761\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 1.977137\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 1.878712\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 1.780793\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 1.683691\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 1.587722\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 1.493370\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 1.401024\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 1.310834\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 1.223203\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 1.138932\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 1.057549\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.979302\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.905072\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.834771\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.769089\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.707516\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.649208\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.596029\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.546997\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.502342\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.461119\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.423262\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.389265\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.358279\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.330504\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.305433\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.284546\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.265727\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.248786\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.234429\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.221942\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.211218\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.201411\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.192478\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.185050\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.178223\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.172895\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.168412\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.164260\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.160599\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.157611\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.154772\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.152334\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.150219\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.148204\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.146324\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.144598\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.143099\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.141714\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.140314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 88 finished \tRBM Reconstruction error 0.139279\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.138420\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.137672\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.136810\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.136008\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.135275\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.134781\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.134230\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.133678\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.133163\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.132577\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.132251\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.131843\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.008800\n",
      ">> Epoch 2 finished \tANN training loss 0.007985\n",
      ">> Epoch 3 finished \tANN training loss 0.007254\n",
      ">> Epoch 4 finished \tANN training loss 0.006597\n",
      ">> Epoch 5 finished \tANN training loss 0.006009\n",
      ">> Epoch 6 finished \tANN training loss 0.005481\n",
      ">> Epoch 7 finished \tANN training loss 0.005007\n",
      ">> Epoch 8 finished \tANN training loss 0.004583\n",
      ">> Epoch 9 finished \tANN training loss 0.004203\n",
      ">> Epoch 10 finished \tANN training loss 0.003863\n",
      ">> Epoch 11 finished \tANN training loss 0.003558\n",
      ">> Epoch 12 finished \tANN training loss 0.003285\n",
      ">> Epoch 13 finished \tANN training loss 0.003041\n",
      ">> Epoch 14 finished \tANN training loss 0.002822\n",
      ">> Epoch 15 finished \tANN training loss 0.002626\n",
      ">> Epoch 16 finished \tANN training loss 0.002450\n",
      ">> Epoch 17 finished \tANN training loss 0.002293\n",
      ">> Epoch 18 finished \tANN training loss 0.002153\n",
      ">> Epoch 19 finished \tANN training loss 0.002027\n",
      ">> Epoch 20 finished \tANN training loss 0.001914\n",
      ">> Epoch 21 finished \tANN training loss 0.001814\n",
      ">> Epoch 22 finished \tANN training loss 0.001724\n",
      ">> Epoch 23 finished \tANN training loss 0.001643\n",
      ">> Epoch 24 finished \tANN training loss 0.001571\n",
      ">> Epoch 25 finished \tANN training loss 0.001506\n",
      ">> Epoch 26 finished \tANN training loss 0.001448\n",
      ">> Epoch 27 finished \tANN training loss 0.001397\n",
      ">> Epoch 28 finished \tANN training loss 0.001350\n",
      ">> Epoch 29 finished \tANN training loss 0.001309\n",
      ">> Epoch 30 finished \tANN training loss 0.001272\n",
      ">> Epoch 31 finished \tANN training loss 0.001239\n",
      ">> Epoch 32 finished \tANN training loss 0.001209\n",
      ">> Epoch 33 finished \tANN training loss 0.001183\n",
      ">> Epoch 34 finished \tANN training loss 0.001159\n",
      ">> Epoch 35 finished \tANN training loss 0.001138\n",
      ">> Epoch 36 finished \tANN training loss 0.001119\n",
      ">> Epoch 37 finished \tANN training loss 0.001102\n",
      ">> Epoch 38 finished \tANN training loss 0.001087\n",
      ">> Epoch 39 finished \tANN training loss 0.001073\n",
      ">> Epoch 40 finished \tANN training loss 0.001061\n",
      ">> Epoch 41 finished \tANN training loss 0.001050\n",
      ">> Epoch 42 finished \tANN training loss 0.001040\n",
      ">> Epoch 43 finished \tANN training loss 0.001032\n",
      ">> Epoch 44 finished \tANN training loss 0.001024\n",
      ">> Epoch 45 finished \tANN training loss 0.001017\n",
      ">> Epoch 46 finished \tANN training loss 0.001010\n",
      ">> Epoch 47 finished \tANN training loss 0.001005\n",
      ">> Epoch 48 finished \tANN training loss 0.001000\n",
      ">> Epoch 49 finished \tANN training loss 0.000995\n",
      ">> Epoch 50 finished \tANN training loss 0.000991\n",
      ">> Epoch 51 finished \tANN training loss 0.000988\n",
      ">> Epoch 52 finished \tANN training loss 0.000984\n",
      ">> Epoch 53 finished \tANN training loss 0.000982\n",
      ">> Epoch 54 finished \tANN training loss 0.000979\n",
      ">> Epoch 55 finished \tANN training loss 0.000977\n",
      ">> Epoch 56 finished \tANN training loss 0.000974\n",
      ">> Epoch 57 finished \tANN training loss 0.000973\n",
      ">> Epoch 58 finished \tANN training loss 0.000971\n",
      ">> Epoch 59 finished \tANN training loss 0.000969\n",
      ">> Epoch 60 finished \tANN training loss 0.000968\n",
      ">> Epoch 61 finished \tANN training loss 0.000967\n",
      ">> Epoch 62 finished \tANN training loss 0.000966\n",
      ">> Epoch 63 finished \tANN training loss 0.000965\n",
      ">> Epoch 64 finished \tANN training loss 0.000964\n",
      ">> Epoch 65 finished \tANN training loss 0.000963\n",
      ">> Epoch 66 finished \tANN training loss 0.000962\n",
      ">> Epoch 67 finished \tANN training loss 0.000961\n",
      ">> Epoch 68 finished \tANN training loss 0.000961\n",
      ">> Epoch 69 finished \tANN training loss 0.000960\n",
      ">> Epoch 70 finished \tANN training loss 0.000960\n",
      ">> Epoch 71 finished \tANN training loss 0.000959\n",
      ">> Epoch 72 finished \tANN training loss 0.000959\n",
      ">> Epoch 73 finished \tANN training loss 0.000958\n",
      ">> Epoch 74 finished \tANN training loss 0.000958\n",
      ">> Epoch 75 finished \tANN training loss 0.000958\n",
      ">> Epoch 76 finished \tANN training loss 0.000957\n",
      ">> Epoch 77 finished \tANN training loss 0.000957\n",
      ">> Epoch 78 finished \tANN training loss 0.000957\n",
      ">> Epoch 79 finished \tANN training loss 0.000957\n",
      ">> Epoch 80 finished \tANN training loss 0.000956\n",
      ">> Epoch 81 finished \tANN training loss 0.000956\n",
      ">> Epoch 82 finished \tANN training loss 0.000956\n",
      ">> Epoch 83 finished \tANN training loss 0.000956\n",
      ">> Epoch 84 finished \tANN training loss 0.000955\n",
      ">> Epoch 85 finished \tANN training loss 0.000955\n",
      ">> Epoch 86 finished \tANN training loss 0.000955\n",
      ">> Epoch 87 finished \tANN training loss 0.000955\n",
      ">> Epoch 88 finished \tANN training loss 0.000955\n",
      ">> Epoch 89 finished \tANN training loss 0.000955\n",
      ">> Epoch 90 finished \tANN training loss 0.000954\n",
      ">> Epoch 91 finished \tANN training loss 0.000954\n",
      ">> Epoch 92 finished \tANN training loss 0.000954\n",
      ">> Epoch 93 finished \tANN training loss 0.000954\n",
      ">> Epoch 94 finished \tANN training loss 0.000954\n",
      ">> Epoch 95 finished \tANN training loss 0.000954\n",
      ">> Epoch 96 finished \tANN training loss 0.000954\n",
      ">> Epoch 97 finished \tANN training loss 0.000954\n",
      ">> Epoch 98 finished \tANN training loss 0.000953\n",
      ">> Epoch 99 finished \tANN training loss 0.000953\n",
      ">> Epoch 100 finished \tANN training loss 0.000953\n",
      ">> Epoch 101 finished \tANN training loss 0.000953\n",
      ">> Epoch 102 finished \tANN training loss 0.000953\n",
      ">> Epoch 103 finished \tANN training loss 0.000953\n",
      ">> Epoch 104 finished \tANN training loss 0.000953\n",
      ">> Epoch 105 finished \tANN training loss 0.000953\n",
      ">> Epoch 106 finished \tANN training loss 0.000952\n",
      ">> Epoch 107 finished \tANN training loss 0.000952\n",
      ">> Epoch 108 finished \tANN training loss 0.000952\n",
      ">> Epoch 109 finished \tANN training loss 0.000952\n",
      ">> Epoch 110 finished \tANN training loss 0.000952\n",
      ">> Epoch 111 finished \tANN training loss 0.000952\n",
      ">> Epoch 112 finished \tANN training loss 0.000952\n",
      ">> Epoch 113 finished \tANN training loss 0.000952\n",
      ">> Epoch 114 finished \tANN training loss 0.000952\n",
      ">> Epoch 115 finished \tANN training loss 0.000951\n",
      ">> Epoch 116 finished \tANN training loss 0.000951\n",
      ">> Epoch 117 finished \tANN training loss 0.000951\n",
      ">> Epoch 118 finished \tANN training loss 0.000951\n",
      ">> Epoch 119 finished \tANN training loss 0.000951\n",
      ">> Epoch 120 finished \tANN training loss 0.000951\n",
      ">> Epoch 121 finished \tANN training loss 0.000951\n",
      ">> Epoch 122 finished \tANN training loss 0.000951\n",
      ">> Epoch 123 finished \tANN training loss 0.000951\n",
      ">> Epoch 124 finished \tANN training loss 0.000950\n",
      ">> Epoch 125 finished \tANN training loss 0.000950\n",
      ">> Epoch 126 finished \tANN training loss 0.000950\n",
      ">> Epoch 127 finished \tANN training loss 0.000950\n",
      ">> Epoch 128 finished \tANN training loss 0.000950\n",
      ">> Epoch 129 finished \tANN training loss 0.000950\n",
      ">> Epoch 130 finished \tANN training loss 0.000950\n",
      ">> Epoch 131 finished \tANN training loss 0.000950\n",
      ">> Epoch 132 finished \tANN training loss 0.000950\n",
      ">> Epoch 133 finished \tANN training loss 0.000949\n",
      ">> Epoch 134 finished \tANN training loss 0.000949\n",
      ">> Epoch 135 finished \tANN training loss 0.000949\n",
      ">> Epoch 136 finished \tANN training loss 0.000949\n",
      ">> Epoch 137 finished \tANN training loss 0.000949\n",
      ">> Epoch 138 finished \tANN training loss 0.000949\n",
      ">> Epoch 139 finished \tANN training loss 0.000949\n",
      ">> Epoch 140 finished \tANN training loss 0.000949\n",
      ">> Epoch 141 finished \tANN training loss 0.000949\n",
      ">> Epoch 142 finished \tANN training loss 0.000949\n",
      ">> Epoch 143 finished \tANN training loss 0.000948\n",
      ">> Epoch 144 finished \tANN training loss 0.000948\n",
      ">> Epoch 145 finished \tANN training loss 0.000948\n",
      ">> Epoch 146 finished \tANN training loss 0.000948\n",
      ">> Epoch 147 finished \tANN training loss 0.000948\n",
      ">> Epoch 148 finished \tANN training loss 0.000948\n",
      ">> Epoch 149 finished \tANN training loss 0.000948\n",
      ">> Epoch 150 finished \tANN training loss 0.000948\n",
      "[END] Fine tuning step\n",
      "############### End Training for NESTLEINDEQ #####################\n",
      "############### End Training for AMBUJACEMEQ #####################\n",
      "[START] Pre-training step:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 1 finished \tRBM Reconstruction error 5.453891\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 5.326585\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 5.193032\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 5.051843\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 4.901496\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 4.740195\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 4.566199\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 4.377522\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 4.172539\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 3.949657\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 3.707365\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 3.445482\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 3.165145\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 2.868600\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 2.559358\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 2.243963\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 1.931397\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 1.629152\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 1.348182\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 1.098247\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 0.883404\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 0.706109\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 0.567509\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 0.461181\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 0.384733\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 0.330570\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 0.293245\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 0.266732\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 0.248156\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 0.234733\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 0.225032\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 0.217507\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.211472\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.206269\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.201666\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.197503\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.193626\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.190041\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.186474\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.183254\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.180062\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.177115\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.174044\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.171051\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.167952\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.165385\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.162859\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.160363\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.157773\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.154925\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.152607\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.150096\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.147789\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.145176\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.142914\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.140707\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.138483\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.136636\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.134267\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.132159\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.129821\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.127765\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.125797\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.123945\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.122035\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.120283\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.118442\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.116907\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.115235\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.113447\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.112092\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.110586\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.109018\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.107414\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.105667\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.104113\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.102900\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.101282\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.099614\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.098564\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.097196\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.095829\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.094858\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.093998\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.092562\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.091377\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.090144\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.089367\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.088693\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.086836\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.085791\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.084175\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.083139\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.082650\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.081359\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.080463\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.079820\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.078821\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.077639\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.076540\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.026753\n",
      ">> Epoch 2 finished \tANN training loss 0.022247\n",
      ">> Epoch 3 finished \tANN training loss 0.018954\n",
      ">> Epoch 4 finished \tANN training loss 0.016535\n",
      ">> Epoch 5 finished \tANN training loss 0.014742\n",
      ">> Epoch 6 finished \tANN training loss 0.013396\n",
      ">> Epoch 7 finished \tANN training loss 0.012372\n",
      ">> Epoch 8 finished \tANN training loss 0.011580\n",
      ">> Epoch 9 finished \tANN training loss 0.010952\n",
      ">> Epoch 10 finished \tANN training loss 0.010444\n",
      ">> Epoch 11 finished \tANN training loss 0.010020\n",
      ">> Epoch 12 finished \tANN training loss 0.009660\n",
      ">> Epoch 13 finished \tANN training loss 0.009345\n",
      ">> Epoch 14 finished \tANN training loss 0.009064\n",
      ">> Epoch 15 finished \tANN training loss 0.008808\n",
      ">> Epoch 16 finished \tANN training loss 0.008572\n",
      ">> Epoch 17 finished \tANN training loss 0.008351\n",
      ">> Epoch 18 finished \tANN training loss 0.008142\n",
      ">> Epoch 19 finished \tANN training loss 0.007944\n",
      ">> Epoch 20 finished \tANN training loss 0.007754\n",
      ">> Epoch 21 finished \tANN training loss 0.007571\n",
      ">> Epoch 22 finished \tANN training loss 0.007394\n",
      ">> Epoch 23 finished \tANN training loss 0.007223\n",
      ">> Epoch 24 finished \tANN training loss 0.007058\n",
      ">> Epoch 25 finished \tANN training loss 0.006897\n",
      ">> Epoch 26 finished \tANN training loss 0.006742\n",
      ">> Epoch 27 finished \tANN training loss 0.006590\n",
      ">> Epoch 28 finished \tANN training loss 0.006443\n",
      ">> Epoch 29 finished \tANN training loss 0.006300\n",
      ">> Epoch 30 finished \tANN training loss 0.006161\n",
      ">> Epoch 31 finished \tANN training loss 0.006025\n",
      ">> Epoch 32 finished \tANN training loss 0.005893\n",
      ">> Epoch 33 finished \tANN training loss 0.005765\n",
      ">> Epoch 34 finished \tANN training loss 0.005641\n",
      ">> Epoch 35 finished \tANN training loss 0.005520\n",
      ">> Epoch 36 finished \tANN training loss 0.005402\n",
      ">> Epoch 37 finished \tANN training loss 0.005287\n",
      ">> Epoch 38 finished \tANN training loss 0.005176\n",
      ">> Epoch 39 finished \tANN training loss 0.005067\n",
      ">> Epoch 40 finished \tANN training loss 0.004962\n",
      ">> Epoch 41 finished \tANN training loss 0.004860\n",
      ">> Epoch 42 finished \tANN training loss 0.004760\n",
      ">> Epoch 43 finished \tANN training loss 0.004663\n",
      ">> Epoch 44 finished \tANN training loss 0.004569\n",
      ">> Epoch 45 finished \tANN training loss 0.004477\n",
      ">> Epoch 46 finished \tANN training loss 0.004388\n",
      ">> Epoch 47 finished \tANN training loss 0.004301\n",
      ">> Epoch 48 finished \tANN training loss 0.004216\n",
      ">> Epoch 49 finished \tANN training loss 0.004134\n",
      ">> Epoch 50 finished \tANN training loss 0.004054\n",
      ">> Epoch 51 finished \tANN training loss 0.003976\n",
      ">> Epoch 52 finished \tANN training loss 0.003900\n",
      ">> Epoch 53 finished \tANN training loss 0.003826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 54 finished \tANN training loss 0.003754\n",
      ">> Epoch 55 finished \tANN training loss 0.003684\n",
      ">> Epoch 56 finished \tANN training loss 0.003616\n",
      ">> Epoch 57 finished \tANN training loss 0.003550\n",
      ">> Epoch 58 finished \tANN training loss 0.003485\n",
      ">> Epoch 59 finished \tANN training loss 0.003422\n",
      ">> Epoch 60 finished \tANN training loss 0.003361\n",
      ">> Epoch 61 finished \tANN training loss 0.003301\n",
      ">> Epoch 62 finished \tANN training loss 0.003243\n",
      ">> Epoch 63 finished \tANN training loss 0.003187\n",
      ">> Epoch 64 finished \tANN training loss 0.003132\n",
      ">> Epoch 65 finished \tANN training loss 0.003078\n",
      ">> Epoch 66 finished \tANN training loss 0.003026\n",
      ">> Epoch 67 finished \tANN training loss 0.002975\n",
      ">> Epoch 68 finished \tANN training loss 0.002926\n",
      ">> Epoch 69 finished \tANN training loss 0.002877\n",
      ">> Epoch 70 finished \tANN training loss 0.002830\n",
      ">> Epoch 71 finished \tANN training loss 0.002785\n",
      ">> Epoch 72 finished \tANN training loss 0.002740\n",
      ">> Epoch 73 finished \tANN training loss 0.002697\n",
      ">> Epoch 74 finished \tANN training loss 0.002655\n",
      ">> Epoch 75 finished \tANN training loss 0.002613\n",
      ">> Epoch 76 finished \tANN training loss 0.002573\n",
      ">> Epoch 77 finished \tANN training loss 0.002534\n",
      ">> Epoch 78 finished \tANN training loss 0.002496\n",
      ">> Epoch 79 finished \tANN training loss 0.002459\n",
      ">> Epoch 80 finished \tANN training loss 0.002423\n",
      ">> Epoch 81 finished \tANN training loss 0.002388\n",
      ">> Epoch 82 finished \tANN training loss 0.002354\n",
      ">> Epoch 83 finished \tANN training loss 0.002321\n",
      ">> Epoch 84 finished \tANN training loss 0.002288\n",
      ">> Epoch 85 finished \tANN training loss 0.002257\n",
      ">> Epoch 86 finished \tANN training loss 0.002226\n",
      ">> Epoch 87 finished \tANN training loss 0.002196\n",
      ">> Epoch 88 finished \tANN training loss 0.002167\n",
      ">> Epoch 89 finished \tANN training loss 0.002138\n",
      ">> Epoch 90 finished \tANN training loss 0.002111\n",
      ">> Epoch 91 finished \tANN training loss 0.002084\n",
      ">> Epoch 92 finished \tANN training loss 0.002058\n",
      ">> Epoch 93 finished \tANN training loss 0.002032\n",
      ">> Epoch 94 finished \tANN training loss 0.002007\n",
      ">> Epoch 95 finished \tANN training loss 0.001983\n",
      ">> Epoch 96 finished \tANN training loss 0.001959\n",
      ">> Epoch 97 finished \tANN training loss 0.001936\n",
      ">> Epoch 98 finished \tANN training loss 0.001914\n",
      ">> Epoch 99 finished \tANN training loss 0.001892\n",
      ">> Epoch 100 finished \tANN training loss 0.001871\n",
      ">> Epoch 101 finished \tANN training loss 0.001850\n",
      ">> Epoch 102 finished \tANN training loss 0.001830\n",
      ">> Epoch 103 finished \tANN training loss 0.001810\n",
      ">> Epoch 104 finished \tANN training loss 0.001791\n",
      ">> Epoch 105 finished \tANN training loss 0.001773\n",
      ">> Epoch 106 finished \tANN training loss 0.001754\n",
      ">> Epoch 107 finished \tANN training loss 0.001737\n",
      ">> Epoch 108 finished \tANN training loss 0.001720\n",
      ">> Epoch 109 finished \tANN training loss 0.001703\n",
      ">> Epoch 110 finished \tANN training loss 0.001686\n",
      ">> Epoch 111 finished \tANN training loss 0.001670\n",
      ">> Epoch 112 finished \tANN training loss 0.001655\n",
      ">> Epoch 113 finished \tANN training loss 0.001640\n",
      ">> Epoch 114 finished \tANN training loss 0.001625\n",
      ">> Epoch 115 finished \tANN training loss 0.001611\n",
      ">> Epoch 116 finished \tANN training loss 0.001597\n",
      ">> Epoch 117 finished \tANN training loss 0.001583\n",
      ">> Epoch 118 finished \tANN training loss 0.001570\n",
      ">> Epoch 119 finished \tANN training loss 0.001557\n",
      ">> Epoch 120 finished \tANN training loss 0.001544\n",
      ">> Epoch 121 finished \tANN training loss 0.001532\n",
      ">> Epoch 122 finished \tANN training loss 0.001520\n",
      ">> Epoch 123 finished \tANN training loss 0.001508\n",
      ">> Epoch 124 finished \tANN training loss 0.001497\n",
      ">> Epoch 125 finished \tANN training loss 0.001486\n",
      ">> Epoch 126 finished \tANN training loss 0.001475\n",
      ">> Epoch 127 finished \tANN training loss 0.001465\n",
      ">> Epoch 128 finished \tANN training loss 0.001454\n",
      ">> Epoch 129 finished \tANN training loss 0.001444\n",
      ">> Epoch 130 finished \tANN training loss 0.001435\n",
      ">> Epoch 131 finished \tANN training loss 0.001425\n",
      ">> Epoch 132 finished \tANN training loss 0.001416\n",
      ">> Epoch 133 finished \tANN training loss 0.001407\n",
      ">> Epoch 134 finished \tANN training loss 0.001398\n",
      ">> Epoch 135 finished \tANN training loss 0.001390\n",
      ">> Epoch 136 finished \tANN training loss 0.001381\n",
      ">> Epoch 137 finished \tANN training loss 0.001373\n",
      ">> Epoch 138 finished \tANN training loss 0.001365\n",
      ">> Epoch 139 finished \tANN training loss 0.001357\n",
      ">> Epoch 140 finished \tANN training loss 0.001350\n",
      ">> Epoch 141 finished \tANN training loss 0.001343\n",
      ">> Epoch 142 finished \tANN training loss 0.001335\n",
      ">> Epoch 143 finished \tANN training loss 0.001328\n",
      ">> Epoch 144 finished \tANN training loss 0.001321\n",
      ">> Epoch 145 finished \tANN training loss 0.001315\n",
      ">> Epoch 146 finished \tANN training loss 0.001308\n",
      ">> Epoch 147 finished \tANN training loss 0.001302\n",
      ">> Epoch 148 finished \tANN training loss 0.001296\n",
      ">> Epoch 149 finished \tANN training loss 0.001290\n",
      ">> Epoch 150 finished \tANN training loss 0.001284\n",
      "[END] Fine tuning step\n",
      "############### End Training for AMBUJACEMEQ #####################\n",
      "############### End Training for APOLLOTYREEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 1.106855\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 1.091838\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 1.077097\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 1.062673\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 1.048525\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 1.034626\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 1.020994\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 1.007621\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 0.994489\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 0.981582\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 0.968918\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 0.956479\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 0.944246\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 0.932246\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 0.920430\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 0.908814\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 0.897388\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 0.886144\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 0.875061\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 0.864153\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 0.853405\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 0.842812\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 0.832374\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 0.822081\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 0.811911\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 0.801894\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 0.792016\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 0.782219\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 0.772564\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 0.763002\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 0.753551\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 0.744214\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.734970\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.725877\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.716806\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.707884\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.699038\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.690249\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.681553\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.672955\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.664422\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.655952\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.647543\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.639274\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.631053\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.622880\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.614812\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.606791\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.598837\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.590957\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.583176\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.575480\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.567827\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.560247\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.552762\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.545367\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.538005\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.530738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 59 finished \tRBM Reconstruction error 0.523506\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.516407\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.509378\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.502415\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.495601\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.488863\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.482117\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.475503\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.468961\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.462494\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.456134\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.449840\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.443634\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.437507\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.431484\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.425576\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.419761\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.413998\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.408383\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.402821\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.397329\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.391945\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.386670\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.381448\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.376445\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.371331\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.366365\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.361483\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.356722\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.352019\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.347436\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.342981\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.338539\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.334164\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.329859\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.325706\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.321508\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.317488\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.313469\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.309546\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.305714\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.301950\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.006335\n",
      ">> Epoch 2 finished \tANN training loss 0.005983\n",
      ">> Epoch 3 finished \tANN training loss 0.005659\n",
      ">> Epoch 4 finished \tANN training loss 0.005358\n",
      ">> Epoch 5 finished \tANN training loss 0.005081\n",
      ">> Epoch 6 finished \tANN training loss 0.004824\n",
      ">> Epoch 7 finished \tANN training loss 0.004586\n",
      ">> Epoch 8 finished \tANN training loss 0.004365\n",
      ">> Epoch 9 finished \tANN training loss 0.004161\n",
      ">> Epoch 10 finished \tANN training loss 0.003972\n",
      ">> Epoch 11 finished \tANN training loss 0.003797\n",
      ">> Epoch 12 finished \tANN training loss 0.003634\n",
      ">> Epoch 13 finished \tANN training loss 0.003483\n",
      ">> Epoch 14 finished \tANN training loss 0.003342\n",
      ">> Epoch 15 finished \tANN training loss 0.003211\n",
      ">> Epoch 16 finished \tANN training loss 0.003090\n",
      ">> Epoch 17 finished \tANN training loss 0.002977\n",
      ">> Epoch 18 finished \tANN training loss 0.002871\n",
      ">> Epoch 19 finished \tANN training loss 0.002773\n",
      ">> Epoch 20 finished \tANN training loss 0.002681\n",
      ">> Epoch 21 finished \tANN training loss 0.002595\n",
      ">> Epoch 22 finished \tANN training loss 0.002515\n",
      ">> Epoch 23 finished \tANN training loss 0.002439\n",
      ">> Epoch 24 finished \tANN training loss 0.002369\n",
      ">> Epoch 25 finished \tANN training loss 0.002303\n",
      ">> Epoch 26 finished \tANN training loss 0.002241\n",
      ">> Epoch 27 finished \tANN training loss 0.002183\n",
      ">> Epoch 28 finished \tANN training loss 0.002128\n",
      ">> Epoch 29 finished \tANN training loss 0.002077\n",
      ">> Epoch 30 finished \tANN training loss 0.002028\n",
      ">> Epoch 31 finished \tANN training loss 0.001982\n",
      ">> Epoch 32 finished \tANN training loss 0.001939\n",
      ">> Epoch 33 finished \tANN training loss 0.001897\n",
      ">> Epoch 34 finished \tANN training loss 0.001859\n",
      ">> Epoch 35 finished \tANN training loss 0.001822\n",
      ">> Epoch 36 finished \tANN training loss 0.001787\n",
      ">> Epoch 37 finished \tANN training loss 0.001753\n",
      ">> Epoch 38 finished \tANN training loss 0.001722\n",
      ">> Epoch 39 finished \tANN training loss 0.001691\n",
      ">> Epoch 40 finished \tANN training loss 0.001663\n",
      ">> Epoch 41 finished \tANN training loss 0.001635\n",
      ">> Epoch 42 finished \tANN training loss 0.001609\n",
      ">> Epoch 43 finished \tANN training loss 0.001583\n",
      ">> Epoch 44 finished \tANN training loss 0.001559\n",
      ">> Epoch 45 finished \tANN training loss 0.001536\n",
      ">> Epoch 46 finished \tANN training loss 0.001514\n",
      ">> Epoch 47 finished \tANN training loss 0.001492\n",
      ">> Epoch 48 finished \tANN training loss 0.001472\n",
      ">> Epoch 49 finished \tANN training loss 0.001452\n",
      ">> Epoch 50 finished \tANN training loss 0.001433\n",
      ">> Epoch 51 finished \tANN training loss 0.001414\n",
      ">> Epoch 52 finished \tANN training loss 0.001396\n",
      ">> Epoch 53 finished \tANN training loss 0.001379\n",
      ">> Epoch 54 finished \tANN training loss 0.001362\n",
      ">> Epoch 55 finished \tANN training loss 0.001346\n",
      ">> Epoch 56 finished \tANN training loss 0.001330\n",
      ">> Epoch 57 finished \tANN training loss 0.001315\n",
      ">> Epoch 58 finished \tANN training loss 0.001300\n",
      ">> Epoch 59 finished \tANN training loss 0.001286\n",
      ">> Epoch 60 finished \tANN training loss 0.001271\n",
      ">> Epoch 61 finished \tANN training loss 0.001258\n",
      ">> Epoch 62 finished \tANN training loss 0.001245\n",
      ">> Epoch 63 finished \tANN training loss 0.001232\n",
      ">> Epoch 64 finished \tANN training loss 0.001219\n",
      ">> Epoch 65 finished \tANN training loss 0.001207\n",
      ">> Epoch 66 finished \tANN training loss 0.001195\n",
      ">> Epoch 67 finished \tANN training loss 0.001183\n",
      ">> Epoch 68 finished \tANN training loss 0.001171\n",
      ">> Epoch 69 finished \tANN training loss 0.001160\n",
      ">> Epoch 70 finished \tANN training loss 0.001149\n",
      ">> Epoch 71 finished \tANN training loss 0.001138\n",
      ">> Epoch 72 finished \tANN training loss 0.001128\n",
      ">> Epoch 73 finished \tANN training loss 0.001118\n",
      ">> Epoch 74 finished \tANN training loss 0.001108\n",
      ">> Epoch 75 finished \tANN training loss 0.001098\n",
      ">> Epoch 76 finished \tANN training loss 0.001088\n",
      ">> Epoch 77 finished \tANN training loss 0.001079\n",
      ">> Epoch 78 finished \tANN training loss 0.001069\n",
      ">> Epoch 79 finished \tANN training loss 0.001060\n",
      ">> Epoch 80 finished \tANN training loss 0.001051\n",
      ">> Epoch 81 finished \tANN training loss 0.001042\n",
      ">> Epoch 82 finished \tANN training loss 0.001034\n",
      ">> Epoch 83 finished \tANN training loss 0.001025\n",
      ">> Epoch 84 finished \tANN training loss 0.001017\n",
      ">> Epoch 85 finished \tANN training loss 0.001009\n",
      ">> Epoch 86 finished \tANN training loss 0.001001\n",
      ">> Epoch 87 finished \tANN training loss 0.000993\n",
      ">> Epoch 88 finished \tANN training loss 0.000986\n",
      ">> Epoch 89 finished \tANN training loss 0.000978\n",
      ">> Epoch 90 finished \tANN training loss 0.000971\n",
      ">> Epoch 91 finished \tANN training loss 0.000963\n",
      ">> Epoch 92 finished \tANN training loss 0.000956\n",
      ">> Epoch 93 finished \tANN training loss 0.000949\n",
      ">> Epoch 94 finished \tANN training loss 0.000942\n",
      ">> Epoch 95 finished \tANN training loss 0.000935\n",
      ">> Epoch 96 finished \tANN training loss 0.000929\n",
      ">> Epoch 97 finished \tANN training loss 0.000922\n",
      ">> Epoch 98 finished \tANN training loss 0.000915\n",
      ">> Epoch 99 finished \tANN training loss 0.000909\n",
      ">> Epoch 100 finished \tANN training loss 0.000903\n",
      ">> Epoch 101 finished \tANN training loss 0.000897\n",
      ">> Epoch 102 finished \tANN training loss 0.000891\n",
      ">> Epoch 103 finished \tANN training loss 0.000885\n",
      ">> Epoch 104 finished \tANN training loss 0.000879\n",
      ">> Epoch 105 finished \tANN training loss 0.000873\n",
      ">> Epoch 106 finished \tANN training loss 0.000867\n",
      ">> Epoch 107 finished \tANN training loss 0.000862\n",
      ">> Epoch 108 finished \tANN training loss 0.000856\n",
      ">> Epoch 109 finished \tANN training loss 0.000851\n",
      ">> Epoch 110 finished \tANN training loss 0.000845\n",
      ">> Epoch 111 finished \tANN training loss 0.000840\n",
      ">> Epoch 112 finished \tANN training loss 0.000835\n",
      ">> Epoch 113 finished \tANN training loss 0.000830\n",
      ">> Epoch 114 finished \tANN training loss 0.000825\n",
      ">> Epoch 115 finished \tANN training loss 0.000820\n",
      ">> Epoch 116 finished \tANN training loss 0.000815\n",
      ">> Epoch 117 finished \tANN training loss 0.000810\n",
      ">> Epoch 118 finished \tANN training loss 0.000806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 119 finished \tANN training loss 0.000801\n",
      ">> Epoch 120 finished \tANN training loss 0.000796\n",
      ">> Epoch 121 finished \tANN training loss 0.000792\n",
      ">> Epoch 122 finished \tANN training loss 0.000788\n",
      ">> Epoch 123 finished \tANN training loss 0.000783\n",
      ">> Epoch 124 finished \tANN training loss 0.000779\n",
      ">> Epoch 125 finished \tANN training loss 0.000775\n",
      ">> Epoch 126 finished \tANN training loss 0.000771\n",
      ">> Epoch 127 finished \tANN training loss 0.000766\n",
      ">> Epoch 128 finished \tANN training loss 0.000762\n",
      ">> Epoch 129 finished \tANN training loss 0.000758\n",
      ">> Epoch 130 finished \tANN training loss 0.000755\n",
      ">> Epoch 131 finished \tANN training loss 0.000751\n",
      ">> Epoch 132 finished \tANN training loss 0.000747\n",
      ">> Epoch 133 finished \tANN training loss 0.000743\n",
      ">> Epoch 134 finished \tANN training loss 0.000740\n",
      ">> Epoch 135 finished \tANN training loss 0.000736\n",
      ">> Epoch 136 finished \tANN training loss 0.000732\n",
      ">> Epoch 137 finished \tANN training loss 0.000729\n",
      ">> Epoch 138 finished \tANN training loss 0.000725\n",
      ">> Epoch 139 finished \tANN training loss 0.000722\n",
      ">> Epoch 140 finished \tANN training loss 0.000719\n",
      ">> Epoch 141 finished \tANN training loss 0.000715\n",
      ">> Epoch 142 finished \tANN training loss 0.000712\n",
      ">> Epoch 143 finished \tANN training loss 0.000709\n",
      ">> Epoch 144 finished \tANN training loss 0.000706\n",
      ">> Epoch 145 finished \tANN training loss 0.000703\n",
      ">> Epoch 146 finished \tANN training loss 0.000700\n",
      ">> Epoch 147 finished \tANN training loss 0.000697\n",
      ">> Epoch 148 finished \tANN training loss 0.000694\n",
      ">> Epoch 149 finished \tANN training loss 0.000691\n",
      ">> Epoch 150 finished \tANN training loss 0.000688\n",
      "[END] Fine tuning step\n",
      "############### End Training for APOLLOTYREEQ #####################\n",
      "############### End Training for M&MFINEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 4.821075\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 4.764320\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 4.707029\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 4.649086\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 4.590391\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 4.530813\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 4.470308\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 4.408721\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 4.345902\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 4.281714\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 4.216029\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 4.148662\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 4.079476\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 4.008329\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 3.935128\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 3.859565\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 3.781700\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 3.701147\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 3.617953\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 3.531893\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 3.442785\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 3.350489\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 3.255070\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 3.156426\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 3.054653\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 2.949849\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 2.841956\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 2.730675\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 2.616774\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 2.500518\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 2.381619\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 2.260844\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 2.139501\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 2.017201\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 1.894654\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 1.773308\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 1.652765\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 1.534363\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 1.419720\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 1.308665\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 1.202217\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 1.101132\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 1.006169\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.918093\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.836765\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.762863\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.694533\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.633772\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.580300\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.532562\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.490846\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.454610\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.423605\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.395135\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.373133\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.352300\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.335137\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.319466\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.306917\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.296091\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.286735\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.278835\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.271807\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.265737\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.260106\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.255588\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.251131\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.247083\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.243481\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.239882\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.236540\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.233503\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.230729\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.228353\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.226149\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.223967\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.221775\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.219597\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.217451\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.215377\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.213596\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.211938\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.209994\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.208249\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.206545\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.204974\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.203365\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.201785\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.200248\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.198812\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.197228\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.195721\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.194203\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.192809\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.191414\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.189991\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.188708\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.187464\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.186067\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.185045\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.009321\n",
      ">> Epoch 2 finished \tANN training loss 0.008617\n",
      ">> Epoch 3 finished \tANN training loss 0.007993\n",
      ">> Epoch 4 finished \tANN training loss 0.007439\n",
      ">> Epoch 5 finished \tANN training loss 0.006947\n",
      ">> Epoch 6 finished \tANN training loss 0.006510\n",
      ">> Epoch 7 finished \tANN training loss 0.006122\n",
      ">> Epoch 8 finished \tANN training loss 0.005777\n",
      ">> Epoch 9 finished \tANN training loss 0.005470\n",
      ">> Epoch 10 finished \tANN training loss 0.005196\n",
      ">> Epoch 11 finished \tANN training loss 0.004953\n",
      ">> Epoch 12 finished \tANN training loss 0.004735\n",
      ">> Epoch 13 finished \tANN training loss 0.004541\n",
      ">> Epoch 14 finished \tANN training loss 0.004367\n",
      ">> Epoch 15 finished \tANN training loss 0.004211\n",
      ">> Epoch 16 finished \tANN training loss 0.004072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 17 finished \tANN training loss 0.003946\n",
      ">> Epoch 18 finished \tANN training loss 0.003833\n",
      ">> Epoch 19 finished \tANN training loss 0.003731\n",
      ">> Epoch 20 finished \tANN training loss 0.003639\n",
      ">> Epoch 21 finished \tANN training loss 0.003555\n",
      ">> Epoch 22 finished \tANN training loss 0.003480\n",
      ">> Epoch 23 finished \tANN training loss 0.003410\n",
      ">> Epoch 24 finished \tANN training loss 0.003347\n",
      ">> Epoch 25 finished \tANN training loss 0.003289\n",
      ">> Epoch 26 finished \tANN training loss 0.003236\n",
      ">> Epoch 27 finished \tANN training loss 0.003187\n",
      ">> Epoch 28 finished \tANN training loss 0.003142\n",
      ">> Epoch 29 finished \tANN training loss 0.003100\n",
      ">> Epoch 30 finished \tANN training loss 0.003061\n",
      ">> Epoch 31 finished \tANN training loss 0.003024\n",
      ">> Epoch 32 finished \tANN training loss 0.002990\n",
      ">> Epoch 33 finished \tANN training loss 0.002958\n",
      ">> Epoch 34 finished \tANN training loss 0.002927\n",
      ">> Epoch 35 finished \tANN training loss 0.002898\n",
      ">> Epoch 36 finished \tANN training loss 0.002871\n",
      ">> Epoch 37 finished \tANN training loss 0.002845\n",
      ">> Epoch 38 finished \tANN training loss 0.002820\n",
      ">> Epoch 39 finished \tANN training loss 0.002797\n",
      ">> Epoch 40 finished \tANN training loss 0.002774\n",
      ">> Epoch 41 finished \tANN training loss 0.002752\n",
      ">> Epoch 42 finished \tANN training loss 0.002731\n",
      ">> Epoch 43 finished \tANN training loss 0.002710\n",
      ">> Epoch 44 finished \tANN training loss 0.002690\n",
      ">> Epoch 45 finished \tANN training loss 0.002671\n",
      ">> Epoch 46 finished \tANN training loss 0.002652\n",
      ">> Epoch 47 finished \tANN training loss 0.002634\n",
      ">> Epoch 48 finished \tANN training loss 0.002616\n",
      ">> Epoch 49 finished \tANN training loss 0.002598\n",
      ">> Epoch 50 finished \tANN training loss 0.002581\n",
      ">> Epoch 51 finished \tANN training loss 0.002564\n",
      ">> Epoch 52 finished \tANN training loss 0.002548\n",
      ">> Epoch 53 finished \tANN training loss 0.002532\n",
      ">> Epoch 54 finished \tANN training loss 0.002516\n",
      ">> Epoch 55 finished \tANN training loss 0.002500\n",
      ">> Epoch 56 finished \tANN training loss 0.002485\n",
      ">> Epoch 57 finished \tANN training loss 0.002470\n",
      ">> Epoch 58 finished \tANN training loss 0.002455\n",
      ">> Epoch 59 finished \tANN training loss 0.002440\n",
      ">> Epoch 60 finished \tANN training loss 0.002426\n",
      ">> Epoch 61 finished \tANN training loss 0.002411\n",
      ">> Epoch 62 finished \tANN training loss 0.002397\n",
      ">> Epoch 63 finished \tANN training loss 0.002383\n",
      ">> Epoch 64 finished \tANN training loss 0.002370\n",
      ">> Epoch 65 finished \tANN training loss 0.002356\n",
      ">> Epoch 66 finished \tANN training loss 0.002343\n",
      ">> Epoch 67 finished \tANN training loss 0.002329\n",
      ">> Epoch 68 finished \tANN training loss 0.002316\n",
      ">> Epoch 69 finished \tANN training loss 0.002303\n",
      ">> Epoch 70 finished \tANN training loss 0.002290\n",
      ">> Epoch 71 finished \tANN training loss 0.002278\n",
      ">> Epoch 72 finished \tANN training loss 0.002265\n",
      ">> Epoch 73 finished \tANN training loss 0.002253\n",
      ">> Epoch 74 finished \tANN training loss 0.002240\n",
      ">> Epoch 75 finished \tANN training loss 0.002228\n",
      ">> Epoch 76 finished \tANN training loss 0.002216\n",
      ">> Epoch 77 finished \tANN training loss 0.002204\n",
      ">> Epoch 78 finished \tANN training loss 0.002192\n",
      ">> Epoch 79 finished \tANN training loss 0.002181\n",
      ">> Epoch 80 finished \tANN training loss 0.002169\n",
      ">> Epoch 81 finished \tANN training loss 0.002158\n",
      ">> Epoch 82 finished \tANN training loss 0.002147\n",
      ">> Epoch 83 finished \tANN training loss 0.002135\n",
      ">> Epoch 84 finished \tANN training loss 0.002124\n",
      ">> Epoch 85 finished \tANN training loss 0.002113\n",
      ">> Epoch 86 finished \tANN training loss 0.002103\n",
      ">> Epoch 87 finished \tANN training loss 0.002092\n",
      ">> Epoch 88 finished \tANN training loss 0.002081\n",
      ">> Epoch 89 finished \tANN training loss 0.002071\n",
      ">> Epoch 90 finished \tANN training loss 0.002060\n",
      ">> Epoch 91 finished \tANN training loss 0.002050\n",
      ">> Epoch 92 finished \tANN training loss 0.002040\n",
      ">> Epoch 93 finished \tANN training loss 0.002030\n",
      ">> Epoch 94 finished \tANN training loss 0.002020\n",
      ">> Epoch 95 finished \tANN training loss 0.002010\n",
      ">> Epoch 96 finished \tANN training loss 0.002000\n",
      ">> Epoch 97 finished \tANN training loss 0.001990\n",
      ">> Epoch 98 finished \tANN training loss 0.001981\n",
      ">> Epoch 99 finished \tANN training loss 0.001971\n",
      ">> Epoch 100 finished \tANN training loss 0.001962\n",
      ">> Epoch 101 finished \tANN training loss 0.001953\n",
      ">> Epoch 102 finished \tANN training loss 0.001943\n",
      ">> Epoch 103 finished \tANN training loss 0.001934\n",
      ">> Epoch 104 finished \tANN training loss 0.001925\n",
      ">> Epoch 105 finished \tANN training loss 0.001916\n",
      ">> Epoch 106 finished \tANN training loss 0.001907\n",
      ">> Epoch 107 finished \tANN training loss 0.001899\n",
      ">> Epoch 108 finished \tANN training loss 0.001890\n",
      ">> Epoch 109 finished \tANN training loss 0.001881\n",
      ">> Epoch 110 finished \tANN training loss 0.001873\n",
      ">> Epoch 111 finished \tANN training loss 0.001865\n",
      ">> Epoch 112 finished \tANN training loss 0.001856\n",
      ">> Epoch 113 finished \tANN training loss 0.001848\n",
      ">> Epoch 114 finished \tANN training loss 0.001840\n",
      ">> Epoch 115 finished \tANN training loss 0.001832\n",
      ">> Epoch 116 finished \tANN training loss 0.001824\n",
      ">> Epoch 117 finished \tANN training loss 0.001816\n",
      ">> Epoch 118 finished \tANN training loss 0.001808\n",
      ">> Epoch 119 finished \tANN training loss 0.001800\n",
      ">> Epoch 120 finished \tANN training loss 0.001793\n",
      ">> Epoch 121 finished \tANN training loss 0.001785\n",
      ">> Epoch 122 finished \tANN training loss 0.001778\n",
      ">> Epoch 123 finished \tANN training loss 0.001770\n",
      ">> Epoch 124 finished \tANN training loss 0.001763\n",
      ">> Epoch 125 finished \tANN training loss 0.001755\n",
      ">> Epoch 126 finished \tANN training loss 0.001748\n",
      ">> Epoch 127 finished \tANN training loss 0.001741\n",
      ">> Epoch 128 finished \tANN training loss 0.001734\n",
      ">> Epoch 129 finished \tANN training loss 0.001727\n",
      ">> Epoch 130 finished \tANN training loss 0.001720\n",
      ">> Epoch 131 finished \tANN training loss 0.001713\n",
      ">> Epoch 132 finished \tANN training loss 0.001707\n",
      ">> Epoch 133 finished \tANN training loss 0.001700\n",
      ">> Epoch 134 finished \tANN training loss 0.001693\n",
      ">> Epoch 135 finished \tANN training loss 0.001687\n",
      ">> Epoch 136 finished \tANN training loss 0.001680\n",
      ">> Epoch 137 finished \tANN training loss 0.001674\n",
      ">> Epoch 138 finished \tANN training loss 0.001667\n",
      ">> Epoch 139 finished \tANN training loss 0.001661\n",
      ">> Epoch 140 finished \tANN training loss 0.001655\n",
      ">> Epoch 141 finished \tANN training loss 0.001649\n",
      ">> Epoch 142 finished \tANN training loss 0.001642\n",
      ">> Epoch 143 finished \tANN training loss 0.001636\n",
      ">> Epoch 144 finished \tANN training loss 0.001630\n",
      ">> Epoch 145 finished \tANN training loss 0.001625\n",
      ">> Epoch 146 finished \tANN training loss 0.001619\n",
      ">> Epoch 147 finished \tANN training loss 0.001613\n",
      ">> Epoch 148 finished \tANN training loss 0.001607\n",
      ">> Epoch 149 finished \tANN training loss 0.001601\n",
      ">> Epoch 150 finished \tANN training loss 0.001596\n",
      "[END] Fine tuning step\n",
      "############### End Training for M&MFINEQ #####################\n",
      "############### End Training for INDUSINDBKEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 0.509145\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 0.505412\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 0.501749\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 0.498157\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 0.494641\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 0.491189\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 0.487818\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 0.484511\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 0.481280\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 0.478103\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 0.474992\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 0.471945\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 0.468968\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 0.466039\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 0.463176\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 0.460373\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 0.457620\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 0.454928\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 0.452281\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 0.449695\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 0.447156\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 0.444662\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 0.442223\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 0.439832\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 0.437490\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 0.435191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 27 finished \tRBM Reconstruction error 0.432943\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 0.430731\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 0.428558\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 0.426432\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 0.424344\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 0.422294\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.420279\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.418310\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.416370\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.414469\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.412599\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.410764\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.408961\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.407193\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.405457\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.403747\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.402067\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.400411\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.398786\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.397185\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.395610\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.394058\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.392533\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.391030\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.389548\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.388084\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.386647\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.385234\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.383838\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.382465\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.381109\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.379777\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.378462\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.377152\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.375872\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.374604\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.373352\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.372112\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.370892\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.369679\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.368482\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.367299\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.366133\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.364983\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.363841\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.362717\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.361601\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.360496\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.359395\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.358302\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.357226\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.356166\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.355106\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.354050\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.353008\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.351971\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.350939\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.349920\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.348905\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.347895\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.346895\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.345900\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.344908\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.343921\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.342950\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.341975\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.341009\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.340051\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.339100\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.338148\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.337203\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.336254\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.335316\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.334379\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.005940\n",
      ">> Epoch 2 finished \tANN training loss 0.005899\n",
      ">> Epoch 3 finished \tANN training loss 0.005859\n",
      ">> Epoch 4 finished \tANN training loss 0.005819\n",
      ">> Epoch 5 finished \tANN training loss 0.005779\n",
      ">> Epoch 6 finished \tANN training loss 0.005740\n",
      ">> Epoch 7 finished \tANN training loss 0.005701\n",
      ">> Epoch 8 finished \tANN training loss 0.005662\n",
      ">> Epoch 9 finished \tANN training loss 0.005623\n",
      ">> Epoch 10 finished \tANN training loss 0.005585\n",
      ">> Epoch 11 finished \tANN training loss 0.005547\n",
      ">> Epoch 12 finished \tANN training loss 0.005510\n",
      ">> Epoch 13 finished \tANN training loss 0.005473\n",
      ">> Epoch 14 finished \tANN training loss 0.005436\n",
      ">> Epoch 15 finished \tANN training loss 0.005399\n",
      ">> Epoch 16 finished \tANN training loss 0.005363\n",
      ">> Epoch 17 finished \tANN training loss 0.005326\n",
      ">> Epoch 18 finished \tANN training loss 0.005291\n",
      ">> Epoch 19 finished \tANN training loss 0.005255\n",
      ">> Epoch 20 finished \tANN training loss 0.005220\n",
      ">> Epoch 21 finished \tANN training loss 0.005185\n",
      ">> Epoch 22 finished \tANN training loss 0.005150\n",
      ">> Epoch 23 finished \tANN training loss 0.005115\n",
      ">> Epoch 24 finished \tANN training loss 0.005081\n",
      ">> Epoch 25 finished \tANN training loss 0.005047\n",
      ">> Epoch 26 finished \tANN training loss 0.005013\n",
      ">> Epoch 27 finished \tANN training loss 0.004980\n",
      ">> Epoch 28 finished \tANN training loss 0.004947\n",
      ">> Epoch 29 finished \tANN training loss 0.004914\n",
      ">> Epoch 30 finished \tANN training loss 0.004882\n",
      ">> Epoch 31 finished \tANN training loss 0.004849\n",
      ">> Epoch 32 finished \tANN training loss 0.004818\n",
      ">> Epoch 33 finished \tANN training loss 0.004786\n",
      ">> Epoch 34 finished \tANN training loss 0.004755\n",
      ">> Epoch 35 finished \tANN training loss 0.004724\n",
      ">> Epoch 36 finished \tANN training loss 0.004693\n",
      ">> Epoch 37 finished \tANN training loss 0.004662\n",
      ">> Epoch 38 finished \tANN training loss 0.004632\n",
      ">> Epoch 39 finished \tANN training loss 0.004602\n",
      ">> Epoch 40 finished \tANN training loss 0.004573\n",
      ">> Epoch 41 finished \tANN training loss 0.004543\n",
      ">> Epoch 42 finished \tANN training loss 0.004514\n",
      ">> Epoch 43 finished \tANN training loss 0.004485\n",
      ">> Epoch 44 finished \tANN training loss 0.004457\n",
      ">> Epoch 45 finished \tANN training loss 0.004428\n",
      ">> Epoch 46 finished \tANN training loss 0.004400\n",
      ">> Epoch 47 finished \tANN training loss 0.004372\n",
      ">> Epoch 48 finished \tANN training loss 0.004344\n",
      ">> Epoch 49 finished \tANN training loss 0.004317\n",
      ">> Epoch 50 finished \tANN training loss 0.004290\n",
      ">> Epoch 51 finished \tANN training loss 0.004263\n",
      ">> Epoch 52 finished \tANN training loss 0.004236\n",
      ">> Epoch 53 finished \tANN training loss 0.004209\n",
      ">> Epoch 54 finished \tANN training loss 0.004183\n",
      ">> Epoch 55 finished \tANN training loss 0.004156\n",
      ">> Epoch 56 finished \tANN training loss 0.004130\n",
      ">> Epoch 57 finished \tANN training loss 0.004104\n",
      ">> Epoch 58 finished \tANN training loss 0.004079\n",
      ">> Epoch 59 finished \tANN training loss 0.004053\n",
      ">> Epoch 60 finished \tANN training loss 0.004028\n",
      ">> Epoch 61 finished \tANN training loss 0.004003\n",
      ">> Epoch 62 finished \tANN training loss 0.003978\n",
      ">> Epoch 63 finished \tANN training loss 0.003953\n",
      ">> Epoch 64 finished \tANN training loss 0.003929\n",
      ">> Epoch 65 finished \tANN training loss 0.003904\n",
      ">> Epoch 66 finished \tANN training loss 0.003880\n",
      ">> Epoch 67 finished \tANN training loss 0.003856\n",
      ">> Epoch 68 finished \tANN training loss 0.003832\n",
      ">> Epoch 69 finished \tANN training loss 0.003808\n",
      ">> Epoch 70 finished \tANN training loss 0.003785\n",
      ">> Epoch 71 finished \tANN training loss 0.003761\n",
      ">> Epoch 72 finished \tANN training loss 0.003738\n",
      ">> Epoch 73 finished \tANN training loss 0.003715\n",
      ">> Epoch 74 finished \tANN training loss 0.003692\n",
      ">> Epoch 75 finished \tANN training loss 0.003669\n",
      ">> Epoch 76 finished \tANN training loss 0.003647\n",
      ">> Epoch 77 finished \tANN training loss 0.003624\n",
      ">> Epoch 78 finished \tANN training loss 0.003602\n",
      ">> Epoch 79 finished \tANN training loss 0.003580\n",
      ">> Epoch 80 finished \tANN training loss 0.003557\n",
      ">> Epoch 81 finished \tANN training loss 0.003536\n",
      ">> Epoch 82 finished \tANN training loss 0.003514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 83 finished \tANN training loss 0.003492\n",
      ">> Epoch 84 finished \tANN training loss 0.003471\n",
      ">> Epoch 85 finished \tANN training loss 0.003450\n",
      ">> Epoch 86 finished \tANN training loss 0.003428\n",
      ">> Epoch 87 finished \tANN training loss 0.003407\n",
      ">> Epoch 88 finished \tANN training loss 0.003387\n",
      ">> Epoch 89 finished \tANN training loss 0.003366\n",
      ">> Epoch 90 finished \tANN training loss 0.003345\n",
      ">> Epoch 91 finished \tANN training loss 0.003325\n",
      ">> Epoch 92 finished \tANN training loss 0.003305\n",
      ">> Epoch 93 finished \tANN training loss 0.003284\n",
      ">> Epoch 94 finished \tANN training loss 0.003264\n",
      ">> Epoch 95 finished \tANN training loss 0.003245\n",
      ">> Epoch 96 finished \tANN training loss 0.003225\n",
      ">> Epoch 97 finished \tANN training loss 0.003205\n",
      ">> Epoch 98 finished \tANN training loss 0.003186\n",
      ">> Epoch 99 finished \tANN training loss 0.003166\n",
      ">> Epoch 100 finished \tANN training loss 0.003147\n",
      ">> Epoch 101 finished \tANN training loss 0.003128\n",
      ">> Epoch 102 finished \tANN training loss 0.003109\n",
      ">> Epoch 103 finished \tANN training loss 0.003090\n",
      ">> Epoch 104 finished \tANN training loss 0.003071\n",
      ">> Epoch 105 finished \tANN training loss 0.003053\n",
      ">> Epoch 106 finished \tANN training loss 0.003034\n",
      ">> Epoch 107 finished \tANN training loss 0.003016\n",
      ">> Epoch 108 finished \tANN training loss 0.002998\n",
      ">> Epoch 109 finished \tANN training loss 0.002979\n",
      ">> Epoch 110 finished \tANN training loss 0.002961\n",
      ">> Epoch 111 finished \tANN training loss 0.002944\n",
      ">> Epoch 112 finished \tANN training loss 0.002926\n",
      ">> Epoch 113 finished \tANN training loss 0.002908\n",
      ">> Epoch 114 finished \tANN training loss 0.002891\n",
      ">> Epoch 115 finished \tANN training loss 0.002873\n",
      ">> Epoch 116 finished \tANN training loss 0.002856\n",
      ">> Epoch 117 finished \tANN training loss 0.002839\n",
      ">> Epoch 118 finished \tANN training loss 0.002822\n",
      ">> Epoch 119 finished \tANN training loss 0.002805\n",
      ">> Epoch 120 finished \tANN training loss 0.002788\n",
      ">> Epoch 121 finished \tANN training loss 0.002771\n",
      ">> Epoch 122 finished \tANN training loss 0.002754\n",
      ">> Epoch 123 finished \tANN training loss 0.002738\n",
      ">> Epoch 124 finished \tANN training loss 0.002721\n",
      ">> Epoch 125 finished \tANN training loss 0.002705\n",
      ">> Epoch 126 finished \tANN training loss 0.002689\n",
      ">> Epoch 127 finished \tANN training loss 0.002673\n",
      ">> Epoch 128 finished \tANN training loss 0.002657\n",
      ">> Epoch 129 finished \tANN training loss 0.002641\n",
      ">> Epoch 130 finished \tANN training loss 0.002625\n",
      ">> Epoch 131 finished \tANN training loss 0.002609\n",
      ">> Epoch 132 finished \tANN training loss 0.002593\n",
      ">> Epoch 133 finished \tANN training loss 0.002578\n",
      ">> Epoch 134 finished \tANN training loss 0.002563\n",
      ">> Epoch 135 finished \tANN training loss 0.002547\n",
      ">> Epoch 136 finished \tANN training loss 0.002532\n",
      ">> Epoch 137 finished \tANN training loss 0.002517\n",
      ">> Epoch 138 finished \tANN training loss 0.002502\n",
      ">> Epoch 139 finished \tANN training loss 0.002487\n",
      ">> Epoch 140 finished \tANN training loss 0.002472\n",
      ">> Epoch 141 finished \tANN training loss 0.002457\n",
      ">> Epoch 142 finished \tANN training loss 0.002443\n",
      ">> Epoch 143 finished \tANN training loss 0.002428\n",
      ">> Epoch 144 finished \tANN training loss 0.002414\n",
      ">> Epoch 145 finished \tANN training loss 0.002400\n",
      ">> Epoch 146 finished \tANN training loss 0.002385\n",
      ">> Epoch 147 finished \tANN training loss 0.002371\n",
      ">> Epoch 148 finished \tANN training loss 0.002357\n",
      ">> Epoch 149 finished \tANN training loss 0.002343\n",
      ">> Epoch 150 finished \tANN training loss 0.002329\n",
      "[END] Fine tuning step\n",
      "############### End Training for INDUSINDBKEQ #####################\n",
      "############### End Training for PELEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 0.324471\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 0.320107\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 0.315856\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 0.311716\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 0.307676\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 0.303739\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 0.299914\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 0.296180\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 0.292538\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 0.288984\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 0.285524\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 0.282154\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 0.278874\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 0.275674\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 0.272555\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 0.269535\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 0.266586\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 0.263713\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 0.260904\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 0.258188\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 0.255534\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 0.252951\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 0.250438\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 0.247997\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 0.245622\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 0.243300\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 0.241047\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 0.238851\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 0.236709\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 0.234628\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 0.232596\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 0.230624\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.228700\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.226833\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.225017\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.223246\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.221519\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.219836\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.218200\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.216610\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.215061\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.213558\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.212088\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.210662\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.209272\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.207922\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.206603\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.205320\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.204066\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.202849\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.201665\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.200507\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.199378\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.198281\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.197214\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.196174\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.195159\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.194166\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.193198\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.192254\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.191337\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.190445\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.189575\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.188725\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.187894\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.187084\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.186296\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.185526\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.184777\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.184049\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.183338\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.182641\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.181961\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.181296\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.180648\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.180013\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.179394\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.178791\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.178200\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.177621\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.177059\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.176503\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.175962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 84 finished \tRBM Reconstruction error 0.175437\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.174919\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.174418\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.173922\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.173442\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.172974\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.172508\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.172056\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.171610\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.171176\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.170748\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.170331\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.169924\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.169524\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.169131\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.168743\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.168362\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.011903\n",
      ">> Epoch 2 finished \tANN training loss 0.011226\n",
      ">> Epoch 3 finished \tANN training loss 0.010592\n",
      ">> Epoch 4 finished \tANN training loss 0.009997\n",
      ">> Epoch 5 finished \tANN training loss 0.009440\n",
      ">> Epoch 6 finished \tANN training loss 0.008917\n",
      ">> Epoch 7 finished \tANN training loss 0.008428\n",
      ">> Epoch 8 finished \tANN training loss 0.007969\n",
      ">> Epoch 9 finished \tANN training loss 0.007538\n",
      ">> Epoch 10 finished \tANN training loss 0.007133\n",
      ">> Epoch 11 finished \tANN training loss 0.006754\n",
      ">> Epoch 12 finished \tANN training loss 0.006398\n",
      ">> Epoch 13 finished \tANN training loss 0.006064\n",
      ">> Epoch 14 finished \tANN training loss 0.005750\n",
      ">> Epoch 15 finished \tANN training loss 0.005456\n",
      ">> Epoch 16 finished \tANN training loss 0.005179\n",
      ">> Epoch 17 finished \tANN training loss 0.004920\n",
      ">> Epoch 18 finished \tANN training loss 0.004677\n",
      ">> Epoch 19 finished \tANN training loss 0.004449\n",
      ">> Epoch 20 finished \tANN training loss 0.004235\n",
      ">> Epoch 21 finished \tANN training loss 0.004034\n",
      ">> Epoch 22 finished \tANN training loss 0.003846\n",
      ">> Epoch 23 finished \tANN training loss 0.003669\n",
      ">> Epoch 24 finished \tANN training loss 0.003503\n",
      ">> Epoch 25 finished \tANN training loss 0.003347\n",
      ">> Epoch 26 finished \tANN training loss 0.003201\n",
      ">> Epoch 27 finished \tANN training loss 0.003064\n",
      ">> Epoch 28 finished \tANN training loss 0.002934\n",
      ">> Epoch 29 finished \tANN training loss 0.002813\n",
      ">> Epoch 30 finished \tANN training loss 0.002699\n",
      ">> Epoch 31 finished \tANN training loss 0.002591\n",
      ">> Epoch 32 finished \tANN training loss 0.002490\n",
      ">> Epoch 33 finished \tANN training loss 0.002395\n",
      ">> Epoch 34 finished \tANN training loss 0.002305\n",
      ">> Epoch 35 finished \tANN training loss 0.002221\n",
      ">> Epoch 36 finished \tANN training loss 0.002141\n",
      ">> Epoch 37 finished \tANN training loss 0.002066\n",
      ">> Epoch 38 finished \tANN training loss 0.001996\n",
      ">> Epoch 39 finished \tANN training loss 0.001929\n",
      ">> Epoch 40 finished \tANN training loss 0.001866\n",
      ">> Epoch 41 finished \tANN training loss 0.001807\n",
      ">> Epoch 42 finished \tANN training loss 0.001751\n",
      ">> Epoch 43 finished \tANN training loss 0.001698\n",
      ">> Epoch 44 finished \tANN training loss 0.001648\n",
      ">> Epoch 45 finished \tANN training loss 0.001601\n",
      ">> Epoch 46 finished \tANN training loss 0.001557\n",
      ">> Epoch 47 finished \tANN training loss 0.001515\n",
      ">> Epoch 48 finished \tANN training loss 0.001475\n",
      ">> Epoch 49 finished \tANN training loss 0.001437\n",
      ">> Epoch 50 finished \tANN training loss 0.001402\n",
      ">> Epoch 51 finished \tANN training loss 0.001368\n",
      ">> Epoch 52 finished \tANN training loss 0.001336\n",
      ">> Epoch 53 finished \tANN training loss 0.001306\n",
      ">> Epoch 54 finished \tANN training loss 0.001277\n",
      ">> Epoch 55 finished \tANN training loss 0.001250\n",
      ">> Epoch 56 finished \tANN training loss 0.001224\n",
      ">> Epoch 57 finished \tANN training loss 0.001200\n",
      ">> Epoch 58 finished \tANN training loss 0.001177\n",
      ">> Epoch 59 finished \tANN training loss 0.001155\n",
      ">> Epoch 60 finished \tANN training loss 0.001134\n",
      ">> Epoch 61 finished \tANN training loss 0.001114\n",
      ">> Epoch 62 finished \tANN training loss 0.001095\n",
      ">> Epoch 63 finished \tANN training loss 0.001077\n",
      ">> Epoch 64 finished \tANN training loss 0.001059\n",
      ">> Epoch 65 finished \tANN training loss 0.001043\n",
      ">> Epoch 66 finished \tANN training loss 0.001027\n",
      ">> Epoch 67 finished \tANN training loss 0.001012\n",
      ">> Epoch 68 finished \tANN training loss 0.000998\n",
      ">> Epoch 69 finished \tANN training loss 0.000984\n",
      ">> Epoch 70 finished \tANN training loss 0.000971\n",
      ">> Epoch 71 finished \tANN training loss 0.000959\n",
      ">> Epoch 72 finished \tANN training loss 0.000947\n",
      ">> Epoch 73 finished \tANN training loss 0.000935\n",
      ">> Epoch 74 finished \tANN training loss 0.000924\n",
      ">> Epoch 75 finished \tANN training loss 0.000913\n",
      ">> Epoch 76 finished \tANN training loss 0.000903\n",
      ">> Epoch 77 finished \tANN training loss 0.000893\n",
      ">> Epoch 78 finished \tANN training loss 0.000884\n",
      ">> Epoch 79 finished \tANN training loss 0.000875\n",
      ">> Epoch 80 finished \tANN training loss 0.000866\n",
      ">> Epoch 81 finished \tANN training loss 0.000858\n",
      ">> Epoch 82 finished \tANN training loss 0.000849\n",
      ">> Epoch 83 finished \tANN training loss 0.000841\n",
      ">> Epoch 84 finished \tANN training loss 0.000834\n",
      ">> Epoch 85 finished \tANN training loss 0.000826\n",
      ">> Epoch 86 finished \tANN training loss 0.000819\n",
      ">> Epoch 87 finished \tANN training loss 0.000812\n",
      ">> Epoch 88 finished \tANN training loss 0.000805\n",
      ">> Epoch 89 finished \tANN training loss 0.000799\n",
      ">> Epoch 90 finished \tANN training loss 0.000792\n",
      ">> Epoch 91 finished \tANN training loss 0.000786\n",
      ">> Epoch 92 finished \tANN training loss 0.000780\n",
      ">> Epoch 93 finished \tANN training loss 0.000774\n",
      ">> Epoch 94 finished \tANN training loss 0.000768\n",
      ">> Epoch 95 finished \tANN training loss 0.000763\n",
      ">> Epoch 96 finished \tANN training loss 0.000757\n",
      ">> Epoch 97 finished \tANN training loss 0.000752\n",
      ">> Epoch 98 finished \tANN training loss 0.000747\n",
      ">> Epoch 99 finished \tANN training loss 0.000741\n",
      ">> Epoch 100 finished \tANN training loss 0.000736\n",
      ">> Epoch 101 finished \tANN training loss 0.000732\n",
      ">> Epoch 102 finished \tANN training loss 0.000727\n",
      ">> Epoch 103 finished \tANN training loss 0.000722\n",
      ">> Epoch 104 finished \tANN training loss 0.000717\n",
      ">> Epoch 105 finished \tANN training loss 0.000713\n",
      ">> Epoch 106 finished \tANN training loss 0.000708\n",
      ">> Epoch 107 finished \tANN training loss 0.000704\n",
      ">> Epoch 108 finished \tANN training loss 0.000699\n",
      ">> Epoch 109 finished \tANN training loss 0.000695\n",
      ">> Epoch 110 finished \tANN training loss 0.000691\n",
      ">> Epoch 111 finished \tANN training loss 0.000687\n",
      ">> Epoch 112 finished \tANN training loss 0.000683\n",
      ">> Epoch 113 finished \tANN training loss 0.000679\n",
      ">> Epoch 114 finished \tANN training loss 0.000675\n",
      ">> Epoch 115 finished \tANN training loss 0.000671\n",
      ">> Epoch 116 finished \tANN training loss 0.000667\n",
      ">> Epoch 117 finished \tANN training loss 0.000663\n",
      ">> Epoch 118 finished \tANN training loss 0.000659\n",
      ">> Epoch 119 finished \tANN training loss 0.000655\n",
      ">> Epoch 120 finished \tANN training loss 0.000652\n",
      ">> Epoch 121 finished \tANN training loss 0.000648\n",
      ">> Epoch 122 finished \tANN training loss 0.000644\n",
      ">> Epoch 123 finished \tANN training loss 0.000641\n",
      ">> Epoch 124 finished \tANN training loss 0.000637\n",
      ">> Epoch 125 finished \tANN training loss 0.000634\n",
      ">> Epoch 126 finished \tANN training loss 0.000630\n",
      ">> Epoch 127 finished \tANN training loss 0.000627\n",
      ">> Epoch 128 finished \tANN training loss 0.000624\n",
      ">> Epoch 129 finished \tANN training loss 0.000620\n",
      ">> Epoch 130 finished \tANN training loss 0.000617\n",
      ">> Epoch 131 finished \tANN training loss 0.000614\n",
      ">> Epoch 132 finished \tANN training loss 0.000610\n",
      ">> Epoch 133 finished \tANN training loss 0.000607\n",
      ">> Epoch 134 finished \tANN training loss 0.000604\n",
      ">> Epoch 135 finished \tANN training loss 0.000601\n",
      ">> Epoch 136 finished \tANN training loss 0.000597\n",
      ">> Epoch 137 finished \tANN training loss 0.000594\n",
      ">> Epoch 138 finished \tANN training loss 0.000591\n",
      ">> Epoch 139 finished \tANN training loss 0.000588\n",
      ">> Epoch 140 finished \tANN training loss 0.000585\n",
      ">> Epoch 141 finished \tANN training loss 0.000582\n",
      ">> Epoch 142 finished \tANN training loss 0.000579\n",
      ">> Epoch 143 finished \tANN training loss 0.000576\n",
      ">> Epoch 144 finished \tANN training loss 0.000573\n",
      ">> Epoch 145 finished \tANN training loss 0.000570\n",
      ">> Epoch 146 finished \tANN training loss 0.000567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 147 finished \tANN training loss 0.000564\n",
      ">> Epoch 148 finished \tANN training loss 0.000561\n",
      ">> Epoch 149 finished \tANN training loss 0.000558\n",
      ">> Epoch 150 finished \tANN training loss 0.000556\n",
      "[END] Fine tuning step\n",
      "############### End Training for PELEQ #####################\n",
      "############### End Training for UBLEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 9.214739\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 9.066522\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 8.910846\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 8.747038\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 8.574322\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 8.391366\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 8.196768\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 7.989191\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 7.767280\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 7.529455\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 7.274360\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 7.000506\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 6.707006\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 6.392076\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 6.056065\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 5.698521\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 5.320566\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 4.924173\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 4.511847\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 4.087947\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 3.658716\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 3.231525\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 2.812510\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 2.412410\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 2.036691\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 1.693737\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 1.390172\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 1.128571\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 0.907156\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 0.727875\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 0.584580\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 0.474328\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.390534\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.330513\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.285754\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.252192\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.229134\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.213033\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.201272\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.193039\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.186814\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.182411\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.178848\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.176220\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.174074\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.172304\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.170757\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.169420\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.168411\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.167422\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.166474\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.165374\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.164765\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.163885\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.163079\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.162462\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.161869\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.161091\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.160475\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.159838\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.159539\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.158995\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.158359\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.157657\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.157324\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.156784\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.156399\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.155763\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.155307\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.155071\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.154287\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.153711\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.153328\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.152722\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.152407\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.151981\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.151811\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.151333\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.151122\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.150935\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.150704\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.150181\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.150129\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.149779\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.149176\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.149145\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.148515\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.148198\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.147853\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.147094\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.146736\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.146300\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.146026\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.145844\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.145511\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.145366\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.144789\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.144402\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.144078\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.143708\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.605517\n",
      ">> Epoch 2 finished \tANN training loss 0.490144\n",
      ">> Epoch 3 finished \tANN training loss 0.397035\n",
      ">> Epoch 4 finished \tANN training loss 0.321972\n",
      ">> Epoch 5 finished \tANN training loss 0.261618\n",
      ">> Epoch 6 finished \tANN training loss 0.213552\n",
      ">> Epoch 7 finished \tANN training loss 0.174891\n",
      ">> Epoch 8 finished \tANN training loss 0.143489\n",
      ">> Epoch 9 finished \tANN training loss 0.117933\n",
      ">> Epoch 10 finished \tANN training loss 0.097104\n",
      ">> Epoch 11 finished \tANN training loss 0.080110\n",
      ">> Epoch 12 finished \tANN training loss 0.066253\n",
      ">> Epoch 13 finished \tANN training loss 0.054964\n",
      ">> Epoch 14 finished \tANN training loss 0.045738\n",
      ">> Epoch 15 finished \tANN training loss 0.038171\n",
      ">> Epoch 16 finished \tANN training loss 0.031956\n",
      ">> Epoch 17 finished \tANN training loss 0.026847\n",
      ">> Epoch 18 finished \tANN training loss 0.022648\n",
      ">> Epoch 19 finished \tANN training loss 0.019193\n",
      ">> Epoch 20 finished \tANN training loss 0.016353\n",
      ">> Epoch 21 finished \tANN training loss 0.014016\n",
      ">> Epoch 22 finished \tANN training loss 0.012093\n",
      ">> Epoch 23 finished \tANN training loss 0.010511\n",
      ">> Epoch 24 finished \tANN training loss 0.009210\n",
      ">> Epoch 25 finished \tANN training loss 0.008139\n",
      ">> Epoch 26 finished \tANN training loss 0.007257\n",
      ">> Epoch 27 finished \tANN training loss 0.006531\n",
      ">> Epoch 28 finished \tANN training loss 0.005932\n",
      ">> Epoch 29 finished \tANN training loss 0.005440\n",
      ">> Epoch 30 finished \tANN training loss 0.005033\n",
      ">> Epoch 31 finished \tANN training loss 0.004698\n",
      ">> Epoch 32 finished \tANN training loss 0.004421\n",
      ">> Epoch 33 finished \tANN training loss 0.004192\n",
      ">> Epoch 34 finished \tANN training loss 0.004003\n",
      ">> Epoch 35 finished \tANN training loss 0.003846\n",
      ">> Epoch 36 finished \tANN training loss 0.003716\n",
      ">> Epoch 37 finished \tANN training loss 0.003608\n",
      ">> Epoch 38 finished \tANN training loss 0.003518\n",
      ">> Epoch 39 finished \tANN training loss 0.003443\n",
      ">> Epoch 40 finished \tANN training loss 0.003380\n",
      ">> Epoch 41 finished \tANN training loss 0.003327\n",
      ">> Epoch 42 finished \tANN training loss 0.003282\n",
      ">> Epoch 43 finished \tANN training loss 0.003244\n",
      ">> Epoch 44 finished \tANN training loss 0.003211\n",
      ">> Epoch 45 finished \tANN training loss 0.003183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 46 finished \tANN training loss 0.003159\n",
      ">> Epoch 47 finished \tANN training loss 0.003138\n",
      ">> Epoch 48 finished \tANN training loss 0.003119\n",
      ">> Epoch 49 finished \tANN training loss 0.003102\n",
      ">> Epoch 50 finished \tANN training loss 0.003087\n",
      ">> Epoch 51 finished \tANN training loss 0.003074\n",
      ">> Epoch 52 finished \tANN training loss 0.003061\n",
      ">> Epoch 53 finished \tANN training loss 0.003050\n",
      ">> Epoch 54 finished \tANN training loss 0.003039\n",
      ">> Epoch 55 finished \tANN training loss 0.003030\n",
      ">> Epoch 56 finished \tANN training loss 0.003020\n",
      ">> Epoch 57 finished \tANN training loss 0.003011\n",
      ">> Epoch 58 finished \tANN training loss 0.003003\n",
      ">> Epoch 59 finished \tANN training loss 0.002994\n",
      ">> Epoch 60 finished \tANN training loss 0.002986\n",
      ">> Epoch 61 finished \tANN training loss 0.002978\n",
      ">> Epoch 62 finished \tANN training loss 0.002970\n",
      ">> Epoch 63 finished \tANN training loss 0.002963\n",
      ">> Epoch 64 finished \tANN training loss 0.002955\n",
      ">> Epoch 65 finished \tANN training loss 0.002947\n",
      ">> Epoch 66 finished \tANN training loss 0.002940\n",
      ">> Epoch 67 finished \tANN training loss 0.002933\n",
      ">> Epoch 68 finished \tANN training loss 0.002925\n",
      ">> Epoch 69 finished \tANN training loss 0.002918\n",
      ">> Epoch 70 finished \tANN training loss 0.002911\n",
      ">> Epoch 71 finished \tANN training loss 0.002903\n",
      ">> Epoch 72 finished \tANN training loss 0.002896\n",
      ">> Epoch 73 finished \tANN training loss 0.002889\n",
      ">> Epoch 74 finished \tANN training loss 0.002882\n",
      ">> Epoch 75 finished \tANN training loss 0.002875\n",
      ">> Epoch 76 finished \tANN training loss 0.002868\n",
      ">> Epoch 77 finished \tANN training loss 0.002861\n",
      ">> Epoch 78 finished \tANN training loss 0.002854\n",
      ">> Epoch 79 finished \tANN training loss 0.002847\n",
      ">> Epoch 80 finished \tANN training loss 0.002840\n",
      ">> Epoch 81 finished \tANN training loss 0.002833\n",
      ">> Epoch 82 finished \tANN training loss 0.002827\n",
      ">> Epoch 83 finished \tANN training loss 0.002820\n",
      ">> Epoch 84 finished \tANN training loss 0.002813\n",
      ">> Epoch 85 finished \tANN training loss 0.002807\n",
      ">> Epoch 86 finished \tANN training loss 0.002801\n",
      ">> Epoch 87 finished \tANN training loss 0.002794\n",
      ">> Epoch 88 finished \tANN training loss 0.002788\n",
      ">> Epoch 89 finished \tANN training loss 0.002782\n",
      ">> Epoch 90 finished \tANN training loss 0.002776\n",
      ">> Epoch 91 finished \tANN training loss 0.002770\n",
      ">> Epoch 92 finished \tANN training loss 0.002764\n",
      ">> Epoch 93 finished \tANN training loss 0.002758\n",
      ">> Epoch 94 finished \tANN training loss 0.002752\n",
      ">> Epoch 95 finished \tANN training loss 0.002746\n",
      ">> Epoch 96 finished \tANN training loss 0.002741\n",
      ">> Epoch 97 finished \tANN training loss 0.002735\n",
      ">> Epoch 98 finished \tANN training loss 0.002730\n",
      ">> Epoch 99 finished \tANN training loss 0.002724\n",
      ">> Epoch 100 finished \tANN training loss 0.002719\n",
      ">> Epoch 101 finished \tANN training loss 0.002713\n",
      ">> Epoch 102 finished \tANN training loss 0.002708\n",
      ">> Epoch 103 finished \tANN training loss 0.002702\n",
      ">> Epoch 104 finished \tANN training loss 0.002697\n",
      ">> Epoch 105 finished \tANN training loss 0.002692\n",
      ">> Epoch 106 finished \tANN training loss 0.002687\n",
      ">> Epoch 107 finished \tANN training loss 0.002682\n",
      ">> Epoch 108 finished \tANN training loss 0.002676\n",
      ">> Epoch 109 finished \tANN training loss 0.002671\n",
      ">> Epoch 110 finished \tANN training loss 0.002666\n",
      ">> Epoch 111 finished \tANN training loss 0.002661\n",
      ">> Epoch 112 finished \tANN training loss 0.002656\n",
      ">> Epoch 113 finished \tANN training loss 0.002652\n",
      ">> Epoch 114 finished \tANN training loss 0.002647\n",
      ">> Epoch 115 finished \tANN training loss 0.002642\n",
      ">> Epoch 116 finished \tANN training loss 0.002637\n",
      ">> Epoch 117 finished \tANN training loss 0.002632\n",
      ">> Epoch 118 finished \tANN training loss 0.002628\n",
      ">> Epoch 119 finished \tANN training loss 0.002623\n",
      ">> Epoch 120 finished \tANN training loss 0.002618\n",
      ">> Epoch 121 finished \tANN training loss 0.002614\n",
      ">> Epoch 122 finished \tANN training loss 0.002609\n",
      ">> Epoch 123 finished \tANN training loss 0.002604\n",
      ">> Epoch 124 finished \tANN training loss 0.002600\n",
      ">> Epoch 125 finished \tANN training loss 0.002595\n",
      ">> Epoch 126 finished \tANN training loss 0.002591\n",
      ">> Epoch 127 finished \tANN training loss 0.002586\n",
      ">> Epoch 128 finished \tANN training loss 0.002582\n",
      ">> Epoch 129 finished \tANN training loss 0.002578\n",
      ">> Epoch 130 finished \tANN training loss 0.002573\n",
      ">> Epoch 131 finished \tANN training loss 0.002569\n",
      ">> Epoch 132 finished \tANN training loss 0.002565\n",
      ">> Epoch 133 finished \tANN training loss 0.002560\n",
      ">> Epoch 134 finished \tANN training loss 0.002556\n",
      ">> Epoch 135 finished \tANN training loss 0.002552\n",
      ">> Epoch 136 finished \tANN training loss 0.002547\n",
      ">> Epoch 137 finished \tANN training loss 0.002543\n",
      ">> Epoch 138 finished \tANN training loss 0.002539\n",
      ">> Epoch 139 finished \tANN training loss 0.002535\n",
      ">> Epoch 140 finished \tANN training loss 0.002531\n",
      ">> Epoch 141 finished \tANN training loss 0.002527\n",
      ">> Epoch 142 finished \tANN training loss 0.002523\n",
      ">> Epoch 143 finished \tANN training loss 0.002518\n",
      ">> Epoch 144 finished \tANN training loss 0.002514\n",
      ">> Epoch 145 finished \tANN training loss 0.002510\n",
      ">> Epoch 146 finished \tANN training loss 0.002506\n",
      ">> Epoch 147 finished \tANN training loss 0.002502\n",
      ">> Epoch 148 finished \tANN training loss 0.002498\n",
      ">> Epoch 149 finished \tANN training loss 0.002494\n",
      ">> Epoch 150 finished \tANN training loss 0.002491\n",
      "[END] Fine tuning step\n",
      "############### End Training for UBLEQ #####################\n",
      "############### End Training for ITCEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 3.395892\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 3.344316\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 3.292462\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 3.240188\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 3.187334\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 3.133714\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 3.079129\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 3.023415\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 2.966370\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 2.907753\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 2.847375\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 2.784891\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 2.720198\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 2.653008\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 2.583202\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 2.510433\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 2.434673\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 2.355638\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 2.273220\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 2.187545\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 2.098387\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 2.006084\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 1.910943\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 1.812893\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 1.712443\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 1.610276\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 1.506960\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 1.403164\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 1.300795\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 1.199407\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 1.101040\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 1.006153\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.916892\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.833335\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.755718\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.686029\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.621686\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.563937\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.514224\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.471022\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.433458\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.400608\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.373012\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.349534\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.329518\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.312108\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.297361\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.284430\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.273127\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.263034\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.253892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 52 finished \tRBM Reconstruction error 0.245652\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.238159\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.231577\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.225373\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.219417\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.213692\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.208413\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.203450\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.198909\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.194448\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.189927\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.185507\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.181313\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.177178\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.173336\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.169682\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.166088\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.162565\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.159047\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.155617\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.152214\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.148930\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.145662\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.142527\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.139436\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.136330\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.133481\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.130583\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.127831\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.125161\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.122511\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.119819\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.117260\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.114738\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.112181\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.109731\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.107251\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.104910\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.102684\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.100455\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.098279\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.096156\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.094114\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.092107\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.089980\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.087981\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.086002\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.084141\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.082370\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.063598\n",
      ">> Epoch 2 finished \tANN training loss 0.053472\n",
      ">> Epoch 3 finished \tANN training loss 0.044990\n",
      ">> Epoch 4 finished \tANN training loss 0.037879\n",
      ">> Epoch 5 finished \tANN training loss 0.031917\n",
      ">> Epoch 6 finished \tANN training loss 0.026918\n",
      ">> Epoch 7 finished \tANN training loss 0.022724\n",
      ">> Epoch 8 finished \tANN training loss 0.019206\n",
      ">> Epoch 9 finished \tANN training loss 0.016254\n",
      ">> Epoch 10 finished \tANN training loss 0.013777\n",
      ">> Epoch 11 finished \tANN training loss 0.011698\n",
      ">> Epoch 12 finished \tANN training loss 0.009953\n",
      ">> Epoch 13 finished \tANN training loss 0.008488\n",
      ">> Epoch 14 finished \tANN training loss 0.007258\n",
      ">> Epoch 15 finished \tANN training loss 0.006224\n",
      ">> Epoch 16 finished \tANN training loss 0.005356\n",
      ">> Epoch 17 finished \tANN training loss 0.004625\n",
      ">> Epoch 18 finished \tANN training loss 0.004011\n",
      ">> Epoch 19 finished \tANN training loss 0.003494\n",
      ">> Epoch 20 finished \tANN training loss 0.003058\n",
      ">> Epoch 21 finished \tANN training loss 0.002690\n",
      ">> Epoch 22 finished \tANN training loss 0.002380\n",
      ">> Epoch 23 finished \tANN training loss 0.002117\n",
      ">> Epoch 24 finished \tANN training loss 0.001895\n",
      ">> Epoch 25 finished \tANN training loss 0.001706\n",
      ">> Epoch 26 finished \tANN training loss 0.001546\n",
      ">> Epoch 27 finished \tANN training loss 0.001409\n",
      ">> Epoch 28 finished \tANN training loss 0.001292\n",
      ">> Epoch 29 finished \tANN training loss 0.001193\n",
      ">> Epoch 30 finished \tANN training loss 0.001107\n",
      ">> Epoch 31 finished \tANN training loss 0.001033\n",
      ">> Epoch 32 finished \tANN training loss 0.000969\n",
      ">> Epoch 33 finished \tANN training loss 0.000913\n",
      ">> Epoch 34 finished \tANN training loss 0.000865\n",
      ">> Epoch 35 finished \tANN training loss 0.000823\n",
      ">> Epoch 36 finished \tANN training loss 0.000785\n",
      ">> Epoch 37 finished \tANN training loss 0.000752\n",
      ">> Epoch 38 finished \tANN training loss 0.000722\n",
      ">> Epoch 39 finished \tANN training loss 0.000696\n",
      ">> Epoch 40 finished \tANN training loss 0.000672\n",
      ">> Epoch 41 finished \tANN training loss 0.000651\n",
      ">> Epoch 42 finished \tANN training loss 0.000631\n",
      ">> Epoch 43 finished \tANN training loss 0.000613\n",
      ">> Epoch 44 finished \tANN training loss 0.000596\n",
      ">> Epoch 45 finished \tANN training loss 0.000581\n",
      ">> Epoch 46 finished \tANN training loss 0.000566\n",
      ">> Epoch 47 finished \tANN training loss 0.000553\n",
      ">> Epoch 48 finished \tANN training loss 0.000540\n",
      ">> Epoch 49 finished \tANN training loss 0.000529\n",
      ">> Epoch 50 finished \tANN training loss 0.000517\n",
      ">> Epoch 51 finished \tANN training loss 0.000507\n",
      ">> Epoch 52 finished \tANN training loss 0.000497\n",
      ">> Epoch 53 finished \tANN training loss 0.000487\n",
      ">> Epoch 54 finished \tANN training loss 0.000478\n",
      ">> Epoch 55 finished \tANN training loss 0.000469\n",
      ">> Epoch 56 finished \tANN training loss 0.000460\n",
      ">> Epoch 57 finished \tANN training loss 0.000452\n",
      ">> Epoch 58 finished \tANN training loss 0.000444\n",
      ">> Epoch 59 finished \tANN training loss 0.000437\n",
      ">> Epoch 60 finished \tANN training loss 0.000429\n",
      ">> Epoch 61 finished \tANN training loss 0.000422\n",
      ">> Epoch 62 finished \tANN training loss 0.000416\n",
      ">> Epoch 63 finished \tANN training loss 0.000409\n",
      ">> Epoch 64 finished \tANN training loss 0.000403\n",
      ">> Epoch 65 finished \tANN training loss 0.000396\n",
      ">> Epoch 66 finished \tANN training loss 0.000390\n",
      ">> Epoch 67 finished \tANN training loss 0.000385\n",
      ">> Epoch 68 finished \tANN training loss 0.000379\n",
      ">> Epoch 69 finished \tANN training loss 0.000373\n",
      ">> Epoch 70 finished \tANN training loss 0.000368\n",
      ">> Epoch 71 finished \tANN training loss 0.000363\n",
      ">> Epoch 72 finished \tANN training loss 0.000358\n",
      ">> Epoch 73 finished \tANN training loss 0.000353\n",
      ">> Epoch 74 finished \tANN training loss 0.000349\n",
      ">> Epoch 75 finished \tANN training loss 0.000344\n",
      ">> Epoch 76 finished \tANN training loss 0.000340\n",
      ">> Epoch 77 finished \tANN training loss 0.000335\n",
      ">> Epoch 78 finished \tANN training loss 0.000331\n",
      ">> Epoch 79 finished \tANN training loss 0.000327\n",
      ">> Epoch 80 finished \tANN training loss 0.000323\n",
      ">> Epoch 81 finished \tANN training loss 0.000319\n",
      ">> Epoch 82 finished \tANN training loss 0.000316\n",
      ">> Epoch 83 finished \tANN training loss 0.000312\n",
      ">> Epoch 84 finished \tANN training loss 0.000309\n",
      ">> Epoch 85 finished \tANN training loss 0.000305\n",
      ">> Epoch 86 finished \tANN training loss 0.000302\n",
      ">> Epoch 87 finished \tANN training loss 0.000299\n",
      ">> Epoch 88 finished \tANN training loss 0.000296\n",
      ">> Epoch 89 finished \tANN training loss 0.000293\n",
      ">> Epoch 90 finished \tANN training loss 0.000290\n",
      ">> Epoch 91 finished \tANN training loss 0.000287\n",
      ">> Epoch 92 finished \tANN training loss 0.000284\n",
      ">> Epoch 93 finished \tANN training loss 0.000281\n",
      ">> Epoch 94 finished \tANN training loss 0.000279\n",
      ">> Epoch 95 finished \tANN training loss 0.000276\n",
      ">> Epoch 96 finished \tANN training loss 0.000274\n",
      ">> Epoch 97 finished \tANN training loss 0.000272\n",
      ">> Epoch 98 finished \tANN training loss 0.000269\n",
      ">> Epoch 99 finished \tANN training loss 0.000267\n",
      ">> Epoch 100 finished \tANN training loss 0.000265\n",
      ">> Epoch 101 finished \tANN training loss 0.000263\n",
      ">> Epoch 102 finished \tANN training loss 0.000261\n",
      ">> Epoch 103 finished \tANN training loss 0.000259\n",
      ">> Epoch 104 finished \tANN training loss 0.000257\n",
      ">> Epoch 105 finished \tANN training loss 0.000255\n",
      ">> Epoch 106 finished \tANN training loss 0.000253\n",
      ">> Epoch 107 finished \tANN training loss 0.000251\n",
      ">> Epoch 108 finished \tANN training loss 0.000249\n",
      ">> Epoch 109 finished \tANN training loss 0.000248\n",
      ">> Epoch 110 finished \tANN training loss 0.000246\n",
      ">> Epoch 111 finished \tANN training loss 0.000245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 112 finished \tANN training loss 0.000243\n",
      ">> Epoch 113 finished \tANN training loss 0.000242\n",
      ">> Epoch 114 finished \tANN training loss 0.000240\n",
      ">> Epoch 115 finished \tANN training loss 0.000239\n",
      ">> Epoch 116 finished \tANN training loss 0.000237\n",
      ">> Epoch 117 finished \tANN training loss 0.000236\n",
      ">> Epoch 118 finished \tANN training loss 0.000235\n",
      ">> Epoch 119 finished \tANN training loss 0.000233\n",
      ">> Epoch 120 finished \tANN training loss 0.000232\n",
      ">> Epoch 121 finished \tANN training loss 0.000231\n",
      ">> Epoch 122 finished \tANN training loss 0.000230\n",
      ">> Epoch 123 finished \tANN training loss 0.000229\n",
      ">> Epoch 124 finished \tANN training loss 0.000228\n",
      ">> Epoch 125 finished \tANN training loss 0.000227\n",
      ">> Epoch 126 finished \tANN training loss 0.000226\n",
      ">> Epoch 127 finished \tANN training loss 0.000225\n",
      ">> Epoch 128 finished \tANN training loss 0.000224\n",
      ">> Epoch 129 finished \tANN training loss 0.000223\n",
      ">> Epoch 130 finished \tANN training loss 0.000222\n",
      ">> Epoch 131 finished \tANN training loss 0.000221\n",
      ">> Epoch 132 finished \tANN training loss 0.000220\n",
      ">> Epoch 133 finished \tANN training loss 0.000219\n",
      ">> Epoch 134 finished \tANN training loss 0.000218\n",
      ">> Epoch 135 finished \tANN training loss 0.000218\n",
      ">> Epoch 136 finished \tANN training loss 0.000217\n",
      ">> Epoch 137 finished \tANN training loss 0.000216\n",
      ">> Epoch 138 finished \tANN training loss 0.000215\n",
      ">> Epoch 139 finished \tANN training loss 0.000215\n",
      ">> Epoch 140 finished \tANN training loss 0.000214\n",
      ">> Epoch 141 finished \tANN training loss 0.000213\n",
      ">> Epoch 142 finished \tANN training loss 0.000213\n",
      ">> Epoch 143 finished \tANN training loss 0.000212\n",
      ">> Epoch 144 finished \tANN training loss 0.000211\n",
      ">> Epoch 145 finished \tANN training loss 0.000211\n",
      ">> Epoch 146 finished \tANN training loss 0.000210\n",
      ">> Epoch 147 finished \tANN training loss 0.000210\n",
      ">> Epoch 148 finished \tANN training loss 0.000209\n",
      ">> Epoch 149 finished \tANN training loss 0.000209\n",
      ">> Epoch 150 finished \tANN training loss 0.000208\n",
      "[END] Fine tuning step\n",
      "############### End Training for ITCEQ #####################\n",
      "############### End Training for ACCEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 7.015051\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 6.849190\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 6.671373\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 6.478253\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 6.266007\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 6.030182\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 5.766014\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 5.468208\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 5.132083\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 4.753710\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 4.330803\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 3.866028\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 3.364720\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 2.842246\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 2.317431\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 1.819055\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 1.370870\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 0.993487\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 0.703611\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 0.497846\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 0.365543\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 0.290710\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 0.256161\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 0.245173\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 0.247080\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 0.254513\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 0.263245\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 0.272935\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 0.280781\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 0.283812\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 0.287827\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 0.290399\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.289942\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.290007\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.289149\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.287586\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.288798\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.288399\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.287179\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.286563\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.284498\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.282487\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.283357\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.281240\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.279538\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.278680\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.275830\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.276580\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.274856\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.276745\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.275958\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.273221\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.269284\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.268724\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.266830\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.269064\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.270562\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.271671\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.270951\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.269213\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.269404\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.265177\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.263892\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.264570\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.264307\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.264220\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.264241\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.262992\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.260302\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.261518\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.261457\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.259632\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.258770\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.262854\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.259936\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.257975\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.259599\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.263897\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.265138\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.264765\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.265471\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.263479\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.261682\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.258726\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.256790\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.259655\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.262644\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.259274\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.259483\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.260740\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.261655\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.265893\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.264664\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.265827\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.265606\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.266545\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.268753\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.266496\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.262893\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.261491\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.029989\n",
      ">> Epoch 2 finished \tANN training loss 0.020807\n",
      ">> Epoch 3 finished \tANN training loss 0.014684\n",
      ">> Epoch 4 finished \tANN training loss 0.010600\n",
      ">> Epoch 5 finished \tANN training loss 0.007873\n",
      ">> Epoch 6 finished \tANN training loss 0.006052\n",
      ">> Epoch 7 finished \tANN training loss 0.004832\n",
      ">> Epoch 8 finished \tANN training loss 0.004011\n",
      ">> Epoch 9 finished \tANN training loss 0.003456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 10 finished \tANN training loss 0.003079\n",
      ">> Epoch 11 finished \tANN training loss 0.002819\n",
      ">> Epoch 12 finished \tANN training loss 0.002638\n",
      ">> Epoch 13 finished \tANN training loss 0.002509\n",
      ">> Epoch 14 finished \tANN training loss 0.002415\n",
      ">> Epoch 15 finished \tANN training loss 0.002345\n",
      ">> Epoch 16 finished \tANN training loss 0.002290\n",
      ">> Epoch 17 finished \tANN training loss 0.002246\n",
      ">> Epoch 18 finished \tANN training loss 0.002209\n",
      ">> Epoch 19 finished \tANN training loss 0.002177\n",
      ">> Epoch 20 finished \tANN training loss 0.002149\n",
      ">> Epoch 21 finished \tANN training loss 0.002123\n",
      ">> Epoch 22 finished \tANN training loss 0.002099\n",
      ">> Epoch 23 finished \tANN training loss 0.002076\n",
      ">> Epoch 24 finished \tANN training loss 0.002055\n",
      ">> Epoch 25 finished \tANN training loss 0.002034\n",
      ">> Epoch 26 finished \tANN training loss 0.002014\n",
      ">> Epoch 27 finished \tANN training loss 0.001995\n",
      ">> Epoch 28 finished \tANN training loss 0.001976\n",
      ">> Epoch 29 finished \tANN training loss 0.001958\n",
      ">> Epoch 30 finished \tANN training loss 0.001940\n",
      ">> Epoch 31 finished \tANN training loss 0.001923\n",
      ">> Epoch 32 finished \tANN training loss 0.001907\n",
      ">> Epoch 33 finished \tANN training loss 0.001890\n",
      ">> Epoch 34 finished \tANN training loss 0.001874\n",
      ">> Epoch 35 finished \tANN training loss 0.001859\n",
      ">> Epoch 36 finished \tANN training loss 0.001844\n",
      ">> Epoch 37 finished \tANN training loss 0.001829\n",
      ">> Epoch 38 finished \tANN training loss 0.001815\n",
      ">> Epoch 39 finished \tANN training loss 0.001801\n",
      ">> Epoch 40 finished \tANN training loss 0.001787\n",
      ">> Epoch 41 finished \tANN training loss 0.001774\n",
      ">> Epoch 42 finished \tANN training loss 0.001761\n",
      ">> Epoch 43 finished \tANN training loss 0.001749\n",
      ">> Epoch 44 finished \tANN training loss 0.001736\n",
      ">> Epoch 45 finished \tANN training loss 0.001724\n",
      ">> Epoch 46 finished \tANN training loss 0.001713\n",
      ">> Epoch 47 finished \tANN training loss 0.001701\n",
      ">> Epoch 48 finished \tANN training loss 0.001690\n",
      ">> Epoch 49 finished \tANN training loss 0.001679\n",
      ">> Epoch 50 finished \tANN training loss 0.001668\n",
      ">> Epoch 51 finished \tANN training loss 0.001658\n",
      ">> Epoch 52 finished \tANN training loss 0.001648\n",
      ">> Epoch 53 finished \tANN training loss 0.001638\n",
      ">> Epoch 54 finished \tANN training loss 0.001628\n",
      ">> Epoch 55 finished \tANN training loss 0.001618\n",
      ">> Epoch 56 finished \tANN training loss 0.001609\n",
      ">> Epoch 57 finished \tANN training loss 0.001600\n",
      ">> Epoch 58 finished \tANN training loss 0.001591\n",
      ">> Epoch 59 finished \tANN training loss 0.001582\n",
      ">> Epoch 60 finished \tANN training loss 0.001574\n",
      ">> Epoch 61 finished \tANN training loss 0.001565\n",
      ">> Epoch 62 finished \tANN training loss 0.001557\n",
      ">> Epoch 63 finished \tANN training loss 0.001549\n",
      ">> Epoch 64 finished \tANN training loss 0.001541\n",
      ">> Epoch 65 finished \tANN training loss 0.001533\n",
      ">> Epoch 66 finished \tANN training loss 0.001526\n",
      ">> Epoch 67 finished \tANN training loss 0.001519\n",
      ">> Epoch 68 finished \tANN training loss 0.001511\n",
      ">> Epoch 69 finished \tANN training loss 0.001505\n",
      ">> Epoch 70 finished \tANN training loss 0.001498\n",
      ">> Epoch 71 finished \tANN training loss 0.001491\n",
      ">> Epoch 72 finished \tANN training loss 0.001484\n",
      ">> Epoch 73 finished \tANN training loss 0.001478\n",
      ">> Epoch 74 finished \tANN training loss 0.001472\n",
      ">> Epoch 75 finished \tANN training loss 0.001466\n",
      ">> Epoch 76 finished \tANN training loss 0.001460\n",
      ">> Epoch 77 finished \tANN training loss 0.001454\n",
      ">> Epoch 78 finished \tANN training loss 0.001448\n",
      ">> Epoch 79 finished \tANN training loss 0.001442\n",
      ">> Epoch 80 finished \tANN training loss 0.001437\n",
      ">> Epoch 81 finished \tANN training loss 0.001432\n",
      ">> Epoch 82 finished \tANN training loss 0.001427\n",
      ">> Epoch 83 finished \tANN training loss 0.001422\n",
      ">> Epoch 84 finished \tANN training loss 0.001417\n",
      ">> Epoch 85 finished \tANN training loss 0.001412\n",
      ">> Epoch 86 finished \tANN training loss 0.001408\n",
      ">> Epoch 87 finished \tANN training loss 0.001403\n",
      ">> Epoch 88 finished \tANN training loss 0.001399\n",
      ">> Epoch 89 finished \tANN training loss 0.001395\n",
      ">> Epoch 90 finished \tANN training loss 0.001390\n",
      ">> Epoch 91 finished \tANN training loss 0.001387\n",
      ">> Epoch 92 finished \tANN training loss 0.001383\n",
      ">> Epoch 93 finished \tANN training loss 0.001379\n",
      ">> Epoch 94 finished \tANN training loss 0.001375\n",
      ">> Epoch 95 finished \tANN training loss 0.001372\n",
      ">> Epoch 96 finished \tANN training loss 0.001368\n",
      ">> Epoch 97 finished \tANN training loss 0.001365\n",
      ">> Epoch 98 finished \tANN training loss 0.001362\n",
      ">> Epoch 99 finished \tANN training loss 0.001358\n",
      ">> Epoch 100 finished \tANN training loss 0.001355\n",
      ">> Epoch 101 finished \tANN training loss 0.001352\n",
      ">> Epoch 102 finished \tANN training loss 0.001349\n",
      ">> Epoch 103 finished \tANN training loss 0.001347\n",
      ">> Epoch 104 finished \tANN training loss 0.001344\n",
      ">> Epoch 105 finished \tANN training loss 0.001341\n",
      ">> Epoch 106 finished \tANN training loss 0.001338\n",
      ">> Epoch 107 finished \tANN training loss 0.001336\n",
      ">> Epoch 108 finished \tANN training loss 0.001333\n",
      ">> Epoch 109 finished \tANN training loss 0.001331\n",
      ">> Epoch 110 finished \tANN training loss 0.001329\n",
      ">> Epoch 111 finished \tANN training loss 0.001326\n",
      ">> Epoch 112 finished \tANN training loss 0.001324\n",
      ">> Epoch 113 finished \tANN training loss 0.001322\n",
      ">> Epoch 114 finished \tANN training loss 0.001320\n",
      ">> Epoch 115 finished \tANN training loss 0.001317\n",
      ">> Epoch 116 finished \tANN training loss 0.001315\n",
      ">> Epoch 117 finished \tANN training loss 0.001313\n",
      ">> Epoch 118 finished \tANN training loss 0.001311\n",
      ">> Epoch 119 finished \tANN training loss 0.001309\n",
      ">> Epoch 120 finished \tANN training loss 0.001308\n",
      ">> Epoch 121 finished \tANN training loss 0.001306\n",
      ">> Epoch 122 finished \tANN training loss 0.001304\n",
      ">> Epoch 123 finished \tANN training loss 0.001302\n",
      ">> Epoch 124 finished \tANN training loss 0.001300\n",
      ">> Epoch 125 finished \tANN training loss 0.001299\n",
      ">> Epoch 126 finished \tANN training loss 0.001297\n",
      ">> Epoch 127 finished \tANN training loss 0.001295\n",
      ">> Epoch 128 finished \tANN training loss 0.001294\n",
      ">> Epoch 129 finished \tANN training loss 0.001292\n",
      ">> Epoch 130 finished \tANN training loss 0.001290\n",
      ">> Epoch 131 finished \tANN training loss 0.001289\n",
      ">> Epoch 132 finished \tANN training loss 0.001287\n",
      ">> Epoch 133 finished \tANN training loss 0.001286\n",
      ">> Epoch 134 finished \tANN training loss 0.001284\n",
      ">> Epoch 135 finished \tANN training loss 0.001283\n",
      ">> Epoch 136 finished \tANN training loss 0.001282\n",
      ">> Epoch 137 finished \tANN training loss 0.001280\n",
      ">> Epoch 138 finished \tANN training loss 0.001279\n",
      ">> Epoch 139 finished \tANN training loss 0.001277\n",
      ">> Epoch 140 finished \tANN training loss 0.001276\n",
      ">> Epoch 141 finished \tANN training loss 0.001275\n",
      ">> Epoch 142 finished \tANN training loss 0.001274\n",
      ">> Epoch 143 finished \tANN training loss 0.001272\n",
      ">> Epoch 144 finished \tANN training loss 0.001271\n",
      ">> Epoch 145 finished \tANN training loss 0.001270\n",
      ">> Epoch 146 finished \tANN training loss 0.001269\n",
      ">> Epoch 147 finished \tANN training loss 0.001267\n",
      ">> Epoch 148 finished \tANN training loss 0.001266\n",
      ">> Epoch 149 finished \tANN training loss 0.001265\n",
      ">> Epoch 150 finished \tANN training loss 0.001264\n",
      "[END] Fine tuning step\n",
      "############### End Training for ACCEQ #####################\n",
      "############### End Training for PNBEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 12.484654\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 12.106984\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 11.675178\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 11.172723\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 10.580355\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 9.876774\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 9.041493\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 8.059638\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 6.931108\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 5.683751\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 4.388077\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 3.146474\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 2.070587\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 1.257547\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 0.720640\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 0.417319\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 0.277450\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 0.223130\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 0.210563\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 0.213593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 21 finished \tRBM Reconstruction error 0.221240\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 0.227085\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 0.231398\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 0.232437\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 0.238330\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 0.238691\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 0.240715\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 0.236934\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 0.238880\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 0.238401\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 0.235985\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 0.237620\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.232866\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.231693\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.232883\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.233286\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.232589\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.232138\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.233397\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.230924\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.229182\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.228031\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.227808\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.228046\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.230229\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.229208\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.230995\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.229656\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.225474\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.224399\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.226218\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.225278\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.226051\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.223505\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.223642\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.221480\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.219095\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.219869\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.220074\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.222591\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.222181\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.220387\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.223942\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.224763\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.223715\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.221661\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.218855\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.219974\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.220756\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.220918\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.220790\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.219248\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.218996\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.217947\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.217233\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.215901\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.219405\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.216779\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.217558\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.216025\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.216202\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.213689\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.213639\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.213880\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.214066\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.215651\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.214118\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.215993\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.210010\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.214728\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.213195\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.214903\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.214647\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.214890\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.212873\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.214443\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.217012\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.217487\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.218381\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.212352\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.116679\n",
      ">> Epoch 2 finished \tANN training loss 0.073412\n",
      ">> Epoch 3 finished \tANN training loss 0.046548\n",
      ">> Epoch 4 finished \tANN training loss 0.029876\n",
      ">> Epoch 5 finished \tANN training loss 0.019529\n",
      ">> Epoch 6 finished \tANN training loss 0.013113\n",
      ">> Epoch 7 finished \tANN training loss 0.009138\n",
      ">> Epoch 8 finished \tANN training loss 0.006675\n",
      ">> Epoch 9 finished \tANN training loss 0.005149\n",
      ">> Epoch 10 finished \tANN training loss 0.004205\n",
      ">> Epoch 11 finished \tANN training loss 0.003622\n",
      ">> Epoch 12 finished \tANN training loss 0.003261\n",
      ">> Epoch 13 finished \tANN training loss 0.003037\n",
      ">> Epoch 14 finished \tANN training loss 0.002897\n",
      ">> Epoch 15 finished \tANN training loss 0.002810\n",
      ">> Epoch 16 finished \tANN training loss 0.002755\n",
      ">> Epoch 17 finished \tANN training loss 0.002721\n",
      ">> Epoch 18 finished \tANN training loss 0.002699\n",
      ">> Epoch 19 finished \tANN training loss 0.002685\n",
      ">> Epoch 20 finished \tANN training loss 0.002676\n",
      ">> Epoch 21 finished \tANN training loss 0.002670\n",
      ">> Epoch 22 finished \tANN training loss 0.002665\n",
      ">> Epoch 23 finished \tANN training loss 0.002662\n",
      ">> Epoch 24 finished \tANN training loss 0.002659\n",
      ">> Epoch 25 finished \tANN training loss 0.002657\n",
      ">> Epoch 26 finished \tANN training loss 0.002655\n",
      ">> Epoch 27 finished \tANN training loss 0.002653\n",
      ">> Epoch 28 finished \tANN training loss 0.002651\n",
      ">> Epoch 29 finished \tANN training loss 0.002649\n",
      ">> Epoch 30 finished \tANN training loss 0.002648\n",
      ">> Epoch 31 finished \tANN training loss 0.002646\n",
      ">> Epoch 32 finished \tANN training loss 0.002644\n",
      ">> Epoch 33 finished \tANN training loss 0.002643\n",
      ">> Epoch 34 finished \tANN training loss 0.002641\n",
      ">> Epoch 35 finished \tANN training loss 0.002640\n",
      ">> Epoch 36 finished \tANN training loss 0.002638\n",
      ">> Epoch 37 finished \tANN training loss 0.002636\n",
      ">> Epoch 38 finished \tANN training loss 0.002635\n",
      ">> Epoch 39 finished \tANN training loss 0.002633\n",
      ">> Epoch 40 finished \tANN training loss 0.002632\n",
      ">> Epoch 41 finished \tANN training loss 0.002630\n",
      ">> Epoch 42 finished \tANN training loss 0.002629\n",
      ">> Epoch 43 finished \tANN training loss 0.002627\n",
      ">> Epoch 44 finished \tANN training loss 0.002625\n",
      ">> Epoch 45 finished \tANN training loss 0.002624\n",
      ">> Epoch 46 finished \tANN training loss 0.002622\n",
      ">> Epoch 47 finished \tANN training loss 0.002621\n",
      ">> Epoch 48 finished \tANN training loss 0.002619\n",
      ">> Epoch 49 finished \tANN training loss 0.002618\n",
      ">> Epoch 50 finished \tANN training loss 0.002616\n",
      ">> Epoch 51 finished \tANN training loss 0.002614\n",
      ">> Epoch 52 finished \tANN training loss 0.002613\n",
      ">> Epoch 53 finished \tANN training loss 0.002611\n",
      ">> Epoch 54 finished \tANN training loss 0.002610\n",
      ">> Epoch 55 finished \tANN training loss 0.002608\n",
      ">> Epoch 56 finished \tANN training loss 0.002607\n",
      ">> Epoch 57 finished \tANN training loss 0.002605\n",
      ">> Epoch 58 finished \tANN training loss 0.002604\n",
      ">> Epoch 59 finished \tANN training loss 0.002602\n",
      ">> Epoch 60 finished \tANN training loss 0.002601\n",
      ">> Epoch 61 finished \tANN training loss 0.002599\n",
      ">> Epoch 62 finished \tANN training loss 0.002598\n",
      ">> Epoch 63 finished \tANN training loss 0.002596\n",
      ">> Epoch 64 finished \tANN training loss 0.002595\n",
      ">> Epoch 65 finished \tANN training loss 0.002593\n",
      ">> Epoch 66 finished \tANN training loss 0.002592\n",
      ">> Epoch 67 finished \tANN training loss 0.002590\n",
      ">> Epoch 68 finished \tANN training loss 0.002589\n",
      ">> Epoch 69 finished \tANN training loss 0.002587\n",
      ">> Epoch 70 finished \tANN training loss 0.002586\n",
      ">> Epoch 71 finished \tANN training loss 0.002584\n",
      ">> Epoch 72 finished \tANN training loss 0.002583\n",
      ">> Epoch 73 finished \tANN training loss 0.002581\n",
      ">> Epoch 74 finished \tANN training loss 0.002580\n",
      ">> Epoch 75 finished \tANN training loss 0.002579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 76 finished \tANN training loss 0.002577\n",
      ">> Epoch 77 finished \tANN training loss 0.002576\n",
      ">> Epoch 78 finished \tANN training loss 0.002574\n",
      ">> Epoch 79 finished \tANN training loss 0.002573\n",
      ">> Epoch 80 finished \tANN training loss 0.002572\n",
      ">> Epoch 81 finished \tANN training loss 0.002570\n",
      ">> Epoch 82 finished \tANN training loss 0.002569\n",
      ">> Epoch 83 finished \tANN training loss 0.002567\n",
      ">> Epoch 84 finished \tANN training loss 0.002566\n",
      ">> Epoch 85 finished \tANN training loss 0.002565\n",
      ">> Epoch 86 finished \tANN training loss 0.002563\n",
      ">> Epoch 87 finished \tANN training loss 0.002562\n",
      ">> Epoch 88 finished \tANN training loss 0.002560\n",
      ">> Epoch 89 finished \tANN training loss 0.002559\n",
      ">> Epoch 90 finished \tANN training loss 0.002558\n",
      ">> Epoch 91 finished \tANN training loss 0.002556\n",
      ">> Epoch 92 finished \tANN training loss 0.002555\n",
      ">> Epoch 93 finished \tANN training loss 0.002553\n",
      ">> Epoch 94 finished \tANN training loss 0.002552\n",
      ">> Epoch 95 finished \tANN training loss 0.002551\n",
      ">> Epoch 96 finished \tANN training loss 0.002549\n",
      ">> Epoch 97 finished \tANN training loss 0.002548\n",
      ">> Epoch 98 finished \tANN training loss 0.002546\n",
      ">> Epoch 99 finished \tANN training loss 0.002545\n",
      ">> Epoch 100 finished \tANN training loss 0.002544\n",
      ">> Epoch 101 finished \tANN training loss 0.002542\n",
      ">> Epoch 102 finished \tANN training loss 0.002541\n",
      ">> Epoch 103 finished \tANN training loss 0.002540\n",
      ">> Epoch 104 finished \tANN training loss 0.002538\n",
      ">> Epoch 105 finished \tANN training loss 0.002537\n",
      ">> Epoch 106 finished \tANN training loss 0.002535\n",
      ">> Epoch 107 finished \tANN training loss 0.002534\n",
      ">> Epoch 108 finished \tANN training loss 0.002533\n",
      ">> Epoch 109 finished \tANN training loss 0.002531\n",
      ">> Epoch 110 finished \tANN training loss 0.002530\n",
      ">> Epoch 111 finished \tANN training loss 0.002529\n",
      ">> Epoch 112 finished \tANN training loss 0.002527\n",
      ">> Epoch 113 finished \tANN training loss 0.002526\n",
      ">> Epoch 114 finished \tANN training loss 0.002524\n",
      ">> Epoch 115 finished \tANN training loss 0.002523\n",
      ">> Epoch 116 finished \tANN training loss 0.002522\n",
      ">> Epoch 117 finished \tANN training loss 0.002520\n",
      ">> Epoch 118 finished \tANN training loss 0.002519\n",
      ">> Epoch 119 finished \tANN training loss 0.002518\n",
      ">> Epoch 120 finished \tANN training loss 0.002516\n",
      ">> Epoch 121 finished \tANN training loss 0.002515\n",
      ">> Epoch 122 finished \tANN training loss 0.002514\n",
      ">> Epoch 123 finished \tANN training loss 0.002512\n",
      ">> Epoch 124 finished \tANN training loss 0.002511\n",
      ">> Epoch 125 finished \tANN training loss 0.002510\n",
      ">> Epoch 126 finished \tANN training loss 0.002508\n",
      ">> Epoch 127 finished \tANN training loss 0.002507\n",
      ">> Epoch 128 finished \tANN training loss 0.002506\n",
      ">> Epoch 129 finished \tANN training loss 0.002504\n",
      ">> Epoch 130 finished \tANN training loss 0.002503\n",
      ">> Epoch 131 finished \tANN training loss 0.002502\n",
      ">> Epoch 132 finished \tANN training loss 0.002500\n",
      ">> Epoch 133 finished \tANN training loss 0.002499\n",
      ">> Epoch 134 finished \tANN training loss 0.002498\n",
      ">> Epoch 135 finished \tANN training loss 0.002497\n",
      ">> Epoch 136 finished \tANN training loss 0.002495\n",
      ">> Epoch 137 finished \tANN training loss 0.002494\n",
      ">> Epoch 138 finished \tANN training loss 0.002493\n",
      ">> Epoch 139 finished \tANN training loss 0.002491\n",
      ">> Epoch 140 finished \tANN training loss 0.002490\n",
      ">> Epoch 141 finished \tANN training loss 0.002489\n",
      ">> Epoch 142 finished \tANN training loss 0.002488\n",
      ">> Epoch 143 finished \tANN training loss 0.002486\n",
      ">> Epoch 144 finished \tANN training loss 0.002485\n",
      ">> Epoch 145 finished \tANN training loss 0.002484\n",
      ">> Epoch 146 finished \tANN training loss 0.002483\n",
      ">> Epoch 147 finished \tANN training loss 0.002482\n",
      ">> Epoch 148 finished \tANN training loss 0.002480\n",
      ">> Epoch 149 finished \tANN training loss 0.002479\n",
      ">> Epoch 150 finished \tANN training loss 0.002478\n",
      "[END] Fine tuning step\n",
      "############### End Training for PNBEQ #####################\n",
      "############### End Training for NIITTECHEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 25.253062\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 25.240897\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 25.228693\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 25.216454\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 25.204170\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 25.191864\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 25.179484\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 25.167060\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 25.154595\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 25.142079\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 25.129516\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 25.116916\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 25.104297\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 25.091620\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 25.078865\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 25.066073\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 25.053241\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 25.040354\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 25.027417\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 25.014449\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 25.001419\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 24.988356\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 24.975226\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 24.962066\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 24.948867\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 24.935598\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 24.922277\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 24.908918\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 24.895500\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 24.882055\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 24.868563\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 24.855010\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 24.841418\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 24.827761\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 24.814059\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 24.800303\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 24.786484\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 24.772619\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 24.758696\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 24.744700\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 24.730681\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 24.716588\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 24.702449\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 24.688221\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 24.673968\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 24.659659\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 24.645296\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 24.630898\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 24.616460\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 24.601947\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 24.587365\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 24.572725\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 24.558047\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 24.543295\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 24.528489\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 24.513613\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 24.498697\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 24.483717\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 24.468647\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 24.453516\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 24.438357\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 24.423146\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 24.407866\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 24.392538\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 24.377143\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 24.361679\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 24.346132\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 24.330567\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 24.314897\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 24.299179\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 24.283381\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 24.267548\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 24.251613\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 24.235624\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 24.219559\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 24.203455\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 24.187243\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 24.170964\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 24.154631\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 24.138220\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 24.121776\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 24.105212\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 24.088588\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 24.071911\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 24.055145\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 24.038362\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 24.021434\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 24.004466\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 23.987430\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 23.970327\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 23.953143\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 23.935835\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 23.918485\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 23.901075\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 23.883603\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 23.865996\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 23.848341\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 23.830632\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 23.812845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 100 finished \tRBM Reconstruction error 23.794945\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.772169\n",
      ">> Epoch 2 finished \tANN training loss 0.769047\n",
      ">> Epoch 3 finished \tANN training loss 0.765969\n",
      ">> Epoch 4 finished \tANN training loss 0.762896\n",
      ">> Epoch 5 finished \tANN training loss 0.759826\n",
      ">> Epoch 6 finished \tANN training loss 0.756788\n",
      ">> Epoch 7 finished \tANN training loss 0.753733\n",
      ">> Epoch 8 finished \tANN training loss 0.750704\n",
      ">> Epoch 9 finished \tANN training loss 0.747665\n",
      ">> Epoch 10 finished \tANN training loss 0.744695\n",
      ">> Epoch 11 finished \tANN training loss 0.741692\n",
      ">> Epoch 12 finished \tANN training loss 0.738699\n",
      ">> Epoch 13 finished \tANN training loss 0.735749\n",
      ">> Epoch 14 finished \tANN training loss 0.732781\n",
      ">> Epoch 15 finished \tANN training loss 0.729875\n",
      ">> Epoch 16 finished \tANN training loss 0.726936\n",
      ">> Epoch 17 finished \tANN training loss 0.724018\n",
      ">> Epoch 18 finished \tANN training loss 0.721094\n",
      ">> Epoch 19 finished \tANN training loss 0.718186\n",
      ">> Epoch 20 finished \tANN training loss 0.715319\n",
      ">> Epoch 21 finished \tANN training loss 0.712446\n",
      ">> Epoch 22 finished \tANN training loss 0.709582\n",
      ">> Epoch 23 finished \tANN training loss 0.706715\n",
      ">> Epoch 24 finished \tANN training loss 0.703877\n",
      ">> Epoch 25 finished \tANN training loss 0.701067\n",
      ">> Epoch 26 finished \tANN training loss 0.698285\n",
      ">> Epoch 27 finished \tANN training loss 0.695472\n",
      ">> Epoch 28 finished \tANN training loss 0.692698\n",
      ">> Epoch 29 finished \tANN training loss 0.689932\n",
      ">> Epoch 30 finished \tANN training loss 0.687163\n",
      ">> Epoch 31 finished \tANN training loss 0.684389\n",
      ">> Epoch 32 finished \tANN training loss 0.681653\n",
      ">> Epoch 33 finished \tANN training loss 0.678928\n",
      ">> Epoch 34 finished \tANN training loss 0.676199\n",
      ">> Epoch 35 finished \tANN training loss 0.673498\n",
      ">> Epoch 36 finished \tANN training loss 0.670812\n",
      ">> Epoch 37 finished \tANN training loss 0.668101\n",
      ">> Epoch 38 finished \tANN training loss 0.665423\n",
      ">> Epoch 39 finished \tANN training loss 0.662746\n",
      ">> Epoch 40 finished \tANN training loss 0.660093\n",
      ">> Epoch 41 finished \tANN training loss 0.657446\n",
      ">> Epoch 42 finished \tANN training loss 0.654817\n",
      ">> Epoch 43 finished \tANN training loss 0.652190\n",
      ">> Epoch 44 finished \tANN training loss 0.649562\n",
      ">> Epoch 45 finished \tANN training loss 0.646971\n",
      ">> Epoch 46 finished \tANN training loss 0.644362\n",
      ">> Epoch 47 finished \tANN training loss 0.641788\n",
      ">> Epoch 48 finished \tANN training loss 0.639237\n",
      ">> Epoch 49 finished \tANN training loss 0.636684\n",
      ">> Epoch 50 finished \tANN training loss 0.634119\n",
      ">> Epoch 51 finished \tANN training loss 0.631580\n",
      ">> Epoch 52 finished \tANN training loss 0.629060\n",
      ">> Epoch 53 finished \tANN training loss 0.626544\n",
      ">> Epoch 54 finished \tANN training loss 0.624037\n",
      ">> Epoch 55 finished \tANN training loss 0.621548\n",
      ">> Epoch 56 finished \tANN training loss 0.619068\n",
      ">> Epoch 57 finished \tANN training loss 0.616589\n",
      ">> Epoch 58 finished \tANN training loss 0.614116\n",
      ">> Epoch 59 finished \tANN training loss 0.611652\n",
      ">> Epoch 60 finished \tANN training loss 0.609222\n",
      ">> Epoch 61 finished \tANN training loss 0.606777\n",
      ">> Epoch 62 finished \tANN training loss 0.604351\n",
      ">> Epoch 63 finished \tANN training loss 0.601923\n",
      ">> Epoch 64 finished \tANN training loss 0.599512\n",
      ">> Epoch 65 finished \tANN training loss 0.597124\n",
      ">> Epoch 66 finished \tANN training loss 0.594751\n",
      ">> Epoch 67 finished \tANN training loss 0.592382\n",
      ">> Epoch 68 finished \tANN training loss 0.590029\n",
      ">> Epoch 69 finished \tANN training loss 0.587673\n",
      ">> Epoch 70 finished \tANN training loss 0.585335\n",
      ">> Epoch 71 finished \tANN training loss 0.582998\n",
      ">> Epoch 72 finished \tANN training loss 0.580686\n",
      ">> Epoch 73 finished \tANN training loss 0.578369\n",
      ">> Epoch 74 finished \tANN training loss 0.576072\n",
      ">> Epoch 75 finished \tANN training loss 0.573773\n",
      ">> Epoch 76 finished \tANN training loss 0.571491\n",
      ">> Epoch 77 finished \tANN training loss 0.569220\n",
      ">> Epoch 78 finished \tANN training loss 0.566924\n",
      ">> Epoch 79 finished \tANN training loss 0.564654\n",
      ">> Epoch 80 finished \tANN training loss 0.562377\n",
      ">> Epoch 81 finished \tANN training loss 0.560118\n",
      ">> Epoch 82 finished \tANN training loss 0.557863\n",
      ">> Epoch 83 finished \tANN training loss 0.555616\n",
      ">> Epoch 84 finished \tANN training loss 0.553374\n",
      ">> Epoch 85 finished \tANN training loss 0.551148\n",
      ">> Epoch 86 finished \tANN training loss 0.548939\n",
      ">> Epoch 87 finished \tANN training loss 0.546719\n",
      ">> Epoch 88 finished \tANN training loss 0.544523\n",
      ">> Epoch 89 finished \tANN training loss 0.542325\n",
      ">> Epoch 90 finished \tANN training loss 0.540126\n",
      ">> Epoch 91 finished \tANN training loss 0.537954\n",
      ">> Epoch 92 finished \tANN training loss 0.535787\n",
      ">> Epoch 93 finished \tANN training loss 0.533641\n",
      ">> Epoch 94 finished \tANN training loss 0.531490\n",
      ">> Epoch 95 finished \tANN training loss 0.529363\n",
      ">> Epoch 96 finished \tANN training loss 0.527240\n",
      ">> Epoch 97 finished \tANN training loss 0.525108\n",
      ">> Epoch 98 finished \tANN training loss 0.522997\n",
      ">> Epoch 99 finished \tANN training loss 0.520892\n",
      ">> Epoch 100 finished \tANN training loss 0.518790\n",
      ">> Epoch 101 finished \tANN training loss 0.516707\n",
      ">> Epoch 102 finished \tANN training loss 0.514603\n",
      ">> Epoch 103 finished \tANN training loss 0.512521\n",
      ">> Epoch 104 finished \tANN training loss 0.510412\n",
      ">> Epoch 105 finished \tANN training loss 0.508320\n",
      ">> Epoch 106 finished \tANN training loss 0.506235\n",
      ">> Epoch 107 finished \tANN training loss 0.504165\n",
      ">> Epoch 108 finished \tANN training loss 0.502106\n",
      ">> Epoch 109 finished \tANN training loss 0.500048\n",
      ">> Epoch 110 finished \tANN training loss 0.498022\n",
      ">> Epoch 111 finished \tANN training loss 0.495965\n",
      ">> Epoch 112 finished \tANN training loss 0.493955\n",
      ">> Epoch 113 finished \tANN training loss 0.491935\n",
      ">> Epoch 114 finished \tANN training loss 0.489936\n",
      ">> Epoch 115 finished \tANN training loss 0.487944\n",
      ">> Epoch 116 finished \tANN training loss 0.485965\n",
      ">> Epoch 117 finished \tANN training loss 0.483997\n",
      ">> Epoch 118 finished \tANN training loss 0.482024\n",
      ">> Epoch 119 finished \tANN training loss 0.480071\n",
      ">> Epoch 120 finished \tANN training loss 0.478126\n",
      ">> Epoch 121 finished \tANN training loss 0.476212\n",
      ">> Epoch 122 finished \tANN training loss 0.474287\n",
      ">> Epoch 123 finished \tANN training loss 0.472377\n",
      ">> Epoch 124 finished \tANN training loss 0.470482\n",
      ">> Epoch 125 finished \tANN training loss 0.468586\n",
      ">> Epoch 126 finished \tANN training loss 0.466702\n",
      ">> Epoch 127 finished \tANN training loss 0.464829\n",
      ">> Epoch 128 finished \tANN training loss 0.462973\n",
      ">> Epoch 129 finished \tANN training loss 0.461102\n",
      ">> Epoch 130 finished \tANN training loss 0.459251\n",
      ">> Epoch 131 finished \tANN training loss 0.457403\n",
      ">> Epoch 132 finished \tANN training loss 0.455546\n",
      ">> Epoch 133 finished \tANN training loss 0.453732\n",
      ">> Epoch 134 finished \tANN training loss 0.451889\n",
      ">> Epoch 135 finished \tANN training loss 0.450079\n",
      ">> Epoch 136 finished \tANN training loss 0.448270\n",
      ">> Epoch 137 finished \tANN training loss 0.446474\n",
      ">> Epoch 138 finished \tANN training loss 0.444667\n",
      ">> Epoch 139 finished \tANN training loss 0.442895\n",
      ">> Epoch 140 finished \tANN training loss 0.441120\n",
      ">> Epoch 141 finished \tANN training loss 0.439358\n",
      ">> Epoch 142 finished \tANN training loss 0.437600\n",
      ">> Epoch 143 finished \tANN training loss 0.435844\n",
      ">> Epoch 144 finished \tANN training loss 0.434100\n",
      ">> Epoch 145 finished \tANN training loss 0.432366\n",
      ">> Epoch 146 finished \tANN training loss 0.430642\n",
      ">> Epoch 147 finished \tANN training loss 0.428911\n",
      ">> Epoch 148 finished \tANN training loss 0.427207\n",
      ">> Epoch 149 finished \tANN training loss 0.425493\n",
      ">> Epoch 150 finished \tANN training loss 0.423806\n",
      "[END] Fine tuning step\n",
      "############### End Training for NIITTECHEQ #####################\n",
      "############### End Training for SBINEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 6.644494\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 6.490027\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 6.323370\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 6.141620\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 5.941110\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 5.718056\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 5.468463\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 5.187787\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 4.872163\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 4.518239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 11 finished \tRBM Reconstruction error 4.125709\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 3.696889\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 3.237282\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 2.760467\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 2.282505\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 1.828524\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 1.419958\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 1.073639\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 0.803888\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 0.602927\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 0.463828\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 0.372451\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 0.315311\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 0.279486\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 0.258242\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 0.245036\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 0.236366\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 0.229877\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 0.224811\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 0.220329\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 0.216563\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 0.213132\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.209198\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.205931\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.202476\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.199382\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.195855\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.192879\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.189783\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.186195\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.183123\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.180585\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.177937\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.175602\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.173018\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.170563\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.167804\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.164564\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.162299\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.159702\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.157746\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.156106\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.154020\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.152059\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.149697\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.148126\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.146437\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.144619\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.143061\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.140794\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.138969\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.136931\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.134838\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.132646\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.131154\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.128990\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.128152\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.126283\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.125538\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.123782\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.121314\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.120205\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.119398\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.118025\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.117198\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.116291\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.115136\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.113752\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.112135\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.110875\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.110126\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.109114\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.108385\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.106695\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.105803\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.105327\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.103606\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.103262\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.102241\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.101397\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.100625\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.099908\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.099340\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.097785\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.097945\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.097696\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.097499\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.095991\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.095514\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.095456\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.272454\n",
      ">> Epoch 2 finished \tANN training loss 0.186871\n",
      ">> Epoch 3 finished \tANN training loss 0.129236\n",
      ">> Epoch 4 finished \tANN training loss 0.090445\n",
      ">> Epoch 5 finished \tANN training loss 0.064191\n",
      ">> Epoch 6 finished \tANN training loss 0.046355\n",
      ">> Epoch 7 finished \tANN training loss 0.034216\n",
      ">> Epoch 8 finished \tANN training loss 0.025938\n",
      ">> Epoch 9 finished \tANN training loss 0.020275\n",
      ">> Epoch 10 finished \tANN training loss 0.016381\n",
      ">> Epoch 11 finished \tANN training loss 0.013691\n",
      ">> Epoch 12 finished \tANN training loss 0.011811\n",
      ">> Epoch 13 finished \tANN training loss 0.010484\n",
      ">> Epoch 14 finished \tANN training loss 0.009532\n",
      ">> Epoch 15 finished \tANN training loss 0.008835\n",
      ">> Epoch 16 finished \tANN training loss 0.008313\n",
      ">> Epoch 17 finished \tANN training loss 0.007911\n",
      ">> Epoch 18 finished \tANN training loss 0.007591\n",
      ">> Epoch 19 finished \tANN training loss 0.007328\n",
      ">> Epoch 20 finished \tANN training loss 0.007105\n",
      ">> Epoch 21 finished \tANN training loss 0.006911\n",
      ">> Epoch 22 finished \tANN training loss 0.006736\n",
      ">> Epoch 23 finished \tANN training loss 0.006576\n",
      ">> Epoch 24 finished \tANN training loss 0.006428\n",
      ">> Epoch 25 finished \tANN training loss 0.006288\n",
      ">> Epoch 26 finished \tANN training loss 0.006155\n",
      ">> Epoch 27 finished \tANN training loss 0.006028\n",
      ">> Epoch 28 finished \tANN training loss 0.005906\n",
      ">> Epoch 29 finished \tANN training loss 0.005789\n",
      ">> Epoch 30 finished \tANN training loss 0.005675\n",
      ">> Epoch 31 finished \tANN training loss 0.005564\n",
      ">> Epoch 32 finished \tANN training loss 0.005457\n",
      ">> Epoch 33 finished \tANN training loss 0.005354\n",
      ">> Epoch 34 finished \tANN training loss 0.005253\n",
      ">> Epoch 35 finished \tANN training loss 0.005155\n",
      ">> Epoch 36 finished \tANN training loss 0.005059\n",
      ">> Epoch 37 finished \tANN training loss 0.004967\n",
      ">> Epoch 38 finished \tANN training loss 0.004877\n",
      ">> Epoch 39 finished \tANN training loss 0.004789\n",
      ">> Epoch 40 finished \tANN training loss 0.004704\n",
      ">> Epoch 41 finished \tANN training loss 0.004621\n",
      ">> Epoch 42 finished \tANN training loss 0.004540\n",
      ">> Epoch 43 finished \tANN training loss 0.004462\n",
      ">> Epoch 44 finished \tANN training loss 0.004386\n",
      ">> Epoch 45 finished \tANN training loss 0.004312\n",
      ">> Epoch 46 finished \tANN training loss 0.004239\n",
      ">> Epoch 47 finished \tANN training loss 0.004169\n",
      ">> Epoch 48 finished \tANN training loss 0.004101\n",
      ">> Epoch 49 finished \tANN training loss 0.004034\n",
      ">> Epoch 50 finished \tANN training loss 0.003970\n",
      ">> Epoch 51 finished \tANN training loss 0.003907\n",
      ">> Epoch 52 finished \tANN training loss 0.003846\n",
      ">> Epoch 53 finished \tANN training loss 0.003786\n",
      ">> Epoch 54 finished \tANN training loss 0.003728\n",
      ">> Epoch 55 finished \tANN training loss 0.003672\n",
      ">> Epoch 56 finished \tANN training loss 0.003617\n",
      ">> Epoch 57 finished \tANN training loss 0.003563\n",
      ">> Epoch 58 finished \tANN training loss 0.003512\n",
      ">> Epoch 59 finished \tANN training loss 0.003461\n",
      ">> Epoch 60 finished \tANN training loss 0.003412\n",
      ">> Epoch 61 finished \tANN training loss 0.003364\n",
      ">> Epoch 62 finished \tANN training loss 0.003317\n",
      ">> Epoch 63 finished \tANN training loss 0.003272\n",
      ">> Epoch 64 finished \tANN training loss 0.003228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 65 finished \tANN training loss 0.003185\n",
      ">> Epoch 66 finished \tANN training loss 0.003143\n",
      ">> Epoch 67 finished \tANN training loss 0.003102\n",
      ">> Epoch 68 finished \tANN training loss 0.003063\n",
      ">> Epoch 69 finished \tANN training loss 0.003024\n",
      ">> Epoch 70 finished \tANN training loss 0.002987\n",
      ">> Epoch 71 finished \tANN training loss 0.002950\n",
      ">> Epoch 72 finished \tANN training loss 0.002914\n",
      ">> Epoch 73 finished \tANN training loss 0.002880\n",
      ">> Epoch 74 finished \tANN training loss 0.002846\n",
      ">> Epoch 75 finished \tANN training loss 0.002813\n",
      ">> Epoch 76 finished \tANN training loss 0.002781\n",
      ">> Epoch 77 finished \tANN training loss 0.002750\n",
      ">> Epoch 78 finished \tANN training loss 0.002720\n",
      ">> Epoch 79 finished \tANN training loss 0.002690\n",
      ">> Epoch 80 finished \tANN training loss 0.002662\n",
      ">> Epoch 81 finished \tANN training loss 0.002634\n",
      ">> Epoch 82 finished \tANN training loss 0.002607\n",
      ">> Epoch 83 finished \tANN training loss 0.002580\n",
      ">> Epoch 84 finished \tANN training loss 0.002554\n",
      ">> Epoch 85 finished \tANN training loss 0.002529\n",
      ">> Epoch 86 finished \tANN training loss 0.002505\n",
      ">> Epoch 87 finished \tANN training loss 0.002481\n",
      ">> Epoch 88 finished \tANN training loss 0.002458\n",
      ">> Epoch 89 finished \tANN training loss 0.002435\n",
      ">> Epoch 90 finished \tANN training loss 0.002413\n",
      ">> Epoch 91 finished \tANN training loss 0.002392\n",
      ">> Epoch 92 finished \tANN training loss 0.002371\n",
      ">> Epoch 93 finished \tANN training loss 0.002351\n",
      ">> Epoch 94 finished \tANN training loss 0.002331\n",
      ">> Epoch 95 finished \tANN training loss 0.002312\n",
      ">> Epoch 96 finished \tANN training loss 0.002293\n",
      ">> Epoch 97 finished \tANN training loss 0.002275\n",
      ">> Epoch 98 finished \tANN training loss 0.002257\n",
      ">> Epoch 99 finished \tANN training loss 0.002240\n",
      ">> Epoch 100 finished \tANN training loss 0.002223\n",
      ">> Epoch 101 finished \tANN training loss 0.002206\n",
      ">> Epoch 102 finished \tANN training loss 0.002190\n",
      ">> Epoch 103 finished \tANN training loss 0.002175\n",
      ">> Epoch 104 finished \tANN training loss 0.002159\n",
      ">> Epoch 105 finished \tANN training loss 0.002145\n",
      ">> Epoch 106 finished \tANN training loss 0.002130\n",
      ">> Epoch 107 finished \tANN training loss 0.002116\n",
      ">> Epoch 108 finished \tANN training loss 0.002102\n",
      ">> Epoch 109 finished \tANN training loss 0.002089\n",
      ">> Epoch 110 finished \tANN training loss 0.002076\n",
      ">> Epoch 111 finished \tANN training loss 0.002063\n",
      ">> Epoch 112 finished \tANN training loss 0.002051\n",
      ">> Epoch 113 finished \tANN training loss 0.002039\n",
      ">> Epoch 114 finished \tANN training loss 0.002027\n",
      ">> Epoch 115 finished \tANN training loss 0.002015\n",
      ">> Epoch 116 finished \tANN training loss 0.002004\n",
      ">> Epoch 117 finished \tANN training loss 0.001993\n",
      ">> Epoch 118 finished \tANN training loss 0.001983\n",
      ">> Epoch 119 finished \tANN training loss 0.001972\n",
      ">> Epoch 120 finished \tANN training loss 0.001962\n",
      ">> Epoch 121 finished \tANN training loss 0.001952\n",
      ">> Epoch 122 finished \tANN training loss 0.001943\n",
      ">> Epoch 123 finished \tANN training loss 0.001933\n",
      ">> Epoch 124 finished \tANN training loss 0.001924\n",
      ">> Epoch 125 finished \tANN training loss 0.001915\n",
      ">> Epoch 126 finished \tANN training loss 0.001907\n",
      ">> Epoch 127 finished \tANN training loss 0.001898\n",
      ">> Epoch 128 finished \tANN training loss 0.001890\n",
      ">> Epoch 129 finished \tANN training loss 0.001882\n",
      ">> Epoch 130 finished \tANN training loss 0.001874\n",
      ">> Epoch 131 finished \tANN training loss 0.001866\n",
      ">> Epoch 132 finished \tANN training loss 0.001858\n",
      ">> Epoch 133 finished \tANN training loss 0.001851\n",
      ">> Epoch 134 finished \tANN training loss 0.001844\n",
      ">> Epoch 135 finished \tANN training loss 0.001837\n",
      ">> Epoch 136 finished \tANN training loss 0.001830\n",
      ">> Epoch 137 finished \tANN training loss 0.001823\n",
      ">> Epoch 138 finished \tANN training loss 0.001817\n",
      ">> Epoch 139 finished \tANN training loss 0.001810\n",
      ">> Epoch 140 finished \tANN training loss 0.001804\n",
      ">> Epoch 141 finished \tANN training loss 0.001798\n",
      ">> Epoch 142 finished \tANN training loss 0.001792\n",
      ">> Epoch 143 finished \tANN training loss 0.001786\n",
      ">> Epoch 144 finished \tANN training loss 0.001780\n",
      ">> Epoch 145 finished \tANN training loss 0.001775\n",
      ">> Epoch 146 finished \tANN training loss 0.001769\n",
      ">> Epoch 147 finished \tANN training loss 0.001764\n",
      ">> Epoch 148 finished \tANN training loss 0.001759\n",
      ">> Epoch 149 finished \tANN training loss 0.001754\n",
      ">> Epoch 150 finished \tANN training loss 0.001749\n",
      "[END] Fine tuning step\n",
      "############### End Training for SBINEQ #####################\n",
      "############### End Training for IBULHSGFINEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 12.055746\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 11.945496\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 11.830883\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 11.711458\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 11.586838\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 11.456544\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 11.320124\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 11.176980\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 11.026682\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 10.868622\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 10.702176\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 10.526670\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 10.341598\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 10.145993\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 9.939492\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 9.721227\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 9.491048\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 9.247807\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 8.990924\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 8.720589\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 8.435549\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 8.136305\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 7.822767\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 7.495213\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 7.153103\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 6.798451\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 6.431887\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 6.053758\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 5.667278\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 5.275015\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 4.878570\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 4.482974\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 4.088676\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 3.702274\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 3.325981\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 2.963169\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 2.616986\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 2.289658\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 1.986465\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 1.709986\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 1.460395\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 1.236004\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 1.039642\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.869542\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.725223\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.603168\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.503723\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.424193\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.362049\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.314581\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.277995\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.251849\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.233720\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.222103\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.215576\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.212722\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.212509\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.214677\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.218808\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.223393\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.228229\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.232746\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.237874\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.241768\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.246541\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.250177\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.254493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 68 finished \tRBM Reconstruction error 0.258362\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.262614\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.266489\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.267174\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.269629\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.271108\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.272832\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.273805\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.274954\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.275501\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.276135\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.276136\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.277388\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.278205\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.278636\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.278936\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.278952\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.280009\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.281035\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.281306\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.281459\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.283761\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.282974\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.281071\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.281210\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.283085\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.281908\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.281476\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.282582\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.282713\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.282654\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.283045\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.282354\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.728867\n",
      ">> Epoch 2 finished \tANN training loss 0.617052\n",
      ">> Epoch 3 finished \tANN training loss 0.522610\n",
      ">> Epoch 4 finished \tANN training loss 0.442727\n",
      ">> Epoch 5 finished \tANN training loss 0.375196\n",
      ">> Epoch 6 finished \tANN training loss 0.318058\n",
      ">> Epoch 7 finished \tANN training loss 0.269685\n",
      ">> Epoch 8 finished \tANN training loss 0.228727\n",
      ">> Epoch 9 finished \tANN training loss 0.194044\n",
      ">> Epoch 10 finished \tANN training loss 0.164670\n",
      ">> Epoch 11 finished \tANN training loss 0.139796\n",
      ">> Epoch 12 finished \tANN training loss 0.118733\n",
      ">> Epoch 13 finished \tANN training loss 0.100885\n",
      ">> Epoch 14 finished \tANN training loss 0.085778\n",
      ">> Epoch 15 finished \tANN training loss 0.072983\n",
      ">> Epoch 16 finished \tANN training loss 0.062148\n",
      ">> Epoch 17 finished \tANN training loss 0.052972\n",
      ">> Epoch 18 finished \tANN training loss 0.045206\n",
      ">> Epoch 19 finished \tANN training loss 0.038629\n",
      ">> Epoch 20 finished \tANN training loss 0.033063\n",
      ">> Epoch 21 finished \tANN training loss 0.028352\n",
      ">> Epoch 22 finished \tANN training loss 0.024366\n",
      ">> Epoch 23 finished \tANN training loss 0.020993\n",
      ">> Epoch 24 finished \tANN training loss 0.018138\n",
      ">> Epoch 25 finished \tANN training loss 0.015722\n",
      ">> Epoch 26 finished \tANN training loss 0.013679\n",
      ">> Epoch 27 finished \tANN training loss 0.011951\n",
      ">> Epoch 28 finished \tANN training loss 0.010489\n",
      ">> Epoch 29 finished \tANN training loss 0.009253\n",
      ">> Epoch 30 finished \tANN training loss 0.008207\n",
      ">> Epoch 31 finished \tANN training loss 0.007323\n",
      ">> Epoch 32 finished \tANN training loss 0.006575\n",
      ">> Epoch 33 finished \tANN training loss 0.005943\n",
      ">> Epoch 34 finished \tANN training loss 0.005408\n",
      ">> Epoch 35 finished \tANN training loss 0.004955\n",
      ">> Epoch 36 finished \tANN training loss 0.004573\n",
      ">> Epoch 37 finished \tANN training loss 0.004250\n",
      ">> Epoch 38 finished \tANN training loss 0.003976\n",
      ">> Epoch 39 finished \tANN training loss 0.003745\n",
      ">> Epoch 40 finished \tANN training loss 0.003550\n",
      ">> Epoch 41 finished \tANN training loss 0.003385\n",
      ">> Epoch 42 finished \tANN training loss 0.003245\n",
      ">> Epoch 43 finished \tANN training loss 0.003126\n",
      ">> Epoch 44 finished \tANN training loss 0.003026\n",
      ">> Epoch 45 finished \tANN training loss 0.002942\n",
      ">> Epoch 46 finished \tANN training loss 0.002870\n",
      ">> Epoch 47 finished \tANN training loss 0.002810\n",
      ">> Epoch 48 finished \tANN training loss 0.002759\n",
      ">> Epoch 49 finished \tANN training loss 0.002715\n",
      ">> Epoch 50 finished \tANN training loss 0.002678\n",
      ">> Epoch 51 finished \tANN training loss 0.002647\n",
      ">> Epoch 52 finished \tANN training loss 0.002621\n",
      ">> Epoch 53 finished \tANN training loss 0.002599\n",
      ">> Epoch 54 finished \tANN training loss 0.002580\n",
      ">> Epoch 55 finished \tANN training loss 0.002563\n",
      ">> Epoch 56 finished \tANN training loss 0.002550\n",
      ">> Epoch 57 finished \tANN training loss 0.002538\n",
      ">> Epoch 58 finished \tANN training loss 0.002528\n",
      ">> Epoch 59 finished \tANN training loss 0.002520\n",
      ">> Epoch 60 finished \tANN training loss 0.002512\n",
      ">> Epoch 61 finished \tANN training loss 0.002506\n",
      ">> Epoch 62 finished \tANN training loss 0.002501\n",
      ">> Epoch 63 finished \tANN training loss 0.002496\n",
      ">> Epoch 64 finished \tANN training loss 0.002493\n",
      ">> Epoch 65 finished \tANN training loss 0.002489\n",
      ">> Epoch 66 finished \tANN training loss 0.002486\n",
      ">> Epoch 67 finished \tANN training loss 0.002484\n",
      ">> Epoch 68 finished \tANN training loss 0.002482\n",
      ">> Epoch 69 finished \tANN training loss 0.002480\n",
      ">> Epoch 70 finished \tANN training loss 0.002478\n",
      ">> Epoch 71 finished \tANN training loss 0.002476\n",
      ">> Epoch 72 finished \tANN training loss 0.002475\n",
      ">> Epoch 73 finished \tANN training loss 0.002474\n",
      ">> Epoch 74 finished \tANN training loss 0.002473\n",
      ">> Epoch 75 finished \tANN training loss 0.002472\n",
      ">> Epoch 76 finished \tANN training loss 0.002471\n",
      ">> Epoch 77 finished \tANN training loss 0.002470\n",
      ">> Epoch 78 finished \tANN training loss 0.002469\n",
      ">> Epoch 79 finished \tANN training loss 0.002469\n",
      ">> Epoch 80 finished \tANN training loss 0.002468\n",
      ">> Epoch 81 finished \tANN training loss 0.002467\n",
      ">> Epoch 82 finished \tANN training loss 0.002467\n",
      ">> Epoch 83 finished \tANN training loss 0.002466\n",
      ">> Epoch 84 finished \tANN training loss 0.002466\n",
      ">> Epoch 85 finished \tANN training loss 0.002465\n",
      ">> Epoch 86 finished \tANN training loss 0.002464\n",
      ">> Epoch 87 finished \tANN training loss 0.002464\n",
      ">> Epoch 88 finished \tANN training loss 0.002463\n",
      ">> Epoch 89 finished \tANN training loss 0.002463\n",
      ">> Epoch 90 finished \tANN training loss 0.002462\n",
      ">> Epoch 91 finished \tANN training loss 0.002462\n",
      ">> Epoch 92 finished \tANN training loss 0.002461\n",
      ">> Epoch 93 finished \tANN training loss 0.002461\n",
      ">> Epoch 94 finished \tANN training loss 0.002460\n",
      ">> Epoch 95 finished \tANN training loss 0.002460\n",
      ">> Epoch 96 finished \tANN training loss 0.002460\n",
      ">> Epoch 97 finished \tANN training loss 0.002459\n",
      ">> Epoch 98 finished \tANN training loss 0.002459\n",
      ">> Epoch 99 finished \tANN training loss 0.002458\n",
      ">> Epoch 100 finished \tANN training loss 0.002458\n",
      ">> Epoch 101 finished \tANN training loss 0.002457\n",
      ">> Epoch 102 finished \tANN training loss 0.002457\n",
      ">> Epoch 103 finished \tANN training loss 0.002456\n",
      ">> Epoch 104 finished \tANN training loss 0.002456\n",
      ">> Epoch 105 finished \tANN training loss 0.002456\n",
      ">> Epoch 106 finished \tANN training loss 0.002455\n",
      ">> Epoch 107 finished \tANN training loss 0.002455\n",
      ">> Epoch 108 finished \tANN training loss 0.002454\n",
      ">> Epoch 109 finished \tANN training loss 0.002454\n",
      ">> Epoch 110 finished \tANN training loss 0.002453\n",
      ">> Epoch 111 finished \tANN training loss 0.002453\n",
      ">> Epoch 112 finished \tANN training loss 0.002452\n",
      ">> Epoch 113 finished \tANN training loss 0.002452\n",
      ">> Epoch 114 finished \tANN training loss 0.002452\n",
      ">> Epoch 115 finished \tANN training loss 0.002451\n",
      ">> Epoch 116 finished \tANN training loss 0.002451\n",
      ">> Epoch 117 finished \tANN training loss 0.002450\n",
      ">> Epoch 118 finished \tANN training loss 0.002450\n",
      ">> Epoch 119 finished \tANN training loss 0.002449\n",
      ">> Epoch 120 finished \tANN training loss 0.002449\n",
      ">> Epoch 121 finished \tANN training loss 0.002449\n",
      ">> Epoch 122 finished \tANN training loss 0.002448\n",
      ">> Epoch 123 finished \tANN training loss 0.002448\n",
      ">> Epoch 124 finished \tANN training loss 0.002447\n",
      ">> Epoch 125 finished \tANN training loss 0.002447\n",
      ">> Epoch 126 finished \tANN training loss 0.002446\n",
      ">> Epoch 127 finished \tANN training loss 0.002446\n",
      ">> Epoch 128 finished \tANN training loss 0.002446\n",
      ">> Epoch 129 finished \tANN training loss 0.002445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 130 finished \tANN training loss 0.002445\n",
      ">> Epoch 131 finished \tANN training loss 0.002444\n",
      ">> Epoch 132 finished \tANN training loss 0.002444\n",
      ">> Epoch 133 finished \tANN training loss 0.002443\n",
      ">> Epoch 134 finished \tANN training loss 0.002443\n",
      ">> Epoch 135 finished \tANN training loss 0.002442\n",
      ">> Epoch 136 finished \tANN training loss 0.002442\n",
      ">> Epoch 137 finished \tANN training loss 0.002441\n",
      ">> Epoch 138 finished \tANN training loss 0.002441\n",
      ">> Epoch 139 finished \tANN training loss 0.002441\n",
      ">> Epoch 140 finished \tANN training loss 0.002440\n",
      ">> Epoch 141 finished \tANN training loss 0.002440\n",
      ">> Epoch 142 finished \tANN training loss 0.002439\n",
      ">> Epoch 143 finished \tANN training loss 0.002439\n",
      ">> Epoch 144 finished \tANN training loss 0.002438\n",
      ">> Epoch 145 finished \tANN training loss 0.002438\n",
      ">> Epoch 146 finished \tANN training loss 0.002438\n",
      ">> Epoch 147 finished \tANN training loss 0.002437\n",
      ">> Epoch 148 finished \tANN training loss 0.002437\n",
      ">> Epoch 149 finished \tANN training loss 0.002436\n",
      ">> Epoch 150 finished \tANN training loss 0.002436\n",
      "[END] Fine tuning step\n",
      "############### End Training for IBULHSGFINEQ #####################\n",
      "############### End Training for NCCEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 4.076754\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 4.018785\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 3.959955\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 3.900022\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 3.838769\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 3.775899\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 3.711200\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 3.644255\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 3.574750\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 3.502413\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 3.426767\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 3.347491\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 3.264212\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 3.176489\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 3.084041\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 2.986661\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 2.883874\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 2.775345\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 2.661192\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 2.541520\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 2.416261\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 2.285904\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 2.150917\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 2.012000\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 1.870853\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 1.728364\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 1.585761\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 1.445434\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 1.308190\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 1.177705\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 1.054258\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 0.940094\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.835987\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.743042\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.661043\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.590159\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.529004\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.477624\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.435121\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.400253\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.371857\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.348420\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.328897\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.313263\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.300092\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.289455\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.280728\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.272860\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.266228\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.259981\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.254302\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.249068\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.244241\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.239669\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.235336\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.231064\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.226951\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.222972\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.219190\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.215468\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.211884\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.208378\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.204898\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.201561\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.198162\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.194879\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.191820\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.188586\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.185443\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.182608\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.179742\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.176925\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.174280\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.171517\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.168942\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.166365\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.163842\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.161516\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.159061\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.156797\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.154513\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.152192\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.150286\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.148131\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.146275\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.143985\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.141830\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.139585\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.137556\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.135375\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.133661\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.131713\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.130009\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.128385\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.126725\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.125054\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.123479\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.121968\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.120613\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.119371\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.060972\n",
      ">> Epoch 2 finished \tANN training loss 0.052963\n",
      ">> Epoch 3 finished \tANN training loss 0.046301\n",
      ">> Epoch 4 finished \tANN training loss 0.040748\n",
      ">> Epoch 5 finished \tANN training loss 0.036110\n",
      ">> Epoch 6 finished \tANN training loss 0.032228\n",
      ">> Epoch 7 finished \tANN training loss 0.028970\n",
      ">> Epoch 8 finished \tANN training loss 0.026228\n",
      ">> Epoch 9 finished \tANN training loss 0.023915\n",
      ">> Epoch 10 finished \tANN training loss 0.021955\n",
      ">> Epoch 11 finished \tANN training loss 0.020290\n",
      ">> Epoch 12 finished \tANN training loss 0.018869\n",
      ">> Epoch 13 finished \tANN training loss 0.017650\n",
      ">> Epoch 14 finished \tANN training loss 0.016599\n",
      ">> Epoch 15 finished \tANN training loss 0.015688\n",
      ">> Epoch 16 finished \tANN training loss 0.014895\n",
      ">> Epoch 17 finished \tANN training loss 0.014199\n",
      ">> Epoch 18 finished \tANN training loss 0.013584\n",
      ">> Epoch 19 finished \tANN training loss 0.013038\n",
      ">> Epoch 20 finished \tANN training loss 0.012549\n",
      ">> Epoch 21 finished \tANN training loss 0.012109\n",
      ">> Epoch 22 finished \tANN training loss 0.011709\n",
      ">> Epoch 23 finished \tANN training loss 0.011344\n",
      ">> Epoch 24 finished \tANN training loss 0.011008\n",
      ">> Epoch 25 finished \tANN training loss 0.010698\n",
      ">> Epoch 26 finished \tANN training loss 0.010409\n",
      ">> Epoch 27 finished \tANN training loss 0.010140\n",
      ">> Epoch 28 finished \tANN training loss 0.009887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 29 finished \tANN training loss 0.009648\n",
      ">> Epoch 30 finished \tANN training loss 0.009421\n",
      ">> Epoch 31 finished \tANN training loss 0.009206\n",
      ">> Epoch 32 finished \tANN training loss 0.009001\n",
      ">> Epoch 33 finished \tANN training loss 0.008804\n",
      ">> Epoch 34 finished \tANN training loss 0.008616\n",
      ">> Epoch 35 finished \tANN training loss 0.008436\n",
      ">> Epoch 36 finished \tANN training loss 0.008262\n",
      ">> Epoch 37 finished \tANN training loss 0.008094\n",
      ">> Epoch 38 finished \tANN training loss 0.007932\n",
      ">> Epoch 39 finished \tANN training loss 0.007776\n",
      ">> Epoch 40 finished \tANN training loss 0.007625\n",
      ">> Epoch 41 finished \tANN training loss 0.007478\n",
      ">> Epoch 42 finished \tANN training loss 0.007336\n",
      ">> Epoch 43 finished \tANN training loss 0.007198\n",
      ">> Epoch 44 finished \tANN training loss 0.007065\n",
      ">> Epoch 45 finished \tANN training loss 0.006935\n",
      ">> Epoch 46 finished \tANN training loss 0.006809\n",
      ">> Epoch 47 finished \tANN training loss 0.006686\n",
      ">> Epoch 48 finished \tANN training loss 0.006567\n",
      ">> Epoch 49 finished \tANN training loss 0.006451\n",
      ">> Epoch 50 finished \tANN training loss 0.006338\n",
      ">> Epoch 51 finished \tANN training loss 0.006229\n",
      ">> Epoch 52 finished \tANN training loss 0.006122\n",
      ">> Epoch 53 finished \tANN training loss 0.006018\n",
      ">> Epoch 54 finished \tANN training loss 0.005917\n",
      ">> Epoch 55 finished \tANN training loss 0.005819\n",
      ">> Epoch 56 finished \tANN training loss 0.005723\n",
      ">> Epoch 57 finished \tANN training loss 0.005630\n",
      ">> Epoch 58 finished \tANN training loss 0.005539\n",
      ">> Epoch 59 finished \tANN training loss 0.005451\n",
      ">> Epoch 60 finished \tANN training loss 0.005364\n",
      ">> Epoch 61 finished \tANN training loss 0.005280\n",
      ">> Epoch 62 finished \tANN training loss 0.005199\n",
      ">> Epoch 63 finished \tANN training loss 0.005119\n",
      ">> Epoch 64 finished \tANN training loss 0.005041\n",
      ">> Epoch 65 finished \tANN training loss 0.004966\n",
      ">> Epoch 66 finished \tANN training loss 0.004892\n",
      ">> Epoch 67 finished \tANN training loss 0.004821\n",
      ">> Epoch 68 finished \tANN training loss 0.004751\n",
      ">> Epoch 69 finished \tANN training loss 0.004683\n",
      ">> Epoch 70 finished \tANN training loss 0.004617\n",
      ">> Epoch 71 finished \tANN training loss 0.004552\n",
      ">> Epoch 72 finished \tANN training loss 0.004489\n",
      ">> Epoch 73 finished \tANN training loss 0.004428\n",
      ">> Epoch 74 finished \tANN training loss 0.004368\n",
      ">> Epoch 75 finished \tANN training loss 0.004310\n",
      ">> Epoch 76 finished \tANN training loss 0.004253\n",
      ">> Epoch 77 finished \tANN training loss 0.004198\n",
      ">> Epoch 78 finished \tANN training loss 0.004145\n",
      ">> Epoch 79 finished \tANN training loss 0.004092\n",
      ">> Epoch 80 finished \tANN training loss 0.004041\n",
      ">> Epoch 81 finished \tANN training loss 0.003991\n",
      ">> Epoch 82 finished \tANN training loss 0.003943\n",
      ">> Epoch 83 finished \tANN training loss 0.003895\n",
      ">> Epoch 84 finished \tANN training loss 0.003849\n",
      ">> Epoch 85 finished \tANN training loss 0.003804\n",
      ">> Epoch 86 finished \tANN training loss 0.003761\n",
      ">> Epoch 87 finished \tANN training loss 0.003718\n",
      ">> Epoch 88 finished \tANN training loss 0.003676\n",
      ">> Epoch 89 finished \tANN training loss 0.003636\n",
      ">> Epoch 90 finished \tANN training loss 0.003596\n",
      ">> Epoch 91 finished \tANN training loss 0.003558\n",
      ">> Epoch 92 finished \tANN training loss 0.003520\n",
      ">> Epoch 93 finished \tANN training loss 0.003484\n",
      ">> Epoch 94 finished \tANN training loss 0.003448\n",
      ">> Epoch 95 finished \tANN training loss 0.003413\n",
      ">> Epoch 96 finished \tANN training loss 0.003380\n",
      ">> Epoch 97 finished \tANN training loss 0.003347\n",
      ">> Epoch 98 finished \tANN training loss 0.003314\n",
      ">> Epoch 99 finished \tANN training loss 0.003283\n",
      ">> Epoch 100 finished \tANN training loss 0.003252\n",
      ">> Epoch 101 finished \tANN training loss 0.003223\n",
      ">> Epoch 102 finished \tANN training loss 0.003194\n",
      ">> Epoch 103 finished \tANN training loss 0.003165\n",
      ">> Epoch 104 finished \tANN training loss 0.003138\n",
      ">> Epoch 105 finished \tANN training loss 0.003111\n",
      ">> Epoch 106 finished \tANN training loss 0.003084\n",
      ">> Epoch 107 finished \tANN training loss 0.003059\n",
      ">> Epoch 108 finished \tANN training loss 0.003034\n",
      ">> Epoch 109 finished \tANN training loss 0.003009\n",
      ">> Epoch 110 finished \tANN training loss 0.002986\n",
      ">> Epoch 111 finished \tANN training loss 0.002962\n",
      ">> Epoch 112 finished \tANN training loss 0.002940\n",
      ">> Epoch 113 finished \tANN training loss 0.002918\n",
      ">> Epoch 114 finished \tANN training loss 0.002896\n",
      ">> Epoch 115 finished \tANN training loss 0.002875\n",
      ">> Epoch 116 finished \tANN training loss 0.002854\n",
      ">> Epoch 117 finished \tANN training loss 0.002834\n",
      ">> Epoch 118 finished \tANN training loss 0.002815\n",
      ">> Epoch 119 finished \tANN training loss 0.002796\n",
      ">> Epoch 120 finished \tANN training loss 0.002777\n",
      ">> Epoch 121 finished \tANN training loss 0.002759\n",
      ">> Epoch 122 finished \tANN training loss 0.002741\n",
      ">> Epoch 123 finished \tANN training loss 0.002723\n",
      ">> Epoch 124 finished \tANN training loss 0.002706\n",
      ">> Epoch 125 finished \tANN training loss 0.002690\n",
      ">> Epoch 126 finished \tANN training loss 0.002674\n",
      ">> Epoch 127 finished \tANN training loss 0.002658\n",
      ">> Epoch 128 finished \tANN training loss 0.002642\n",
      ">> Epoch 129 finished \tANN training loss 0.002627\n",
      ">> Epoch 130 finished \tANN training loss 0.002612\n",
      ">> Epoch 131 finished \tANN training loss 0.002598\n",
      ">> Epoch 132 finished \tANN training loss 0.002584\n",
      ">> Epoch 133 finished \tANN training loss 0.002570\n",
      ">> Epoch 134 finished \tANN training loss 0.002556\n",
      ">> Epoch 135 finished \tANN training loss 0.002543\n",
      ">> Epoch 136 finished \tANN training loss 0.002530\n",
      ">> Epoch 137 finished \tANN training loss 0.002518\n",
      ">> Epoch 138 finished \tANN training loss 0.002505\n",
      ">> Epoch 139 finished \tANN training loss 0.002493\n",
      ">> Epoch 140 finished \tANN training loss 0.002482\n",
      ">> Epoch 141 finished \tANN training loss 0.002470\n",
      ">> Epoch 142 finished \tANN training loss 0.002459\n",
      ">> Epoch 143 finished \tANN training loss 0.002448\n",
      ">> Epoch 144 finished \tANN training loss 0.002437\n",
      ">> Epoch 145 finished \tANN training loss 0.002426\n",
      ">> Epoch 146 finished \tANN training loss 0.002416\n",
      ">> Epoch 147 finished \tANN training loss 0.002406\n",
      ">> Epoch 148 finished \tANN training loss 0.002396\n",
      ">> Epoch 149 finished \tANN training loss 0.002387\n",
      ">> Epoch 150 finished \tANN training loss 0.002377\n",
      "[END] Fine tuning step\n",
      "############### End Training for NCCEQ #####################\n",
      "############### End Training for ULTRACEMCOEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 4.467162\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 4.401124\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 4.334227\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 4.266275\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 4.197151\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 4.126727\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 4.054825\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 3.981268\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 3.905969\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 3.828613\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 3.749072\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 3.667290\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 3.583051\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 3.496034\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 3.406035\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 3.313090\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 3.217008\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 3.117720\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 3.015110\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 2.909053\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 2.799745\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 2.687204\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 2.571660\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 2.453331\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 2.332302\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 2.209605\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 2.085527\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 1.960388\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 1.835052\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 1.709631\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 1.585702\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 1.463785\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 1.345348\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 1.231044\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 1.122426\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 1.020478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 37 finished \tRBM Reconstruction error 0.924095\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.835240\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.754389\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.680889\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.614631\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.555229\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.502110\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.457275\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.418487\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.385431\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.356677\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.332085\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.311464\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.294327\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.279480\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.267635\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.257075\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.248342\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.240930\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.234421\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.229113\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.224245\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.219509\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.215701\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.212198\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.208932\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.206026\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.203322\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.200980\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.198712\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.196372\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.194490\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.192443\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.190920\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.189018\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.187190\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.185211\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.183618\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.181955\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.180514\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.178915\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.177426\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.175991\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.174480\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.173250\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.172031\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.170857\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.169519\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.168298\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.167020\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.165795\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.164572\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.163222\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.162059\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.160803\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.159609\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.158313\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.157030\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.155816\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.154680\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.153550\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.152579\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.151475\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.150349\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.042595\n",
      ">> Epoch 2 finished \tANN training loss 0.036498\n",
      ">> Epoch 3 finished \tANN training loss 0.031303\n",
      ">> Epoch 4 finished \tANN training loss 0.026879\n",
      ">> Epoch 5 finished \tANN training loss 0.023112\n",
      ">> Epoch 6 finished \tANN training loss 0.019903\n",
      ">> Epoch 7 finished \tANN training loss 0.017167\n",
      ">> Epoch 8 finished \tANN training loss 0.014833\n",
      ">> Epoch 9 finished \tANN training loss 0.012841\n",
      ">> Epoch 10 finished \tANN training loss 0.011140\n",
      ">> Epoch 11 finished \tANN training loss 0.009689\n",
      ">> Epoch 12 finished \tANN training loss 0.008450\n",
      ">> Epoch 13 finished \tANN training loss 0.007394\n",
      ">> Epoch 14 finished \tANN training loss 0.006492\n",
      ">> Epoch 15 finished \tANN training loss 0.005724\n",
      ">> Epoch 16 finished \tANN training loss 0.005068\n",
      ">> Epoch 17 finished \tANN training loss 0.004510\n",
      ">> Epoch 18 finished \tANN training loss 0.004034\n",
      ">> Epoch 19 finished \tANN training loss 0.003628\n",
      ">> Epoch 20 finished \tANN training loss 0.003281\n",
      ">> Epoch 21 finished \tANN training loss 0.002985\n",
      ">> Epoch 22 finished \tANN training loss 0.002732\n",
      ">> Epoch 23 finished \tANN training loss 0.002516\n",
      ">> Epoch 24 finished \tANN training loss 0.002331\n",
      ">> Epoch 25 finished \tANN training loss 0.002173\n",
      ">> Epoch 26 finished \tANN training loss 0.002038\n",
      ">> Epoch 27 finished \tANN training loss 0.001922\n",
      ">> Epoch 28 finished \tANN training loss 0.001822\n",
      ">> Epoch 29 finished \tANN training loss 0.001737\n",
      ">> Epoch 30 finished \tANN training loss 0.001663\n",
      ">> Epoch 31 finished \tANN training loss 0.001600\n",
      ">> Epoch 32 finished \tANN training loss 0.001545\n",
      ">> Epoch 33 finished \tANN training loss 0.001498\n",
      ">> Epoch 34 finished \tANN training loss 0.001456\n",
      ">> Epoch 35 finished \tANN training loss 0.001421\n",
      ">> Epoch 36 finished \tANN training loss 0.001389\n",
      ">> Epoch 37 finished \tANN training loss 0.001362\n",
      ">> Epoch 38 finished \tANN training loss 0.001338\n",
      ">> Epoch 39 finished \tANN training loss 0.001317\n",
      ">> Epoch 40 finished \tANN training loss 0.001298\n",
      ">> Epoch 41 finished \tANN training loss 0.001282\n",
      ">> Epoch 42 finished \tANN training loss 0.001267\n",
      ">> Epoch 43 finished \tANN training loss 0.001254\n",
      ">> Epoch 44 finished \tANN training loss 0.001242\n",
      ">> Epoch 45 finished \tANN training loss 0.001231\n",
      ">> Epoch 46 finished \tANN training loss 0.001221\n",
      ">> Epoch 47 finished \tANN training loss 0.001211\n",
      ">> Epoch 48 finished \tANN training loss 0.001203\n",
      ">> Epoch 49 finished \tANN training loss 0.001195\n",
      ">> Epoch 50 finished \tANN training loss 0.001188\n",
      ">> Epoch 51 finished \tANN training loss 0.001181\n",
      ">> Epoch 52 finished \tANN training loss 0.001174\n",
      ">> Epoch 53 finished \tANN training loss 0.001168\n",
      ">> Epoch 54 finished \tANN training loss 0.001162\n",
      ">> Epoch 55 finished \tANN training loss 0.001157\n",
      ">> Epoch 56 finished \tANN training loss 0.001152\n",
      ">> Epoch 57 finished \tANN training loss 0.001146\n",
      ">> Epoch 58 finished \tANN training loss 0.001141\n",
      ">> Epoch 59 finished \tANN training loss 0.001137\n",
      ">> Epoch 60 finished \tANN training loss 0.001132\n",
      ">> Epoch 61 finished \tANN training loss 0.001127\n",
      ">> Epoch 62 finished \tANN training loss 0.001123\n",
      ">> Epoch 63 finished \tANN training loss 0.001118\n",
      ">> Epoch 64 finished \tANN training loss 0.001114\n",
      ">> Epoch 65 finished \tANN training loss 0.001110\n",
      ">> Epoch 66 finished \tANN training loss 0.001106\n",
      ">> Epoch 67 finished \tANN training loss 0.001102\n",
      ">> Epoch 68 finished \tANN training loss 0.001098\n",
      ">> Epoch 69 finished \tANN training loss 0.001094\n",
      ">> Epoch 70 finished \tANN training loss 0.001090\n",
      ">> Epoch 71 finished \tANN training loss 0.001086\n",
      ">> Epoch 72 finished \tANN training loss 0.001083\n",
      ">> Epoch 73 finished \tANN training loss 0.001079\n",
      ">> Epoch 74 finished \tANN training loss 0.001075\n",
      ">> Epoch 75 finished \tANN training loss 0.001072\n",
      ">> Epoch 76 finished \tANN training loss 0.001068\n",
      ">> Epoch 77 finished \tANN training loss 0.001065\n",
      ">> Epoch 78 finished \tANN training loss 0.001062\n",
      ">> Epoch 79 finished \tANN training loss 0.001058\n",
      ">> Epoch 80 finished \tANN training loss 0.001055\n",
      ">> Epoch 81 finished \tANN training loss 0.001052\n",
      ">> Epoch 82 finished \tANN training loss 0.001048\n",
      ">> Epoch 83 finished \tANN training loss 0.001045\n",
      ">> Epoch 84 finished \tANN training loss 0.001042\n",
      ">> Epoch 85 finished \tANN training loss 0.001039\n",
      ">> Epoch 86 finished \tANN training loss 0.001036\n",
      ">> Epoch 87 finished \tANN training loss 0.001033\n",
      ">> Epoch 88 finished \tANN training loss 0.001030\n",
      ">> Epoch 89 finished \tANN training loss 0.001027\n",
      ">> Epoch 90 finished \tANN training loss 0.001024\n",
      ">> Epoch 91 finished \tANN training loss 0.001021\n",
      ">> Epoch 92 finished \tANN training loss 0.001018\n",
      ">> Epoch 93 finished \tANN training loss 0.001015\n",
      ">> Epoch 94 finished \tANN training loss 0.001012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 95 finished \tANN training loss 0.001009\n",
      ">> Epoch 96 finished \tANN training loss 0.001007\n",
      ">> Epoch 97 finished \tANN training loss 0.001004\n",
      ">> Epoch 98 finished \tANN training loss 0.001001\n",
      ">> Epoch 99 finished \tANN training loss 0.000998\n",
      ">> Epoch 100 finished \tANN training loss 0.000996\n",
      ">> Epoch 101 finished \tANN training loss 0.000993\n",
      ">> Epoch 102 finished \tANN training loss 0.000991\n",
      ">> Epoch 103 finished \tANN training loss 0.000988\n",
      ">> Epoch 104 finished \tANN training loss 0.000986\n",
      ">> Epoch 105 finished \tANN training loss 0.000983\n",
      ">> Epoch 106 finished \tANN training loss 0.000981\n",
      ">> Epoch 107 finished \tANN training loss 0.000978\n",
      ">> Epoch 108 finished \tANN training loss 0.000976\n",
      ">> Epoch 109 finished \tANN training loss 0.000973\n",
      ">> Epoch 110 finished \tANN training loss 0.000971\n",
      ">> Epoch 111 finished \tANN training loss 0.000969\n",
      ">> Epoch 112 finished \tANN training loss 0.000966\n",
      ">> Epoch 113 finished \tANN training loss 0.000964\n",
      ">> Epoch 114 finished \tANN training loss 0.000962\n",
      ">> Epoch 115 finished \tANN training loss 0.000960\n",
      ">> Epoch 116 finished \tANN training loss 0.000958\n",
      ">> Epoch 117 finished \tANN training loss 0.000955\n",
      ">> Epoch 118 finished \tANN training loss 0.000953\n",
      ">> Epoch 119 finished \tANN training loss 0.000951\n",
      ">> Epoch 120 finished \tANN training loss 0.000949\n",
      ">> Epoch 121 finished \tANN training loss 0.000947\n",
      ">> Epoch 122 finished \tANN training loss 0.000945\n",
      ">> Epoch 123 finished \tANN training loss 0.000943\n",
      ">> Epoch 124 finished \tANN training loss 0.000941\n",
      ">> Epoch 125 finished \tANN training loss 0.000939\n",
      ">> Epoch 126 finished \tANN training loss 0.000937\n",
      ">> Epoch 127 finished \tANN training loss 0.000935\n",
      ">> Epoch 128 finished \tANN training loss 0.000933\n",
      ">> Epoch 129 finished \tANN training loss 0.000931\n",
      ">> Epoch 130 finished \tANN training loss 0.000929\n",
      ">> Epoch 131 finished \tANN training loss 0.000927\n",
      ">> Epoch 132 finished \tANN training loss 0.000926\n",
      ">> Epoch 133 finished \tANN training loss 0.000924\n",
      ">> Epoch 134 finished \tANN training loss 0.000922\n",
      ">> Epoch 135 finished \tANN training loss 0.000920\n",
      ">> Epoch 136 finished \tANN training loss 0.000919\n",
      ">> Epoch 137 finished \tANN training loss 0.000917\n",
      ">> Epoch 138 finished \tANN training loss 0.000915\n",
      ">> Epoch 139 finished \tANN training loss 0.000913\n",
      ">> Epoch 140 finished \tANN training loss 0.000912\n",
      ">> Epoch 141 finished \tANN training loss 0.000910\n",
      ">> Epoch 142 finished \tANN training loss 0.000909\n",
      ">> Epoch 143 finished \tANN training loss 0.000907\n",
      ">> Epoch 144 finished \tANN training loss 0.000905\n",
      ">> Epoch 145 finished \tANN training loss 0.000904\n",
      ">> Epoch 146 finished \tANN training loss 0.000902\n",
      ">> Epoch 147 finished \tANN training loss 0.000901\n",
      ">> Epoch 148 finished \tANN training loss 0.000899\n",
      ">> Epoch 149 finished \tANN training loss 0.000898\n",
      ">> Epoch 150 finished \tANN training loss 0.000896\n",
      "[END] Fine tuning step\n",
      "############### End Training for ULTRACEMCOEQ #####################\n",
      "############### End Training for IFCIEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 4.130154\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 4.045736\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 3.960664\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 3.874615\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 3.787330\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 3.698334\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 3.607255\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 3.513619\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 3.417108\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 3.317191\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 3.213270\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 3.105114\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 2.992131\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 2.874165\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 2.750630\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 2.621521\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 2.487090\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 2.347478\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 2.203286\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 2.055065\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 1.903993\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 1.751935\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 1.600103\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 1.450250\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 1.306022\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 1.168242\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 1.039528\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 0.922642\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 0.817276\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 0.724485\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 0.643682\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 0.575528\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.518903\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.472785\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.436290\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.407095\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.383021\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.363417\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.348134\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.335862\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.325644\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.317157\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.309744\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.303243\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.297731\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.292607\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.288223\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.284376\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.280607\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.276934\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.273699\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.270527\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.267653\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.264683\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.262028\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.259368\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.256520\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.253881\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.251184\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.248679\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.246452\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.243965\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.241572\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.239237\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.237163\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.234679\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.232443\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.230365\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.228271\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.226095\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.223996\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.221748\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.219784\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.217722\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.215772\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.213920\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.212131\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.210139\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.208072\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.206216\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.204239\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.202417\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.200659\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.198868\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.197048\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.195475\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.193580\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.191980\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.190487\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.188543\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.186912\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.185376\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.183755\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.182303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 95 finished \tRBM Reconstruction error 0.180877\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.179135\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.177693\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.176329\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.174814\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.173436\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.083331\n",
      ">> Epoch 2 finished \tANN training loss 0.066982\n",
      ">> Epoch 3 finished \tANN training loss 0.054026\n",
      ">> Epoch 4 finished \tANN training loss 0.043758\n",
      ">> Epoch 5 finished \tANN training loss 0.035621\n",
      ">> Epoch 6 finished \tANN training loss 0.029169\n",
      ">> Epoch 7 finished \tANN training loss 0.024053\n",
      ">> Epoch 8 finished \tANN training loss 0.019996\n",
      ">> Epoch 9 finished \tANN training loss 0.016776\n",
      ">> Epoch 10 finished \tANN training loss 0.014218\n",
      ">> Epoch 11 finished \tANN training loss 0.012186\n",
      ">> Epoch 12 finished \tANN training loss 0.010567\n",
      ">> Epoch 13 finished \tANN training loss 0.009278\n",
      ">> Epoch 14 finished \tANN training loss 0.008250\n",
      ">> Epoch 15 finished \tANN training loss 0.007429\n",
      ">> Epoch 16 finished \tANN training loss 0.006771\n",
      ">> Epoch 17 finished \tANN training loss 0.006243\n",
      ">> Epoch 18 finished \tANN training loss 0.005819\n",
      ">> Epoch 19 finished \tANN training loss 0.005477\n",
      ">> Epoch 20 finished \tANN training loss 0.005200\n",
      ">> Epoch 21 finished \tANN training loss 0.004975\n",
      ">> Epoch 22 finished \tANN training loss 0.004791\n",
      ">> Epoch 23 finished \tANN training loss 0.004639\n",
      ">> Epoch 24 finished \tANN training loss 0.004514\n",
      ">> Epoch 25 finished \tANN training loss 0.004409\n",
      ">> Epoch 26 finished \tANN training loss 0.004321\n",
      ">> Epoch 27 finished \tANN training loss 0.004246\n",
      ">> Epoch 28 finished \tANN training loss 0.004181\n",
      ">> Epoch 29 finished \tANN training loss 0.004125\n",
      ">> Epoch 30 finished \tANN training loss 0.004075\n",
      ">> Epoch 31 finished \tANN training loss 0.004031\n",
      ">> Epoch 32 finished \tANN training loss 0.003991\n",
      ">> Epoch 33 finished \tANN training loss 0.003955\n",
      ">> Epoch 34 finished \tANN training loss 0.003921\n",
      ">> Epoch 35 finished \tANN training loss 0.003890\n",
      ">> Epoch 36 finished \tANN training loss 0.003861\n",
      ">> Epoch 37 finished \tANN training loss 0.003834\n",
      ">> Epoch 38 finished \tANN training loss 0.003808\n",
      ">> Epoch 39 finished \tANN training loss 0.003783\n",
      ">> Epoch 40 finished \tANN training loss 0.003759\n",
      ">> Epoch 41 finished \tANN training loss 0.003736\n",
      ">> Epoch 42 finished \tANN training loss 0.003714\n",
      ">> Epoch 43 finished \tANN training loss 0.003692\n",
      ">> Epoch 44 finished \tANN training loss 0.003671\n",
      ">> Epoch 45 finished \tANN training loss 0.003650\n",
      ">> Epoch 46 finished \tANN training loss 0.003630\n",
      ">> Epoch 47 finished \tANN training loss 0.003610\n",
      ">> Epoch 48 finished \tANN training loss 0.003591\n",
      ">> Epoch 49 finished \tANN training loss 0.003572\n",
      ">> Epoch 50 finished \tANN training loss 0.003554\n",
      ">> Epoch 51 finished \tANN training loss 0.003536\n",
      ">> Epoch 52 finished \tANN training loss 0.003518\n",
      ">> Epoch 53 finished \tANN training loss 0.003500\n",
      ">> Epoch 54 finished \tANN training loss 0.003483\n",
      ">> Epoch 55 finished \tANN training loss 0.003466\n",
      ">> Epoch 56 finished \tANN training loss 0.003450\n",
      ">> Epoch 57 finished \tANN training loss 0.003433\n",
      ">> Epoch 58 finished \tANN training loss 0.003417\n",
      ">> Epoch 59 finished \tANN training loss 0.003401\n",
      ">> Epoch 60 finished \tANN training loss 0.003386\n",
      ">> Epoch 61 finished \tANN training loss 0.003370\n",
      ">> Epoch 62 finished \tANN training loss 0.003355\n",
      ">> Epoch 63 finished \tANN training loss 0.003341\n",
      ">> Epoch 64 finished \tANN training loss 0.003326\n",
      ">> Epoch 65 finished \tANN training loss 0.003312\n",
      ">> Epoch 66 finished \tANN training loss 0.003298\n",
      ">> Epoch 67 finished \tANN training loss 0.003284\n",
      ">> Epoch 68 finished \tANN training loss 0.003270\n",
      ">> Epoch 69 finished \tANN training loss 0.003257\n",
      ">> Epoch 70 finished \tANN training loss 0.003244\n",
      ">> Epoch 71 finished \tANN training loss 0.003231\n",
      ">> Epoch 72 finished \tANN training loss 0.003218\n",
      ">> Epoch 73 finished \tANN training loss 0.003205\n",
      ">> Epoch 74 finished \tANN training loss 0.003193\n",
      ">> Epoch 75 finished \tANN training loss 0.003181\n",
      ">> Epoch 76 finished \tANN training loss 0.003168\n",
      ">> Epoch 77 finished \tANN training loss 0.003157\n",
      ">> Epoch 78 finished \tANN training loss 0.003145\n",
      ">> Epoch 79 finished \tANN training loss 0.003134\n",
      ">> Epoch 80 finished \tANN training loss 0.003122\n",
      ">> Epoch 81 finished \tANN training loss 0.003111\n",
      ">> Epoch 82 finished \tANN training loss 0.003100\n",
      ">> Epoch 83 finished \tANN training loss 0.003089\n",
      ">> Epoch 84 finished \tANN training loss 0.003079\n",
      ">> Epoch 85 finished \tANN training loss 0.003068\n",
      ">> Epoch 86 finished \tANN training loss 0.003058\n",
      ">> Epoch 87 finished \tANN training loss 0.003048\n",
      ">> Epoch 88 finished \tANN training loss 0.003038\n",
      ">> Epoch 89 finished \tANN training loss 0.003028\n",
      ">> Epoch 90 finished \tANN training loss 0.003019\n",
      ">> Epoch 91 finished \tANN training loss 0.003009\n",
      ">> Epoch 92 finished \tANN training loss 0.003000\n",
      ">> Epoch 93 finished \tANN training loss 0.002990\n",
      ">> Epoch 94 finished \tANN training loss 0.002981\n",
      ">> Epoch 95 finished \tANN training loss 0.002972\n",
      ">> Epoch 96 finished \tANN training loss 0.002963\n",
      ">> Epoch 97 finished \tANN training loss 0.002955\n",
      ">> Epoch 98 finished \tANN training loss 0.002946\n",
      ">> Epoch 99 finished \tANN training loss 0.002938\n",
      ">> Epoch 100 finished \tANN training loss 0.002929\n",
      ">> Epoch 101 finished \tANN training loss 0.002921\n",
      ">> Epoch 102 finished \tANN training loss 0.002913\n",
      ">> Epoch 103 finished \tANN training loss 0.002905\n",
      ">> Epoch 104 finished \tANN training loss 0.002897\n",
      ">> Epoch 105 finished \tANN training loss 0.002889\n",
      ">> Epoch 106 finished \tANN training loss 0.002882\n",
      ">> Epoch 107 finished \tANN training loss 0.002874\n",
      ">> Epoch 108 finished \tANN training loss 0.002867\n",
      ">> Epoch 109 finished \tANN training loss 0.002859\n",
      ">> Epoch 110 finished \tANN training loss 0.002852\n",
      ">> Epoch 111 finished \tANN training loss 0.002845\n",
      ">> Epoch 112 finished \tANN training loss 0.002838\n",
      ">> Epoch 113 finished \tANN training loss 0.002831\n",
      ">> Epoch 114 finished \tANN training loss 0.002824\n",
      ">> Epoch 115 finished \tANN training loss 0.002817\n",
      ">> Epoch 116 finished \tANN training loss 0.002811\n",
      ">> Epoch 117 finished \tANN training loss 0.002804\n",
      ">> Epoch 118 finished \tANN training loss 0.002798\n",
      ">> Epoch 119 finished \tANN training loss 0.002791\n",
      ">> Epoch 120 finished \tANN training loss 0.002785\n",
      ">> Epoch 121 finished \tANN training loss 0.002779\n",
      ">> Epoch 122 finished \tANN training loss 0.002773\n",
      ">> Epoch 123 finished \tANN training loss 0.002766\n",
      ">> Epoch 124 finished \tANN training loss 0.002760\n",
      ">> Epoch 125 finished \tANN training loss 0.002754\n",
      ">> Epoch 126 finished \tANN training loss 0.002749\n",
      ">> Epoch 127 finished \tANN training loss 0.002743\n",
      ">> Epoch 128 finished \tANN training loss 0.002737\n",
      ">> Epoch 129 finished \tANN training loss 0.002732\n",
      ">> Epoch 130 finished \tANN training loss 0.002726\n",
      ">> Epoch 131 finished \tANN training loss 0.002720\n",
      ">> Epoch 132 finished \tANN training loss 0.002715\n",
      ">> Epoch 133 finished \tANN training loss 0.002710\n",
      ">> Epoch 134 finished \tANN training loss 0.002704\n",
      ">> Epoch 135 finished \tANN training loss 0.002699\n",
      ">> Epoch 136 finished \tANN training loss 0.002694\n",
      ">> Epoch 137 finished \tANN training loss 0.002689\n",
      ">> Epoch 138 finished \tANN training loss 0.002684\n",
      ">> Epoch 139 finished \tANN training loss 0.002679\n",
      ">> Epoch 140 finished \tANN training loss 0.002674\n",
      ">> Epoch 141 finished \tANN training loss 0.002669\n",
      ">> Epoch 142 finished \tANN training loss 0.002664\n",
      ">> Epoch 143 finished \tANN training loss 0.002659\n",
      ">> Epoch 144 finished \tANN training loss 0.002654\n",
      ">> Epoch 145 finished \tANN training loss 0.002650\n",
      ">> Epoch 146 finished \tANN training loss 0.002645\n",
      ">> Epoch 147 finished \tANN training loss 0.002640\n",
      ">> Epoch 148 finished \tANN training loss 0.002636\n",
      ">> Epoch 149 finished \tANN training loss 0.002631\n",
      ">> Epoch 150 finished \tANN training loss 0.002627\n",
      "[END] Fine tuning step\n",
      "############### End Training for IFCIEQ #####################\n",
      "############### End Training for JSWSTEELEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 0.889736\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 0.877196\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 0.864925\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 0.852920\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 0.841178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 6 finished \tRBM Reconstruction error 0.829676\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 0.818434\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 0.807428\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 0.796659\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 0.786117\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 0.775785\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 0.765687\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 0.755819\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 0.746147\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 0.736684\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 0.727433\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 0.718362\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 0.709497\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 0.700829\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 0.692340\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 0.684022\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 0.675875\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 0.667894\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 0.660067\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 0.652415\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 0.644909\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 0.637554\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 0.630343\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 0.623285\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 0.616342\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 0.609554\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 0.602885\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.596329\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.589904\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.583603\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.577428\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.571362\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.565429\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.559583\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.553832\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.548199\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.542681\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.537231\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.531884\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.526644\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.521492\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.516439\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.511447\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.506523\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.501704\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.496964\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.492306\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.487718\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.483206\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.478762\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.474378\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.470057\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.465803\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.461641\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.457521\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.453483\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.449494\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.445565\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.441710\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.437894\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.434129\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.430429\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.426781\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.423225\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.419715\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.416249\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.412812\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.409424\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.406089\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.402804\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.399570\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.396377\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.393242\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.390182\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.387147\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.384144\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.381178\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.378272\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.375399\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.372570\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.369786\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.367057\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.364347\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.361668\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.359015\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.356376\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.353804\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.351287\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.348776\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.346312\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.343893\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.341506\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.339152\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.336813\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.334536\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.010968\n",
      ">> Epoch 2 finished \tANN training loss 0.010407\n",
      ">> Epoch 3 finished \tANN training loss 0.009880\n",
      ">> Epoch 4 finished \tANN training loss 0.009385\n",
      ">> Epoch 5 finished \tANN training loss 0.008920\n",
      ">> Epoch 6 finished \tANN training loss 0.008482\n",
      ">> Epoch 7 finished \tANN training loss 0.008071\n",
      ">> Epoch 8 finished \tANN training loss 0.007684\n",
      ">> Epoch 9 finished \tANN training loss 0.007320\n",
      ">> Epoch 10 finished \tANN training loss 0.006978\n",
      ">> Epoch 11 finished \tANN training loss 0.006655\n",
      ">> Epoch 12 finished \tANN training loss 0.006352\n",
      ">> Epoch 13 finished \tANN training loss 0.006066\n",
      ">> Epoch 14 finished \tANN training loss 0.005796\n",
      ">> Epoch 15 finished \tANN training loss 0.005542\n",
      ">> Epoch 16 finished \tANN training loss 0.005302\n",
      ">> Epoch 17 finished \tANN training loss 0.005075\n",
      ">> Epoch 18 finished \tANN training loss 0.004861\n",
      ">> Epoch 19 finished \tANN training loss 0.004658\n",
      ">> Epoch 20 finished \tANN training loss 0.004467\n",
      ">> Epoch 21 finished \tANN training loss 0.004286\n",
      ">> Epoch 22 finished \tANN training loss 0.004116\n",
      ">> Epoch 23 finished \tANN training loss 0.003956\n",
      ">> Epoch 24 finished \tANN training loss 0.003805\n",
      ">> Epoch 25 finished \tANN training loss 0.003663\n",
      ">> Epoch 26 finished \tANN training loss 0.003530\n",
      ">> Epoch 27 finished \tANN training loss 0.003404\n",
      ">> Epoch 28 finished \tANN training loss 0.003286\n",
      ">> Epoch 29 finished \tANN training loss 0.003175\n",
      ">> Epoch 30 finished \tANN training loss 0.003070\n",
      ">> Epoch 31 finished \tANN training loss 0.002971\n",
      ">> Epoch 32 finished \tANN training loss 0.002878\n",
      ">> Epoch 33 finished \tANN training loss 0.002791\n",
      ">> Epoch 34 finished \tANN training loss 0.002708\n",
      ">> Epoch 35 finished \tANN training loss 0.002630\n",
      ">> Epoch 36 finished \tANN training loss 0.002557\n",
      ">> Epoch 37 finished \tANN training loss 0.002487\n",
      ">> Epoch 38 finished \tANN training loss 0.002421\n",
      ">> Epoch 39 finished \tANN training loss 0.002359\n",
      ">> Epoch 40 finished \tANN training loss 0.002300\n",
      ">> Epoch 41 finished \tANN training loss 0.002245\n",
      ">> Epoch 42 finished \tANN training loss 0.002192\n",
      ">> Epoch 43 finished \tANN training loss 0.002142\n",
      ">> Epoch 44 finished \tANN training loss 0.002094\n",
      ">> Epoch 45 finished \tANN training loss 0.002049\n",
      ">> Epoch 46 finished \tANN training loss 0.002007\n",
      ">> Epoch 47 finished \tANN training loss 0.001966\n",
      ">> Epoch 48 finished \tANN training loss 0.001928\n",
      ">> Epoch 49 finished \tANN training loss 0.001891\n",
      ">> Epoch 50 finished \tANN training loss 0.001856\n",
      ">> Epoch 51 finished \tANN training loss 0.001822\n",
      ">> Epoch 52 finished \tANN training loss 0.001791\n",
      ">> Epoch 53 finished \tANN training loss 0.001760\n",
      ">> Epoch 54 finished \tANN training loss 0.001731\n",
      ">> Epoch 55 finished \tANN training loss 0.001703\n",
      ">> Epoch 56 finished \tANN training loss 0.001677\n",
      ">> Epoch 57 finished \tANN training loss 0.001652\n",
      ">> Epoch 58 finished \tANN training loss 0.001627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 59 finished \tANN training loss 0.001604\n",
      ">> Epoch 60 finished \tANN training loss 0.001581\n",
      ">> Epoch 61 finished \tANN training loss 0.001560\n",
      ">> Epoch 62 finished \tANN training loss 0.001539\n",
      ">> Epoch 63 finished \tANN training loss 0.001519\n",
      ">> Epoch 64 finished \tANN training loss 0.001500\n",
      ">> Epoch 65 finished \tANN training loss 0.001482\n",
      ">> Epoch 66 finished \tANN training loss 0.001464\n",
      ">> Epoch 67 finished \tANN training loss 0.001447\n",
      ">> Epoch 68 finished \tANN training loss 0.001431\n",
      ">> Epoch 69 finished \tANN training loss 0.001415\n",
      ">> Epoch 70 finished \tANN training loss 0.001399\n",
      ">> Epoch 71 finished \tANN training loss 0.001384\n",
      ">> Epoch 72 finished \tANN training loss 0.001370\n",
      ">> Epoch 73 finished \tANN training loss 0.001356\n",
      ">> Epoch 74 finished \tANN training loss 0.001342\n",
      ">> Epoch 75 finished \tANN training loss 0.001329\n",
      ">> Epoch 76 finished \tANN training loss 0.001316\n",
      ">> Epoch 77 finished \tANN training loss 0.001304\n",
      ">> Epoch 78 finished \tANN training loss 0.001292\n",
      ">> Epoch 79 finished \tANN training loss 0.001280\n",
      ">> Epoch 80 finished \tANN training loss 0.001268\n",
      ">> Epoch 81 finished \tANN training loss 0.001257\n",
      ">> Epoch 82 finished \tANN training loss 0.001246\n",
      ">> Epoch 83 finished \tANN training loss 0.001236\n",
      ">> Epoch 84 finished \tANN training loss 0.001225\n",
      ">> Epoch 85 finished \tANN training loss 0.001215\n",
      ">> Epoch 86 finished \tANN training loss 0.001205\n",
      ">> Epoch 87 finished \tANN training loss 0.001196\n",
      ">> Epoch 88 finished \tANN training loss 0.001186\n",
      ">> Epoch 89 finished \tANN training loss 0.001177\n",
      ">> Epoch 90 finished \tANN training loss 0.001168\n",
      ">> Epoch 91 finished \tANN training loss 0.001159\n",
      ">> Epoch 92 finished \tANN training loss 0.001150\n",
      ">> Epoch 93 finished \tANN training loss 0.001142\n",
      ">> Epoch 94 finished \tANN training loss 0.001133\n",
      ">> Epoch 95 finished \tANN training loss 0.001125\n",
      ">> Epoch 96 finished \tANN training loss 0.001117\n",
      ">> Epoch 97 finished \tANN training loss 0.001109\n",
      ">> Epoch 98 finished \tANN training loss 0.001101\n",
      ">> Epoch 99 finished \tANN training loss 0.001094\n",
      ">> Epoch 100 finished \tANN training loss 0.001086\n",
      ">> Epoch 101 finished \tANN training loss 0.001079\n",
      ">> Epoch 102 finished \tANN training loss 0.001071\n",
      ">> Epoch 103 finished \tANN training loss 0.001064\n",
      ">> Epoch 104 finished \tANN training loss 0.001057\n",
      ">> Epoch 105 finished \tANN training loss 0.001050\n",
      ">> Epoch 106 finished \tANN training loss 0.001044\n",
      ">> Epoch 107 finished \tANN training loss 0.001037\n",
      ">> Epoch 108 finished \tANN training loss 0.001030\n",
      ">> Epoch 109 finished \tANN training loss 0.001024\n",
      ">> Epoch 110 finished \tANN training loss 0.001017\n",
      ">> Epoch 111 finished \tANN training loss 0.001011\n",
      ">> Epoch 112 finished \tANN training loss 0.001005\n",
      ">> Epoch 113 finished \tANN training loss 0.000998\n",
      ">> Epoch 114 finished \tANN training loss 0.000992\n",
      ">> Epoch 115 finished \tANN training loss 0.000986\n",
      ">> Epoch 116 finished \tANN training loss 0.000980\n",
      ">> Epoch 117 finished \tANN training loss 0.000975\n",
      ">> Epoch 118 finished \tANN training loss 0.000969\n",
      ">> Epoch 119 finished \tANN training loss 0.000963\n",
      ">> Epoch 120 finished \tANN training loss 0.000958\n",
      ">> Epoch 121 finished \tANN training loss 0.000952\n",
      ">> Epoch 122 finished \tANN training loss 0.000947\n",
      ">> Epoch 123 finished \tANN training loss 0.000941\n",
      ">> Epoch 124 finished \tANN training loss 0.000936\n",
      ">> Epoch 125 finished \tANN training loss 0.000931\n",
      ">> Epoch 126 finished \tANN training loss 0.000925\n",
      ">> Epoch 127 finished \tANN training loss 0.000920\n",
      ">> Epoch 128 finished \tANN training loss 0.000915\n",
      ">> Epoch 129 finished \tANN training loss 0.000910\n",
      ">> Epoch 130 finished \tANN training loss 0.000905\n",
      ">> Epoch 131 finished \tANN training loss 0.000900\n",
      ">> Epoch 132 finished \tANN training loss 0.000895\n",
      ">> Epoch 133 finished \tANN training loss 0.000891\n",
      ">> Epoch 134 finished \tANN training loss 0.000886\n",
      ">> Epoch 135 finished \tANN training loss 0.000881\n",
      ">> Epoch 136 finished \tANN training loss 0.000876\n",
      ">> Epoch 137 finished \tANN training loss 0.000872\n",
      ">> Epoch 138 finished \tANN training loss 0.000867\n",
      ">> Epoch 139 finished \tANN training loss 0.000863\n",
      ">> Epoch 140 finished \tANN training loss 0.000858\n",
      ">> Epoch 141 finished \tANN training loss 0.000854\n",
      ">> Epoch 142 finished \tANN training loss 0.000850\n",
      ">> Epoch 143 finished \tANN training loss 0.000845\n",
      ">> Epoch 144 finished \tANN training loss 0.000841\n",
      ">> Epoch 145 finished \tANN training loss 0.000837\n",
      ">> Epoch 146 finished \tANN training loss 0.000833\n",
      ">> Epoch 147 finished \tANN training loss 0.000829\n",
      ">> Epoch 148 finished \tANN training loss 0.000825\n",
      ">> Epoch 149 finished \tANN training loss 0.000821\n",
      ">> Epoch 150 finished \tANN training loss 0.000817\n",
      "[END] Fine tuning step\n",
      "############### End Training for JSWSTEELEQ #####################\n",
      "############### End Training for HINDPETROEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 0.389054\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 0.380358\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 0.371876\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 0.363620\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 0.355580\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 0.347736\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 0.340108\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 0.332672\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 0.325451\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 0.318410\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 0.311563\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 0.304898\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 0.298415\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 0.292113\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 0.285987\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 0.280033\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 0.274246\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 0.268616\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 0.263151\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 0.257821\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 0.252648\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 0.247613\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 0.242716\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 0.237967\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 0.233342\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 0.228852\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 0.224499\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 0.220259\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 0.216139\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 0.212138\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 0.208253\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 0.204479\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.200807\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.197247\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.193786\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.190438\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.187178\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.184003\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.180934\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.177943\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.175047\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.172240\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.169515\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.166859\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.164288\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.161793\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.159369\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.157021\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.154734\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.152520\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.150369\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.148285\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.146262\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.144308\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.142399\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.140548\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.138756\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.137019\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.135331\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.133693\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.132110\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.130572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 63 finished \tRBM Reconstruction error 0.129081\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.127630\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.126231\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.124871\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.123548\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.122264\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.121025\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.119822\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.118648\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.117512\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.116413\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.115356\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.114331\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.113332\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.112357\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.111414\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.110501\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.109622\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.108767\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.107942\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.107144\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.106372\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.105614\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.104888\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.104182\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.103495\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.102838\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.102192\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.101570\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.100964\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.100378\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.099805\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.099257\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.098723\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.098203\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.097706\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.097218\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.096743\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.003100\n",
      ">> Epoch 2 finished \tANN training loss 0.003003\n",
      ">> Epoch 3 finished \tANN training loss 0.002912\n",
      ">> Epoch 4 finished \tANN training loss 0.002827\n",
      ">> Epoch 5 finished \tANN training loss 0.002747\n",
      ">> Epoch 6 finished \tANN training loss 0.002672\n",
      ">> Epoch 7 finished \tANN training loss 0.002602\n",
      ">> Epoch 8 finished \tANN training loss 0.002536\n",
      ">> Epoch 9 finished \tANN training loss 0.002474\n",
      ">> Epoch 10 finished \tANN training loss 0.002415\n",
      ">> Epoch 11 finished \tANN training loss 0.002361\n",
      ">> Epoch 12 finished \tANN training loss 0.002309\n",
      ">> Epoch 13 finished \tANN training loss 0.002261\n",
      ">> Epoch 14 finished \tANN training loss 0.002215\n",
      ">> Epoch 15 finished \tANN training loss 0.002172\n",
      ">> Epoch 16 finished \tANN training loss 0.002132\n",
      ">> Epoch 17 finished \tANN training loss 0.002094\n",
      ">> Epoch 18 finished \tANN training loss 0.002058\n",
      ">> Epoch 19 finished \tANN training loss 0.002025\n",
      ">> Epoch 20 finished \tANN training loss 0.001993\n",
      ">> Epoch 21 finished \tANN training loss 0.001963\n",
      ">> Epoch 22 finished \tANN training loss 0.001935\n",
      ">> Epoch 23 finished \tANN training loss 0.001908\n",
      ">> Epoch 24 finished \tANN training loss 0.001883\n",
      ">> Epoch 25 finished \tANN training loss 0.001859\n",
      ">> Epoch 26 finished \tANN training loss 0.001837\n",
      ">> Epoch 27 finished \tANN training loss 0.001816\n",
      ">> Epoch 28 finished \tANN training loss 0.001796\n",
      ">> Epoch 29 finished \tANN training loss 0.001777\n",
      ">> Epoch 30 finished \tANN training loss 0.001759\n",
      ">> Epoch 31 finished \tANN training loss 0.001742\n",
      ">> Epoch 32 finished \tANN training loss 0.001725\n",
      ">> Epoch 33 finished \tANN training loss 0.001710\n",
      ">> Epoch 34 finished \tANN training loss 0.001695\n",
      ">> Epoch 35 finished \tANN training loss 0.001681\n",
      ">> Epoch 36 finished \tANN training loss 0.001668\n",
      ">> Epoch 37 finished \tANN training loss 0.001656\n",
      ">> Epoch 38 finished \tANN training loss 0.001644\n",
      ">> Epoch 39 finished \tANN training loss 0.001632\n",
      ">> Epoch 40 finished \tANN training loss 0.001621\n",
      ">> Epoch 41 finished \tANN training loss 0.001611\n",
      ">> Epoch 42 finished \tANN training loss 0.001601\n",
      ">> Epoch 43 finished \tANN training loss 0.001591\n",
      ">> Epoch 44 finished \tANN training loss 0.001582\n",
      ">> Epoch 45 finished \tANN training loss 0.001573\n",
      ">> Epoch 46 finished \tANN training loss 0.001565\n",
      ">> Epoch 47 finished \tANN training loss 0.001557\n",
      ">> Epoch 48 finished \tANN training loss 0.001549\n",
      ">> Epoch 49 finished \tANN training loss 0.001541\n",
      ">> Epoch 50 finished \tANN training loss 0.001534\n",
      ">> Epoch 51 finished \tANN training loss 0.001527\n",
      ">> Epoch 52 finished \tANN training loss 0.001520\n",
      ">> Epoch 53 finished \tANN training loss 0.001514\n",
      ">> Epoch 54 finished \tANN training loss 0.001507\n",
      ">> Epoch 55 finished \tANN training loss 0.001501\n",
      ">> Epoch 56 finished \tANN training loss 0.001495\n",
      ">> Epoch 57 finished \tANN training loss 0.001489\n",
      ">> Epoch 58 finished \tANN training loss 0.001484\n",
      ">> Epoch 59 finished \tANN training loss 0.001478\n",
      ">> Epoch 60 finished \tANN training loss 0.001473\n",
      ">> Epoch 61 finished \tANN training loss 0.001468\n",
      ">> Epoch 62 finished \tANN training loss 0.001463\n",
      ">> Epoch 63 finished \tANN training loss 0.001458\n",
      ">> Epoch 64 finished \tANN training loss 0.001453\n",
      ">> Epoch 65 finished \tANN training loss 0.001449\n",
      ">> Epoch 66 finished \tANN training loss 0.001444\n",
      ">> Epoch 67 finished \tANN training loss 0.001439\n",
      ">> Epoch 68 finished \tANN training loss 0.001435\n",
      ">> Epoch 69 finished \tANN training loss 0.001431\n",
      ">> Epoch 70 finished \tANN training loss 0.001426\n",
      ">> Epoch 71 finished \tANN training loss 0.001422\n",
      ">> Epoch 72 finished \tANN training loss 0.001418\n",
      ">> Epoch 73 finished \tANN training loss 0.001414\n",
      ">> Epoch 74 finished \tANN training loss 0.001410\n",
      ">> Epoch 75 finished \tANN training loss 0.001406\n",
      ">> Epoch 76 finished \tANN training loss 0.001402\n",
      ">> Epoch 77 finished \tANN training loss 0.001399\n",
      ">> Epoch 78 finished \tANN training loss 0.001395\n",
      ">> Epoch 79 finished \tANN training loss 0.001391\n",
      ">> Epoch 80 finished \tANN training loss 0.001388\n",
      ">> Epoch 81 finished \tANN training loss 0.001384\n",
      ">> Epoch 82 finished \tANN training loss 0.001380\n",
      ">> Epoch 83 finished \tANN training loss 0.001377\n",
      ">> Epoch 84 finished \tANN training loss 0.001373\n",
      ">> Epoch 85 finished \tANN training loss 0.001370\n",
      ">> Epoch 86 finished \tANN training loss 0.001367\n",
      ">> Epoch 87 finished \tANN training loss 0.001363\n",
      ">> Epoch 88 finished \tANN training loss 0.001360\n",
      ">> Epoch 89 finished \tANN training loss 0.001357\n",
      ">> Epoch 90 finished \tANN training loss 0.001353\n",
      ">> Epoch 91 finished \tANN training loss 0.001350\n",
      ">> Epoch 92 finished \tANN training loss 0.001347\n",
      ">> Epoch 93 finished \tANN training loss 0.001344\n",
      ">> Epoch 94 finished \tANN training loss 0.001340\n",
      ">> Epoch 95 finished \tANN training loss 0.001337\n",
      ">> Epoch 96 finished \tANN training loss 0.001334\n",
      ">> Epoch 97 finished \tANN training loss 0.001331\n",
      ">> Epoch 98 finished \tANN training loss 0.001328\n",
      ">> Epoch 99 finished \tANN training loss 0.001325\n",
      ">> Epoch 100 finished \tANN training loss 0.001322\n",
      ">> Epoch 101 finished \tANN training loss 0.001319\n",
      ">> Epoch 102 finished \tANN training loss 0.001316\n",
      ">> Epoch 103 finished \tANN training loss 0.001313\n",
      ">> Epoch 104 finished \tANN training loss 0.001310\n",
      ">> Epoch 105 finished \tANN training loss 0.001307\n",
      ">> Epoch 106 finished \tANN training loss 0.001304\n",
      ">> Epoch 107 finished \tANN training loss 0.001301\n",
      ">> Epoch 108 finished \tANN training loss 0.001298\n",
      ">> Epoch 109 finished \tANN training loss 0.001295\n",
      ">> Epoch 110 finished \tANN training loss 0.001292\n",
      ">> Epoch 111 finished \tANN training loss 0.001289\n",
      ">> Epoch 112 finished \tANN training loss 0.001287\n",
      ">> Epoch 113 finished \tANN training loss 0.001284\n",
      ">> Epoch 114 finished \tANN training loss 0.001281\n",
      ">> Epoch 115 finished \tANN training loss 0.001278\n",
      ">> Epoch 116 finished \tANN training loss 0.001275\n",
      ">> Epoch 117 finished \tANN training loss 0.001273\n",
      ">> Epoch 118 finished \tANN training loss 0.001270\n",
      ">> Epoch 119 finished \tANN training loss 0.001267\n",
      ">> Epoch 120 finished \tANN training loss 0.001264\n",
      ">> Epoch 121 finished \tANN training loss 0.001262\n",
      ">> Epoch 122 finished \tANN training loss 0.001259\n",
      ">> Epoch 123 finished \tANN training loss 0.001256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 124 finished \tANN training loss 0.001253\n",
      ">> Epoch 125 finished \tANN training loss 0.001251\n",
      ">> Epoch 126 finished \tANN training loss 0.001248\n",
      ">> Epoch 127 finished \tANN training loss 0.001245\n",
      ">> Epoch 128 finished \tANN training loss 0.001243\n",
      ">> Epoch 129 finished \tANN training loss 0.001240\n",
      ">> Epoch 130 finished \tANN training loss 0.001237\n",
      ">> Epoch 131 finished \tANN training loss 0.001235\n",
      ">> Epoch 132 finished \tANN training loss 0.001232\n",
      ">> Epoch 133 finished \tANN training loss 0.001230\n",
      ">> Epoch 134 finished \tANN training loss 0.001227\n",
      ">> Epoch 135 finished \tANN training loss 0.001224\n",
      ">> Epoch 136 finished \tANN training loss 0.001222\n",
      ">> Epoch 137 finished \tANN training loss 0.001219\n",
      ">> Epoch 138 finished \tANN training loss 0.001217\n",
      ">> Epoch 139 finished \tANN training loss 0.001214\n",
      ">> Epoch 140 finished \tANN training loss 0.001212\n",
      ">> Epoch 141 finished \tANN training loss 0.001209\n",
      ">> Epoch 142 finished \tANN training loss 0.001207\n",
      ">> Epoch 143 finished \tANN training loss 0.001204\n",
      ">> Epoch 144 finished \tANN training loss 0.001202\n",
      ">> Epoch 145 finished \tANN training loss 0.001199\n",
      ">> Epoch 146 finished \tANN training loss 0.001197\n",
      ">> Epoch 147 finished \tANN training loss 0.001194\n",
      ">> Epoch 148 finished \tANN training loss 0.001192\n",
      ">> Epoch 149 finished \tANN training loss 0.001189\n",
      ">> Epoch 150 finished \tANN training loss 0.001187\n",
      "[END] Fine tuning step\n",
      "############### End Training for HINDPETROEQ #####################\n",
      "############### End Training for TATAMOTORSEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 3.069895\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 3.011667\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 2.953210\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 2.894395\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 2.835116\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 2.775137\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 2.714413\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 2.652742\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 2.589920\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 2.525760\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 2.460199\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 2.393040\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 2.324215\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 2.253558\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 2.180911\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 2.106211\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 2.029485\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 1.950740\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 1.870001\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 1.787278\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 1.702975\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 1.617136\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 1.530204\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 1.442642\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 1.354895\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 1.267714\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 1.181631\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 1.097352\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 1.015174\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 0.935936\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 0.860953\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 0.789642\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.723381\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.662000\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.606473\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.556281\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.511198\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.471049\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.435820\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.405258\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.378808\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.356546\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.337249\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.320095\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.305557\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.293225\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.282136\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.272721\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.264352\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.257535\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.250535\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.244681\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.238988\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.233638\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.229265\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.224901\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.220753\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.216673\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.212861\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.209674\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.206209\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.203029\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.199873\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.196648\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.193672\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.190686\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.188023\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.185035\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.182181\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.179383\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.176660\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.173919\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.171447\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.168933\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.166423\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.163983\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.161427\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.159424\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.156980\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.154693\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.152496\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.150264\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.148104\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.145961\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.143824\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.141602\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.139541\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.137521\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.135610\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.133546\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.131701\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.129876\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.127954\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.126100\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.124316\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.122537\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.120879\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.119093\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.117257\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.115584\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.039035\n",
      ">> Epoch 2 finished \tANN training loss 0.033687\n",
      ">> Epoch 3 finished \tANN training loss 0.029185\n",
      ">> Epoch 4 finished \tANN training loss 0.025390\n",
      ">> Epoch 5 finished \tANN training loss 0.022186\n",
      ">> Epoch 6 finished \tANN training loss 0.019480\n",
      ">> Epoch 7 finished \tANN training loss 0.017189\n",
      ">> Epoch 8 finished \tANN training loss 0.015249\n",
      ">> Epoch 9 finished \tANN training loss 0.013604\n",
      ">> Epoch 10 finished \tANN training loss 0.012207\n",
      ">> Epoch 11 finished \tANN training loss 0.011018\n",
      ">> Epoch 12 finished \tANN training loss 0.010006\n",
      ">> Epoch 13 finished \tANN training loss 0.009141\n",
      ">> Epoch 14 finished \tANN training loss 0.008402\n",
      ">> Epoch 15 finished \tANN training loss 0.007767\n",
      ">> Epoch 16 finished \tANN training loss 0.007221\n",
      ">> Epoch 17 finished \tANN training loss 0.006750\n",
      ">> Epoch 18 finished \tANN training loss 0.006342\n",
      ">> Epoch 19 finished \tANN training loss 0.005988\n",
      ">> Epoch 20 finished \tANN training loss 0.005678\n",
      ">> Epoch 21 finished \tANN training loss 0.005406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 22 finished \tANN training loss 0.005167\n",
      ">> Epoch 23 finished \tANN training loss 0.004955\n",
      ">> Epoch 24 finished \tANN training loss 0.004767\n",
      ">> Epoch 25 finished \tANN training loss 0.004598\n",
      ">> Epoch 26 finished \tANN training loss 0.004446\n",
      ">> Epoch 27 finished \tANN training loss 0.004308\n",
      ">> Epoch 28 finished \tANN training loss 0.004182\n",
      ">> Epoch 29 finished \tANN training loss 0.004067\n",
      ">> Epoch 30 finished \tANN training loss 0.003961\n",
      ">> Epoch 31 finished \tANN training loss 0.003863\n",
      ">> Epoch 32 finished \tANN training loss 0.003771\n",
      ">> Epoch 33 finished \tANN training loss 0.003686\n",
      ">> Epoch 34 finished \tANN training loss 0.003605\n",
      ">> Epoch 35 finished \tANN training loss 0.003529\n",
      ">> Epoch 36 finished \tANN training loss 0.003456\n",
      ">> Epoch 37 finished \tANN training loss 0.003388\n",
      ">> Epoch 38 finished \tANN training loss 0.003322\n",
      ">> Epoch 39 finished \tANN training loss 0.003259\n",
      ">> Epoch 40 finished \tANN training loss 0.003199\n",
      ">> Epoch 41 finished \tANN training loss 0.003140\n",
      ">> Epoch 42 finished \tANN training loss 0.003084\n",
      ">> Epoch 43 finished \tANN training loss 0.003030\n",
      ">> Epoch 44 finished \tANN training loss 0.002978\n",
      ">> Epoch 45 finished \tANN training loss 0.002927\n",
      ">> Epoch 46 finished \tANN training loss 0.002877\n",
      ">> Epoch 47 finished \tANN training loss 0.002829\n",
      ">> Epoch 48 finished \tANN training loss 0.002783\n",
      ">> Epoch 49 finished \tANN training loss 0.002737\n",
      ">> Epoch 50 finished \tANN training loss 0.002693\n",
      ">> Epoch 51 finished \tANN training loss 0.002650\n",
      ">> Epoch 52 finished \tANN training loss 0.002607\n",
      ">> Epoch 53 finished \tANN training loss 0.002566\n",
      ">> Epoch 54 finished \tANN training loss 0.002526\n",
      ">> Epoch 55 finished \tANN training loss 0.002487\n",
      ">> Epoch 56 finished \tANN training loss 0.002449\n",
      ">> Epoch 57 finished \tANN training loss 0.002411\n",
      ">> Epoch 58 finished \tANN training loss 0.002375\n",
      ">> Epoch 59 finished \tANN training loss 0.002339\n",
      ">> Epoch 60 finished \tANN training loss 0.002304\n",
      ">> Epoch 61 finished \tANN training loss 0.002270\n",
      ">> Epoch 62 finished \tANN training loss 0.002237\n",
      ">> Epoch 63 finished \tANN training loss 0.002204\n",
      ">> Epoch 64 finished \tANN training loss 0.002172\n",
      ">> Epoch 65 finished \tANN training loss 0.002141\n",
      ">> Epoch 66 finished \tANN training loss 0.002111\n",
      ">> Epoch 67 finished \tANN training loss 0.002081\n",
      ">> Epoch 68 finished \tANN training loss 0.002052\n",
      ">> Epoch 69 finished \tANN training loss 0.002023\n",
      ">> Epoch 70 finished \tANN training loss 0.001995\n",
      ">> Epoch 71 finished \tANN training loss 0.001968\n",
      ">> Epoch 72 finished \tANN training loss 0.001941\n",
      ">> Epoch 73 finished \tANN training loss 0.001915\n",
      ">> Epoch 74 finished \tANN training loss 0.001889\n",
      ">> Epoch 75 finished \tANN training loss 0.001864\n",
      ">> Epoch 76 finished \tANN training loss 0.001839\n",
      ">> Epoch 77 finished \tANN training loss 0.001815\n",
      ">> Epoch 78 finished \tANN training loss 0.001792\n",
      ">> Epoch 79 finished \tANN training loss 0.001769\n",
      ">> Epoch 80 finished \tANN training loss 0.001746\n",
      ">> Epoch 81 finished \tANN training loss 0.001724\n",
      ">> Epoch 82 finished \tANN training loss 0.001702\n",
      ">> Epoch 83 finished \tANN training loss 0.001681\n",
      ">> Epoch 84 finished \tANN training loss 0.001660\n",
      ">> Epoch 85 finished \tANN training loss 0.001640\n",
      ">> Epoch 86 finished \tANN training loss 0.001620\n",
      ">> Epoch 87 finished \tANN training loss 0.001600\n",
      ">> Epoch 88 finished \tANN training loss 0.001581\n",
      ">> Epoch 89 finished \tANN training loss 0.001563\n",
      ">> Epoch 90 finished \tANN training loss 0.001544\n",
      ">> Epoch 91 finished \tANN training loss 0.001526\n",
      ">> Epoch 92 finished \tANN training loss 0.001509\n",
      ">> Epoch 93 finished \tANN training loss 0.001492\n",
      ">> Epoch 94 finished \tANN training loss 0.001475\n",
      ">> Epoch 95 finished \tANN training loss 0.001458\n",
      ">> Epoch 96 finished \tANN training loss 0.001442\n",
      ">> Epoch 97 finished \tANN training loss 0.001426\n",
      ">> Epoch 98 finished \tANN training loss 0.001411\n",
      ">> Epoch 99 finished \tANN training loss 0.001395\n",
      ">> Epoch 100 finished \tANN training loss 0.001381\n",
      ">> Epoch 101 finished \tANN training loss 0.001366\n",
      ">> Epoch 102 finished \tANN training loss 0.001352\n",
      ">> Epoch 103 finished \tANN training loss 0.001338\n",
      ">> Epoch 104 finished \tANN training loss 0.001324\n",
      ">> Epoch 105 finished \tANN training loss 0.001310\n",
      ">> Epoch 106 finished \tANN training loss 0.001297\n",
      ">> Epoch 107 finished \tANN training loss 0.001284\n",
      ">> Epoch 108 finished \tANN training loss 0.001272\n",
      ">> Epoch 109 finished \tANN training loss 0.001259\n",
      ">> Epoch 110 finished \tANN training loss 0.001247\n",
      ">> Epoch 111 finished \tANN training loss 0.001235\n",
      ">> Epoch 112 finished \tANN training loss 0.001223\n",
      ">> Epoch 113 finished \tANN training loss 0.001212\n",
      ">> Epoch 114 finished \tANN training loss 0.001201\n",
      ">> Epoch 115 finished \tANN training loss 0.001190\n",
      ">> Epoch 116 finished \tANN training loss 0.001179\n",
      ">> Epoch 117 finished \tANN training loss 0.001168\n",
      ">> Epoch 118 finished \tANN training loss 0.001158\n",
      ">> Epoch 119 finished \tANN training loss 0.001148\n",
      ">> Epoch 120 finished \tANN training loss 0.001138\n",
      ">> Epoch 121 finished \tANN training loss 0.001128\n",
      ">> Epoch 122 finished \tANN training loss 0.001119\n",
      ">> Epoch 123 finished \tANN training loss 0.001109\n",
      ">> Epoch 124 finished \tANN training loss 0.001100\n",
      ">> Epoch 125 finished \tANN training loss 0.001091\n",
      ">> Epoch 126 finished \tANN training loss 0.001082\n",
      ">> Epoch 127 finished \tANN training loss 0.001074\n",
      ">> Epoch 128 finished \tANN training loss 0.001065\n",
      ">> Epoch 129 finished \tANN training loss 0.001057\n",
      ">> Epoch 130 finished \tANN training loss 0.001049\n",
      ">> Epoch 131 finished \tANN training loss 0.001041\n",
      ">> Epoch 132 finished \tANN training loss 0.001033\n",
      ">> Epoch 133 finished \tANN training loss 0.001025\n",
      ">> Epoch 134 finished \tANN training loss 0.001018\n",
      ">> Epoch 135 finished \tANN training loss 0.001010\n",
      ">> Epoch 136 finished \tANN training loss 0.001003\n",
      ">> Epoch 137 finished \tANN training loss 0.000996\n",
      ">> Epoch 138 finished \tANN training loss 0.000989\n",
      ">> Epoch 139 finished \tANN training loss 0.000982\n",
      ">> Epoch 140 finished \tANN training loss 0.000976\n",
      ">> Epoch 141 finished \tANN training loss 0.000969\n",
      ">> Epoch 142 finished \tANN training loss 0.000963\n",
      ">> Epoch 143 finished \tANN training loss 0.000956\n",
      ">> Epoch 144 finished \tANN training loss 0.000950\n",
      ">> Epoch 145 finished \tANN training loss 0.000944\n",
      ">> Epoch 146 finished \tANN training loss 0.000938\n",
      ">> Epoch 147 finished \tANN training loss 0.000932\n",
      ">> Epoch 148 finished \tANN training loss 0.000927\n",
      ">> Epoch 149 finished \tANN training loss 0.000921\n",
      ">> Epoch 150 finished \tANN training loss 0.000916\n",
      "[END] Fine tuning step\n",
      "############### End Training for TATAMOTORSEQ #####################\n",
      "############### End Training for ORIENTBANKEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 6.998703\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 6.823131\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 6.636472\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 6.435869\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 6.217699\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 5.977972\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 5.711966\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 5.414881\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 5.082296\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 4.710428\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 4.297995\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 3.845912\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 3.361286\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 2.857034\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 2.352052\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 1.874241\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 1.448388\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 1.089842\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 0.809782\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 0.610230\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 0.474427\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 0.386278\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 0.333085\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 0.302080\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 0.282277\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 0.270663\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 0.262927\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 0.257326\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 0.252946\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 0.248980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 31 finished \tRBM Reconstruction error 0.245573\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 0.242339\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.239350\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.236657\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.233692\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.230847\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.228496\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.225954\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.223290\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.220903\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.218959\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.216641\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.214624\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.212267\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.210355\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.208147\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.205955\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.204160\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.202194\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.199955\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.198265\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.196083\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.194289\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.192763\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.190615\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.189105\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.186942\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.185261\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.183158\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.181855\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.179855\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.178301\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.177151\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.175595\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.174400\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.172454\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.170515\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.169372\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.168122\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.166830\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.165410\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.163949\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.162769\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.161201\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.160117\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.158622\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.157722\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.156541\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.155708\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.154603\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.153551\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.151398\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.150431\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.149107\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.147581\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.146198\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.145539\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.144393\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.143506\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.143470\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.142093\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.140830\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.140590\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.139763\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.138860\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.137660\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.136524\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.135480\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.134418\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.133698\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.156469\n",
      ">> Epoch 2 finished \tANN training loss 0.110508\n",
      ">> Epoch 3 finished \tANN training loss 0.078366\n",
      ">> Epoch 4 finished \tANN training loss 0.055975\n",
      ">> Epoch 5 finished \tANN training loss 0.040315\n",
      ">> Epoch 6 finished \tANN training loss 0.029354\n",
      ">> Epoch 7 finished \tANN training loss 0.021679\n",
      ">> Epoch 8 finished \tANN training loss 0.016307\n",
      ">> Epoch 9 finished \tANN training loss 0.012549\n",
      ">> Epoch 10 finished \tANN training loss 0.009919\n",
      ">> Epoch 11 finished \tANN training loss 0.008080\n",
      ">> Epoch 12 finished \tANN training loss 0.006792\n",
      ">> Epoch 13 finished \tANN training loss 0.005889\n",
      ">> Epoch 14 finished \tANN training loss 0.005255\n",
      ">> Epoch 15 finished \tANN training loss 0.004809\n",
      ">> Epoch 16 finished \tANN training loss 0.004494\n",
      ">> Epoch 17 finished \tANN training loss 0.004271\n",
      ">> Epoch 18 finished \tANN training loss 0.004111\n",
      ">> Epoch 19 finished \tANN training loss 0.003996\n",
      ">> Epoch 20 finished \tANN training loss 0.003911\n",
      ">> Epoch 21 finished \tANN training loss 0.003848\n",
      ">> Epoch 22 finished \tANN training loss 0.003801\n",
      ">> Epoch 23 finished \tANN training loss 0.003764\n",
      ">> Epoch 24 finished \tANN training loss 0.003735\n",
      ">> Epoch 25 finished \tANN training loss 0.003712\n",
      ">> Epoch 26 finished \tANN training loss 0.003692\n",
      ">> Epoch 27 finished \tANN training loss 0.003674\n",
      ">> Epoch 28 finished \tANN training loss 0.003659\n",
      ">> Epoch 29 finished \tANN training loss 0.003644\n",
      ">> Epoch 30 finished \tANN training loss 0.003631\n",
      ">> Epoch 31 finished \tANN training loss 0.003618\n",
      ">> Epoch 32 finished \tANN training loss 0.003606\n",
      ">> Epoch 33 finished \tANN training loss 0.003594\n",
      ">> Epoch 34 finished \tANN training loss 0.003583\n",
      ">> Epoch 35 finished \tANN training loss 0.003571\n",
      ">> Epoch 36 finished \tANN training loss 0.003560\n",
      ">> Epoch 37 finished \tANN training loss 0.003550\n",
      ">> Epoch 38 finished \tANN training loss 0.003539\n",
      ">> Epoch 39 finished \tANN training loss 0.003528\n",
      ">> Epoch 40 finished \tANN training loss 0.003518\n",
      ">> Epoch 41 finished \tANN training loss 0.003507\n",
      ">> Epoch 42 finished \tANN training loss 0.003497\n",
      ">> Epoch 43 finished \tANN training loss 0.003487\n",
      ">> Epoch 44 finished \tANN training loss 0.003477\n",
      ">> Epoch 45 finished \tANN training loss 0.003467\n",
      ">> Epoch 46 finished \tANN training loss 0.003457\n",
      ">> Epoch 47 finished \tANN training loss 0.003447\n",
      ">> Epoch 48 finished \tANN training loss 0.003438\n",
      ">> Epoch 49 finished \tANN training loss 0.003429\n",
      ">> Epoch 50 finished \tANN training loss 0.003420\n",
      ">> Epoch 51 finished \tANN training loss 0.003411\n",
      ">> Epoch 52 finished \tANN training loss 0.003402\n",
      ">> Epoch 53 finished \tANN training loss 0.003394\n",
      ">> Epoch 54 finished \tANN training loss 0.003386\n",
      ">> Epoch 55 finished \tANN training loss 0.003377\n",
      ">> Epoch 56 finished \tANN training loss 0.003370\n",
      ">> Epoch 57 finished \tANN training loss 0.003362\n",
      ">> Epoch 58 finished \tANN training loss 0.003354\n",
      ">> Epoch 59 finished \tANN training loss 0.003347\n",
      ">> Epoch 60 finished \tANN training loss 0.003340\n",
      ">> Epoch 61 finished \tANN training loss 0.003333\n",
      ">> Epoch 62 finished \tANN training loss 0.003326\n",
      ">> Epoch 63 finished \tANN training loss 0.003319\n",
      ">> Epoch 64 finished \tANN training loss 0.003312\n",
      ">> Epoch 65 finished \tANN training loss 0.003305\n",
      ">> Epoch 66 finished \tANN training loss 0.003299\n",
      ">> Epoch 67 finished \tANN training loss 0.003292\n",
      ">> Epoch 68 finished \tANN training loss 0.003286\n",
      ">> Epoch 69 finished \tANN training loss 0.003280\n",
      ">> Epoch 70 finished \tANN training loss 0.003274\n",
      ">> Epoch 71 finished \tANN training loss 0.003268\n",
      ">> Epoch 72 finished \tANN training loss 0.003262\n",
      ">> Epoch 73 finished \tANN training loss 0.003256\n",
      ">> Epoch 74 finished \tANN training loss 0.003250\n",
      ">> Epoch 75 finished \tANN training loss 0.003244\n",
      ">> Epoch 76 finished \tANN training loss 0.003238\n",
      ">> Epoch 77 finished \tANN training loss 0.003233\n",
      ">> Epoch 78 finished \tANN training loss 0.003227\n",
      ">> Epoch 79 finished \tANN training loss 0.003222\n",
      ">> Epoch 80 finished \tANN training loss 0.003217\n",
      ">> Epoch 81 finished \tANN training loss 0.003211\n",
      ">> Epoch 82 finished \tANN training loss 0.003206\n",
      ">> Epoch 83 finished \tANN training loss 0.003201\n",
      ">> Epoch 84 finished \tANN training loss 0.003196\n",
      ">> Epoch 85 finished \tANN training loss 0.003191\n",
      ">> Epoch 86 finished \tANN training loss 0.003186\n",
      ">> Epoch 87 finished \tANN training loss 0.003181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 88 finished \tANN training loss 0.003176\n",
      ">> Epoch 89 finished \tANN training loss 0.003171\n",
      ">> Epoch 90 finished \tANN training loss 0.003166\n",
      ">> Epoch 91 finished \tANN training loss 0.003161\n",
      ">> Epoch 92 finished \tANN training loss 0.003157\n",
      ">> Epoch 93 finished \tANN training loss 0.003152\n",
      ">> Epoch 94 finished \tANN training loss 0.003147\n",
      ">> Epoch 95 finished \tANN training loss 0.003143\n",
      ">> Epoch 96 finished \tANN training loss 0.003138\n",
      ">> Epoch 97 finished \tANN training loss 0.003134\n",
      ">> Epoch 98 finished \tANN training loss 0.003129\n",
      ">> Epoch 99 finished \tANN training loss 0.003125\n",
      ">> Epoch 100 finished \tANN training loss 0.003121\n",
      ">> Epoch 101 finished \tANN training loss 0.003116\n",
      ">> Epoch 102 finished \tANN training loss 0.003112\n",
      ">> Epoch 103 finished \tANN training loss 0.003108\n",
      ">> Epoch 104 finished \tANN training loss 0.003103\n",
      ">> Epoch 105 finished \tANN training loss 0.003099\n",
      ">> Epoch 106 finished \tANN training loss 0.003095\n",
      ">> Epoch 107 finished \tANN training loss 0.003091\n",
      ">> Epoch 108 finished \tANN training loss 0.003087\n",
      ">> Epoch 109 finished \tANN training loss 0.003083\n",
      ">> Epoch 110 finished \tANN training loss 0.003079\n",
      ">> Epoch 111 finished \tANN training loss 0.003075\n",
      ">> Epoch 112 finished \tANN training loss 0.003071\n",
      ">> Epoch 113 finished \tANN training loss 0.003067\n",
      ">> Epoch 114 finished \tANN training loss 0.003063\n",
      ">> Epoch 115 finished \tANN training loss 0.003059\n",
      ">> Epoch 116 finished \tANN training loss 0.003055\n",
      ">> Epoch 117 finished \tANN training loss 0.003051\n",
      ">> Epoch 118 finished \tANN training loss 0.003047\n",
      ">> Epoch 119 finished \tANN training loss 0.003043\n",
      ">> Epoch 120 finished \tANN training loss 0.003039\n",
      ">> Epoch 121 finished \tANN training loss 0.003036\n",
      ">> Epoch 122 finished \tANN training loss 0.003032\n",
      ">> Epoch 123 finished \tANN training loss 0.003028\n",
      ">> Epoch 124 finished \tANN training loss 0.003024\n",
      ">> Epoch 125 finished \tANN training loss 0.003020\n",
      ">> Epoch 126 finished \tANN training loss 0.003017\n",
      ">> Epoch 127 finished \tANN training loss 0.003013\n",
      ">> Epoch 128 finished \tANN training loss 0.003009\n",
      ">> Epoch 129 finished \tANN training loss 0.003006\n",
      ">> Epoch 130 finished \tANN training loss 0.003002\n",
      ">> Epoch 131 finished \tANN training loss 0.002998\n",
      ">> Epoch 132 finished \tANN training loss 0.002995\n",
      ">> Epoch 133 finished \tANN training loss 0.002991\n",
      ">> Epoch 134 finished \tANN training loss 0.002988\n",
      ">> Epoch 135 finished \tANN training loss 0.002984\n",
      ">> Epoch 136 finished \tANN training loss 0.002981\n",
      ">> Epoch 137 finished \tANN training loss 0.002977\n",
      ">> Epoch 138 finished \tANN training loss 0.002974\n",
      ">> Epoch 139 finished \tANN training loss 0.002971\n",
      ">> Epoch 140 finished \tANN training loss 0.002967\n",
      ">> Epoch 141 finished \tANN training loss 0.002964\n",
      ">> Epoch 142 finished \tANN training loss 0.002961\n",
      ">> Epoch 143 finished \tANN training loss 0.002957\n",
      ">> Epoch 144 finished \tANN training loss 0.002954\n",
      ">> Epoch 145 finished \tANN training loss 0.002951\n",
      ">> Epoch 146 finished \tANN training loss 0.002948\n",
      ">> Epoch 147 finished \tANN training loss 0.002945\n",
      ">> Epoch 148 finished \tANN training loss 0.002941\n",
      ">> Epoch 149 finished \tANN training loss 0.002938\n",
      ">> Epoch 150 finished \tANN training loss 0.002935\n",
      "[END] Fine tuning step\n",
      "############### End Training for ORIENTBANKEQ #####################\n",
      "############### End Training for MCXEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 17.055010\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 16.830543\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 16.590638\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 16.332916\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 16.054541\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 15.752253\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 15.422486\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 15.061219\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 14.664038\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 14.225726\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 13.742396\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 13.208836\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 12.619234\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 11.971857\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 11.263262\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 10.493051\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 9.661571\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 8.776192\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 7.848464\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 6.890031\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 5.926954\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 4.985177\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 4.088639\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 3.258738\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 2.531264\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 1.907907\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 1.405224\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 1.018616\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 0.736671\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 0.542704\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 0.424255\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 0.358217\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.333723\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.336129\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.354980\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.380802\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.410658\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.442923\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.468716\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.493294\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.518719\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.539748\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.555508\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.566377\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.577777\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.590868\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.596847\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.602792\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.610027\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.611613\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.615632\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.624207\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.626358\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.625745\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.631250\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.632063\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.630141\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.626849\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.629620\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.630822\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.631295\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.630900\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.634221\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.632871\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.633163\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.634149\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.632888\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.629658\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.624227\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.620874\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.626838\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.629260\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.635793\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.637228\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.637042\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.638518\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.633004\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.632143\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.635565\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.638689\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.641229\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.644154\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.646996\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.645324\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.644362\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.643918\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.643914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 88 finished \tRBM Reconstruction error 0.644532\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.642226\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.639361\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.639288\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.635484\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.636458\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.636121\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.639656\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.638777\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.640405\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.640590\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.641625\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.643878\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.173314\n",
      ">> Epoch 2 finished \tANN training loss 0.137653\n",
      ">> Epoch 3 finished \tANN training loss 0.109634\n",
      ">> Epoch 4 finished \tANN training loss 0.087627\n",
      ">> Epoch 5 finished \tANN training loss 0.070348\n",
      ">> Epoch 6 finished \tANN training loss 0.056798\n",
      ">> Epoch 7 finished \tANN training loss 0.046180\n",
      ">> Epoch 8 finished \tANN training loss 0.037861\n",
      ">> Epoch 9 finished \tANN training loss 0.031344\n",
      ">> Epoch 10 finished \tANN training loss 0.026242\n",
      ">> Epoch 11 finished \tANN training loss 0.022247\n",
      ">> Epoch 12 finished \tANN training loss 0.019118\n",
      ">> Epoch 13 finished \tANN training loss 0.016669\n",
      ">> Epoch 14 finished \tANN training loss 0.014754\n",
      ">> Epoch 15 finished \tANN training loss 0.013256\n",
      ">> Epoch 16 finished \tANN training loss 0.012082\n",
      ">> Epoch 17 finished \tANN training loss 0.011165\n",
      ">> Epoch 18 finished \tANN training loss 0.010446\n",
      ">> Epoch 19 finished \tANN training loss 0.009885\n",
      ">> Epoch 20 finished \tANN training loss 0.009445\n",
      ">> Epoch 21 finished \tANN training loss 0.009100\n",
      ">> Epoch 22 finished \tANN training loss 0.008830\n",
      ">> Epoch 23 finished \tANN training loss 0.008617\n",
      ">> Epoch 24 finished \tANN training loss 0.008450\n",
      ">> Epoch 25 finished \tANN training loss 0.008319\n",
      ">> Epoch 26 finished \tANN training loss 0.008215\n",
      ">> Epoch 27 finished \tANN training loss 0.008134\n",
      ">> Epoch 28 finished \tANN training loss 0.008069\n",
      ">> Epoch 29 finished \tANN training loss 0.008017\n",
      ">> Epoch 30 finished \tANN training loss 0.007976\n",
      ">> Epoch 31 finished \tANN training loss 0.007942\n",
      ">> Epoch 32 finished \tANN training loss 0.007915\n",
      ">> Epoch 33 finished \tANN training loss 0.007893\n",
      ">> Epoch 34 finished \tANN training loss 0.007875\n",
      ">> Epoch 35 finished \tANN training loss 0.007860\n",
      ">> Epoch 36 finished \tANN training loss 0.007847\n",
      ">> Epoch 37 finished \tANN training loss 0.007836\n",
      ">> Epoch 38 finished \tANN training loss 0.007827\n",
      ">> Epoch 39 finished \tANN training loss 0.007818\n",
      ">> Epoch 40 finished \tANN training loss 0.007811\n",
      ">> Epoch 41 finished \tANN training loss 0.007804\n",
      ">> Epoch 42 finished \tANN training loss 0.007798\n",
      ">> Epoch 43 finished \tANN training loss 0.007793\n",
      ">> Epoch 44 finished \tANN training loss 0.007787\n",
      ">> Epoch 45 finished \tANN training loss 0.007782\n",
      ">> Epoch 46 finished \tANN training loss 0.007777\n",
      ">> Epoch 47 finished \tANN training loss 0.007772\n",
      ">> Epoch 48 finished \tANN training loss 0.007767\n",
      ">> Epoch 49 finished \tANN training loss 0.007762\n",
      ">> Epoch 50 finished \tANN training loss 0.007758\n",
      ">> Epoch 51 finished \tANN training loss 0.007754\n",
      ">> Epoch 52 finished \tANN training loss 0.007749\n",
      ">> Epoch 53 finished \tANN training loss 0.007744\n",
      ">> Epoch 54 finished \tANN training loss 0.007740\n",
      ">> Epoch 55 finished \tANN training loss 0.007736\n",
      ">> Epoch 56 finished \tANN training loss 0.007732\n",
      ">> Epoch 57 finished \tANN training loss 0.007727\n",
      ">> Epoch 58 finished \tANN training loss 0.007723\n",
      ">> Epoch 59 finished \tANN training loss 0.007718\n",
      ">> Epoch 60 finished \tANN training loss 0.007714\n",
      ">> Epoch 61 finished \tANN training loss 0.007710\n",
      ">> Epoch 62 finished \tANN training loss 0.007706\n",
      ">> Epoch 63 finished \tANN training loss 0.007701\n",
      ">> Epoch 64 finished \tANN training loss 0.007697\n",
      ">> Epoch 65 finished \tANN training loss 0.007693\n",
      ">> Epoch 66 finished \tANN training loss 0.007689\n",
      ">> Epoch 67 finished \tANN training loss 0.007684\n",
      ">> Epoch 68 finished \tANN training loss 0.007681\n",
      ">> Epoch 69 finished \tANN training loss 0.007676\n",
      ">> Epoch 70 finished \tANN training loss 0.007672\n",
      ">> Epoch 71 finished \tANN training loss 0.007667\n",
      ">> Epoch 72 finished \tANN training loss 0.007663\n",
      ">> Epoch 73 finished \tANN training loss 0.007659\n",
      ">> Epoch 74 finished \tANN training loss 0.007655\n",
      ">> Epoch 75 finished \tANN training loss 0.007651\n",
      ">> Epoch 76 finished \tANN training loss 0.007646\n",
      ">> Epoch 77 finished \tANN training loss 0.007643\n",
      ">> Epoch 78 finished \tANN training loss 0.007638\n",
      ">> Epoch 79 finished \tANN training loss 0.007634\n",
      ">> Epoch 80 finished \tANN training loss 0.007630\n",
      ">> Epoch 81 finished \tANN training loss 0.007626\n",
      ">> Epoch 82 finished \tANN training loss 0.007622\n",
      ">> Epoch 83 finished \tANN training loss 0.007617\n",
      ">> Epoch 84 finished \tANN training loss 0.007614\n",
      ">> Epoch 85 finished \tANN training loss 0.007609\n",
      ">> Epoch 86 finished \tANN training loss 0.007605\n",
      ">> Epoch 87 finished \tANN training loss 0.007601\n",
      ">> Epoch 88 finished \tANN training loss 0.007597\n",
      ">> Epoch 89 finished \tANN training loss 0.007593\n",
      ">> Epoch 90 finished \tANN training loss 0.007589\n",
      ">> Epoch 91 finished \tANN training loss 0.007585\n",
      ">> Epoch 92 finished \tANN training loss 0.007581\n",
      ">> Epoch 93 finished \tANN training loss 0.007576\n",
      ">> Epoch 94 finished \tANN training loss 0.007573\n",
      ">> Epoch 95 finished \tANN training loss 0.007569\n",
      ">> Epoch 96 finished \tANN training loss 0.007564\n",
      ">> Epoch 97 finished \tANN training loss 0.007560\n",
      ">> Epoch 98 finished \tANN training loss 0.007556\n",
      ">> Epoch 99 finished \tANN training loss 0.007552\n",
      ">> Epoch 100 finished \tANN training loss 0.007548\n",
      ">> Epoch 101 finished \tANN training loss 0.007543\n",
      ">> Epoch 102 finished \tANN training loss 0.007539\n",
      ">> Epoch 103 finished \tANN training loss 0.007535\n",
      ">> Epoch 104 finished \tANN training loss 0.007531\n",
      ">> Epoch 105 finished \tANN training loss 0.007527\n",
      ">> Epoch 106 finished \tANN training loss 0.007523\n",
      ">> Epoch 107 finished \tANN training loss 0.007519\n",
      ">> Epoch 108 finished \tANN training loss 0.007515\n",
      ">> Epoch 109 finished \tANN training loss 0.007510\n",
      ">> Epoch 110 finished \tANN training loss 0.007506\n",
      ">> Epoch 111 finished \tANN training loss 0.007502\n",
      ">> Epoch 112 finished \tANN training loss 0.007498\n",
      ">> Epoch 113 finished \tANN training loss 0.007493\n",
      ">> Epoch 114 finished \tANN training loss 0.007490\n",
      ">> Epoch 115 finished \tANN training loss 0.007485\n",
      ">> Epoch 116 finished \tANN training loss 0.007481\n",
      ">> Epoch 117 finished \tANN training loss 0.007476\n",
      ">> Epoch 118 finished \tANN training loss 0.007472\n",
      ">> Epoch 119 finished \tANN training loss 0.007468\n",
      ">> Epoch 120 finished \tANN training loss 0.007464\n",
      ">> Epoch 121 finished \tANN training loss 0.007459\n",
      ">> Epoch 122 finished \tANN training loss 0.007455\n",
      ">> Epoch 123 finished \tANN training loss 0.007450\n",
      ">> Epoch 124 finished \tANN training loss 0.007446\n",
      ">> Epoch 125 finished \tANN training loss 0.007441\n",
      ">> Epoch 126 finished \tANN training loss 0.007437\n",
      ">> Epoch 127 finished \tANN training loss 0.007432\n",
      ">> Epoch 128 finished \tANN training loss 0.007428\n",
      ">> Epoch 129 finished \tANN training loss 0.007423\n",
      ">> Epoch 130 finished \tANN training loss 0.007419\n",
      ">> Epoch 131 finished \tANN training loss 0.007414\n",
      ">> Epoch 132 finished \tANN training loss 0.007409\n",
      ">> Epoch 133 finished \tANN training loss 0.007404\n",
      ">> Epoch 134 finished \tANN training loss 0.007400\n",
      ">> Epoch 135 finished \tANN training loss 0.007395\n",
      ">> Epoch 136 finished \tANN training loss 0.007390\n",
      ">> Epoch 137 finished \tANN training loss 0.007386\n",
      ">> Epoch 138 finished \tANN training loss 0.007381\n",
      ">> Epoch 139 finished \tANN training loss 0.007376\n",
      ">> Epoch 140 finished \tANN training loss 0.007371\n",
      ">> Epoch 141 finished \tANN training loss 0.007367\n",
      ">> Epoch 142 finished \tANN training loss 0.007362\n",
      ">> Epoch 143 finished \tANN training loss 0.007357\n",
      ">> Epoch 144 finished \tANN training loss 0.007352\n",
      ">> Epoch 145 finished \tANN training loss 0.007348\n",
      ">> Epoch 146 finished \tANN training loss 0.007344\n",
      ">> Epoch 147 finished \tANN training loss 0.007339\n",
      ">> Epoch 148 finished \tANN training loss 0.007334\n",
      ">> Epoch 149 finished \tANN training loss 0.007330\n",
      ">> Epoch 150 finished \tANN training loss 0.007325\n",
      "[END] Fine tuning step\n",
      "############### End Training for MCXEQ #####################\n",
      "############### End Training for DHFLEQ #####################\n",
      "[START] Pre-training step:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 1 finished \tRBM Reconstruction error 0.484939\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 0.479931\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 0.475030\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 0.470225\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 0.465526\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 0.460934\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 0.456443\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 0.452039\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 0.447729\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 0.443503\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 0.439377\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 0.435328\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 0.431365\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 0.427491\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 0.423697\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 0.419991\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 0.416353\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 0.412797\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 0.409322\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 0.405914\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 0.402591\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 0.399321\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 0.396126\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 0.393006\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 0.389945\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 0.386941\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 0.384008\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 0.381136\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 0.378318\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 0.375567\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 0.372867\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 0.370229\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.367640\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.365109\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.362632\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.360198\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.357816\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.355491\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.353211\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.350968\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.348775\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.346633\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.344526\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.342469\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.340445\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.338458\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.336508\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.334590\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.332720\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.330892\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.329088\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.327320\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.325582\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.323873\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.322197\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.320544\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.318927\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.317345\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.315786\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.314269\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.312771\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.311304\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.309852\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.308425\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.307030\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.305646\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.304291\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.302953\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.301640\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.300352\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.299080\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.297833\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.296596\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.295381\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.294191\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.293022\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.291856\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.290717\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.289592\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.288481\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.287388\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.286311\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.285246\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.284200\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.283163\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.282148\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.281147\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.280154\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.279168\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.278199\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.277247\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.276299\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.275362\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.274428\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.273514\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.272609\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.271716\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.270827\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.269952\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.269079\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.019003\n",
      ">> Epoch 2 finished \tANN training loss 0.018390\n",
      ">> Epoch 3 finished \tANN training loss 0.017805\n",
      ">> Epoch 4 finished \tANN training loss 0.017245\n",
      ">> Epoch 5 finished \tANN training loss 0.016711\n",
      ">> Epoch 6 finished \tANN training loss 0.016200\n",
      ">> Epoch 7 finished \tANN training loss 0.015712\n",
      ">> Epoch 8 finished \tANN training loss 0.015245\n",
      ">> Epoch 9 finished \tANN training loss 0.014799\n",
      ">> Epoch 10 finished \tANN training loss 0.014372\n",
      ">> Epoch 11 finished \tANN training loss 0.013963\n",
      ">> Epoch 12 finished \tANN training loss 0.013573\n",
      ">> Epoch 13 finished \tANN training loss 0.013199\n",
      ">> Epoch 14 finished \tANN training loss 0.012842\n",
      ">> Epoch 15 finished \tANN training loss 0.012501\n",
      ">> Epoch 16 finished \tANN training loss 0.012174\n",
      ">> Epoch 17 finished \tANN training loss 0.011862\n",
      ">> Epoch 18 finished \tANN training loss 0.011563\n",
      ">> Epoch 19 finished \tANN training loss 0.011277\n",
      ">> Epoch 20 finished \tANN training loss 0.011004\n",
      ">> Epoch 21 finished \tANN training loss 0.010742\n",
      ">> Epoch 22 finished \tANN training loss 0.010491\n",
      ">> Epoch 23 finished \tANN training loss 0.010251\n",
      ">> Epoch 24 finished \tANN training loss 0.010022\n",
      ">> Epoch 25 finished \tANN training loss 0.009801\n",
      ">> Epoch 26 finished \tANN training loss 0.009591\n",
      ">> Epoch 27 finished \tANN training loss 0.009388\n",
      ">> Epoch 28 finished \tANN training loss 0.009194\n",
      ">> Epoch 29 finished \tANN training loss 0.009008\n",
      ">> Epoch 30 finished \tANN training loss 0.008830\n",
      ">> Epoch 31 finished \tANN training loss 0.008658\n",
      ">> Epoch 32 finished \tANN training loss 0.008494\n",
      ">> Epoch 33 finished \tANN training loss 0.008336\n",
      ">> Epoch 34 finished \tANN training loss 0.008184\n",
      ">> Epoch 35 finished \tANN training loss 0.008038\n",
      ">> Epoch 36 finished \tANN training loss 0.007898\n",
      ">> Epoch 37 finished \tANN training loss 0.007763\n",
      ">> Epoch 38 finished \tANN training loss 0.007633\n",
      ">> Epoch 39 finished \tANN training loss 0.007508\n",
      ">> Epoch 40 finished \tANN training loss 0.007388\n",
      ">> Epoch 41 finished \tANN training loss 0.007272\n",
      ">> Epoch 42 finished \tANN training loss 0.007160\n",
      ">> Epoch 43 finished \tANN training loss 0.007053\n",
      ">> Epoch 44 finished \tANN training loss 0.006949\n",
      ">> Epoch 45 finished \tANN training loss 0.006849\n",
      ">> Epoch 46 finished \tANN training loss 0.006753\n",
      ">> Epoch 47 finished \tANN training loss 0.006660\n",
      ">> Epoch 48 finished \tANN training loss 0.006570\n",
      ">> Epoch 49 finished \tANN training loss 0.006483\n",
      ">> Epoch 50 finished \tANN training loss 0.006399\n",
      ">> Epoch 51 finished \tANN training loss 0.006318\n",
      ">> Epoch 52 finished \tANN training loss 0.006240\n",
      ">> Epoch 53 finished \tANN training loss 0.006165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 54 finished \tANN training loss 0.006092\n",
      ">> Epoch 55 finished \tANN training loss 0.006021\n",
      ">> Epoch 56 finished \tANN training loss 0.005953\n",
      ">> Epoch 57 finished \tANN training loss 0.005887\n",
      ">> Epoch 58 finished \tANN training loss 0.005823\n",
      ">> Epoch 59 finished \tANN training loss 0.005761\n",
      ">> Epoch 60 finished \tANN training loss 0.005701\n",
      ">> Epoch 61 finished \tANN training loss 0.005643\n",
      ">> Epoch 62 finished \tANN training loss 0.005586\n",
      ">> Epoch 63 finished \tANN training loss 0.005532\n",
      ">> Epoch 64 finished \tANN training loss 0.005479\n",
      ">> Epoch 65 finished \tANN training loss 0.005427\n",
      ">> Epoch 66 finished \tANN training loss 0.005377\n",
      ">> Epoch 67 finished \tANN training loss 0.005329\n",
      ">> Epoch 68 finished \tANN training loss 0.005282\n",
      ">> Epoch 69 finished \tANN training loss 0.005236\n",
      ">> Epoch 70 finished \tANN training loss 0.005192\n",
      ">> Epoch 71 finished \tANN training loss 0.005148\n",
      ">> Epoch 72 finished \tANN training loss 0.005106\n",
      ">> Epoch 73 finished \tANN training loss 0.005065\n",
      ">> Epoch 74 finished \tANN training loss 0.005025\n",
      ">> Epoch 75 finished \tANN training loss 0.004986\n",
      ">> Epoch 76 finished \tANN training loss 0.004948\n",
      ">> Epoch 77 finished \tANN training loss 0.004911\n",
      ">> Epoch 78 finished \tANN training loss 0.004874\n",
      ">> Epoch 79 finished \tANN training loss 0.004839\n",
      ">> Epoch 80 finished \tANN training loss 0.004804\n",
      ">> Epoch 81 finished \tANN training loss 0.004771\n",
      ">> Epoch 82 finished \tANN training loss 0.004738\n",
      ">> Epoch 83 finished \tANN training loss 0.004705\n",
      ">> Epoch 84 finished \tANN training loss 0.004673\n",
      ">> Epoch 85 finished \tANN training loss 0.004642\n",
      ">> Epoch 86 finished \tANN training loss 0.004612\n",
      ">> Epoch 87 finished \tANN training loss 0.004582\n",
      ">> Epoch 88 finished \tANN training loss 0.004553\n",
      ">> Epoch 89 finished \tANN training loss 0.004524\n",
      ">> Epoch 90 finished \tANN training loss 0.004496\n",
      ">> Epoch 91 finished \tANN training loss 0.004468\n",
      ">> Epoch 92 finished \tANN training loss 0.004441\n",
      ">> Epoch 93 finished \tANN training loss 0.004414\n",
      ">> Epoch 94 finished \tANN training loss 0.004388\n",
      ">> Epoch 95 finished \tANN training loss 0.004362\n",
      ">> Epoch 96 finished \tANN training loss 0.004337\n",
      ">> Epoch 97 finished \tANN training loss 0.004312\n",
      ">> Epoch 98 finished \tANN training loss 0.004287\n",
      ">> Epoch 99 finished \tANN training loss 0.004263\n",
      ">> Epoch 100 finished \tANN training loss 0.004239\n",
      ">> Epoch 101 finished \tANN training loss 0.004216\n",
      ">> Epoch 102 finished \tANN training loss 0.004193\n",
      ">> Epoch 103 finished \tANN training loss 0.004170\n",
      ">> Epoch 104 finished \tANN training loss 0.004148\n",
      ">> Epoch 105 finished \tANN training loss 0.004126\n",
      ">> Epoch 106 finished \tANN training loss 0.004104\n",
      ">> Epoch 107 finished \tANN training loss 0.004082\n",
      ">> Epoch 108 finished \tANN training loss 0.004061\n",
      ">> Epoch 109 finished \tANN training loss 0.004040\n",
      ">> Epoch 110 finished \tANN training loss 0.004019\n",
      ">> Epoch 111 finished \tANN training loss 0.003999\n",
      ">> Epoch 112 finished \tANN training loss 0.003979\n",
      ">> Epoch 113 finished \tANN training loss 0.003958\n",
      ">> Epoch 114 finished \tANN training loss 0.003939\n",
      ">> Epoch 115 finished \tANN training loss 0.003919\n",
      ">> Epoch 116 finished \tANN training loss 0.003900\n",
      ">> Epoch 117 finished \tANN training loss 0.003880\n",
      ">> Epoch 118 finished \tANN training loss 0.003862\n",
      ">> Epoch 119 finished \tANN training loss 0.003843\n",
      ">> Epoch 120 finished \tANN training loss 0.003824\n",
      ">> Epoch 121 finished \tANN training loss 0.003806\n",
      ">> Epoch 122 finished \tANN training loss 0.003788\n",
      ">> Epoch 123 finished \tANN training loss 0.003770\n",
      ">> Epoch 124 finished \tANN training loss 0.003752\n",
      ">> Epoch 125 finished \tANN training loss 0.003734\n",
      ">> Epoch 126 finished \tANN training loss 0.003717\n",
      ">> Epoch 127 finished \tANN training loss 0.003699\n",
      ">> Epoch 128 finished \tANN training loss 0.003682\n",
      ">> Epoch 129 finished \tANN training loss 0.003665\n",
      ">> Epoch 130 finished \tANN training loss 0.003648\n",
      ">> Epoch 131 finished \tANN training loss 0.003632\n",
      ">> Epoch 132 finished \tANN training loss 0.003615\n",
      ">> Epoch 133 finished \tANN training loss 0.003599\n",
      ">> Epoch 134 finished \tANN training loss 0.003582\n",
      ">> Epoch 135 finished \tANN training loss 0.003566\n",
      ">> Epoch 136 finished \tANN training loss 0.003550\n",
      ">> Epoch 137 finished \tANN training loss 0.003534\n",
      ">> Epoch 138 finished \tANN training loss 0.003519\n",
      ">> Epoch 139 finished \tANN training loss 0.003503\n",
      ">> Epoch 140 finished \tANN training loss 0.003487\n",
      ">> Epoch 141 finished \tANN training loss 0.003472\n",
      ">> Epoch 142 finished \tANN training loss 0.003456\n",
      ">> Epoch 143 finished \tANN training loss 0.003441\n",
      ">> Epoch 144 finished \tANN training loss 0.003426\n",
      ">> Epoch 145 finished \tANN training loss 0.003411\n",
      ">> Epoch 146 finished \tANN training loss 0.003396\n",
      ">> Epoch 147 finished \tANN training loss 0.003381\n",
      ">> Epoch 148 finished \tANN training loss 0.003367\n",
      ">> Epoch 149 finished \tANN training loss 0.003352\n",
      ">> Epoch 150 finished \tANN training loss 0.003337\n",
      "[END] Fine tuning step\n",
      "############### End Training for DHFLEQ #####################\n",
      "############### End Training for NBCCEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 8.517680\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 8.456388\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 8.393830\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 8.329874\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 8.264422\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 8.197353\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 8.128548\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 8.057781\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 7.984899\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 7.909716\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 7.832123\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 7.751797\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 7.668700\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 7.582449\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 7.492901\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 7.399876\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 7.303039\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 7.202168\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 7.097003\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 6.987402\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 6.873061\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 6.753527\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 6.628796\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 6.498379\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 6.362120\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 6.219735\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 6.071390\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 5.916616\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 5.755238\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 5.587253\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 5.412702\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 5.231265\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 5.043440\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 4.849295\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 4.649285\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 4.443581\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 4.233049\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 4.018335\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 3.799870\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 3.580001\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 3.357945\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 3.135018\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 2.913394\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 2.694966\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 2.479850\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 2.270329\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 2.067585\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 1.870868\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 1.684611\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 1.509342\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 1.346195\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 1.195611\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 1.055794\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.930946\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.817317\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.716565\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.627438\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.549812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 59 finished \tRBM Reconstruction error 0.484222\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.429027\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.383153\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.345030\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.314477\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.290330\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.272180\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.258935\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.249801\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.243578\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.240112\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.239048\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.239843\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.242025\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.245109\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.248775\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.251828\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.256873\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.261475\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.265373\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.270399\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.274793\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.278723\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.281468\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.285192\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.288803\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.292107\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.294297\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.297362\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.299381\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.301309\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.301557\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.304374\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.306302\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.308605\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.308736\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.309390\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.310850\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.311256\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.310844\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.310996\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.311003\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.691840\n",
      ">> Epoch 2 finished \tANN training loss 0.593114\n",
      ">> Epoch 3 finished \tANN training loss 0.508958\n",
      ">> Epoch 4 finished \tANN training loss 0.437344\n",
      ">> Epoch 5 finished \tANN training loss 0.376102\n",
      ">> Epoch 6 finished \tANN training loss 0.323627\n",
      ">> Epoch 7 finished \tANN training loss 0.278611\n",
      ">> Epoch 8 finished \tANN training loss 0.239941\n",
      ">> Epoch 9 finished \tANN training loss 0.206684\n",
      ">> Epoch 10 finished \tANN training loss 0.178074\n",
      ">> Epoch 11 finished \tANN training loss 0.153466\n",
      ">> Epoch 12 finished \tANN training loss 0.132286\n",
      ">> Epoch 13 finished \tANN training loss 0.114059\n",
      ">> Epoch 14 finished \tANN training loss 0.098378\n",
      ">> Epoch 15 finished \tANN training loss 0.084880\n",
      ">> Epoch 16 finished \tANN training loss 0.073266\n",
      ">> Epoch 17 finished \tANN training loss 0.063269\n",
      ">> Epoch 18 finished \tANN training loss 0.054669\n",
      ">> Epoch 19 finished \tANN training loss 0.047265\n",
      ">> Epoch 20 finished \tANN training loss 0.040896\n",
      ">> Epoch 21 finished \tANN training loss 0.035414\n",
      ">> Epoch 22 finished \tANN training loss 0.030698\n",
      ">> Epoch 23 finished \tANN training loss 0.026639\n",
      ">> Epoch 24 finished \tANN training loss 0.023147\n",
      ">> Epoch 25 finished \tANN training loss 0.020144\n",
      ">> Epoch 26 finished \tANN training loss 0.017561\n",
      ">> Epoch 27 finished \tANN training loss 0.015337\n",
      ">> Epoch 28 finished \tANN training loss 0.013426\n",
      ">> Epoch 29 finished \tANN training loss 0.011781\n",
      ">> Epoch 30 finished \tANN training loss 0.010368\n",
      ">> Epoch 31 finished \tANN training loss 0.009151\n",
      ">> Epoch 32 finished \tANN training loss 0.008105\n",
      ">> Epoch 33 finished \tANN training loss 0.007206\n",
      ">> Epoch 34 finished \tANN training loss 0.006433\n",
      ">> Epoch 35 finished \tANN training loss 0.005768\n",
      ">> Epoch 36 finished \tANN training loss 0.005197\n",
      ">> Epoch 37 finished \tANN training loss 0.004706\n",
      ">> Epoch 38 finished \tANN training loss 0.004283\n",
      ">> Epoch 39 finished \tANN training loss 0.003919\n",
      ">> Epoch 40 finished \tANN training loss 0.003607\n",
      ">> Epoch 41 finished \tANN training loss 0.003338\n",
      ">> Epoch 42 finished \tANN training loss 0.003106\n",
      ">> Epoch 43 finished \tANN training loss 0.002907\n",
      ">> Epoch 44 finished \tANN training loss 0.002736\n",
      ">> Epoch 45 finished \tANN training loss 0.002589\n",
      ">> Epoch 46 finished \tANN training loss 0.002462\n",
      ">> Epoch 47 finished \tANN training loss 0.002353\n",
      ">> Epoch 48 finished \tANN training loss 0.002259\n",
      ">> Epoch 49 finished \tANN training loss 0.002178\n",
      ">> Epoch 50 finished \tANN training loss 0.002108\n",
      ">> Epoch 51 finished \tANN training loss 0.002048\n",
      ">> Epoch 52 finished \tANN training loss 0.001997\n",
      ">> Epoch 53 finished \tANN training loss 0.001952\n",
      ">> Epoch 54 finished \tANN training loss 0.001914\n",
      ">> Epoch 55 finished \tANN training loss 0.001880\n",
      ">> Epoch 56 finished \tANN training loss 0.001852\n",
      ">> Epoch 57 finished \tANN training loss 0.001827\n",
      ">> Epoch 58 finished \tANN training loss 0.001805\n",
      ">> Epoch 59 finished \tANN training loss 0.001787\n",
      ">> Epoch 60 finished \tANN training loss 0.001770\n",
      ">> Epoch 61 finished \tANN training loss 0.001756\n",
      ">> Epoch 62 finished \tANN training loss 0.001744\n",
      ">> Epoch 63 finished \tANN training loss 0.001733\n",
      ">> Epoch 64 finished \tANN training loss 0.001724\n",
      ">> Epoch 65 finished \tANN training loss 0.001716\n",
      ">> Epoch 66 finished \tANN training loss 0.001709\n",
      ">> Epoch 67 finished \tANN training loss 0.001703\n",
      ">> Epoch 68 finished \tANN training loss 0.001697\n",
      ">> Epoch 69 finished \tANN training loss 0.001692\n",
      ">> Epoch 70 finished \tANN training loss 0.001688\n",
      ">> Epoch 71 finished \tANN training loss 0.001684\n",
      ">> Epoch 72 finished \tANN training loss 0.001680\n",
      ">> Epoch 73 finished \tANN training loss 0.001677\n",
      ">> Epoch 74 finished \tANN training loss 0.001674\n",
      ">> Epoch 75 finished \tANN training loss 0.001671\n",
      ">> Epoch 76 finished \tANN training loss 0.001669\n",
      ">> Epoch 77 finished \tANN training loss 0.001667\n",
      ">> Epoch 78 finished \tANN training loss 0.001665\n",
      ">> Epoch 79 finished \tANN training loss 0.001663\n",
      ">> Epoch 80 finished \tANN training loss 0.001661\n",
      ">> Epoch 81 finished \tANN training loss 0.001660\n",
      ">> Epoch 82 finished \tANN training loss 0.001658\n",
      ">> Epoch 83 finished \tANN training loss 0.001657\n",
      ">> Epoch 84 finished \tANN training loss 0.001655\n",
      ">> Epoch 85 finished \tANN training loss 0.001654\n",
      ">> Epoch 86 finished \tANN training loss 0.001652\n",
      ">> Epoch 87 finished \tANN training loss 0.001651\n",
      ">> Epoch 88 finished \tANN training loss 0.001650\n",
      ">> Epoch 89 finished \tANN training loss 0.001649\n",
      ">> Epoch 90 finished \tANN training loss 0.001648\n",
      ">> Epoch 91 finished \tANN training loss 0.001646\n",
      ">> Epoch 92 finished \tANN training loss 0.001645\n",
      ">> Epoch 93 finished \tANN training loss 0.001644\n",
      ">> Epoch 94 finished \tANN training loss 0.001643\n",
      ">> Epoch 95 finished \tANN training loss 0.001642\n",
      ">> Epoch 96 finished \tANN training loss 0.001641\n",
      ">> Epoch 97 finished \tANN training loss 0.001640\n",
      ">> Epoch 98 finished \tANN training loss 0.001639\n",
      ">> Epoch 99 finished \tANN training loss 0.001638\n",
      ">> Epoch 100 finished \tANN training loss 0.001637\n",
      ">> Epoch 101 finished \tANN training loss 0.001636\n",
      ">> Epoch 102 finished \tANN training loss 0.001635\n",
      ">> Epoch 103 finished \tANN training loss 0.001634\n",
      ">> Epoch 104 finished \tANN training loss 0.001633\n",
      ">> Epoch 105 finished \tANN training loss 0.001632\n",
      ">> Epoch 106 finished \tANN training loss 0.001632\n",
      ">> Epoch 107 finished \tANN training loss 0.001631\n",
      ">> Epoch 108 finished \tANN training loss 0.001630\n",
      ">> Epoch 109 finished \tANN training loss 0.001629\n",
      ">> Epoch 110 finished \tANN training loss 0.001628\n",
      ">> Epoch 111 finished \tANN training loss 0.001627\n",
      ">> Epoch 112 finished \tANN training loss 0.001626\n",
      ">> Epoch 113 finished \tANN training loss 0.001625\n",
      ">> Epoch 114 finished \tANN training loss 0.001624\n",
      ">> Epoch 115 finished \tANN training loss 0.001624\n",
      ">> Epoch 116 finished \tANN training loss 0.001623\n",
      ">> Epoch 117 finished \tANN training loss 0.001622\n",
      ">> Epoch 118 finished \tANN training loss 0.001621\n",
      ">> Epoch 119 finished \tANN training loss 0.001620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 120 finished \tANN training loss 0.001619\n",
      ">> Epoch 121 finished \tANN training loss 0.001618\n",
      ">> Epoch 122 finished \tANN training loss 0.001618\n",
      ">> Epoch 123 finished \tANN training loss 0.001617\n",
      ">> Epoch 124 finished \tANN training loss 0.001616\n",
      ">> Epoch 125 finished \tANN training loss 0.001615\n",
      ">> Epoch 126 finished \tANN training loss 0.001614\n",
      ">> Epoch 127 finished \tANN training loss 0.001614\n",
      ">> Epoch 128 finished \tANN training loss 0.001613\n",
      ">> Epoch 129 finished \tANN training loss 0.001612\n",
      ">> Epoch 130 finished \tANN training loss 0.001611\n",
      ">> Epoch 131 finished \tANN training loss 0.001610\n",
      ">> Epoch 132 finished \tANN training loss 0.001609\n",
      ">> Epoch 133 finished \tANN training loss 0.001609\n",
      ">> Epoch 134 finished \tANN training loss 0.001608\n",
      ">> Epoch 135 finished \tANN training loss 0.001607\n",
      ">> Epoch 136 finished \tANN training loss 0.001606\n",
      ">> Epoch 137 finished \tANN training loss 0.001606\n",
      ">> Epoch 138 finished \tANN training loss 0.001605\n",
      ">> Epoch 139 finished \tANN training loss 0.001604\n",
      ">> Epoch 140 finished \tANN training loss 0.001603\n",
      ">> Epoch 141 finished \tANN training loss 0.001602\n",
      ">> Epoch 142 finished \tANN training loss 0.001602\n",
      ">> Epoch 143 finished \tANN training loss 0.001601\n",
      ">> Epoch 144 finished \tANN training loss 0.001600\n",
      ">> Epoch 145 finished \tANN training loss 0.001599\n",
      ">> Epoch 146 finished \tANN training loss 0.001599\n",
      ">> Epoch 147 finished \tANN training loss 0.001598\n",
      ">> Epoch 148 finished \tANN training loss 0.001597\n",
      ">> Epoch 149 finished \tANN training loss 0.001596\n",
      ">> Epoch 150 finished \tANN training loss 0.001596\n",
      "[END] Fine tuning step\n",
      "############### End Training for NBCCEQ #####################\n",
      "############### End Training for GSFCEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 2.682331\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 2.628705\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 2.575076\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 2.521481\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 2.467753\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 2.413845\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 2.359614\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 2.305033\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 2.249947\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 2.194227\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 2.137901\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 2.080798\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 2.022891\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 1.964090\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 1.904380\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 1.843524\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 1.781672\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 1.718987\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 1.655169\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 1.590412\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 1.524937\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 1.458821\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 1.392253\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 1.325543\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 1.258579\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 1.191824\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 1.125431\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 1.060039\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 0.996088\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 0.933589\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 0.872765\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 0.814154\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.758396\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.705560\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.656176\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.610360\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.567857\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.528599\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.493600\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.461608\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.432019\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.405693\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.382836\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.362047\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.344042\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.328035\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.313934\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.301342\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.290657\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.281237\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.272875\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.265092\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.258219\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.251617\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.246039\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.241048\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.236446\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.231932\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.228169\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.224343\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.220927\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.217476\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.214383\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.211024\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.208093\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.205341\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.202664\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.199984\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.197344\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.194787\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.192327\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.189800\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.187356\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.184980\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.182798\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.180584\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.178484\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.176167\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.173989\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.172035\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.170022\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.167945\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.165991\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.164013\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.161966\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.159964\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.158221\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.156448\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.154504\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.152670\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.150963\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.149179\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.147429\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.145725\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.143905\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.142175\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.140544\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.138834\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.137233\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.135486\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.045299\n",
      ">> Epoch 2 finished \tANN training loss 0.041587\n",
      ">> Epoch 3 finished \tANN training loss 0.038404\n",
      ">> Epoch 4 finished \tANN training loss 0.035664\n",
      ">> Epoch 5 finished \tANN training loss 0.033298\n",
      ">> Epoch 6 finished \tANN training loss 0.031246\n",
      ">> Epoch 7 finished \tANN training loss 0.029460\n",
      ">> Epoch 8 finished \tANN training loss 0.027899\n",
      ">> Epoch 9 finished \tANN training loss 0.026528\n",
      ">> Epoch 10 finished \tANN training loss 0.025316\n",
      ">> Epoch 11 finished \tANN training loss 0.024240\n",
      ">> Epoch 12 finished \tANN training loss 0.023280\n",
      ">> Epoch 13 finished \tANN training loss 0.022418\n",
      ">> Epoch 14 finished \tANN training loss 0.021639\n",
      ">> Epoch 15 finished \tANN training loss 0.020931\n",
      ">> Epoch 16 finished \tANN training loss 0.020285\n",
      ">> Epoch 17 finished \tANN training loss 0.019691\n",
      ">> Epoch 18 finished \tANN training loss 0.019142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 19 finished \tANN training loss 0.018632\n",
      ">> Epoch 20 finished \tANN training loss 0.018156\n",
      ">> Epoch 21 finished \tANN training loss 0.017709\n",
      ">> Epoch 22 finished \tANN training loss 0.017288\n",
      ">> Epoch 23 finished \tANN training loss 0.016889\n",
      ">> Epoch 24 finished \tANN training loss 0.016510\n",
      ">> Epoch 25 finished \tANN training loss 0.016149\n",
      ">> Epoch 26 finished \tANN training loss 0.015804\n",
      ">> Epoch 27 finished \tANN training loss 0.015472\n",
      ">> Epoch 28 finished \tANN training loss 0.015154\n",
      ">> Epoch 29 finished \tANN training loss 0.014846\n",
      ">> Epoch 30 finished \tANN training loss 0.014550\n",
      ">> Epoch 31 finished \tANN training loss 0.014263\n",
      ">> Epoch 32 finished \tANN training loss 0.013985\n",
      ">> Epoch 33 finished \tANN training loss 0.013714\n",
      ">> Epoch 34 finished \tANN training loss 0.013452\n",
      ">> Epoch 35 finished \tANN training loss 0.013197\n",
      ">> Epoch 36 finished \tANN training loss 0.012948\n",
      ">> Epoch 37 finished \tANN training loss 0.012706\n",
      ">> Epoch 38 finished \tANN training loss 0.012469\n",
      ">> Epoch 39 finished \tANN training loss 0.012239\n",
      ">> Epoch 40 finished \tANN training loss 0.012013\n",
      ">> Epoch 41 finished \tANN training loss 0.011793\n",
      ">> Epoch 42 finished \tANN training loss 0.011578\n",
      ">> Epoch 43 finished \tANN training loss 0.011368\n",
      ">> Epoch 44 finished \tANN training loss 0.011162\n",
      ">> Epoch 45 finished \tANN training loss 0.010961\n",
      ">> Epoch 46 finished \tANN training loss 0.010764\n",
      ">> Epoch 47 finished \tANN training loss 0.010572\n",
      ">> Epoch 48 finished \tANN training loss 0.010383\n",
      ">> Epoch 49 finished \tANN training loss 0.010199\n",
      ">> Epoch 50 finished \tANN training loss 0.010018\n",
      ">> Epoch 51 finished \tANN training loss 0.009841\n",
      ">> Epoch 52 finished \tANN training loss 0.009668\n",
      ">> Epoch 53 finished \tANN training loss 0.009498\n",
      ">> Epoch 54 finished \tANN training loss 0.009332\n",
      ">> Epoch 55 finished \tANN training loss 0.009169\n",
      ">> Epoch 56 finished \tANN training loss 0.009009\n",
      ">> Epoch 57 finished \tANN training loss 0.008853\n",
      ">> Epoch 58 finished \tANN training loss 0.008699\n",
      ">> Epoch 59 finished \tANN training loss 0.008549\n",
      ">> Epoch 60 finished \tANN training loss 0.008402\n",
      ">> Epoch 61 finished \tANN training loss 0.008258\n",
      ">> Epoch 62 finished \tANN training loss 0.008116\n",
      ">> Epoch 63 finished \tANN training loss 0.007977\n",
      ">> Epoch 64 finished \tANN training loss 0.007841\n",
      ">> Epoch 65 finished \tANN training loss 0.007708\n",
      ">> Epoch 66 finished \tANN training loss 0.007578\n",
      ">> Epoch 67 finished \tANN training loss 0.007449\n",
      ">> Epoch 68 finished \tANN training loss 0.007324\n",
      ">> Epoch 69 finished \tANN training loss 0.007201\n",
      ">> Epoch 70 finished \tANN training loss 0.007080\n",
      ">> Epoch 71 finished \tANN training loss 0.006961\n",
      ">> Epoch 72 finished \tANN training loss 0.006845\n",
      ">> Epoch 73 finished \tANN training loss 0.006731\n",
      ">> Epoch 74 finished \tANN training loss 0.006619\n",
      ">> Epoch 75 finished \tANN training loss 0.006510\n",
      ">> Epoch 76 finished \tANN training loss 0.006402\n",
      ">> Epoch 77 finished \tANN training loss 0.006297\n",
      ">> Epoch 78 finished \tANN training loss 0.006193\n",
      ">> Epoch 79 finished \tANN training loss 0.006092\n",
      ">> Epoch 80 finished \tANN training loss 0.005992\n",
      ">> Epoch 81 finished \tANN training loss 0.005895\n",
      ">> Epoch 82 finished \tANN training loss 0.005799\n",
      ">> Epoch 83 finished \tANN training loss 0.005705\n",
      ">> Epoch 84 finished \tANN training loss 0.005613\n",
      ">> Epoch 85 finished \tANN training loss 0.005522\n",
      ">> Epoch 86 finished \tANN training loss 0.005434\n",
      ">> Epoch 87 finished \tANN training loss 0.005347\n",
      ">> Epoch 88 finished \tANN training loss 0.005261\n",
      ">> Epoch 89 finished \tANN training loss 0.005177\n",
      ">> Epoch 90 finished \tANN training loss 0.005095\n",
      ">> Epoch 91 finished \tANN training loss 0.005014\n",
      ">> Epoch 92 finished \tANN training loss 0.004935\n",
      ">> Epoch 93 finished \tANN training loss 0.004857\n",
      ">> Epoch 94 finished \tANN training loss 0.004781\n",
      ">> Epoch 95 finished \tANN training loss 0.004706\n",
      ">> Epoch 96 finished \tANN training loss 0.004633\n",
      ">> Epoch 97 finished \tANN training loss 0.004561\n",
      ">> Epoch 98 finished \tANN training loss 0.004490\n",
      ">> Epoch 99 finished \tANN training loss 0.004421\n",
      ">> Epoch 100 finished \tANN training loss 0.004353\n",
      ">> Epoch 101 finished \tANN training loss 0.004286\n",
      ">> Epoch 102 finished \tANN training loss 0.004220\n",
      ">> Epoch 103 finished \tANN training loss 0.004156\n",
      ">> Epoch 104 finished \tANN training loss 0.004093\n",
      ">> Epoch 105 finished \tANN training loss 0.004031\n",
      ">> Epoch 106 finished \tANN training loss 0.003970\n",
      ">> Epoch 107 finished \tANN training loss 0.003910\n",
      ">> Epoch 108 finished \tANN training loss 0.003851\n",
      ">> Epoch 109 finished \tANN training loss 0.003794\n",
      ">> Epoch 110 finished \tANN training loss 0.003737\n",
      ">> Epoch 111 finished \tANN training loss 0.003682\n",
      ">> Epoch 112 finished \tANN training loss 0.003628\n",
      ">> Epoch 113 finished \tANN training loss 0.003574\n",
      ">> Epoch 114 finished \tANN training loss 0.003522\n",
      ">> Epoch 115 finished \tANN training loss 0.003470\n",
      ">> Epoch 116 finished \tANN training loss 0.003420\n",
      ">> Epoch 117 finished \tANN training loss 0.003370\n",
      ">> Epoch 118 finished \tANN training loss 0.003322\n",
      ">> Epoch 119 finished \tANN training loss 0.003274\n",
      ">> Epoch 120 finished \tANN training loss 0.003227\n",
      ">> Epoch 121 finished \tANN training loss 0.003181\n",
      ">> Epoch 122 finished \tANN training loss 0.003136\n",
      ">> Epoch 123 finished \tANN training loss 0.003091\n",
      ">> Epoch 124 finished \tANN training loss 0.003048\n",
      ">> Epoch 125 finished \tANN training loss 0.003005\n",
      ">> Epoch 126 finished \tANN training loss 0.002963\n",
      ">> Epoch 127 finished \tANN training loss 0.002922\n",
      ">> Epoch 128 finished \tANN training loss 0.002882\n",
      ">> Epoch 129 finished \tANN training loss 0.002842\n",
      ">> Epoch 130 finished \tANN training loss 0.002803\n",
      ">> Epoch 131 finished \tANN training loss 0.002765\n",
      ">> Epoch 132 finished \tANN training loss 0.002727\n",
      ">> Epoch 133 finished \tANN training loss 0.002690\n",
      ">> Epoch 134 finished \tANN training loss 0.002654\n",
      ">> Epoch 135 finished \tANN training loss 0.002618\n",
      ">> Epoch 136 finished \tANN training loss 0.002583\n",
      ">> Epoch 137 finished \tANN training loss 0.002549\n",
      ">> Epoch 138 finished \tANN training loss 0.002516\n",
      ">> Epoch 139 finished \tANN training loss 0.002482\n",
      ">> Epoch 140 finished \tANN training loss 0.002450\n",
      ">> Epoch 141 finished \tANN training loss 0.002418\n",
      ">> Epoch 142 finished \tANN training loss 0.002387\n",
      ">> Epoch 143 finished \tANN training loss 0.002356\n",
      ">> Epoch 144 finished \tANN training loss 0.002326\n",
      ">> Epoch 145 finished \tANN training loss 0.002296\n",
      ">> Epoch 146 finished \tANN training loss 0.002267\n",
      ">> Epoch 147 finished \tANN training loss 0.002239\n",
      ">> Epoch 148 finished \tANN training loss 0.002211\n",
      ">> Epoch 149 finished \tANN training loss 0.002183\n",
      ">> Epoch 150 finished \tANN training loss 0.002156\n",
      "[END] Fine tuning step\n",
      "############### End Training for GSFCEQ #####################\n",
      "############### End Training for GODREJCPEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 1.262218\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 1.249373\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 1.236714\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 1.224219\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 1.211895\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 1.199744\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 1.187754\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 1.175921\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 1.164260\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 1.152741\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 1.141357\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 1.130115\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 1.119020\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 1.108062\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 1.097219\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 1.086505\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 1.075933\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 1.065465\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 1.055110\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 1.044862\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 1.034731\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 1.024697\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 1.014785\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 1.004953\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 0.995205\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 0.985532\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 0.975952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 28 finished \tRBM Reconstruction error 0.966448\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 0.957019\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 0.947681\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 0.938408\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 0.929212\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.920077\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.911010\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.902009\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.893048\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.884137\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.875289\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.866486\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.857759\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.849072\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.840450\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.831840\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.823281\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.814753\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.806251\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.797820\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.789433\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.781060\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.772671\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.764394\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.756103\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.747858\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.739657\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.731498\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.723338\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.715225\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.707103\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.699044\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.691035\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.683078\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.675147\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.667247\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.659400\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.651550\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.643796\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.636038\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.628314\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.620682\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.613034\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.605424\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.597911\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.590494\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.583060\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.575677\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.568385\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.561144\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.553920\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.546779\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.539700\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.532764\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.525773\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.518863\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.512072\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.505256\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.498556\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.491875\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.485366\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.478947\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.472575\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.466328\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.460135\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.453989\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.447989\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.442058\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.436168\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.430357\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.424759\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.419119\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.413539\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.018538\n",
      ">> Epoch 2 finished \tANN training loss 0.018345\n",
      ">> Epoch 3 finished \tANN training loss 0.018154\n",
      ">> Epoch 4 finished \tANN training loss 0.017966\n",
      ">> Epoch 5 finished \tANN training loss 0.017779\n",
      ">> Epoch 6 finished \tANN training loss 0.017595\n",
      ">> Epoch 7 finished \tANN training loss 0.017413\n",
      ">> Epoch 8 finished \tANN training loss 0.017233\n",
      ">> Epoch 9 finished \tANN training loss 0.017056\n",
      ">> Epoch 10 finished \tANN training loss 0.016880\n",
      ">> Epoch 11 finished \tANN training loss 0.016706\n",
      ">> Epoch 12 finished \tANN training loss 0.016535\n",
      ">> Epoch 13 finished \tANN training loss 0.016366\n",
      ">> Epoch 14 finished \tANN training loss 0.016198\n",
      ">> Epoch 15 finished \tANN training loss 0.016033\n",
      ">> Epoch 16 finished \tANN training loss 0.015869\n",
      ">> Epoch 17 finished \tANN training loss 0.015707\n",
      ">> Epoch 18 finished \tANN training loss 0.015548\n",
      ">> Epoch 19 finished \tANN training loss 0.015390\n",
      ">> Epoch 20 finished \tANN training loss 0.015235\n",
      ">> Epoch 21 finished \tANN training loss 0.015081\n",
      ">> Epoch 22 finished \tANN training loss 0.014929\n",
      ">> Epoch 23 finished \tANN training loss 0.014779\n",
      ">> Epoch 24 finished \tANN training loss 0.014631\n",
      ">> Epoch 25 finished \tANN training loss 0.014485\n",
      ">> Epoch 26 finished \tANN training loss 0.014340\n",
      ">> Epoch 27 finished \tANN training loss 0.014197\n",
      ">> Epoch 28 finished \tANN training loss 0.014056\n",
      ">> Epoch 29 finished \tANN training loss 0.013917\n",
      ">> Epoch 30 finished \tANN training loss 0.013778\n",
      ">> Epoch 31 finished \tANN training loss 0.013642\n",
      ">> Epoch 32 finished \tANN training loss 0.013507\n",
      ">> Epoch 33 finished \tANN training loss 0.013373\n",
      ">> Epoch 34 finished \tANN training loss 0.013241\n",
      ">> Epoch 35 finished \tANN training loss 0.013110\n",
      ">> Epoch 36 finished \tANN training loss 0.012981\n",
      ">> Epoch 37 finished \tANN training loss 0.012853\n",
      ">> Epoch 38 finished \tANN training loss 0.012726\n",
      ">> Epoch 39 finished \tANN training loss 0.012601\n",
      ">> Epoch 40 finished \tANN training loss 0.012477\n",
      ">> Epoch 41 finished \tANN training loss 0.012355\n",
      ">> Epoch 42 finished \tANN training loss 0.012234\n",
      ">> Epoch 43 finished \tANN training loss 0.012114\n",
      ">> Epoch 44 finished \tANN training loss 0.011996\n",
      ">> Epoch 45 finished \tANN training loss 0.011879\n",
      ">> Epoch 46 finished \tANN training loss 0.011763\n",
      ">> Epoch 47 finished \tANN training loss 0.011649\n",
      ">> Epoch 48 finished \tANN training loss 0.011535\n",
      ">> Epoch 49 finished \tANN training loss 0.011423\n",
      ">> Epoch 50 finished \tANN training loss 0.011313\n",
      ">> Epoch 51 finished \tANN training loss 0.011203\n",
      ">> Epoch 52 finished \tANN training loss 0.011095\n",
      ">> Epoch 53 finished \tANN training loss 0.010988\n",
      ">> Epoch 54 finished \tANN training loss 0.010882\n",
      ">> Epoch 55 finished \tANN training loss 0.010778\n",
      ">> Epoch 56 finished \tANN training loss 0.010674\n",
      ">> Epoch 57 finished \tANN training loss 0.010572\n",
      ">> Epoch 58 finished \tANN training loss 0.010471\n",
      ">> Epoch 59 finished \tANN training loss 0.010371\n",
      ">> Epoch 60 finished \tANN training loss 0.010272\n",
      ">> Epoch 61 finished \tANN training loss 0.010175\n",
      ">> Epoch 62 finished \tANN training loss 0.010078\n",
      ">> Epoch 63 finished \tANN training loss 0.009982\n",
      ">> Epoch 64 finished \tANN training loss 0.009888\n",
      ">> Epoch 65 finished \tANN training loss 0.009794\n",
      ">> Epoch 66 finished \tANN training loss 0.009702\n",
      ">> Epoch 67 finished \tANN training loss 0.009611\n",
      ">> Epoch 68 finished \tANN training loss 0.009520\n",
      ">> Epoch 69 finished \tANN training loss 0.009431\n",
      ">> Epoch 70 finished \tANN training loss 0.009342\n",
      ">> Epoch 71 finished \tANN training loss 0.009255\n",
      ">> Epoch 72 finished \tANN training loss 0.009168\n",
      ">> Epoch 73 finished \tANN training loss 0.009083\n",
      ">> Epoch 74 finished \tANN training loss 0.008998\n",
      ">> Epoch 75 finished \tANN training loss 0.008914\n",
      ">> Epoch 76 finished \tANN training loss 0.008831\n",
      ">> Epoch 77 finished \tANN training loss 0.008749\n",
      ">> Epoch 78 finished \tANN training loss 0.008667\n",
      ">> Epoch 79 finished \tANN training loss 0.008587\n",
      ">> Epoch 80 finished \tANN training loss 0.008507\n",
      ">> Epoch 81 finished \tANN training loss 0.008428\n",
      ">> Epoch 82 finished \tANN training loss 0.008350\n",
      ">> Epoch 83 finished \tANN training loss 0.008273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 84 finished \tANN training loss 0.008196\n",
      ">> Epoch 85 finished \tANN training loss 0.008121\n",
      ">> Epoch 86 finished \tANN training loss 0.008046\n",
      ">> Epoch 87 finished \tANN training loss 0.007971\n",
      ">> Epoch 88 finished \tANN training loss 0.007898\n",
      ">> Epoch 89 finished \tANN training loss 0.007825\n",
      ">> Epoch 90 finished \tANN training loss 0.007753\n",
      ">> Epoch 91 finished \tANN training loss 0.007682\n",
      ">> Epoch 92 finished \tANN training loss 0.007612\n",
      ">> Epoch 93 finished \tANN training loss 0.007542\n",
      ">> Epoch 94 finished \tANN training loss 0.007473\n",
      ">> Epoch 95 finished \tANN training loss 0.007405\n",
      ">> Epoch 96 finished \tANN training loss 0.007337\n",
      ">> Epoch 97 finished \tANN training loss 0.007270\n",
      ">> Epoch 98 finished \tANN training loss 0.007204\n",
      ">> Epoch 99 finished \tANN training loss 0.007139\n",
      ">> Epoch 100 finished \tANN training loss 0.007074\n",
      ">> Epoch 101 finished \tANN training loss 0.007010\n",
      ">> Epoch 102 finished \tANN training loss 0.006946\n",
      ">> Epoch 103 finished \tANN training loss 0.006883\n",
      ">> Epoch 104 finished \tANN training loss 0.006821\n",
      ">> Epoch 105 finished \tANN training loss 0.006759\n",
      ">> Epoch 106 finished \tANN training loss 0.006698\n",
      ">> Epoch 107 finished \tANN training loss 0.006637\n",
      ">> Epoch 108 finished \tANN training loss 0.006578\n",
      ">> Epoch 109 finished \tANN training loss 0.006518\n",
      ">> Epoch 110 finished \tANN training loss 0.006459\n",
      ">> Epoch 111 finished \tANN training loss 0.006401\n",
      ">> Epoch 112 finished \tANN training loss 0.006344\n",
      ">> Epoch 113 finished \tANN training loss 0.006287\n",
      ">> Epoch 114 finished \tANN training loss 0.006230\n",
      ">> Epoch 115 finished \tANN training loss 0.006174\n",
      ">> Epoch 116 finished \tANN training loss 0.006119\n",
      ">> Epoch 117 finished \tANN training loss 0.006064\n",
      ">> Epoch 118 finished \tANN training loss 0.006010\n",
      ">> Epoch 119 finished \tANN training loss 0.005956\n",
      ">> Epoch 120 finished \tANN training loss 0.005903\n",
      ">> Epoch 121 finished \tANN training loss 0.005850\n",
      ">> Epoch 122 finished \tANN training loss 0.005798\n",
      ">> Epoch 123 finished \tANN training loss 0.005746\n",
      ">> Epoch 124 finished \tANN training loss 0.005695\n",
      ">> Epoch 125 finished \tANN training loss 0.005645\n",
      ">> Epoch 126 finished \tANN training loss 0.005595\n",
      ">> Epoch 127 finished \tANN training loss 0.005545\n",
      ">> Epoch 128 finished \tANN training loss 0.005496\n",
      ">> Epoch 129 finished \tANN training loss 0.005447\n",
      ">> Epoch 130 finished \tANN training loss 0.005399\n",
      ">> Epoch 131 finished \tANN training loss 0.005352\n",
      ">> Epoch 132 finished \tANN training loss 0.005305\n",
      ">> Epoch 133 finished \tANN training loss 0.005258\n",
      ">> Epoch 134 finished \tANN training loss 0.005212\n",
      ">> Epoch 135 finished \tANN training loss 0.005166\n",
      ">> Epoch 136 finished \tANN training loss 0.005121\n",
      ">> Epoch 137 finished \tANN training loss 0.005076\n",
      ">> Epoch 138 finished \tANN training loss 0.005032\n",
      ">> Epoch 139 finished \tANN training loss 0.004988\n",
      ">> Epoch 140 finished \tANN training loss 0.004944\n",
      ">> Epoch 141 finished \tANN training loss 0.004901\n",
      ">> Epoch 142 finished \tANN training loss 0.004859\n",
      ">> Epoch 143 finished \tANN training loss 0.004817\n",
      ">> Epoch 144 finished \tANN training loss 0.004775\n",
      ">> Epoch 145 finished \tANN training loss 0.004734\n",
      ">> Epoch 146 finished \tANN training loss 0.004693\n",
      ">> Epoch 147 finished \tANN training loss 0.004652\n",
      ">> Epoch 148 finished \tANN training loss 0.004612\n",
      ">> Epoch 149 finished \tANN training loss 0.004573\n",
      ">> Epoch 150 finished \tANN training loss 0.004533\n",
      "[END] Fine tuning step\n",
      "############### End Training for GODREJCPEQ #####################\n",
      "############### End Training for HAVELLSEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 0.852181\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 0.845208\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 0.838345\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 0.831601\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 0.824946\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 0.818401\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 0.811953\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 0.805599\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 0.799361\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 0.793214\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 0.787162\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 0.781200\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 0.775320\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 0.769533\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 0.763835\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 0.758235\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 0.752702\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 0.747243\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 0.741871\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 0.736582\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 0.731374\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 0.726226\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 0.721157\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 0.716154\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 0.711229\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 0.706365\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 0.701576\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 0.696838\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 0.692161\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 0.687559\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 0.683015\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 0.678520\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.674081\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.669696\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.665359\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.661074\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.656852\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.652676\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.648541\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.644440\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.640403\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.636412\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.632443\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.628521\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.624642\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.620808\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.617009\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.613248\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.609530\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.605841\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.602183\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.598546\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.594950\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.591381\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.587838\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.584339\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.580850\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.577378\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.573960\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.570555\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.567171\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.563806\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.560469\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.557167\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.553861\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.550570\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.547320\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.544088\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.540888\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.537695\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.534537\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.531365\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.528243\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.525123\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.522017\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.518921\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.515841\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.512788\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.509734\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.506698\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.503689\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.500666\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.497673\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.494692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 85 finished \tRBM Reconstruction error 0.491725\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.488763\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.485819\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.482872\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.479939\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.477022\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.474111\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.471227\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.468327\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.465453\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.462590\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.459746\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.456900\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.454061\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.451224\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.448423\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.035482\n",
      ">> Epoch 2 finished \tANN training loss 0.033936\n",
      ">> Epoch 3 finished \tANN training loss 0.032467\n",
      ">> Epoch 4 finished \tANN training loss 0.031072\n",
      ">> Epoch 5 finished \tANN training loss 0.029745\n",
      ">> Epoch 6 finished \tANN training loss 0.028484\n",
      ">> Epoch 7 finished \tANN training loss 0.027284\n",
      ">> Epoch 8 finished \tANN training loss 0.026141\n",
      ">> Epoch 9 finished \tANN training loss 0.025054\n",
      ">> Epoch 10 finished \tANN training loss 0.024018\n",
      ">> Epoch 11 finished \tANN training loss 0.023032\n",
      ">> Epoch 12 finished \tANN training loss 0.022093\n",
      ">> Epoch 13 finished \tANN training loss 0.021198\n",
      ">> Epoch 14 finished \tANN training loss 0.020346\n",
      ">> Epoch 15 finished \tANN training loss 0.019534\n",
      ">> Epoch 16 finished \tANN training loss 0.018760\n",
      ">> Epoch 17 finished \tANN training loss 0.018024\n",
      ">> Epoch 18 finished \tANN training loss 0.017322\n",
      ">> Epoch 19 finished \tANN training loss 0.016653\n",
      ">> Epoch 20 finished \tANN training loss 0.016015\n",
      ">> Epoch 21 finished \tANN training loss 0.015407\n",
      ">> Epoch 22 finished \tANN training loss 0.014827\n",
      ">> Epoch 23 finished \tANN training loss 0.014274\n",
      ">> Epoch 24 finished \tANN training loss 0.013747\n",
      ">> Epoch 25 finished \tANN training loss 0.013244\n",
      ">> Epoch 26 finished \tANN training loss 0.012764\n",
      ">> Epoch 27 finished \tANN training loss 0.012307\n",
      ">> Epoch 28 finished \tANN training loss 0.011870\n",
      ">> Epoch 29 finished \tANN training loss 0.011453\n",
      ">> Epoch 30 finished \tANN training loss 0.011056\n",
      ">> Epoch 31 finished \tANN training loss 0.010677\n",
      ">> Epoch 32 finished \tANN training loss 0.010315\n",
      ">> Epoch 33 finished \tANN training loss 0.009969\n",
      ">> Epoch 34 finished \tANN training loss 0.009640\n",
      ">> Epoch 35 finished \tANN training loss 0.009325\n",
      ">> Epoch 36 finished \tANN training loss 0.009025\n",
      ">> Epoch 37 finished \tANN training loss 0.008738\n",
      ">> Epoch 38 finished \tANN training loss 0.008464\n",
      ">> Epoch 39 finished \tANN training loss 0.008202\n",
      ">> Epoch 40 finished \tANN training loss 0.007953\n",
      ">> Epoch 41 finished \tANN training loss 0.007715\n",
      ">> Epoch 42 finished \tANN training loss 0.007488\n",
      ">> Epoch 43 finished \tANN training loss 0.007271\n",
      ">> Epoch 44 finished \tANN training loss 0.007064\n",
      ">> Epoch 45 finished \tANN training loss 0.006866\n",
      ">> Epoch 46 finished \tANN training loss 0.006677\n",
      ">> Epoch 47 finished \tANN training loss 0.006496\n",
      ">> Epoch 48 finished \tANN training loss 0.006323\n",
      ">> Epoch 49 finished \tANN training loss 0.006157\n",
      ">> Epoch 50 finished \tANN training loss 0.005999\n",
      ">> Epoch 51 finished \tANN training loss 0.005847\n",
      ">> Epoch 52 finished \tANN training loss 0.005701\n",
      ">> Epoch 53 finished \tANN training loss 0.005562\n",
      ">> Epoch 54 finished \tANN training loss 0.005428\n",
      ">> Epoch 55 finished \tANN training loss 0.005300\n",
      ">> Epoch 56 finished \tANN training loss 0.005177\n",
      ">> Epoch 57 finished \tANN training loss 0.005059\n",
      ">> Epoch 58 finished \tANN training loss 0.004945\n",
      ">> Epoch 59 finished \tANN training loss 0.004836\n",
      ">> Epoch 60 finished \tANN training loss 0.004731\n",
      ">> Epoch 61 finished \tANN training loss 0.004630\n",
      ">> Epoch 62 finished \tANN training loss 0.004534\n",
      ">> Epoch 63 finished \tANN training loss 0.004440\n",
      ">> Epoch 64 finished \tANN training loss 0.004351\n",
      ">> Epoch 65 finished \tANN training loss 0.004264\n",
      ">> Epoch 66 finished \tANN training loss 0.004181\n",
      ">> Epoch 67 finished \tANN training loss 0.004101\n",
      ">> Epoch 68 finished \tANN training loss 0.004024\n",
      ">> Epoch 69 finished \tANN training loss 0.003950\n",
      ">> Epoch 70 finished \tANN training loss 0.003878\n",
      ">> Epoch 71 finished \tANN training loss 0.003809\n",
      ">> Epoch 72 finished \tANN training loss 0.003742\n",
      ">> Epoch 73 finished \tANN training loss 0.003677\n",
      ">> Epoch 74 finished \tANN training loss 0.003615\n",
      ">> Epoch 75 finished \tANN training loss 0.003555\n",
      ">> Epoch 76 finished \tANN training loss 0.003496\n",
      ">> Epoch 77 finished \tANN training loss 0.003440\n",
      ">> Epoch 78 finished \tANN training loss 0.003385\n",
      ">> Epoch 79 finished \tANN training loss 0.003332\n",
      ">> Epoch 80 finished \tANN training loss 0.003281\n",
      ">> Epoch 81 finished \tANN training loss 0.003231\n",
      ">> Epoch 82 finished \tANN training loss 0.003183\n",
      ">> Epoch 83 finished \tANN training loss 0.003135\n",
      ">> Epoch 84 finished \tANN training loss 0.003090\n",
      ">> Epoch 85 finished \tANN training loss 0.003045\n",
      ">> Epoch 86 finished \tANN training loss 0.003002\n",
      ">> Epoch 87 finished \tANN training loss 0.002959\n",
      ">> Epoch 88 finished \tANN training loss 0.002918\n",
      ">> Epoch 89 finished \tANN training loss 0.002878\n",
      ">> Epoch 90 finished \tANN training loss 0.002839\n",
      ">> Epoch 91 finished \tANN training loss 0.002801\n",
      ">> Epoch 92 finished \tANN training loss 0.002764\n",
      ">> Epoch 93 finished \tANN training loss 0.002728\n",
      ">> Epoch 94 finished \tANN training loss 0.002692\n",
      ">> Epoch 95 finished \tANN training loss 0.002658\n",
      ">> Epoch 96 finished \tANN training loss 0.002625\n",
      ">> Epoch 97 finished \tANN training loss 0.002592\n",
      ">> Epoch 98 finished \tANN training loss 0.002560\n",
      ">> Epoch 99 finished \tANN training loss 0.002529\n",
      ">> Epoch 100 finished \tANN training loss 0.002499\n",
      ">> Epoch 101 finished \tANN training loss 0.002470\n",
      ">> Epoch 102 finished \tANN training loss 0.002441\n",
      ">> Epoch 103 finished \tANN training loss 0.002413\n",
      ">> Epoch 104 finished \tANN training loss 0.002386\n",
      ">> Epoch 105 finished \tANN training loss 0.002359\n",
      ">> Epoch 106 finished \tANN training loss 0.002332\n",
      ">> Epoch 107 finished \tANN training loss 0.002307\n",
      ">> Epoch 108 finished \tANN training loss 0.002282\n",
      ">> Epoch 109 finished \tANN training loss 0.002257\n",
      ">> Epoch 110 finished \tANN training loss 0.002233\n",
      ">> Epoch 111 finished \tANN training loss 0.002210\n",
      ">> Epoch 112 finished \tANN training loss 0.002186\n",
      ">> Epoch 113 finished \tANN training loss 0.002164\n",
      ">> Epoch 114 finished \tANN training loss 0.002142\n",
      ">> Epoch 115 finished \tANN training loss 0.002120\n",
      ">> Epoch 116 finished \tANN training loss 0.002098\n",
      ">> Epoch 117 finished \tANN training loss 0.002077\n",
      ">> Epoch 118 finished \tANN training loss 0.002057\n",
      ">> Epoch 119 finished \tANN training loss 0.002036\n",
      ">> Epoch 120 finished \tANN training loss 0.002017\n",
      ">> Epoch 121 finished \tANN training loss 0.001997\n",
      ">> Epoch 122 finished \tANN training loss 0.001978\n",
      ">> Epoch 123 finished \tANN training loss 0.001959\n",
      ">> Epoch 124 finished \tANN training loss 0.001940\n",
      ">> Epoch 125 finished \tANN training loss 0.001922\n",
      ">> Epoch 126 finished \tANN training loss 0.001904\n",
      ">> Epoch 127 finished \tANN training loss 0.001886\n",
      ">> Epoch 128 finished \tANN training loss 0.001869\n",
      ">> Epoch 129 finished \tANN training loss 0.001851\n",
      ">> Epoch 130 finished \tANN training loss 0.001834\n",
      ">> Epoch 131 finished \tANN training loss 0.001818\n",
      ">> Epoch 132 finished \tANN training loss 0.001801\n",
      ">> Epoch 133 finished \tANN training loss 0.001785\n",
      ">> Epoch 134 finished \tANN training loss 0.001769\n",
      ">> Epoch 135 finished \tANN training loss 0.001753\n",
      ">> Epoch 136 finished \tANN training loss 0.001738\n",
      ">> Epoch 137 finished \tANN training loss 0.001722\n",
      ">> Epoch 138 finished \tANN training loss 0.001707\n",
      ">> Epoch 139 finished \tANN training loss 0.001692\n",
      ">> Epoch 140 finished \tANN training loss 0.001677\n",
      ">> Epoch 141 finished \tANN training loss 0.001663\n",
      ">> Epoch 142 finished \tANN training loss 0.001649\n",
      ">> Epoch 143 finished \tANN training loss 0.001634\n",
      ">> Epoch 144 finished \tANN training loss 0.001620\n",
      ">> Epoch 145 finished \tANN training loss 0.001606\n",
      ">> Epoch 146 finished \tANN training loss 0.001593\n",
      ">> Epoch 147 finished \tANN training loss 0.001579\n",
      ">> Epoch 148 finished \tANN training loss 0.001566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 149 finished \tANN training loss 0.001553\n",
      ">> Epoch 150 finished \tANN training loss 0.001540\n",
      "[END] Fine tuning step\n",
      "############### End Training for HAVELLSEQ #####################\n",
      "############### End Training for ESCORTSEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 18.618011\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 18.610429\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 18.602822\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 18.595214\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 18.587592\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 18.579961\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 18.572317\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 18.564656\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 18.557000\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 18.549319\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 18.541612\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 18.533904\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 18.526174\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 18.518415\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 18.510664\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 18.502904\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 18.495128\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 18.487349\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 18.479542\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 18.471721\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 18.463883\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 18.456037\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 18.448185\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 18.440291\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 18.432397\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 18.424491\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 18.416562\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 18.408629\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 18.400665\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 18.392708\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 18.384743\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 18.376759\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 18.368739\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 18.360702\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 18.352663\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 18.344609\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 18.336552\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 18.328459\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 18.320354\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 18.312232\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 18.304098\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 18.295946\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 18.287773\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 18.279588\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 18.271394\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 18.263163\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 18.254931\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 18.246673\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 18.238407\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 18.230129\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 18.221824\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 18.213494\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 18.205156\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 18.196802\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 18.188412\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 18.180010\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 18.171600\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 18.163172\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 18.154735\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 18.146283\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 18.137790\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 18.129281\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 18.120763\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 18.112228\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 18.103672\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 18.095108\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 18.086529\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 18.077938\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 18.069312\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 18.060681\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 18.052029\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 18.043349\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 18.034668\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 18.025929\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 18.017200\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 18.008437\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 17.999655\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 17.990865\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 17.982051\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 17.973223\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 17.964357\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 17.955491\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 17.946589\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 17.937688\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 17.928752\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 17.919802\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 17.910813\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 17.901804\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 17.892801\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 17.883774\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 17.874715\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 17.865639\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 17.856540\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 17.847425\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 17.838324\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 17.829163\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 17.819986\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 17.810805\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 17.801596\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 17.792374\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.576003\n",
      ">> Epoch 2 finished \tANN training loss 0.574423\n",
      ">> Epoch 3 finished \tANN training loss 0.572818\n",
      ">> Epoch 4 finished \tANN training loss 0.571231\n",
      ">> Epoch 5 finished \tANN training loss 0.569661\n",
      ">> Epoch 6 finished \tANN training loss 0.568106\n",
      ">> Epoch 7 finished \tANN training loss 0.566485\n",
      ">> Epoch 8 finished \tANN training loss 0.564914\n",
      ">> Epoch 9 finished \tANN training loss 0.563385\n",
      ">> Epoch 10 finished \tANN training loss 0.561846\n",
      ">> Epoch 11 finished \tANN training loss 0.560286\n",
      ">> Epoch 12 finished \tANN training loss 0.558717\n",
      ">> Epoch 13 finished \tANN training loss 0.557189\n",
      ">> Epoch 14 finished \tANN training loss 0.555671\n",
      ">> Epoch 15 finished \tANN training loss 0.554152\n",
      ">> Epoch 16 finished \tANN training loss 0.552614\n",
      ">> Epoch 17 finished \tANN training loss 0.551079\n",
      ">> Epoch 18 finished \tANN training loss 0.549592\n",
      ">> Epoch 19 finished \tANN training loss 0.548050\n",
      ">> Epoch 20 finished \tANN training loss 0.546535\n",
      ">> Epoch 21 finished \tANN training loss 0.545068\n",
      ">> Epoch 22 finished \tANN training loss 0.543546\n",
      ">> Epoch 23 finished \tANN training loss 0.542027\n",
      ">> Epoch 24 finished \tANN training loss 0.540551\n",
      ">> Epoch 25 finished \tANN training loss 0.539101\n",
      ">> Epoch 26 finished \tANN training loss 0.537594\n",
      ">> Epoch 27 finished \tANN training loss 0.536102\n",
      ">> Epoch 28 finished \tANN training loss 0.534645\n",
      ">> Epoch 29 finished \tANN training loss 0.533194\n",
      ">> Epoch 30 finished \tANN training loss 0.531702\n",
      ">> Epoch 31 finished \tANN training loss 0.530254\n",
      ">> Epoch 32 finished \tANN training loss 0.528766\n",
      ">> Epoch 33 finished \tANN training loss 0.527306\n",
      ">> Epoch 34 finished \tANN training loss 0.525868\n",
      ">> Epoch 35 finished \tANN training loss 0.524418\n",
      ">> Epoch 36 finished \tANN training loss 0.522964\n",
      ">> Epoch 37 finished \tANN training loss 0.521530\n",
      ">> Epoch 38 finished \tANN training loss 0.520070\n",
      ">> Epoch 39 finished \tANN training loss 0.518682\n",
      ">> Epoch 40 finished \tANN training loss 0.517257\n",
      ">> Epoch 41 finished \tANN training loss 0.515815\n",
      ">> Epoch 42 finished \tANN training loss 0.514450\n",
      ">> Epoch 43 finished \tANN training loss 0.513015\n",
      ">> Epoch 44 finished \tANN training loss 0.511617\n",
      ">> Epoch 45 finished \tANN training loss 0.510223\n",
      ">> Epoch 46 finished \tANN training loss 0.508811\n",
      ">> Epoch 47 finished \tANN training loss 0.507419\n",
      ">> Epoch 48 finished \tANN training loss 0.506043\n",
      ">> Epoch 49 finished \tANN training loss 0.504645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 50 finished \tANN training loss 0.503286\n",
      ">> Epoch 51 finished \tANN training loss 0.501897\n",
      ">> Epoch 52 finished \tANN training loss 0.500521\n",
      ">> Epoch 53 finished \tANN training loss 0.499151\n",
      ">> Epoch 54 finished \tANN training loss 0.497803\n",
      ">> Epoch 55 finished \tANN training loss 0.496441\n",
      ">> Epoch 56 finished \tANN training loss 0.495118\n",
      ">> Epoch 57 finished \tANN training loss 0.493710\n",
      ">> Epoch 58 finished \tANN training loss 0.492376\n",
      ">> Epoch 59 finished \tANN training loss 0.491065\n",
      ">> Epoch 60 finished \tANN training loss 0.489718\n",
      ">> Epoch 61 finished \tANN training loss 0.488380\n",
      ">> Epoch 62 finished \tANN training loss 0.487045\n",
      ">> Epoch 63 finished \tANN training loss 0.485735\n",
      ">> Epoch 64 finished \tANN training loss 0.484398\n",
      ">> Epoch 65 finished \tANN training loss 0.483095\n",
      ">> Epoch 66 finished \tANN training loss 0.481768\n",
      ">> Epoch 67 finished \tANN training loss 0.480461\n",
      ">> Epoch 68 finished \tANN training loss 0.479160\n",
      ">> Epoch 69 finished \tANN training loss 0.477861\n",
      ">> Epoch 70 finished \tANN training loss 0.476532\n",
      ">> Epoch 71 finished \tANN training loss 0.475249\n",
      ">> Epoch 72 finished \tANN training loss 0.473957\n",
      ">> Epoch 73 finished \tANN training loss 0.472661\n",
      ">> Epoch 74 finished \tANN training loss 0.471397\n",
      ">> Epoch 75 finished \tANN training loss 0.470082\n",
      ">> Epoch 76 finished \tANN training loss 0.468783\n",
      ">> Epoch 77 finished \tANN training loss 0.467543\n",
      ">> Epoch 78 finished \tANN training loss 0.466234\n",
      ">> Epoch 79 finished \tANN training loss 0.464965\n",
      ">> Epoch 80 finished \tANN training loss 0.463694\n",
      ">> Epoch 81 finished \tANN training loss 0.462453\n",
      ">> Epoch 82 finished \tANN training loss 0.461209\n",
      ">> Epoch 83 finished \tANN training loss 0.459934\n",
      ">> Epoch 84 finished \tANN training loss 0.458688\n",
      ">> Epoch 85 finished \tANN training loss 0.457420\n",
      ">> Epoch 86 finished \tANN training loss 0.456187\n",
      ">> Epoch 87 finished \tANN training loss 0.454953\n",
      ">> Epoch 88 finished \tANN training loss 0.453709\n",
      ">> Epoch 89 finished \tANN training loss 0.452474\n",
      ">> Epoch 90 finished \tANN training loss 0.451228\n",
      ">> Epoch 91 finished \tANN training loss 0.449990\n",
      ">> Epoch 92 finished \tANN training loss 0.448737\n",
      ">> Epoch 93 finished \tANN training loss 0.447494\n",
      ">> Epoch 94 finished \tANN training loss 0.446270\n",
      ">> Epoch 95 finished \tANN training loss 0.445049\n",
      ">> Epoch 96 finished \tANN training loss 0.443822\n",
      ">> Epoch 97 finished \tANN training loss 0.442567\n",
      ">> Epoch 98 finished \tANN training loss 0.441362\n",
      ">> Epoch 99 finished \tANN training loss 0.440137\n",
      ">> Epoch 100 finished \tANN training loss 0.438935\n",
      ">> Epoch 101 finished \tANN training loss 0.437725\n",
      ">> Epoch 102 finished \tANN training loss 0.436498\n",
      ">> Epoch 103 finished \tANN training loss 0.435292\n",
      ">> Epoch 104 finished \tANN training loss 0.434094\n",
      ">> Epoch 105 finished \tANN training loss 0.432940\n",
      ">> Epoch 106 finished \tANN training loss 0.431685\n",
      ">> Epoch 107 finished \tANN training loss 0.430520\n",
      ">> Epoch 108 finished \tANN training loss 0.429308\n",
      ">> Epoch 109 finished \tANN training loss 0.428132\n",
      ">> Epoch 110 finished \tANN training loss 0.426956\n",
      ">> Epoch 111 finished \tANN training loss 0.425795\n",
      ">> Epoch 112 finished \tANN training loss 0.424652\n",
      ">> Epoch 113 finished \tANN training loss 0.423446\n",
      ">> Epoch 114 finished \tANN training loss 0.422314\n",
      ">> Epoch 115 finished \tANN training loss 0.421122\n",
      ">> Epoch 116 finished \tANN training loss 0.419962\n",
      ">> Epoch 117 finished \tANN training loss 0.418817\n",
      ">> Epoch 118 finished \tANN training loss 0.417680\n",
      ">> Epoch 119 finished \tANN training loss 0.416550\n",
      ">> Epoch 120 finished \tANN training loss 0.415376\n",
      ">> Epoch 121 finished \tANN training loss 0.414247\n",
      ">> Epoch 122 finished \tANN training loss 0.413093\n",
      ">> Epoch 123 finished \tANN training loss 0.411975\n",
      ">> Epoch 124 finished \tANN training loss 0.410800\n",
      ">> Epoch 125 finished \tANN training loss 0.409673\n",
      ">> Epoch 126 finished \tANN training loss 0.408556\n",
      ">> Epoch 127 finished \tANN training loss 0.407419\n",
      ">> Epoch 128 finished \tANN training loss 0.406315\n",
      ">> Epoch 129 finished \tANN training loss 0.405166\n",
      ">> Epoch 130 finished \tANN training loss 0.404057\n",
      ">> Epoch 131 finished \tANN training loss 0.402928\n",
      ">> Epoch 132 finished \tANN training loss 0.401831\n",
      ">> Epoch 133 finished \tANN training loss 0.400731\n",
      ">> Epoch 134 finished \tANN training loss 0.399620\n",
      ">> Epoch 135 finished \tANN training loss 0.398526\n",
      ">> Epoch 136 finished \tANN training loss 0.397473\n",
      ">> Epoch 137 finished \tANN training loss 0.396357\n",
      ">> Epoch 138 finished \tANN training loss 0.395284\n",
      ">> Epoch 139 finished \tANN training loss 0.394206\n",
      ">> Epoch 140 finished \tANN training loss 0.393134\n",
      ">> Epoch 141 finished \tANN training loss 0.392047\n",
      ">> Epoch 142 finished \tANN training loss 0.391012\n",
      ">> Epoch 143 finished \tANN training loss 0.389929\n",
      ">> Epoch 144 finished \tANN training loss 0.388872\n",
      ">> Epoch 145 finished \tANN training loss 0.387839\n",
      ">> Epoch 146 finished \tANN training loss 0.386798\n",
      ">> Epoch 147 finished \tANN training loss 0.385711\n",
      ">> Epoch 148 finished \tANN training loss 0.384676\n",
      ">> Epoch 149 finished \tANN training loss 0.383636\n",
      ">> Epoch 150 finished \tANN training loss 0.382607\n",
      "[END] Fine tuning step\n",
      "############### End Training for ESCORTSEQ #####################\n",
      "############### End Training for WIPROEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 4.733777\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 4.618627\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 4.502109\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 4.383723\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 4.262825\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 4.138859\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 4.011014\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 3.878559\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 3.740711\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 3.596773\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 3.446039\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 3.287868\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 3.121821\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 2.947381\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 2.765183\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 2.575170\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 2.378354\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 2.176407\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 1.972101\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 1.767638\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 1.566301\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 1.372916\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 1.190885\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 1.022462\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 0.872463\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 0.742383\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 0.631522\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 0.541813\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 0.469317\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 0.411513\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 0.368148\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 0.335633\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.310224\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.291675\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.277412\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.266783\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.258540\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.252174\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.246908\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.242733\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.239026\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.236128\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.233249\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.230754\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.228512\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.226430\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.224461\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.222622\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.220979\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.219317\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.217638\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.216121\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.214647\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.213107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 55 finished \tRBM Reconstruction error 0.211633\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.210233\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.208913\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.207458\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.206162\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.204751\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.203339\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.202003\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.200790\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.199552\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.198334\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.197059\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.195810\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.194521\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.193336\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.192135\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.191002\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.189835\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.188580\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.187392\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.186281\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.185180\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.183956\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.182813\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.181720\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.180687\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.179604\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.178559\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.177499\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.176412\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.175307\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.174271\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.173253\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.172274\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.171240\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.170174\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.169149\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.168181\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.167144\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.166171\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.165224\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.164215\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.163256\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.162301\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.161356\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.160447\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.090309\n",
      ">> Epoch 2 finished \tANN training loss 0.073929\n",
      ">> Epoch 3 finished \tANN training loss 0.060889\n",
      ">> Epoch 4 finished \tANN training loss 0.050498\n",
      ">> Epoch 5 finished \tANN training loss 0.042211\n",
      ">> Epoch 6 finished \tANN training loss 0.035599\n",
      ">> Epoch 7 finished \tANN training loss 0.030317\n",
      ">> Epoch 8 finished \tANN training loss 0.026097\n",
      ">> Epoch 9 finished \tANN training loss 0.022721\n",
      ">> Epoch 10 finished \tANN training loss 0.020017\n",
      ">> Epoch 11 finished \tANN training loss 0.017848\n",
      ">> Epoch 12 finished \tANN training loss 0.016106\n",
      ">> Epoch 13 finished \tANN training loss 0.014703\n",
      ">> Epoch 14 finished \tANN training loss 0.013570\n",
      ">> Epoch 15 finished \tANN training loss 0.012653\n",
      ">> Epoch 16 finished \tANN training loss 0.011907\n",
      ">> Epoch 17 finished \tANN training loss 0.011298\n",
      ">> Epoch 18 finished \tANN training loss 0.010798\n",
      ">> Epoch 19 finished \tANN training loss 0.010384\n",
      ">> Epoch 20 finished \tANN training loss 0.010040\n",
      ">> Epoch 21 finished \tANN training loss 0.009751\n",
      ">> Epoch 22 finished \tANN training loss 0.009505\n",
      ">> Epoch 23 finished \tANN training loss 0.009296\n",
      ">> Epoch 24 finished \tANN training loss 0.009114\n",
      ">> Epoch 25 finished \tANN training loss 0.008954\n",
      ">> Epoch 26 finished \tANN training loss 0.008812\n",
      ">> Epoch 27 finished \tANN training loss 0.008685\n",
      ">> Epoch 28 finished \tANN training loss 0.008570\n",
      ">> Epoch 29 finished \tANN training loss 0.008464\n",
      ">> Epoch 30 finished \tANN training loss 0.008365\n",
      ">> Epoch 31 finished \tANN training loss 0.008273\n",
      ">> Epoch 32 finished \tANN training loss 0.008187\n",
      ">> Epoch 33 finished \tANN training loss 0.008104\n",
      ">> Epoch 34 finished \tANN training loss 0.008025\n",
      ">> Epoch 35 finished \tANN training loss 0.007949\n",
      ">> Epoch 36 finished \tANN training loss 0.007876\n",
      ">> Epoch 37 finished \tANN training loss 0.007805\n",
      ">> Epoch 38 finished \tANN training loss 0.007736\n",
      ">> Epoch 39 finished \tANN training loss 0.007668\n",
      ">> Epoch 40 finished \tANN training loss 0.007602\n",
      ">> Epoch 41 finished \tANN training loss 0.007537\n",
      ">> Epoch 42 finished \tANN training loss 0.007474\n",
      ">> Epoch 43 finished \tANN training loss 0.007411\n",
      ">> Epoch 44 finished \tANN training loss 0.007350\n",
      ">> Epoch 45 finished \tANN training loss 0.007289\n",
      ">> Epoch 46 finished \tANN training loss 0.007230\n",
      ">> Epoch 47 finished \tANN training loss 0.007171\n",
      ">> Epoch 48 finished \tANN training loss 0.007114\n",
      ">> Epoch 49 finished \tANN training loss 0.007057\n",
      ">> Epoch 50 finished \tANN training loss 0.007000\n",
      ">> Epoch 51 finished \tANN training loss 0.006945\n",
      ">> Epoch 52 finished \tANN training loss 0.006890\n",
      ">> Epoch 53 finished \tANN training loss 0.006836\n",
      ">> Epoch 54 finished \tANN training loss 0.006783\n",
      ">> Epoch 55 finished \tANN training loss 0.006730\n",
      ">> Epoch 56 finished \tANN training loss 0.006678\n",
      ">> Epoch 57 finished \tANN training loss 0.006626\n",
      ">> Epoch 58 finished \tANN training loss 0.006575\n",
      ">> Epoch 59 finished \tANN training loss 0.006525\n",
      ">> Epoch 60 finished \tANN training loss 0.006475\n",
      ">> Epoch 61 finished \tANN training loss 0.006425\n",
      ">> Epoch 62 finished \tANN training loss 0.006377\n",
      ">> Epoch 63 finished \tANN training loss 0.006329\n",
      ">> Epoch 64 finished \tANN training loss 0.006281\n",
      ">> Epoch 65 finished \tANN training loss 0.006234\n",
      ">> Epoch 66 finished \tANN training loss 0.006187\n",
      ">> Epoch 67 finished \tANN training loss 0.006141\n",
      ">> Epoch 68 finished \tANN training loss 0.006095\n",
      ">> Epoch 69 finished \tANN training loss 0.006050\n",
      ">> Epoch 70 finished \tANN training loss 0.006005\n",
      ">> Epoch 71 finished \tANN training loss 0.005960\n",
      ">> Epoch 72 finished \tANN training loss 0.005917\n",
      ">> Epoch 73 finished \tANN training loss 0.005873\n",
      ">> Epoch 74 finished \tANN training loss 0.005830\n",
      ">> Epoch 75 finished \tANN training loss 0.005788\n",
      ">> Epoch 76 finished \tANN training loss 0.005745\n",
      ">> Epoch 77 finished \tANN training loss 0.005704\n",
      ">> Epoch 78 finished \tANN training loss 0.005663\n",
      ">> Epoch 79 finished \tANN training loss 0.005622\n",
      ">> Epoch 80 finished \tANN training loss 0.005581\n",
      ">> Epoch 81 finished \tANN training loss 0.005541\n",
      ">> Epoch 82 finished \tANN training loss 0.005502\n",
      ">> Epoch 83 finished \tANN training loss 0.005462\n",
      ">> Epoch 84 finished \tANN training loss 0.005424\n",
      ">> Epoch 85 finished \tANN training loss 0.005385\n",
      ">> Epoch 86 finished \tANN training loss 0.005347\n",
      ">> Epoch 87 finished \tANN training loss 0.005310\n",
      ">> Epoch 88 finished \tANN training loss 0.005273\n",
      ">> Epoch 89 finished \tANN training loss 0.005236\n",
      ">> Epoch 90 finished \tANN training loss 0.005199\n",
      ">> Epoch 91 finished \tANN training loss 0.005163\n",
      ">> Epoch 92 finished \tANN training loss 0.005128\n",
      ">> Epoch 93 finished \tANN training loss 0.005093\n",
      ">> Epoch 94 finished \tANN training loss 0.005058\n",
      ">> Epoch 95 finished \tANN training loss 0.005023\n",
      ">> Epoch 96 finished \tANN training loss 0.004989\n",
      ">> Epoch 97 finished \tANN training loss 0.004956\n",
      ">> Epoch 98 finished \tANN training loss 0.004922\n",
      ">> Epoch 99 finished \tANN training loss 0.004889\n",
      ">> Epoch 100 finished \tANN training loss 0.004857\n",
      ">> Epoch 101 finished \tANN training loss 0.004824\n",
      ">> Epoch 102 finished \tANN training loss 0.004793\n",
      ">> Epoch 103 finished \tANN training loss 0.004761\n",
      ">> Epoch 104 finished \tANN training loss 0.004730\n",
      ">> Epoch 105 finished \tANN training loss 0.004699\n",
      ">> Epoch 106 finished \tANN training loss 0.004669\n",
      ">> Epoch 107 finished \tANN training loss 0.004638\n",
      ">> Epoch 108 finished \tANN training loss 0.004609\n",
      ">> Epoch 109 finished \tANN training loss 0.004579\n",
      ">> Epoch 110 finished \tANN training loss 0.004550\n",
      ">> Epoch 111 finished \tANN training loss 0.004521\n",
      ">> Epoch 112 finished \tANN training loss 0.004493\n",
      ">> Epoch 113 finished \tANN training loss 0.004464\n",
      ">> Epoch 114 finished \tANN training loss 0.004437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 115 finished \tANN training loss 0.004409\n",
      ">> Epoch 116 finished \tANN training loss 0.004382\n",
      ">> Epoch 117 finished \tANN training loss 0.004355\n",
      ">> Epoch 118 finished \tANN training loss 0.004328\n",
      ">> Epoch 119 finished \tANN training loss 0.004302\n",
      ">> Epoch 120 finished \tANN training loss 0.004276\n",
      ">> Epoch 121 finished \tANN training loss 0.004250\n",
      ">> Epoch 122 finished \tANN training loss 0.004225\n",
      ">> Epoch 123 finished \tANN training loss 0.004199\n",
      ">> Epoch 124 finished \tANN training loss 0.004175\n",
      ">> Epoch 125 finished \tANN training loss 0.004150\n",
      ">> Epoch 126 finished \tANN training loss 0.004126\n",
      ">> Epoch 127 finished \tANN training loss 0.004102\n",
      ">> Epoch 128 finished \tANN training loss 0.004078\n",
      ">> Epoch 129 finished \tANN training loss 0.004054\n",
      ">> Epoch 130 finished \tANN training loss 0.004031\n",
      ">> Epoch 131 finished \tANN training loss 0.004008\n",
      ">> Epoch 132 finished \tANN training loss 0.003985\n",
      ">> Epoch 133 finished \tANN training loss 0.003963\n",
      ">> Epoch 134 finished \tANN training loss 0.003940\n",
      ">> Epoch 135 finished \tANN training loss 0.003918\n",
      ">> Epoch 136 finished \tANN training loss 0.003896\n",
      ">> Epoch 137 finished \tANN training loss 0.003875\n",
      ">> Epoch 138 finished \tANN training loss 0.003853\n",
      ">> Epoch 139 finished \tANN training loss 0.003832\n",
      ">> Epoch 140 finished \tANN training loss 0.003811\n",
      ">> Epoch 141 finished \tANN training loss 0.003790\n",
      ">> Epoch 142 finished \tANN training loss 0.003770\n",
      ">> Epoch 143 finished \tANN training loss 0.003749\n",
      ">> Epoch 144 finished \tANN training loss 0.003729\n",
      ">> Epoch 145 finished \tANN training loss 0.003709\n",
      ">> Epoch 146 finished \tANN training loss 0.003690\n",
      ">> Epoch 147 finished \tANN training loss 0.003670\n",
      ">> Epoch 148 finished \tANN training loss 0.003651\n",
      ">> Epoch 149 finished \tANN training loss 0.003632\n",
      ">> Epoch 150 finished \tANN training loss 0.003613\n",
      "[END] Fine tuning step\n",
      "############### End Training for WIPROEQ #####################\n",
      "############### End Training for CIPLAEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 4.189893\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 4.092920\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 3.994110\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 3.893147\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 3.789402\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 3.682351\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 3.571449\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 3.456087\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 3.335702\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 3.209669\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 3.077693\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 2.939067\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 2.793613\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 2.641372\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 2.482562\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 2.317586\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 2.147347\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 1.973244\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 1.797361\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 1.621604\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 1.448453\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 1.281836\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 1.123807\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 0.978123\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 0.845524\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 0.728934\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 0.627990\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 0.542125\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 0.471661\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 0.414247\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 0.368842\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 0.332852\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.304478\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.282748\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.265623\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.252697\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.241814\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.233117\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.225433\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.219059\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.213693\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.209195\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.204950\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.201057\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.197713\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.194328\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.191307\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.188415\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.185751\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.182980\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.180337\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.177890\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.175592\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.173311\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.170887\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.168869\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.166695\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.164526\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.162596\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.160631\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.158343\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.156196\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.154124\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.152313\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.150379\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.148567\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.146795\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.144866\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.143027\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.141215\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.139427\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.137626\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.135706\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.133990\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.132221\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.130511\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.128687\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.127147\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.125491\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.124065\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.122621\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.121355\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.119888\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.118402\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.116972\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.115596\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.114225\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.112676\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.111337\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.109802\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.108390\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.107072\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.105727\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.104546\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.103135\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.101844\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.100722\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.099467\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.098199\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.096823\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.114096\n",
      ">> Epoch 2 finished \tANN training loss 0.089681\n",
      ">> Epoch 3 finished \tANN training loss 0.070605\n",
      ">> Epoch 4 finished \tANN training loss 0.055701\n",
      ">> Epoch 5 finished \tANN training loss 0.044043\n",
      ">> Epoch 6 finished \tANN training loss 0.034914\n",
      ">> Epoch 7 finished \tANN training loss 0.027754\n",
      ">> Epoch 8 finished \tANN training loss 0.022127\n",
      ">> Epoch 9 finished \tANN training loss 0.017694\n",
      ">> Epoch 10 finished \tANN training loss 0.014221\n",
      ">> Epoch 11 finished \tANN training loss 0.011514\n",
      ">> Epoch 12 finished \tANN training loss 0.009403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 13 finished \tANN training loss 0.007755\n",
      ">> Epoch 14 finished \tANN training loss 0.006468\n",
      ">> Epoch 15 finished \tANN training loss 0.005461\n",
      ">> Epoch 16 finished \tANN training loss 0.004671\n",
      ">> Epoch 17 finished \tANN training loss 0.004050\n",
      ">> Epoch 18 finished \tANN training loss 0.003562\n",
      ">> Epoch 19 finished \tANN training loss 0.003176\n",
      ">> Epoch 20 finished \tANN training loss 0.002869\n",
      ">> Epoch 21 finished \tANN training loss 0.002625\n",
      ">> Epoch 22 finished \tANN training loss 0.002430\n",
      ">> Epoch 23 finished \tANN training loss 0.002273\n",
      ">> Epoch 24 finished \tANN training loss 0.002145\n",
      ">> Epoch 25 finished \tANN training loss 0.002041\n",
      ">> Epoch 26 finished \tANN training loss 0.001954\n",
      ">> Epoch 27 finished \tANN training loss 0.001882\n",
      ">> Epoch 28 finished \tANN training loss 0.001821\n",
      ">> Epoch 29 finished \tANN training loss 0.001769\n",
      ">> Epoch 30 finished \tANN training loss 0.001723\n",
      ">> Epoch 31 finished \tANN training loss 0.001683\n",
      ">> Epoch 32 finished \tANN training loss 0.001648\n",
      ">> Epoch 33 finished \tANN training loss 0.001616\n",
      ">> Epoch 34 finished \tANN training loss 0.001586\n",
      ">> Epoch 35 finished \tANN training loss 0.001559\n",
      ">> Epoch 36 finished \tANN training loss 0.001534\n",
      ">> Epoch 37 finished \tANN training loss 0.001510\n",
      ">> Epoch 38 finished \tANN training loss 0.001488\n",
      ">> Epoch 39 finished \tANN training loss 0.001467\n",
      ">> Epoch 40 finished \tANN training loss 0.001446\n",
      ">> Epoch 41 finished \tANN training loss 0.001426\n",
      ">> Epoch 42 finished \tANN training loss 0.001407\n",
      ">> Epoch 43 finished \tANN training loss 0.001389\n",
      ">> Epoch 44 finished \tANN training loss 0.001371\n",
      ">> Epoch 45 finished \tANN training loss 0.001353\n",
      ">> Epoch 46 finished \tANN training loss 0.001336\n",
      ">> Epoch 47 finished \tANN training loss 0.001320\n",
      ">> Epoch 48 finished \tANN training loss 0.001303\n",
      ">> Epoch 49 finished \tANN training loss 0.001287\n",
      ">> Epoch 50 finished \tANN training loss 0.001272\n",
      ">> Epoch 51 finished \tANN training loss 0.001256\n",
      ">> Epoch 52 finished \tANN training loss 0.001241\n",
      ">> Epoch 53 finished \tANN training loss 0.001227\n",
      ">> Epoch 54 finished \tANN training loss 0.001212\n",
      ">> Epoch 55 finished \tANN training loss 0.001198\n",
      ">> Epoch 56 finished \tANN training loss 0.001185\n",
      ">> Epoch 57 finished \tANN training loss 0.001171\n",
      ">> Epoch 58 finished \tANN training loss 0.001158\n",
      ">> Epoch 59 finished \tANN training loss 0.001145\n",
      ">> Epoch 60 finished \tANN training loss 0.001132\n",
      ">> Epoch 61 finished \tANN training loss 0.001119\n",
      ">> Epoch 62 finished \tANN training loss 0.001107\n",
      ">> Epoch 63 finished \tANN training loss 0.001095\n",
      ">> Epoch 64 finished \tANN training loss 0.001083\n",
      ">> Epoch 65 finished \tANN training loss 0.001071\n",
      ">> Epoch 66 finished \tANN training loss 0.001060\n",
      ">> Epoch 67 finished \tANN training loss 0.001049\n",
      ">> Epoch 68 finished \tANN training loss 0.001037\n",
      ">> Epoch 69 finished \tANN training loss 0.001027\n",
      ">> Epoch 70 finished \tANN training loss 0.001016\n",
      ">> Epoch 71 finished \tANN training loss 0.001006\n",
      ">> Epoch 72 finished \tANN training loss 0.000995\n",
      ">> Epoch 73 finished \tANN training loss 0.000985\n",
      ">> Epoch 74 finished \tANN training loss 0.000975\n",
      ">> Epoch 75 finished \tANN training loss 0.000966\n",
      ">> Epoch 76 finished \tANN training loss 0.000956\n",
      ">> Epoch 77 finished \tANN training loss 0.000947\n",
      ">> Epoch 78 finished \tANN training loss 0.000938\n",
      ">> Epoch 79 finished \tANN training loss 0.000929\n",
      ">> Epoch 80 finished \tANN training loss 0.000920\n",
      ">> Epoch 81 finished \tANN training loss 0.000911\n",
      ">> Epoch 82 finished \tANN training loss 0.000903\n",
      ">> Epoch 83 finished \tANN training loss 0.000895\n",
      ">> Epoch 84 finished \tANN training loss 0.000886\n",
      ">> Epoch 85 finished \tANN training loss 0.000878\n",
      ">> Epoch 86 finished \tANN training loss 0.000870\n",
      ">> Epoch 87 finished \tANN training loss 0.000863\n",
      ">> Epoch 88 finished \tANN training loss 0.000855\n",
      ">> Epoch 89 finished \tANN training loss 0.000848\n",
      ">> Epoch 90 finished \tANN training loss 0.000840\n",
      ">> Epoch 91 finished \tANN training loss 0.000833\n",
      ">> Epoch 92 finished \tANN training loss 0.000826\n",
      ">> Epoch 93 finished \tANN training loss 0.000819\n",
      ">> Epoch 94 finished \tANN training loss 0.000812\n",
      ">> Epoch 95 finished \tANN training loss 0.000806\n",
      ">> Epoch 96 finished \tANN training loss 0.000799\n",
      ">> Epoch 97 finished \tANN training loss 0.000793\n",
      ">> Epoch 98 finished \tANN training loss 0.000786\n",
      ">> Epoch 99 finished \tANN training loss 0.000780\n",
      ">> Epoch 100 finished \tANN training loss 0.000774\n",
      ">> Epoch 101 finished \tANN training loss 0.000768\n",
      ">> Epoch 102 finished \tANN training loss 0.000762\n",
      ">> Epoch 103 finished \tANN training loss 0.000756\n",
      ">> Epoch 104 finished \tANN training loss 0.000751\n",
      ">> Epoch 105 finished \tANN training loss 0.000745\n",
      ">> Epoch 106 finished \tANN training loss 0.000740\n",
      ">> Epoch 107 finished \tANN training loss 0.000734\n",
      ">> Epoch 108 finished \tANN training loss 0.000729\n",
      ">> Epoch 109 finished \tANN training loss 0.000724\n",
      ">> Epoch 110 finished \tANN training loss 0.000719\n",
      ">> Epoch 111 finished \tANN training loss 0.000714\n",
      ">> Epoch 112 finished \tANN training loss 0.000709\n",
      ">> Epoch 113 finished \tANN training loss 0.000704\n",
      ">> Epoch 114 finished \tANN training loss 0.000699\n",
      ">> Epoch 115 finished \tANN training loss 0.000695\n",
      ">> Epoch 116 finished \tANN training loss 0.000690\n",
      ">> Epoch 117 finished \tANN training loss 0.000686\n",
      ">> Epoch 118 finished \tANN training loss 0.000681\n",
      ">> Epoch 119 finished \tANN training loss 0.000677\n",
      ">> Epoch 120 finished \tANN training loss 0.000673\n",
      ">> Epoch 121 finished \tANN training loss 0.000669\n",
      ">> Epoch 122 finished \tANN training loss 0.000665\n",
      ">> Epoch 123 finished \tANN training loss 0.000661\n",
      ">> Epoch 124 finished \tANN training loss 0.000657\n",
      ">> Epoch 125 finished \tANN training loss 0.000653\n",
      ">> Epoch 126 finished \tANN training loss 0.000649\n",
      ">> Epoch 127 finished \tANN training loss 0.000645\n",
      ">> Epoch 128 finished \tANN training loss 0.000642\n",
      ">> Epoch 129 finished \tANN training loss 0.000638\n",
      ">> Epoch 130 finished \tANN training loss 0.000634\n",
      ">> Epoch 131 finished \tANN training loss 0.000631\n",
      ">> Epoch 132 finished \tANN training loss 0.000628\n",
      ">> Epoch 133 finished \tANN training loss 0.000624\n",
      ">> Epoch 134 finished \tANN training loss 0.000621\n",
      ">> Epoch 135 finished \tANN training loss 0.000618\n",
      ">> Epoch 136 finished \tANN training loss 0.000615\n",
      ">> Epoch 137 finished \tANN training loss 0.000612\n",
      ">> Epoch 138 finished \tANN training loss 0.000608\n",
      ">> Epoch 139 finished \tANN training loss 0.000605\n",
      ">> Epoch 140 finished \tANN training loss 0.000603\n",
      ">> Epoch 141 finished \tANN training loss 0.000600\n",
      ">> Epoch 142 finished \tANN training loss 0.000597\n",
      ">> Epoch 143 finished \tANN training loss 0.000594\n",
      ">> Epoch 144 finished \tANN training loss 0.000591\n",
      ">> Epoch 145 finished \tANN training loss 0.000589\n",
      ">> Epoch 146 finished \tANN training loss 0.000586\n",
      ">> Epoch 147 finished \tANN training loss 0.000583\n",
      ">> Epoch 148 finished \tANN training loss 0.000581\n",
      ">> Epoch 149 finished \tANN training loss 0.000578\n",
      ">> Epoch 150 finished \tANN training loss 0.000576\n",
      "[END] Fine tuning step\n",
      "############### End Training for CIPLAEQ #####################\n",
      "############### End Training for JISLJALEQSEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 5.874625\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 5.746988\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 5.610134\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 5.462156\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 5.301080\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 5.124814\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 4.931063\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 4.717581\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 4.482023\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 4.222534\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 3.938164\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 3.628723\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 3.296274\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 2.945070\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 2.581429\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 2.216219\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 1.858208\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 1.522025\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 1.218728\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 0.956091\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 0.741643\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 0.574447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 23 finished \tRBM Reconstruction error 0.450014\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 0.364518\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 0.306762\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 0.270360\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 0.248473\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 0.235682\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 0.228558\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 0.224469\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 0.221909\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 0.220017\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.218907\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.218284\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.216705\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.214052\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.212168\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.209079\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.206450\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.204150\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.201373\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.199797\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.197383\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.194812\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.192987\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.191349\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.188750\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.187018\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.186351\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.184918\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.183663\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.180631\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.178079\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.177028\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.175494\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.175144\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.172447\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.171246\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.168742\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.167898\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.166376\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.164870\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.162728\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.160907\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.160670\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.158604\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.157821\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.155674\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.152089\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.151912\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.152141\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.152550\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.151044\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.151510\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.150833\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.149045\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.150507\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.148753\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.147702\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.146242\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.145359\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.144966\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.145611\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.145927\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.146182\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.144025\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.142133\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.141000\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.141554\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.142391\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.143675\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.144452\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.142817\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.143925\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.144841\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.144525\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.141995\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.141624\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.143947\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.143703\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.243840\n",
      ">> Epoch 2 finished \tANN training loss 0.182364\n",
      ">> Epoch 3 finished \tANN training loss 0.136020\n",
      ">> Epoch 4 finished \tANN training loss 0.101354\n",
      ">> Epoch 5 finished \tANN training loss 0.075634\n",
      ">> Epoch 6 finished \tANN training loss 0.056553\n",
      ">> Epoch 7 finished \tANN training loss 0.042386\n",
      ">> Epoch 8 finished \tANN training loss 0.031873\n",
      ">> Epoch 9 finished \tANN training loss 0.024070\n",
      ">> Epoch 10 finished \tANN training loss 0.018310\n",
      ">> Epoch 11 finished \tANN training loss 0.014103\n",
      ">> Epoch 12 finished \tANN training loss 0.010986\n",
      ">> Epoch 13 finished \tANN training loss 0.008655\n",
      ">> Epoch 14 finished \tANN training loss 0.006907\n",
      ">> Epoch 15 finished \tANN training loss 0.005596\n",
      ">> Epoch 16 finished \tANN training loss 0.004612\n",
      ">> Epoch 17 finished \tANN training loss 0.003874\n",
      ">> Epoch 18 finished \tANN training loss 0.003319\n",
      ">> Epoch 19 finished \tANN training loss 0.002902\n",
      ">> Epoch 20 finished \tANN training loss 0.002588\n",
      ">> Epoch 21 finished \tANN training loss 0.002351\n",
      ">> Epoch 22 finished \tANN training loss 0.002171\n",
      ">> Epoch 23 finished \tANN training loss 0.002035\n",
      ">> Epoch 24 finished \tANN training loss 0.001930\n",
      ">> Epoch 25 finished \tANN training loss 0.001850\n",
      ">> Epoch 26 finished \tANN training loss 0.001789\n",
      ">> Epoch 27 finished \tANN training loss 0.001741\n",
      ">> Epoch 28 finished \tANN training loss 0.001703\n",
      ">> Epoch 29 finished \tANN training loss 0.001672\n",
      ">> Epoch 30 finished \tANN training loss 0.001648\n",
      ">> Epoch 31 finished \tANN training loss 0.001628\n",
      ">> Epoch 32 finished \tANN training loss 0.001611\n",
      ">> Epoch 33 finished \tANN training loss 0.001597\n",
      ">> Epoch 34 finished \tANN training loss 0.001585\n",
      ">> Epoch 35 finished \tANN training loss 0.001574\n",
      ">> Epoch 36 finished \tANN training loss 0.001564\n",
      ">> Epoch 37 finished \tANN training loss 0.001555\n",
      ">> Epoch 38 finished \tANN training loss 0.001547\n",
      ">> Epoch 39 finished \tANN training loss 0.001540\n",
      ">> Epoch 40 finished \tANN training loss 0.001533\n",
      ">> Epoch 41 finished \tANN training loss 0.001526\n",
      ">> Epoch 42 finished \tANN training loss 0.001520\n",
      ">> Epoch 43 finished \tANN training loss 0.001514\n",
      ">> Epoch 44 finished \tANN training loss 0.001508\n",
      ">> Epoch 45 finished \tANN training loss 0.001502\n",
      ">> Epoch 46 finished \tANN training loss 0.001497\n",
      ">> Epoch 47 finished \tANN training loss 0.001492\n",
      ">> Epoch 48 finished \tANN training loss 0.001487\n",
      ">> Epoch 49 finished \tANN training loss 0.001482\n",
      ">> Epoch 50 finished \tANN training loss 0.001477\n",
      ">> Epoch 51 finished \tANN training loss 0.001472\n",
      ">> Epoch 52 finished \tANN training loss 0.001468\n",
      ">> Epoch 53 finished \tANN training loss 0.001463\n",
      ">> Epoch 54 finished \tANN training loss 0.001459\n",
      ">> Epoch 55 finished \tANN training loss 0.001455\n",
      ">> Epoch 56 finished \tANN training loss 0.001451\n",
      ">> Epoch 57 finished \tANN training loss 0.001447\n",
      ">> Epoch 58 finished \tANN training loss 0.001443\n",
      ">> Epoch 59 finished \tANN training loss 0.001439\n",
      ">> Epoch 60 finished \tANN training loss 0.001435\n",
      ">> Epoch 61 finished \tANN training loss 0.001431\n",
      ">> Epoch 62 finished \tANN training loss 0.001428\n",
      ">> Epoch 63 finished \tANN training loss 0.001424\n",
      ">> Epoch 64 finished \tANN training loss 0.001421\n",
      ">> Epoch 65 finished \tANN training loss 0.001418\n",
      ">> Epoch 66 finished \tANN training loss 0.001414\n",
      ">> Epoch 67 finished \tANN training loss 0.001411\n",
      ">> Epoch 68 finished \tANN training loss 0.001408\n",
      ">> Epoch 69 finished \tANN training loss 0.001405\n",
      ">> Epoch 70 finished \tANN training loss 0.001402\n",
      ">> Epoch 71 finished \tANN training loss 0.001399\n",
      ">> Epoch 72 finished \tANN training loss 0.001396\n",
      ">> Epoch 73 finished \tANN training loss 0.001394\n",
      ">> Epoch 74 finished \tANN training loss 0.001391\n",
      ">> Epoch 75 finished \tANN training loss 0.001388\n",
      ">> Epoch 76 finished \tANN training loss 0.001386\n",
      ">> Epoch 77 finished \tANN training loss 0.001383\n",
      ">> Epoch 78 finished \tANN training loss 0.001381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 79 finished \tANN training loss 0.001378\n",
      ">> Epoch 80 finished \tANN training loss 0.001376\n",
      ">> Epoch 81 finished \tANN training loss 0.001374\n",
      ">> Epoch 82 finished \tANN training loss 0.001371\n",
      ">> Epoch 83 finished \tANN training loss 0.001369\n",
      ">> Epoch 84 finished \tANN training loss 0.001367\n",
      ">> Epoch 85 finished \tANN training loss 0.001365\n",
      ">> Epoch 86 finished \tANN training loss 0.001363\n",
      ">> Epoch 87 finished \tANN training loss 0.001361\n",
      ">> Epoch 88 finished \tANN training loss 0.001359\n",
      ">> Epoch 89 finished \tANN training loss 0.001357\n",
      ">> Epoch 90 finished \tANN training loss 0.001355\n",
      ">> Epoch 91 finished \tANN training loss 0.001353\n",
      ">> Epoch 92 finished \tANN training loss 0.001351\n",
      ">> Epoch 93 finished \tANN training loss 0.001349\n",
      ">> Epoch 94 finished \tANN training loss 0.001348\n",
      ">> Epoch 95 finished \tANN training loss 0.001346\n",
      ">> Epoch 96 finished \tANN training loss 0.001344\n",
      ">> Epoch 97 finished \tANN training loss 0.001343\n",
      ">> Epoch 98 finished \tANN training loss 0.001341\n",
      ">> Epoch 99 finished \tANN training loss 0.001339\n",
      ">> Epoch 100 finished \tANN training loss 0.001338\n",
      ">> Epoch 101 finished \tANN training loss 0.001336\n",
      ">> Epoch 102 finished \tANN training loss 0.001335\n",
      ">> Epoch 103 finished \tANN training loss 0.001333\n",
      ">> Epoch 104 finished \tANN training loss 0.001332\n",
      ">> Epoch 105 finished \tANN training loss 0.001331\n",
      ">> Epoch 106 finished \tANN training loss 0.001329\n",
      ">> Epoch 107 finished \tANN training loss 0.001328\n",
      ">> Epoch 108 finished \tANN training loss 0.001326\n",
      ">> Epoch 109 finished \tANN training loss 0.001325\n",
      ">> Epoch 110 finished \tANN training loss 0.001324\n",
      ">> Epoch 111 finished \tANN training loss 0.001323\n",
      ">> Epoch 112 finished \tANN training loss 0.001321\n",
      ">> Epoch 113 finished \tANN training loss 0.001320\n",
      ">> Epoch 114 finished \tANN training loss 0.001319\n",
      ">> Epoch 115 finished \tANN training loss 0.001318\n",
      ">> Epoch 116 finished \tANN training loss 0.001317\n",
      ">> Epoch 117 finished \tANN training loss 0.001316\n",
      ">> Epoch 118 finished \tANN training loss 0.001314\n",
      ">> Epoch 119 finished \tANN training loss 0.001313\n",
      ">> Epoch 120 finished \tANN training loss 0.001312\n",
      ">> Epoch 121 finished \tANN training loss 0.001311\n",
      ">> Epoch 122 finished \tANN training loss 0.001310\n",
      ">> Epoch 123 finished \tANN training loss 0.001309\n",
      ">> Epoch 124 finished \tANN training loss 0.001308\n",
      ">> Epoch 125 finished \tANN training loss 0.001307\n",
      ">> Epoch 126 finished \tANN training loss 0.001306\n",
      ">> Epoch 127 finished \tANN training loss 0.001305\n",
      ">> Epoch 128 finished \tANN training loss 0.001304\n",
      ">> Epoch 129 finished \tANN training loss 0.001303\n",
      ">> Epoch 130 finished \tANN training loss 0.001302\n",
      ">> Epoch 131 finished \tANN training loss 0.001302\n",
      ">> Epoch 132 finished \tANN training loss 0.001301\n",
      ">> Epoch 133 finished \tANN training loss 0.001300\n",
      ">> Epoch 134 finished \tANN training loss 0.001299\n",
      ">> Epoch 135 finished \tANN training loss 0.001298\n",
      ">> Epoch 136 finished \tANN training loss 0.001297\n",
      ">> Epoch 137 finished \tANN training loss 0.001296\n",
      ">> Epoch 138 finished \tANN training loss 0.001296\n",
      ">> Epoch 139 finished \tANN training loss 0.001295\n",
      ">> Epoch 140 finished \tANN training loss 0.001294\n",
      ">> Epoch 141 finished \tANN training loss 0.001293\n",
      ">> Epoch 142 finished \tANN training loss 0.001292\n",
      ">> Epoch 143 finished \tANN training loss 0.001292\n",
      ">> Epoch 144 finished \tANN training loss 0.001291\n",
      ">> Epoch 145 finished \tANN training loss 0.001290\n",
      ">> Epoch 146 finished \tANN training loss 0.001289\n",
      ">> Epoch 147 finished \tANN training loss 0.001289\n",
      ">> Epoch 148 finished \tANN training loss 0.001288\n",
      ">> Epoch 149 finished \tANN training loss 0.001287\n",
      ">> Epoch 150 finished \tANN training loss 0.001287\n",
      "[END] Fine tuning step\n",
      "############### End Training for JISLJALEQSEQ #####################\n",
      "############### End Training for IGLEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 0.822256\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 0.812777\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 0.803453\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 0.794267\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 0.785221\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 0.776318\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 0.767536\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 0.758888\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 0.750394\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 0.742021\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 0.733782\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 0.725663\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 0.717674\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 0.709808\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 0.702076\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 0.694438\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 0.686935\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 0.679549\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 0.672274\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 0.665111\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 0.658057\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 0.651126\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 0.644292\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 0.637563\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 0.630942\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 0.624422\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 0.617998\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 0.611660\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 0.605439\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 0.599295\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 0.593265\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 0.587314\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.581457\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.575682\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.569991\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.564402\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.558895\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.553476\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.548137\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.542874\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.537686\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.532568\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.527534\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.522582\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.517705\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.512894\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.508158\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.503483\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.498885\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.494354\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.489888\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.485496\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.481163\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.476897\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.472686\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.468535\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.464449\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.460431\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.456463\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.452542\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.448687\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.444886\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.441135\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.437456\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.433804\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.430198\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.426646\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.423146\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.419705\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.416307\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.412978\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.409698\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.406467\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.403293\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.400161\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.397048\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.393990\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.390960\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.387983\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.385050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 81 finished \tRBM Reconstruction error 0.382184\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.379336\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.376545\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.373780\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.371053\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.368375\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.365735\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.363110\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.360519\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.357966\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.355477\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.353007\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.350580\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.348171\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.345824\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.343483\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.341187\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.338951\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.336722\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.334516\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.015277\n",
      ">> Epoch 2 finished \tANN training loss 0.014807\n",
      ">> Epoch 3 finished \tANN training loss 0.014357\n",
      ">> Epoch 4 finished \tANN training loss 0.013926\n",
      ">> Epoch 5 finished \tANN training loss 0.013513\n",
      ">> Epoch 6 finished \tANN training loss 0.013117\n",
      ">> Epoch 7 finished \tANN training loss 0.012738\n",
      ">> Epoch 8 finished \tANN training loss 0.012374\n",
      ">> Epoch 9 finished \tANN training loss 0.012026\n",
      ">> Epoch 10 finished \tANN training loss 0.011692\n",
      ">> Epoch 11 finished \tANN training loss 0.011371\n",
      ">> Epoch 12 finished \tANN training loss 0.011064\n",
      ">> Epoch 13 finished \tANN training loss 0.010770\n",
      ">> Epoch 14 finished \tANN training loss 0.010488\n",
      ">> Epoch 15 finished \tANN training loss 0.010217\n",
      ">> Epoch 16 finished \tANN training loss 0.009958\n",
      ">> Epoch 17 finished \tANN training loss 0.009709\n",
      ">> Epoch 18 finished \tANN training loss 0.009470\n",
      ">> Epoch 19 finished \tANN training loss 0.009241\n",
      ">> Epoch 20 finished \tANN training loss 0.009021\n",
      ">> Epoch 21 finished \tANN training loss 0.008809\n",
      ">> Epoch 22 finished \tANN training loss 0.008606\n",
      ">> Epoch 23 finished \tANN training loss 0.008411\n",
      ">> Epoch 24 finished \tANN training loss 0.008224\n",
      ">> Epoch 25 finished \tANN training loss 0.008044\n",
      ">> Epoch 26 finished \tANN training loss 0.007872\n",
      ">> Epoch 27 finished \tANN training loss 0.007706\n",
      ">> Epoch 28 finished \tANN training loss 0.007546\n",
      ">> Epoch 29 finished \tANN training loss 0.007393\n",
      ">> Epoch 30 finished \tANN training loss 0.007245\n",
      ">> Epoch 31 finished \tANN training loss 0.007103\n",
      ">> Epoch 32 finished \tANN training loss 0.006967\n",
      ">> Epoch 33 finished \tANN training loss 0.006835\n",
      ">> Epoch 34 finished \tANN training loss 0.006709\n",
      ">> Epoch 35 finished \tANN training loss 0.006587\n",
      ">> Epoch 36 finished \tANN training loss 0.006470\n",
      ">> Epoch 37 finished \tANN training loss 0.006357\n",
      ">> Epoch 38 finished \tANN training loss 0.006248\n",
      ">> Epoch 39 finished \tANN training loss 0.006144\n",
      ">> Epoch 40 finished \tANN training loss 0.006043\n",
      ">> Epoch 41 finished \tANN training loss 0.005945\n",
      ">> Epoch 42 finished \tANN training loss 0.005851\n",
      ">> Epoch 43 finished \tANN training loss 0.005761\n",
      ">> Epoch 44 finished \tANN training loss 0.005673\n",
      ">> Epoch 45 finished \tANN training loss 0.005589\n",
      ">> Epoch 46 finished \tANN training loss 0.005507\n",
      ">> Epoch 47 finished \tANN training loss 0.005429\n",
      ">> Epoch 48 finished \tANN training loss 0.005353\n",
      ">> Epoch 49 finished \tANN training loss 0.005279\n",
      ">> Epoch 50 finished \tANN training loss 0.005208\n",
      ">> Epoch 51 finished \tANN training loss 0.005140\n",
      ">> Epoch 52 finished \tANN training loss 0.005073\n",
      ">> Epoch 53 finished \tANN training loss 0.005009\n",
      ">> Epoch 54 finished \tANN training loss 0.004947\n",
      ">> Epoch 55 finished \tANN training loss 0.004887\n",
      ">> Epoch 56 finished \tANN training loss 0.004828\n",
      ">> Epoch 57 finished \tANN training loss 0.004772\n",
      ">> Epoch 58 finished \tANN training loss 0.004717\n",
      ">> Epoch 59 finished \tANN training loss 0.004664\n",
      ">> Epoch 60 finished \tANN training loss 0.004613\n",
      ">> Epoch 61 finished \tANN training loss 0.004563\n",
      ">> Epoch 62 finished \tANN training loss 0.004514\n",
      ">> Epoch 63 finished \tANN training loss 0.004467\n",
      ">> Epoch 64 finished \tANN training loss 0.004421\n",
      ">> Epoch 65 finished \tANN training loss 0.004377\n",
      ">> Epoch 66 finished \tANN training loss 0.004334\n",
      ">> Epoch 67 finished \tANN training loss 0.004292\n",
      ">> Epoch 68 finished \tANN training loss 0.004251\n",
      ">> Epoch 69 finished \tANN training loss 0.004211\n",
      ">> Epoch 70 finished \tANN training loss 0.004172\n",
      ">> Epoch 71 finished \tANN training loss 0.004135\n",
      ">> Epoch 72 finished \tANN training loss 0.004098\n",
      ">> Epoch 73 finished \tANN training loss 0.004062\n",
      ">> Epoch 74 finished \tANN training loss 0.004027\n",
      ">> Epoch 75 finished \tANN training loss 0.003993\n",
      ">> Epoch 76 finished \tANN training loss 0.003960\n",
      ">> Epoch 77 finished \tANN training loss 0.003927\n",
      ">> Epoch 78 finished \tANN training loss 0.003896\n",
      ">> Epoch 79 finished \tANN training loss 0.003865\n",
      ">> Epoch 80 finished \tANN training loss 0.003834\n",
      ">> Epoch 81 finished \tANN training loss 0.003805\n",
      ">> Epoch 82 finished \tANN training loss 0.003776\n",
      ">> Epoch 83 finished \tANN training loss 0.003747\n",
      ">> Epoch 84 finished \tANN training loss 0.003720\n",
      ">> Epoch 85 finished \tANN training loss 0.003692\n",
      ">> Epoch 86 finished \tANN training loss 0.003666\n",
      ">> Epoch 87 finished \tANN training loss 0.003640\n",
      ">> Epoch 88 finished \tANN training loss 0.003614\n",
      ">> Epoch 89 finished \tANN training loss 0.003589\n",
      ">> Epoch 90 finished \tANN training loss 0.003564\n",
      ">> Epoch 91 finished \tANN training loss 0.003540\n",
      ">> Epoch 92 finished \tANN training loss 0.003516\n",
      ">> Epoch 93 finished \tANN training loss 0.003493\n",
      ">> Epoch 94 finished \tANN training loss 0.003470\n",
      ">> Epoch 95 finished \tANN training loss 0.003448\n",
      ">> Epoch 96 finished \tANN training loss 0.003426\n",
      ">> Epoch 97 finished \tANN training loss 0.003404\n",
      ">> Epoch 98 finished \tANN training loss 0.003383\n",
      ">> Epoch 99 finished \tANN training loss 0.003362\n",
      ">> Epoch 100 finished \tANN training loss 0.003341\n",
      ">> Epoch 101 finished \tANN training loss 0.003320\n",
      ">> Epoch 102 finished \tANN training loss 0.003300\n",
      ">> Epoch 103 finished \tANN training loss 0.003281\n",
      ">> Epoch 104 finished \tANN training loss 0.003261\n",
      ">> Epoch 105 finished \tANN training loss 0.003242\n",
      ">> Epoch 106 finished \tANN training loss 0.003223\n",
      ">> Epoch 107 finished \tANN training loss 0.003204\n",
      ">> Epoch 108 finished \tANN training loss 0.003186\n",
      ">> Epoch 109 finished \tANN training loss 0.003167\n",
      ">> Epoch 110 finished \tANN training loss 0.003149\n",
      ">> Epoch 111 finished \tANN training loss 0.003132\n",
      ">> Epoch 112 finished \tANN training loss 0.003114\n",
      ">> Epoch 113 finished \tANN training loss 0.003097\n",
      ">> Epoch 114 finished \tANN training loss 0.003080\n",
      ">> Epoch 115 finished \tANN training loss 0.003063\n",
      ">> Epoch 116 finished \tANN training loss 0.003046\n",
      ">> Epoch 117 finished \tANN training loss 0.003030\n",
      ">> Epoch 118 finished \tANN training loss 0.003013\n",
      ">> Epoch 119 finished \tANN training loss 0.002997\n",
      ">> Epoch 120 finished \tANN training loss 0.002981\n",
      ">> Epoch 121 finished \tANN training loss 0.002965\n",
      ">> Epoch 122 finished \tANN training loss 0.002950\n",
      ">> Epoch 123 finished \tANN training loss 0.002934\n",
      ">> Epoch 124 finished \tANN training loss 0.002919\n",
      ">> Epoch 125 finished \tANN training loss 0.002904\n",
      ">> Epoch 126 finished \tANN training loss 0.002889\n",
      ">> Epoch 127 finished \tANN training loss 0.002874\n",
      ">> Epoch 128 finished \tANN training loss 0.002859\n",
      ">> Epoch 129 finished \tANN training loss 0.002844\n",
      ">> Epoch 130 finished \tANN training loss 0.002830\n",
      ">> Epoch 131 finished \tANN training loss 0.002816\n",
      ">> Epoch 132 finished \tANN training loss 0.002801\n",
      ">> Epoch 133 finished \tANN training loss 0.002787\n",
      ">> Epoch 134 finished \tANN training loss 0.002773\n",
      ">> Epoch 135 finished \tANN training loss 0.002760\n",
      ">> Epoch 136 finished \tANN training loss 0.002746\n",
      ">> Epoch 137 finished \tANN training loss 0.002732\n",
      ">> Epoch 138 finished \tANN training loss 0.002719\n",
      ">> Epoch 139 finished \tANN training loss 0.002705\n",
      ">> Epoch 140 finished \tANN training loss 0.002692\n",
      ">> Epoch 141 finished \tANN training loss 0.002679\n",
      ">> Epoch 142 finished \tANN training loss 0.002666\n",
      ">> Epoch 143 finished \tANN training loss 0.002653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 144 finished \tANN training loss 0.002640\n",
      ">> Epoch 145 finished \tANN training loss 0.002627\n",
      ">> Epoch 146 finished \tANN training loss 0.002615\n",
      ">> Epoch 147 finished \tANN training loss 0.002602\n",
      ">> Epoch 148 finished \tANN training loss 0.002589\n",
      ">> Epoch 149 finished \tANN training loss 0.002577\n",
      ">> Epoch 150 finished \tANN training loss 0.002565\n",
      "[END] Fine tuning step\n",
      "############### End Training for IGLEQ #####################\n",
      "############### End Training for IOCEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 2.329814\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 2.281428\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 2.233647\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 2.186437\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 2.139837\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 2.093728\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 2.048098\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 2.002888\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 1.958101\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 1.913641\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 1.869446\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 1.825551\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 1.781850\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 1.738343\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 1.694930\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 1.651684\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 1.608454\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 1.565274\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 1.522112\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 1.478988\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 1.435823\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 1.392695\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 1.349470\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 1.306363\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 1.263278\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 1.220282\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 1.177278\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 1.134400\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 1.091853\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 1.049430\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 1.007314\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 0.965730\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.924580\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.884269\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.844457\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.805426\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.767372\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.730545\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.694744\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.660256\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.627005\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.595255\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.564802\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.536101\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.508961\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.483326\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.459390\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.437125\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.416395\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.397185\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.379430\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.363540\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.348937\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.335522\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.323323\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.311690\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.301437\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.292430\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.284149\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.276349\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.269395\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.263272\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.257616\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.252641\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.248092\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.243945\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.240185\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.236536\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.233476\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.230561\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.227888\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.225355\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.223077\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.220667\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.218519\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.216448\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.214418\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.212666\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.210982\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.209217\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.207487\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.205917\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.204435\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.203002\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.201551\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.200143\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.198863\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.197473\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.196283\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.195021\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.193667\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.192542\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.191274\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.190158\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.188880\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.187663\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.186485\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.185291\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.184182\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.183087\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.097949\n",
      ">> Epoch 2 finished \tANN training loss 0.086640\n",
      ">> Epoch 3 finished \tANN training loss 0.076666\n",
      ">> Epoch 4 finished \tANN training loss 0.067867\n",
      ">> Epoch 5 finished \tANN training loss 0.060100\n",
      ">> Epoch 6 finished \tANN training loss 0.053237\n",
      ">> Epoch 7 finished \tANN training loss 0.047172\n",
      ">> Epoch 8 finished \tANN training loss 0.041810\n",
      ">> Epoch 9 finished \tANN training loss 0.037069\n",
      ">> Epoch 10 finished \tANN training loss 0.032875\n",
      ">> Epoch 11 finished \tANN training loss 0.029167\n",
      ">> Epoch 12 finished \tANN training loss 0.025888\n",
      ">> Epoch 13 finished \tANN training loss 0.022987\n",
      ">> Epoch 14 finished \tANN training loss 0.020421\n",
      ">> Epoch 15 finished \tANN training loss 0.018153\n",
      ">> Epoch 16 finished \tANN training loss 0.016147\n",
      ">> Epoch 17 finished \tANN training loss 0.014373\n",
      ">> Epoch 18 finished \tANN training loss 0.012804\n",
      ">> Epoch 19 finished \tANN training loss 0.011418\n",
      ">> Epoch 20 finished \tANN training loss 0.010193\n",
      ">> Epoch 21 finished \tANN training loss 0.009110\n",
      ">> Epoch 22 finished \tANN training loss 0.008153\n",
      ">> Epoch 23 finished \tANN training loss 0.007307\n",
      ">> Epoch 24 finished \tANN training loss 0.006560\n",
      ">> Epoch 25 finished \tANN training loss 0.005900\n",
      ">> Epoch 26 finished \tANN training loss 0.005317\n",
      ">> Epoch 27 finished \tANN training loss 0.004802\n",
      ">> Epoch 28 finished \tANN training loss 0.004348\n",
      ">> Epoch 29 finished \tANN training loss 0.003946\n",
      ">> Epoch 30 finished \tANN training loss 0.003592\n",
      ">> Epoch 31 finished \tANN training loss 0.003279\n",
      ">> Epoch 32 finished \tANN training loss 0.003002\n",
      ">> Epoch 33 finished \tANN training loss 0.002758\n",
      ">> Epoch 34 finished \tANN training loss 0.002543\n",
      ">> Epoch 35 finished \tANN training loss 0.002352\n",
      ">> Epoch 36 finished \tANN training loss 0.002184\n",
      ">> Epoch 37 finished \tANN training loss 0.002036\n",
      ">> Epoch 38 finished \tANN training loss 0.001905\n",
      ">> Epoch 39 finished \tANN training loss 0.001789\n",
      ">> Epoch 40 finished \tANN training loss 0.001686\n",
      ">> Epoch 41 finished \tANN training loss 0.001596\n",
      ">> Epoch 42 finished \tANN training loss 0.001516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 43 finished \tANN training loss 0.001445\n",
      ">> Epoch 44 finished \tANN training loss 0.001382\n",
      ">> Epoch 45 finished \tANN training loss 0.001327\n",
      ">> Epoch 46 finished \tANN training loss 0.001277\n",
      ">> Epoch 47 finished \tANN training loss 0.001234\n",
      ">> Epoch 48 finished \tANN training loss 0.001195\n",
      ">> Epoch 49 finished \tANN training loss 0.001160\n",
      ">> Epoch 50 finished \tANN training loss 0.001130\n",
      ">> Epoch 51 finished \tANN training loss 0.001102\n",
      ">> Epoch 52 finished \tANN training loss 0.001078\n",
      ">> Epoch 53 finished \tANN training loss 0.001056\n",
      ">> Epoch 54 finished \tANN training loss 0.001037\n",
      ">> Epoch 55 finished \tANN training loss 0.001019\n",
      ">> Epoch 56 finished \tANN training loss 0.001004\n",
      ">> Epoch 57 finished \tANN training loss 0.000989\n",
      ">> Epoch 58 finished \tANN training loss 0.000977\n",
      ">> Epoch 59 finished \tANN training loss 0.000965\n",
      ">> Epoch 60 finished \tANN training loss 0.000955\n",
      ">> Epoch 61 finished \tANN training loss 0.000945\n",
      ">> Epoch 62 finished \tANN training loss 0.000937\n",
      ">> Epoch 63 finished \tANN training loss 0.000929\n",
      ">> Epoch 64 finished \tANN training loss 0.000922\n",
      ">> Epoch 65 finished \tANN training loss 0.000915\n",
      ">> Epoch 66 finished \tANN training loss 0.000909\n",
      ">> Epoch 67 finished \tANN training loss 0.000903\n",
      ">> Epoch 68 finished \tANN training loss 0.000898\n",
      ">> Epoch 69 finished \tANN training loss 0.000893\n",
      ">> Epoch 70 finished \tANN training loss 0.000889\n",
      ">> Epoch 71 finished \tANN training loss 0.000884\n",
      ">> Epoch 72 finished \tANN training loss 0.000880\n",
      ">> Epoch 73 finished \tANN training loss 0.000877\n",
      ">> Epoch 74 finished \tANN training loss 0.000873\n",
      ">> Epoch 75 finished \tANN training loss 0.000869\n",
      ">> Epoch 76 finished \tANN training loss 0.000866\n",
      ">> Epoch 77 finished \tANN training loss 0.000863\n",
      ">> Epoch 78 finished \tANN training loss 0.000860\n",
      ">> Epoch 79 finished \tANN training loss 0.000857\n",
      ">> Epoch 80 finished \tANN training loss 0.000854\n",
      ">> Epoch 81 finished \tANN training loss 0.000852\n",
      ">> Epoch 82 finished \tANN training loss 0.000849\n",
      ">> Epoch 83 finished \tANN training loss 0.000846\n",
      ">> Epoch 84 finished \tANN training loss 0.000844\n",
      ">> Epoch 85 finished \tANN training loss 0.000842\n",
      ">> Epoch 86 finished \tANN training loss 0.000839\n",
      ">> Epoch 87 finished \tANN training loss 0.000837\n",
      ">> Epoch 88 finished \tANN training loss 0.000835\n",
      ">> Epoch 89 finished \tANN training loss 0.000833\n",
      ">> Epoch 90 finished \tANN training loss 0.000830\n",
      ">> Epoch 91 finished \tANN training loss 0.000828\n",
      ">> Epoch 92 finished \tANN training loss 0.000826\n",
      ">> Epoch 93 finished \tANN training loss 0.000824\n",
      ">> Epoch 94 finished \tANN training loss 0.000822\n",
      ">> Epoch 95 finished \tANN training loss 0.000820\n",
      ">> Epoch 96 finished \tANN training loss 0.000818\n",
      ">> Epoch 97 finished \tANN training loss 0.000816\n",
      ">> Epoch 98 finished \tANN training loss 0.000814\n",
      ">> Epoch 99 finished \tANN training loss 0.000812\n",
      ">> Epoch 100 finished \tANN training loss 0.000811\n",
      ">> Epoch 101 finished \tANN training loss 0.000809\n",
      ">> Epoch 102 finished \tANN training loss 0.000807\n",
      ">> Epoch 103 finished \tANN training loss 0.000805\n",
      ">> Epoch 104 finished \tANN training loss 0.000803\n",
      ">> Epoch 105 finished \tANN training loss 0.000802\n",
      ">> Epoch 106 finished \tANN training loss 0.000800\n",
      ">> Epoch 107 finished \tANN training loss 0.000798\n",
      ">> Epoch 108 finished \tANN training loss 0.000797\n",
      ">> Epoch 109 finished \tANN training loss 0.000795\n",
      ">> Epoch 110 finished \tANN training loss 0.000793\n",
      ">> Epoch 111 finished \tANN training loss 0.000792\n",
      ">> Epoch 112 finished \tANN training loss 0.000790\n",
      ">> Epoch 113 finished \tANN training loss 0.000788\n",
      ">> Epoch 114 finished \tANN training loss 0.000787\n",
      ">> Epoch 115 finished \tANN training loss 0.000785\n",
      ">> Epoch 116 finished \tANN training loss 0.000784\n",
      ">> Epoch 117 finished \tANN training loss 0.000782\n",
      ">> Epoch 118 finished \tANN training loss 0.000781\n",
      ">> Epoch 119 finished \tANN training loss 0.000779\n",
      ">> Epoch 120 finished \tANN training loss 0.000777\n",
      ">> Epoch 121 finished \tANN training loss 0.000776\n",
      ">> Epoch 122 finished \tANN training loss 0.000775\n",
      ">> Epoch 123 finished \tANN training loss 0.000773\n",
      ">> Epoch 124 finished \tANN training loss 0.000772\n",
      ">> Epoch 125 finished \tANN training loss 0.000770\n",
      ">> Epoch 126 finished \tANN training loss 0.000769\n",
      ">> Epoch 127 finished \tANN training loss 0.000767\n",
      ">> Epoch 128 finished \tANN training loss 0.000766\n",
      ">> Epoch 129 finished \tANN training loss 0.000765\n",
      ">> Epoch 130 finished \tANN training loss 0.000763\n",
      ">> Epoch 131 finished \tANN training loss 0.000762\n",
      ">> Epoch 132 finished \tANN training loss 0.000761\n",
      ">> Epoch 133 finished \tANN training loss 0.000759\n",
      ">> Epoch 134 finished \tANN training loss 0.000758\n",
      ">> Epoch 135 finished \tANN training loss 0.000757\n",
      ">> Epoch 136 finished \tANN training loss 0.000755\n",
      ">> Epoch 137 finished \tANN training loss 0.000754\n",
      ">> Epoch 138 finished \tANN training loss 0.000753\n",
      ">> Epoch 139 finished \tANN training loss 0.000752\n",
      ">> Epoch 140 finished \tANN training loss 0.000750\n",
      ">> Epoch 141 finished \tANN training loss 0.000749\n",
      ">> Epoch 142 finished \tANN training loss 0.000748\n",
      ">> Epoch 143 finished \tANN training loss 0.000747\n",
      ">> Epoch 144 finished \tANN training loss 0.000745\n",
      ">> Epoch 145 finished \tANN training loss 0.000744\n",
      ">> Epoch 146 finished \tANN training loss 0.000743\n",
      ">> Epoch 147 finished \tANN training loss 0.000742\n",
      ">> Epoch 148 finished \tANN training loss 0.000741\n",
      ">> Epoch 149 finished \tANN training loss 0.000740\n",
      ">> Epoch 150 finished \tANN training loss 0.000738\n",
      "[END] Fine tuning step\n",
      "############### End Training for IOCEQ #####################\n",
      "############### End Training for BATAINDIAEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 0.763938\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 0.756921\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 0.750045\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 0.743314\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 0.736719\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 0.730262\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 0.723937\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 0.717755\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 0.711694\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 0.705762\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 0.699956\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 0.694272\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 0.688706\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 0.683246\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 0.677913\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 0.672691\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 0.667560\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 0.662529\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 0.657600\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 0.652774\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 0.648038\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 0.643399\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 0.638841\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 0.634365\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 0.629967\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 0.625654\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 0.621419\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 0.617246\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 0.613152\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 0.609121\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 0.605168\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 0.601275\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.597438\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.593648\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.589923\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.586264\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.582649\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.579091\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.575585\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.572117\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.568713\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.565347\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.562018\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.558726\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.555472\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.552248\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.549070\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.545920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 49 finished \tRBM Reconstruction error 0.542811\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.539732\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.536684\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.533672\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.530686\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.527726\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.524782\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.521858\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.518978\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.516100\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.513238\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.510409\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.507590\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.504799\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.502010\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.499235\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.496471\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.493733\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.490999\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.488288\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.485584\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.482882\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.480205\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.477515\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.474851\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.472189\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.469549\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.466922\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.464294\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.461671\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.459046\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.456418\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.453813\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.451208\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.448604\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.446011\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.443420\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.440832\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.438243\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.435640\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.433062\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.430472\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.427901\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.425314\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.422726\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.420137\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.417569\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.414988\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.412420\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.409841\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.407253\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.404663\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.066723\n",
      ">> Epoch 2 finished \tANN training loss 0.062847\n",
      ">> Epoch 3 finished \tANN training loss 0.059227\n",
      ">> Epoch 4 finished \tANN training loss 0.055845\n",
      ">> Epoch 5 finished \tANN training loss 0.052685\n",
      ">> Epoch 6 finished \tANN training loss 0.049731\n",
      ">> Epoch 7 finished \tANN training loss 0.046968\n",
      ">> Epoch 8 finished \tANN training loss 0.044385\n",
      ">> Epoch 9 finished \tANN training loss 0.041969\n",
      ">> Epoch 10 finished \tANN training loss 0.039710\n",
      ">> Epoch 11 finished \tANN training loss 0.037600\n",
      ">> Epoch 12 finished \tANN training loss 0.035632\n",
      ">> Epoch 13 finished \tANN training loss 0.033795\n",
      ">> Epoch 14 finished \tANN training loss 0.032077\n",
      ">> Epoch 15 finished \tANN training loss 0.030469\n",
      ">> Epoch 16 finished \tANN training loss 0.028964\n",
      ">> Epoch 17 finished \tANN training loss 0.027555\n",
      ">> Epoch 18 finished \tANN training loss 0.026235\n",
      ">> Epoch 19 finished \tANN training loss 0.024997\n",
      ">> Epoch 20 finished \tANN training loss 0.023837\n",
      ">> Epoch 21 finished \tANN training loss 0.022749\n",
      ">> Epoch 22 finished \tANN training loss 0.021729\n",
      ">> Epoch 23 finished \tANN training loss 0.020772\n",
      ">> Epoch 24 finished \tANN training loss 0.019875\n",
      ">> Epoch 25 finished \tANN training loss 0.019033\n",
      ">> Epoch 26 finished \tANN training loss 0.018242\n",
      ">> Epoch 27 finished \tANN training loss 0.017498\n",
      ">> Epoch 28 finished \tANN training loss 0.016800\n",
      ">> Epoch 29 finished \tANN training loss 0.016143\n",
      ">> Epoch 30 finished \tANN training loss 0.015527\n",
      ">> Epoch 31 finished \tANN training loss 0.014947\n",
      ">> Epoch 32 finished \tANN training loss 0.014402\n",
      ">> Epoch 33 finished \tANN training loss 0.013890\n",
      ">> Epoch 34 finished \tANN training loss 0.013407\n",
      ">> Epoch 35 finished \tANN training loss 0.012952\n",
      ">> Epoch 36 finished \tANN training loss 0.012523\n",
      ">> Epoch 37 finished \tANN training loss 0.012116\n",
      ">> Epoch 38 finished \tANN training loss 0.011732\n",
      ">> Epoch 39 finished \tANN training loss 0.011368\n",
      ">> Epoch 40 finished \tANN training loss 0.011023\n",
      ">> Epoch 41 finished \tANN training loss 0.010696\n",
      ">> Epoch 42 finished \tANN training loss 0.010385\n",
      ">> Epoch 43 finished \tANN training loss 0.010090\n",
      ">> Epoch 44 finished \tANN training loss 0.009809\n",
      ">> Epoch 45 finished \tANN training loss 0.009542\n",
      ">> Epoch 46 finished \tANN training loss 0.009288\n",
      ">> Epoch 47 finished \tANN training loss 0.009046\n",
      ">> Epoch 48 finished \tANN training loss 0.008814\n",
      ">> Epoch 49 finished \tANN training loss 0.008594\n",
      ">> Epoch 50 finished \tANN training loss 0.008383\n",
      ">> Epoch 51 finished \tANN training loss 0.008182\n",
      ">> Epoch 52 finished \tANN training loss 0.007989\n",
      ">> Epoch 53 finished \tANN training loss 0.007804\n",
      ">> Epoch 54 finished \tANN training loss 0.007627\n",
      ">> Epoch 55 finished \tANN training loss 0.007458\n",
      ">> Epoch 56 finished \tANN training loss 0.007295\n",
      ">> Epoch 57 finished \tANN training loss 0.007139\n",
      ">> Epoch 58 finished \tANN training loss 0.006989\n",
      ">> Epoch 59 finished \tANN training loss 0.006844\n",
      ">> Epoch 60 finished \tANN training loss 0.006705\n",
      ">> Epoch 61 finished \tANN training loss 0.006571\n",
      ">> Epoch 62 finished \tANN training loss 0.006442\n",
      ">> Epoch 63 finished \tANN training loss 0.006317\n",
      ">> Epoch 64 finished \tANN training loss 0.006197\n",
      ">> Epoch 65 finished \tANN training loss 0.006081\n",
      ">> Epoch 66 finished \tANN training loss 0.005969\n",
      ">> Epoch 67 finished \tANN training loss 0.005860\n",
      ">> Epoch 68 finished \tANN training loss 0.005755\n",
      ">> Epoch 69 finished \tANN training loss 0.005653\n",
      ">> Epoch 70 finished \tANN training loss 0.005554\n",
      ">> Epoch 71 finished \tANN training loss 0.005458\n",
      ">> Epoch 72 finished \tANN training loss 0.005365\n",
      ">> Epoch 73 finished \tANN training loss 0.005275\n",
      ">> Epoch 74 finished \tANN training loss 0.005187\n",
      ">> Epoch 75 finished \tANN training loss 0.005101\n",
      ">> Epoch 76 finished \tANN training loss 0.005018\n",
      ">> Epoch 77 finished \tANN training loss 0.004937\n",
      ">> Epoch 78 finished \tANN training loss 0.004858\n",
      ">> Epoch 79 finished \tANN training loss 0.004781\n",
      ">> Epoch 80 finished \tANN training loss 0.004706\n",
      ">> Epoch 81 finished \tANN training loss 0.004633\n",
      ">> Epoch 82 finished \tANN training loss 0.004562\n",
      ">> Epoch 83 finished \tANN training loss 0.004492\n",
      ">> Epoch 84 finished \tANN training loss 0.004424\n",
      ">> Epoch 85 finished \tANN training loss 0.004357\n",
      ">> Epoch 86 finished \tANN training loss 0.004292\n",
      ">> Epoch 87 finished \tANN training loss 0.004228\n",
      ">> Epoch 88 finished \tANN training loss 0.004166\n",
      ">> Epoch 89 finished \tANN training loss 0.004105\n",
      ">> Epoch 90 finished \tANN training loss 0.004045\n",
      ">> Epoch 91 finished \tANN training loss 0.003987\n",
      ">> Epoch 92 finished \tANN training loss 0.003929\n",
      ">> Epoch 93 finished \tANN training loss 0.003873\n",
      ">> Epoch 94 finished \tANN training loss 0.003818\n",
      ">> Epoch 95 finished \tANN training loss 0.003764\n",
      ">> Epoch 96 finished \tANN training loss 0.003711\n",
      ">> Epoch 97 finished \tANN training loss 0.003658\n",
      ">> Epoch 98 finished \tANN training loss 0.003607\n",
      ">> Epoch 99 finished \tANN training loss 0.003557\n",
      ">> Epoch 100 finished \tANN training loss 0.003508\n",
      ">> Epoch 101 finished \tANN training loss 0.003459\n",
      ">> Epoch 102 finished \tANN training loss 0.003412\n",
      ">> Epoch 103 finished \tANN training loss 0.003365\n",
      ">> Epoch 104 finished \tANN training loss 0.003319\n",
      ">> Epoch 105 finished \tANN training loss 0.003273\n",
      ">> Epoch 106 finished \tANN training loss 0.003229\n",
      ">> Epoch 107 finished \tANN training loss 0.003185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 108 finished \tANN training loss 0.003142\n",
      ">> Epoch 109 finished \tANN training loss 0.003100\n",
      ">> Epoch 110 finished \tANN training loss 0.003058\n",
      ">> Epoch 111 finished \tANN training loss 0.003017\n",
      ">> Epoch 112 finished \tANN training loss 0.002977\n",
      ">> Epoch 113 finished \tANN training loss 0.002937\n",
      ">> Epoch 114 finished \tANN training loss 0.002898\n",
      ">> Epoch 115 finished \tANN training loss 0.002860\n",
      ">> Epoch 116 finished \tANN training loss 0.002822\n",
      ">> Epoch 117 finished \tANN training loss 0.002784\n",
      ">> Epoch 118 finished \tANN training loss 0.002748\n",
      ">> Epoch 119 finished \tANN training loss 0.002711\n",
      ">> Epoch 120 finished \tANN training loss 0.002676\n",
      ">> Epoch 121 finished \tANN training loss 0.002641\n",
      ">> Epoch 122 finished \tANN training loss 0.002606\n",
      ">> Epoch 123 finished \tANN training loss 0.002572\n",
      ">> Epoch 124 finished \tANN training loss 0.002539\n",
      ">> Epoch 125 finished \tANN training loss 0.002505\n",
      ">> Epoch 126 finished \tANN training loss 0.002473\n",
      ">> Epoch 127 finished \tANN training loss 0.002441\n",
      ">> Epoch 128 finished \tANN training loss 0.002409\n",
      ">> Epoch 129 finished \tANN training loss 0.002378\n",
      ">> Epoch 130 finished \tANN training loss 0.002347\n",
      ">> Epoch 131 finished \tANN training loss 0.002317\n",
      ">> Epoch 132 finished \tANN training loss 0.002287\n",
      ">> Epoch 133 finished \tANN training loss 0.002258\n",
      ">> Epoch 134 finished \tANN training loss 0.002229\n",
      ">> Epoch 135 finished \tANN training loss 0.002200\n",
      ">> Epoch 136 finished \tANN training loss 0.002172\n",
      ">> Epoch 137 finished \tANN training loss 0.002144\n",
      ">> Epoch 138 finished \tANN training loss 0.002117\n",
      ">> Epoch 139 finished \tANN training loss 0.002090\n",
      ">> Epoch 140 finished \tANN training loss 0.002063\n",
      ">> Epoch 141 finished \tANN training loss 0.002037\n",
      ">> Epoch 142 finished \tANN training loss 0.002011\n",
      ">> Epoch 143 finished \tANN training loss 0.001985\n",
      ">> Epoch 144 finished \tANN training loss 0.001960\n",
      ">> Epoch 145 finished \tANN training loss 0.001935\n",
      ">> Epoch 146 finished \tANN training loss 0.001911\n",
      ">> Epoch 147 finished \tANN training loss 0.001887\n",
      ">> Epoch 148 finished \tANN training loss 0.001863\n",
      ">> Epoch 149 finished \tANN training loss 0.001839\n",
      ">> Epoch 150 finished \tANN training loss 0.001816\n",
      "[END] Fine tuning step\n",
      "############### End Training for BATAINDIAEQ #####################\n",
      "############### End Training for UJJIVANEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 18.462200\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 18.342752\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 18.219328\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 18.091862\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 17.960106\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 17.823844\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 17.682569\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 17.536125\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 17.384216\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 17.226399\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 17.062537\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 16.891928\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 16.714340\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 16.529458\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 16.336822\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 16.136194\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 15.926742\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 15.708543\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 15.480830\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 15.243377\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 14.995737\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 14.736948\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 14.467565\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 14.186431\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 13.893626\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 13.589255\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 13.271947\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 12.942282\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 12.599742\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 12.244651\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 11.876927\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 11.497210\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 11.104957\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 10.700893\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 10.285263\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 9.860328\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 9.427161\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 8.987221\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 8.538110\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 8.086718\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 7.633001\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 7.175063\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 6.721426\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 6.270000\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 5.823440\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 5.386480\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 4.958316\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 4.543511\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 4.146590\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 3.765907\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 3.401482\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 3.063555\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 2.747806\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 2.454835\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 2.184014\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 1.941330\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 1.721162\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 1.524371\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 1.348127\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 1.197576\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 1.067339\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.953247\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.858501\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.778649\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.714307\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.662982\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.621608\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.589352\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.566187\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.549808\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.539360\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.533481\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.531410\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.531908\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.534744\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.539318\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.545945\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.553469\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.560724\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.569355\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.577366\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.586691\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.593502\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.601985\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.607566\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.616332\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.622331\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.628925\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.633666\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.641642\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.649805\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.653897\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.656613\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.659516\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.663288\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.666676\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.666430\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.668599\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.669085\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.670186\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.041461\n",
      ">> Epoch 2 finished \tANN training loss 0.038090\n",
      ">> Epoch 3 finished \tANN training loss 0.035123\n",
      ">> Epoch 4 finished \tANN training loss 0.032511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 5 finished \tANN training loss 0.030209\n",
      ">> Epoch 6 finished \tANN training loss 0.028181\n",
      ">> Epoch 7 finished \tANN training loss 0.026393\n",
      ">> Epoch 8 finished \tANN training loss 0.024820\n",
      ">> Epoch 9 finished \tANN training loss 0.023434\n",
      ">> Epoch 10 finished \tANN training loss 0.022214\n",
      ">> Epoch 11 finished \tANN training loss 0.021138\n",
      ">> Epoch 12 finished \tANN training loss 0.020189\n",
      ">> Epoch 13 finished \tANN training loss 0.019354\n",
      ">> Epoch 14 finished \tANN training loss 0.018618\n",
      ">> Epoch 15 finished \tANN training loss 0.017969\n",
      ">> Epoch 16 finished \tANN training loss 0.017396\n",
      ">> Epoch 17 finished \tANN training loss 0.016891\n",
      ">> Epoch 18 finished \tANN training loss 0.016445\n",
      ">> Epoch 19 finished \tANN training loss 0.016053\n",
      ">> Epoch 20 finished \tANN training loss 0.015705\n",
      ">> Epoch 21 finished \tANN training loss 0.015399\n",
      ">> Epoch 22 finished \tANN training loss 0.015127\n",
      ">> Epoch 23 finished \tANN training loss 0.014888\n",
      ">> Epoch 24 finished \tANN training loss 0.014676\n",
      ">> Epoch 25 finished \tANN training loss 0.014490\n",
      ">> Epoch 26 finished \tANN training loss 0.014323\n",
      ">> Epoch 27 finished \tANN training loss 0.014176\n",
      ">> Epoch 28 finished \tANN training loss 0.014046\n",
      ">> Epoch 29 finished \tANN training loss 0.013930\n",
      ">> Epoch 30 finished \tANN training loss 0.013828\n",
      ">> Epoch 31 finished \tANN training loss 0.013736\n",
      ">> Epoch 32 finished \tANN training loss 0.013655\n",
      ">> Epoch 33 finished \tANN training loss 0.013582\n",
      ">> Epoch 34 finished \tANN training loss 0.013517\n",
      ">> Epoch 35 finished \tANN training loss 0.013459\n",
      ">> Epoch 36 finished \tANN training loss 0.013407\n",
      ">> Epoch 37 finished \tANN training loss 0.013360\n",
      ">> Epoch 38 finished \tANN training loss 0.013318\n",
      ">> Epoch 39 finished \tANN training loss 0.013279\n",
      ">> Epoch 40 finished \tANN training loss 0.013245\n",
      ">> Epoch 41 finished \tANN training loss 0.013214\n",
      ">> Epoch 42 finished \tANN training loss 0.013186\n",
      ">> Epoch 43 finished \tANN training loss 0.013159\n",
      ">> Epoch 44 finished \tANN training loss 0.013136\n",
      ">> Epoch 45 finished \tANN training loss 0.013114\n",
      ">> Epoch 46 finished \tANN training loss 0.013094\n",
      ">> Epoch 47 finished \tANN training loss 0.013074\n",
      ">> Epoch 48 finished \tANN training loss 0.013057\n",
      ">> Epoch 49 finished \tANN training loss 0.013042\n",
      ">> Epoch 50 finished \tANN training loss 0.013026\n",
      ">> Epoch 51 finished \tANN training loss 0.013011\n",
      ">> Epoch 52 finished \tANN training loss 0.012999\n",
      ">> Epoch 53 finished \tANN training loss 0.012987\n",
      ">> Epoch 54 finished \tANN training loss 0.012973\n",
      ">> Epoch 55 finished \tANN training loss 0.012963\n",
      ">> Epoch 56 finished \tANN training loss 0.012951\n",
      ">> Epoch 57 finished \tANN training loss 0.012940\n",
      ">> Epoch 58 finished \tANN training loss 0.012929\n",
      ">> Epoch 59 finished \tANN training loss 0.012921\n",
      ">> Epoch 60 finished \tANN training loss 0.012912\n",
      ">> Epoch 61 finished \tANN training loss 0.012902\n",
      ">> Epoch 62 finished \tANN training loss 0.012892\n",
      ">> Epoch 63 finished \tANN training loss 0.012884\n",
      ">> Epoch 64 finished \tANN training loss 0.012875\n",
      ">> Epoch 65 finished \tANN training loss 0.012866\n",
      ">> Epoch 66 finished \tANN training loss 0.012858\n",
      ">> Epoch 67 finished \tANN training loss 0.012850\n",
      ">> Epoch 68 finished \tANN training loss 0.012841\n",
      ">> Epoch 69 finished \tANN training loss 0.012833\n",
      ">> Epoch 70 finished \tANN training loss 0.012826\n",
      ">> Epoch 71 finished \tANN training loss 0.012817\n",
      ">> Epoch 72 finished \tANN training loss 0.012810\n",
      ">> Epoch 73 finished \tANN training loss 0.012802\n",
      ">> Epoch 74 finished \tANN training loss 0.012795\n",
      ">> Epoch 75 finished \tANN training loss 0.012786\n",
      ">> Epoch 76 finished \tANN training loss 0.012779\n",
      ">> Epoch 77 finished \tANN training loss 0.012771\n",
      ">> Epoch 78 finished \tANN training loss 0.012765\n",
      ">> Epoch 79 finished \tANN training loss 0.012758\n",
      ">> Epoch 80 finished \tANN training loss 0.012749\n",
      ">> Epoch 81 finished \tANN training loss 0.012743\n",
      ">> Epoch 82 finished \tANN training loss 0.012735\n",
      ">> Epoch 83 finished \tANN training loss 0.012728\n",
      ">> Epoch 84 finished \tANN training loss 0.012720\n",
      ">> Epoch 85 finished \tANN training loss 0.012713\n",
      ">> Epoch 86 finished \tANN training loss 0.012708\n",
      ">> Epoch 87 finished \tANN training loss 0.012699\n",
      ">> Epoch 88 finished \tANN training loss 0.012692\n",
      ">> Epoch 89 finished \tANN training loss 0.012684\n",
      ">> Epoch 90 finished \tANN training loss 0.012677\n",
      ">> Epoch 91 finished \tANN training loss 0.012671\n",
      ">> Epoch 92 finished \tANN training loss 0.012664\n",
      ">> Epoch 93 finished \tANN training loss 0.012657\n",
      ">> Epoch 94 finished \tANN training loss 0.012650\n",
      ">> Epoch 95 finished \tANN training loss 0.012643\n",
      ">> Epoch 96 finished \tANN training loss 0.012636\n",
      ">> Epoch 97 finished \tANN training loss 0.012628\n",
      ">> Epoch 98 finished \tANN training loss 0.012622\n",
      ">> Epoch 99 finished \tANN training loss 0.012615\n",
      ">> Epoch 100 finished \tANN training loss 0.012608\n",
      ">> Epoch 101 finished \tANN training loss 0.012601\n",
      ">> Epoch 102 finished \tANN training loss 0.012595\n",
      ">> Epoch 103 finished \tANN training loss 0.012588\n",
      ">> Epoch 104 finished \tANN training loss 0.012580\n",
      ">> Epoch 105 finished \tANN training loss 0.012574\n",
      ">> Epoch 106 finished \tANN training loss 0.012567\n",
      ">> Epoch 107 finished \tANN training loss 0.012560\n",
      ">> Epoch 108 finished \tANN training loss 0.012554\n",
      ">> Epoch 109 finished \tANN training loss 0.012547\n",
      ">> Epoch 110 finished \tANN training loss 0.012541\n",
      ">> Epoch 111 finished \tANN training loss 0.012533\n",
      ">> Epoch 112 finished \tANN training loss 0.012526\n",
      ">> Epoch 113 finished \tANN training loss 0.012520\n",
      ">> Epoch 114 finished \tANN training loss 0.012512\n",
      ">> Epoch 115 finished \tANN training loss 0.012507\n",
      ">> Epoch 116 finished \tANN training loss 0.012500\n",
      ">> Epoch 117 finished \tANN training loss 0.012493\n",
      ">> Epoch 118 finished \tANN training loss 0.012487\n",
      ">> Epoch 119 finished \tANN training loss 0.012481\n",
      ">> Epoch 120 finished \tANN training loss 0.012473\n",
      ">> Epoch 121 finished \tANN training loss 0.012466\n",
      ">> Epoch 122 finished \tANN training loss 0.012459\n",
      ">> Epoch 123 finished \tANN training loss 0.012453\n",
      ">> Epoch 124 finished \tANN training loss 0.012446\n",
      ">> Epoch 125 finished \tANN training loss 0.012440\n",
      ">> Epoch 126 finished \tANN training loss 0.012433\n",
      ">> Epoch 127 finished \tANN training loss 0.012427\n",
      ">> Epoch 128 finished \tANN training loss 0.012421\n",
      ">> Epoch 129 finished \tANN training loss 0.012414\n",
      ">> Epoch 130 finished \tANN training loss 0.012408\n",
      ">> Epoch 131 finished \tANN training loss 0.012400\n",
      ">> Epoch 132 finished \tANN training loss 0.012394\n",
      ">> Epoch 133 finished \tANN training loss 0.012388\n",
      ">> Epoch 134 finished \tANN training loss 0.012381\n",
      ">> Epoch 135 finished \tANN training loss 0.012375\n",
      ">> Epoch 136 finished \tANN training loss 0.012368\n",
      ">> Epoch 137 finished \tANN training loss 0.012362\n",
      ">> Epoch 138 finished \tANN training loss 0.012356\n",
      ">> Epoch 139 finished \tANN training loss 0.012349\n",
      ">> Epoch 140 finished \tANN training loss 0.012343\n",
      ">> Epoch 141 finished \tANN training loss 0.012336\n",
      ">> Epoch 142 finished \tANN training loss 0.012330\n",
      ">> Epoch 143 finished \tANN training loss 0.012323\n",
      ">> Epoch 144 finished \tANN training loss 0.012318\n",
      ">> Epoch 145 finished \tANN training loss 0.012310\n",
      ">> Epoch 146 finished \tANN training loss 0.012304\n",
      ">> Epoch 147 finished \tANN training loss 0.012297\n",
      ">> Epoch 148 finished \tANN training loss 0.012291\n",
      ">> Epoch 149 finished \tANN training loss 0.012285\n",
      ">> Epoch 150 finished \tANN training loss 0.012278\n",
      "[END] Fine tuning step\n",
      "############### End Training for UJJIVANEQ #####################\n",
      "############### End Training for POWERGRIDEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 7.326045\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 7.198574\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 7.067626\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 6.932893\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 6.793764\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 6.649680\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 6.500063\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 6.344160\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 6.181415\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 6.011280\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 5.832899\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 5.645804\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 5.449368\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 5.243125\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 5.026441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 16 finished \tRBM Reconstruction error 4.799239\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 4.561693\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 4.313476\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 4.055780\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 3.789361\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 3.515979\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 3.237642\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 2.956952\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 2.675210\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 2.397055\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 2.126210\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 1.866656\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 1.620574\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 1.394025\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 1.188257\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 1.005627\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 0.846700\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.709852\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.594956\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.499512\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.421653\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.360229\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.311144\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.273435\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.244897\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.220902\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.203944\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.190145\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.179572\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.171618\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.165785\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.160660\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.156446\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.153184\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.150472\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.148358\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.146849\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.145133\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.143847\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.142635\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.141738\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.140843\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.140037\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.139370\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.138690\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.138153\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.137707\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.137386\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.137066\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.136685\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.136252\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.135946\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.135621\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.135304\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.135007\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.134789\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.134577\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.134347\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.134130\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.133873\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.133625\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.133478\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.133342\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.133233\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.133075\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.132813\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.132598\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.132474\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.132387\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.132222\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.131944\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.131792\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.131723\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.131561\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.131419\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.131285\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.131139\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.131037\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.130877\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.130724\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.130548\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.130417\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.130279\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.130191\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.130036\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.152394\n",
      ">> Epoch 2 finished \tANN training loss 0.125995\n",
      ">> Epoch 3 finished \tANN training loss 0.104331\n",
      ">> Epoch 4 finished \tANN training loss 0.086526\n",
      ">> Epoch 5 finished \tANN training loss 0.071874\n",
      ">> Epoch 6 finished \tANN training loss 0.059807\n",
      ">> Epoch 7 finished \tANN training loss 0.049860\n",
      ">> Epoch 8 finished \tANN training loss 0.041654\n",
      ">> Epoch 9 finished \tANN training loss 0.034880\n",
      ">> Epoch 10 finished \tANN training loss 0.029284\n",
      ">> Epoch 11 finished \tANN training loss 0.024658\n",
      ">> Epoch 12 finished \tANN training loss 0.020834\n",
      ">> Epoch 13 finished \tANN training loss 0.017671\n",
      ">> Epoch 14 finished \tANN training loss 0.015054\n",
      ">> Epoch 15 finished \tANN training loss 0.012888\n",
      ">> Epoch 16 finished \tANN training loss 0.011095\n",
      ">> Epoch 17 finished \tANN training loss 0.009610\n",
      ">> Epoch 18 finished \tANN training loss 0.008380\n",
      ">> Epoch 19 finished \tANN training loss 0.007361\n",
      ">> Epoch 20 finished \tANN training loss 0.006515\n",
      ">> Epoch 21 finished \tANN training loss 0.005815\n",
      ">> Epoch 22 finished \tANN training loss 0.005234\n",
      ">> Epoch 23 finished \tANN training loss 0.004753\n",
      ">> Epoch 24 finished \tANN training loss 0.004353\n",
      ">> Epoch 25 finished \tANN training loss 0.004021\n",
      ">> Epoch 26 finished \tANN training loss 0.003746\n",
      ">> Epoch 27 finished \tANN training loss 0.003517\n",
      ">> Epoch 28 finished \tANN training loss 0.003328\n",
      ">> Epoch 29 finished \tANN training loss 0.003170\n",
      ">> Epoch 30 finished \tANN training loss 0.003039\n",
      ">> Epoch 31 finished \tANN training loss 0.002930\n",
      ">> Epoch 32 finished \tANN training loss 0.002840\n",
      ">> Epoch 33 finished \tANN training loss 0.002764\n",
      ">> Epoch 34 finished \tANN training loss 0.002702\n",
      ">> Epoch 35 finished \tANN training loss 0.002649\n",
      ">> Epoch 36 finished \tANN training loss 0.002606\n",
      ">> Epoch 37 finished \tANN training loss 0.002569\n",
      ">> Epoch 38 finished \tANN training loss 0.002539\n",
      ">> Epoch 39 finished \tANN training loss 0.002514\n",
      ">> Epoch 40 finished \tANN training loss 0.002492\n",
      ">> Epoch 41 finished \tANN training loss 0.002474\n",
      ">> Epoch 42 finished \tANN training loss 0.002459\n",
      ">> Epoch 43 finished \tANN training loss 0.002446\n",
      ">> Epoch 44 finished \tANN training loss 0.002436\n",
      ">> Epoch 45 finished \tANN training loss 0.002427\n",
      ">> Epoch 46 finished \tANN training loss 0.002419\n",
      ">> Epoch 47 finished \tANN training loss 0.002412\n",
      ">> Epoch 48 finished \tANN training loss 0.002406\n",
      ">> Epoch 49 finished \tANN training loss 0.002401\n",
      ">> Epoch 50 finished \tANN training loss 0.002397\n",
      ">> Epoch 51 finished \tANN training loss 0.002393\n",
      ">> Epoch 52 finished \tANN training loss 0.002390\n",
      ">> Epoch 53 finished \tANN training loss 0.002387\n",
      ">> Epoch 54 finished \tANN training loss 0.002384\n",
      ">> Epoch 55 finished \tANN training loss 0.002381\n",
      ">> Epoch 56 finished \tANN training loss 0.002379\n",
      ">> Epoch 57 finished \tANN training loss 0.002377\n",
      ">> Epoch 58 finished \tANN training loss 0.002375\n",
      ">> Epoch 59 finished \tANN training loss 0.002373\n",
      ">> Epoch 60 finished \tANN training loss 0.002372\n",
      ">> Epoch 61 finished \tANN training loss 0.002370\n",
      ">> Epoch 62 finished \tANN training loss 0.002369\n",
      ">> Epoch 63 finished \tANN training loss 0.002367\n",
      ">> Epoch 64 finished \tANN training loss 0.002366\n",
      ">> Epoch 65 finished \tANN training loss 0.002364\n",
      ">> Epoch 66 finished \tANN training loss 0.002363\n",
      ">> Epoch 67 finished \tANN training loss 0.002361\n",
      ">> Epoch 68 finished \tANN training loss 0.002360\n",
      ">> Epoch 69 finished \tANN training loss 0.002359\n",
      ">> Epoch 70 finished \tANN training loss 0.002358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 71 finished \tANN training loss 0.002356\n",
      ">> Epoch 72 finished \tANN training loss 0.002355\n",
      ">> Epoch 73 finished \tANN training loss 0.002354\n",
      ">> Epoch 74 finished \tANN training loss 0.002353\n",
      ">> Epoch 75 finished \tANN training loss 0.002351\n",
      ">> Epoch 76 finished \tANN training loss 0.002350\n",
      ">> Epoch 77 finished \tANN training loss 0.002349\n",
      ">> Epoch 78 finished \tANN training loss 0.002348\n",
      ">> Epoch 79 finished \tANN training loss 0.002346\n",
      ">> Epoch 80 finished \tANN training loss 0.002345\n",
      ">> Epoch 81 finished \tANN training loss 0.002344\n",
      ">> Epoch 82 finished \tANN training loss 0.002343\n",
      ">> Epoch 83 finished \tANN training loss 0.002342\n",
      ">> Epoch 84 finished \tANN training loss 0.002341\n",
      ">> Epoch 85 finished \tANN training loss 0.002339\n",
      ">> Epoch 86 finished \tANN training loss 0.002338\n",
      ">> Epoch 87 finished \tANN training loss 0.002337\n",
      ">> Epoch 88 finished \tANN training loss 0.002336\n",
      ">> Epoch 89 finished \tANN training loss 0.002335\n",
      ">> Epoch 90 finished \tANN training loss 0.002334\n",
      ">> Epoch 91 finished \tANN training loss 0.002332\n",
      ">> Epoch 92 finished \tANN training loss 0.002331\n",
      ">> Epoch 93 finished \tANN training loss 0.002330\n",
      ">> Epoch 94 finished \tANN training loss 0.002329\n",
      ">> Epoch 95 finished \tANN training loss 0.002328\n",
      ">> Epoch 96 finished \tANN training loss 0.002327\n",
      ">> Epoch 97 finished \tANN training loss 0.002326\n",
      ">> Epoch 98 finished \tANN training loss 0.002324\n",
      ">> Epoch 99 finished \tANN training loss 0.002323\n",
      ">> Epoch 100 finished \tANN training loss 0.002322\n",
      ">> Epoch 101 finished \tANN training loss 0.002321\n",
      ">> Epoch 102 finished \tANN training loss 0.002320\n",
      ">> Epoch 103 finished \tANN training loss 0.002319\n",
      ">> Epoch 104 finished \tANN training loss 0.002318\n",
      ">> Epoch 105 finished \tANN training loss 0.002317\n",
      ">> Epoch 106 finished \tANN training loss 0.002315\n",
      ">> Epoch 107 finished \tANN training loss 0.002314\n",
      ">> Epoch 108 finished \tANN training loss 0.002313\n",
      ">> Epoch 109 finished \tANN training loss 0.002312\n",
      ">> Epoch 110 finished \tANN training loss 0.002311\n",
      ">> Epoch 111 finished \tANN training loss 0.002310\n",
      ">> Epoch 112 finished \tANN training loss 0.002309\n",
      ">> Epoch 113 finished \tANN training loss 0.002308\n",
      ">> Epoch 114 finished \tANN training loss 0.002306\n",
      ">> Epoch 115 finished \tANN training loss 0.002305\n",
      ">> Epoch 116 finished \tANN training loss 0.002304\n",
      ">> Epoch 117 finished \tANN training loss 0.002303\n",
      ">> Epoch 118 finished \tANN training loss 0.002302\n",
      ">> Epoch 119 finished \tANN training loss 0.002301\n",
      ">> Epoch 120 finished \tANN training loss 0.002300\n",
      ">> Epoch 121 finished \tANN training loss 0.002299\n",
      ">> Epoch 122 finished \tANN training loss 0.002298\n",
      ">> Epoch 123 finished \tANN training loss 0.002297\n",
      ">> Epoch 124 finished \tANN training loss 0.002296\n",
      ">> Epoch 125 finished \tANN training loss 0.002294\n",
      ">> Epoch 126 finished \tANN training loss 0.002293\n",
      ">> Epoch 127 finished \tANN training loss 0.002292\n",
      ">> Epoch 128 finished \tANN training loss 0.002291\n",
      ">> Epoch 129 finished \tANN training loss 0.002290\n",
      ">> Epoch 130 finished \tANN training loss 0.002289\n",
      ">> Epoch 131 finished \tANN training loss 0.002288\n",
      ">> Epoch 132 finished \tANN training loss 0.002287\n",
      ">> Epoch 133 finished \tANN training loss 0.002286\n",
      ">> Epoch 134 finished \tANN training loss 0.002285\n",
      ">> Epoch 135 finished \tANN training loss 0.002284\n",
      ">> Epoch 136 finished \tANN training loss 0.002283\n",
      ">> Epoch 137 finished \tANN training loss 0.002281\n",
      ">> Epoch 138 finished \tANN training loss 0.002280\n",
      ">> Epoch 139 finished \tANN training loss 0.002279\n",
      ">> Epoch 140 finished \tANN training loss 0.002278\n",
      ">> Epoch 141 finished \tANN training loss 0.002277\n",
      ">> Epoch 142 finished \tANN training loss 0.002276\n",
      ">> Epoch 143 finished \tANN training loss 0.002275\n",
      ">> Epoch 144 finished \tANN training loss 0.002274\n",
      ">> Epoch 145 finished \tANN training loss 0.002273\n",
      ">> Epoch 146 finished \tANN training loss 0.002272\n",
      ">> Epoch 147 finished \tANN training loss 0.002271\n",
      ">> Epoch 148 finished \tANN training loss 0.002270\n",
      ">> Epoch 149 finished \tANN training loss 0.002269\n",
      ">> Epoch 150 finished \tANN training loss 0.002268\n",
      "[END] Fine tuning step\n",
      "############### End Training for POWERGRIDEQ #####################\n",
      "############### End Training for ARVINDEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 1.148333\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 1.127669\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 1.107481\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 1.087728\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 1.068428\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 1.049556\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 1.031115\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 1.013082\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 0.995457\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 0.978215\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 0.961362\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 0.944867\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 0.928742\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 0.912966\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 0.897559\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 0.882476\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 0.867679\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 0.853220\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 0.839051\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 0.825181\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 0.811594\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 0.798271\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 0.785207\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 0.772425\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 0.759923\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 0.747647\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 0.735582\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 0.723772\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 0.712188\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 0.700793\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 0.689621\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 0.678670\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.667893\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.657314\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.646930\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.636734\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.626724\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.616905\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.607262\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.597802\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.588475\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.579350\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.570389\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.561569\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.552905\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.544382\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.536034\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.527850\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.519820\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.511908\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.504163\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.496532\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.489026\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.481713\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.474524\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.467497\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.460591\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.453808\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.447157\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.440680\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.434285\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.428091\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.422005\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.416043\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.410212\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.404481\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.398927\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.393474\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.388163\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.382985\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.377866\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.372884\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.368077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 74 finished \tRBM Reconstruction error 0.363351\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.358784\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.354291\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.349890\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.345617\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.341468\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.337407\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.333459\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.329597\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.325849\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.322224\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.318702\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.315203\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.311925\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.308703\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.305576\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.302457\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.299448\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.296508\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.293691\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.290912\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.288229\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.285608\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.283058\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.280609\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.278228\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.275906\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.006461\n",
      ">> Epoch 2 finished \tANN training loss 0.006157\n",
      ">> Epoch 3 finished \tANN training loss 0.005875\n",
      ">> Epoch 4 finished \tANN training loss 0.005614\n",
      ">> Epoch 5 finished \tANN training loss 0.005372\n",
      ">> Epoch 6 finished \tANN training loss 0.005147\n",
      ">> Epoch 7 finished \tANN training loss 0.004939\n",
      ">> Epoch 8 finished \tANN training loss 0.004745\n",
      ">> Epoch 9 finished \tANN training loss 0.004566\n",
      ">> Epoch 10 finished \tANN training loss 0.004399\n",
      ">> Epoch 11 finished \tANN training loss 0.004245\n",
      ">> Epoch 12 finished \tANN training loss 0.004101\n",
      ">> Epoch 13 finished \tANN training loss 0.003968\n",
      ">> Epoch 14 finished \tANN training loss 0.003845\n",
      ">> Epoch 15 finished \tANN training loss 0.003731\n",
      ">> Epoch 16 finished \tANN training loss 0.003624\n",
      ">> Epoch 17 finished \tANN training loss 0.003525\n",
      ">> Epoch 18 finished \tANN training loss 0.003432\n",
      ">> Epoch 19 finished \tANN training loss 0.003345\n",
      ">> Epoch 20 finished \tANN training loss 0.003264\n",
      ">> Epoch 21 finished \tANN training loss 0.003187\n",
      ">> Epoch 22 finished \tANN training loss 0.003115\n",
      ">> Epoch 23 finished \tANN training loss 0.003048\n",
      ">> Epoch 24 finished \tANN training loss 0.002984\n",
      ">> Epoch 25 finished \tANN training loss 0.002923\n",
      ">> Epoch 26 finished \tANN training loss 0.002866\n",
      ">> Epoch 27 finished \tANN training loss 0.002812\n",
      ">> Epoch 28 finished \tANN training loss 0.002761\n",
      ">> Epoch 29 finished \tANN training loss 0.002712\n",
      ">> Epoch 30 finished \tANN training loss 0.002666\n",
      ">> Epoch 31 finished \tANN training loss 0.002621\n",
      ">> Epoch 32 finished \tANN training loss 0.002579\n",
      ">> Epoch 33 finished \tANN training loss 0.002539\n",
      ">> Epoch 34 finished \tANN training loss 0.002501\n",
      ">> Epoch 35 finished \tANN training loss 0.002464\n",
      ">> Epoch 36 finished \tANN training loss 0.002429\n",
      ">> Epoch 37 finished \tANN training loss 0.002396\n",
      ">> Epoch 38 finished \tANN training loss 0.002363\n",
      ">> Epoch 39 finished \tANN training loss 0.002332\n",
      ">> Epoch 40 finished \tANN training loss 0.002302\n",
      ">> Epoch 41 finished \tANN training loss 0.002273\n",
      ">> Epoch 42 finished \tANN training loss 0.002246\n",
      ">> Epoch 43 finished \tANN training loss 0.002219\n",
      ">> Epoch 44 finished \tANN training loss 0.002193\n",
      ">> Epoch 45 finished \tANN training loss 0.002168\n",
      ">> Epoch 46 finished \tANN training loss 0.002144\n",
      ">> Epoch 47 finished \tANN training loss 0.002120\n",
      ">> Epoch 48 finished \tANN training loss 0.002097\n",
      ">> Epoch 49 finished \tANN training loss 0.002075\n",
      ">> Epoch 50 finished \tANN training loss 0.002053\n",
      ">> Epoch 51 finished \tANN training loss 0.002032\n",
      ">> Epoch 52 finished \tANN training loss 0.002012\n",
      ">> Epoch 53 finished \tANN training loss 0.001992\n",
      ">> Epoch 54 finished \tANN training loss 0.001972\n",
      ">> Epoch 55 finished \tANN training loss 0.001953\n",
      ">> Epoch 56 finished \tANN training loss 0.001935\n",
      ">> Epoch 57 finished \tANN training loss 0.001916\n",
      ">> Epoch 58 finished \tANN training loss 0.001899\n",
      ">> Epoch 59 finished \tANN training loss 0.001881\n",
      ">> Epoch 60 finished \tANN training loss 0.001864\n",
      ">> Epoch 61 finished \tANN training loss 0.001848\n",
      ">> Epoch 62 finished \tANN training loss 0.001831\n",
      ">> Epoch 63 finished \tANN training loss 0.001815\n",
      ">> Epoch 64 finished \tANN training loss 0.001800\n",
      ">> Epoch 65 finished \tANN training loss 0.001784\n",
      ">> Epoch 66 finished \tANN training loss 0.001769\n",
      ">> Epoch 67 finished \tANN training loss 0.001754\n",
      ">> Epoch 68 finished \tANN training loss 0.001739\n",
      ">> Epoch 69 finished \tANN training loss 0.001725\n",
      ">> Epoch 70 finished \tANN training loss 0.001711\n",
      ">> Epoch 71 finished \tANN training loss 0.001697\n",
      ">> Epoch 72 finished \tANN training loss 0.001683\n",
      ">> Epoch 73 finished \tANN training loss 0.001670\n",
      ">> Epoch 74 finished \tANN training loss 0.001657\n",
      ">> Epoch 75 finished \tANN training loss 0.001644\n",
      ">> Epoch 76 finished \tANN training loss 0.001631\n",
      ">> Epoch 77 finished \tANN training loss 0.001618\n",
      ">> Epoch 78 finished \tANN training loss 0.001606\n",
      ">> Epoch 79 finished \tANN training loss 0.001593\n",
      ">> Epoch 80 finished \tANN training loss 0.001581\n",
      ">> Epoch 81 finished \tANN training loss 0.001569\n",
      ">> Epoch 82 finished \tANN training loss 0.001557\n",
      ">> Epoch 83 finished \tANN training loss 0.001546\n",
      ">> Epoch 84 finished \tANN training loss 0.001534\n",
      ">> Epoch 85 finished \tANN training loss 0.001523\n",
      ">> Epoch 86 finished \tANN training loss 0.001512\n",
      ">> Epoch 87 finished \tANN training loss 0.001501\n",
      ">> Epoch 88 finished \tANN training loss 0.001490\n",
      ">> Epoch 89 finished \tANN training loss 0.001479\n",
      ">> Epoch 90 finished \tANN training loss 0.001469\n",
      ">> Epoch 91 finished \tANN training loss 0.001458\n",
      ">> Epoch 92 finished \tANN training loss 0.001448\n",
      ">> Epoch 93 finished \tANN training loss 0.001438\n",
      ">> Epoch 94 finished \tANN training loss 0.001428\n",
      ">> Epoch 95 finished \tANN training loss 0.001418\n",
      ">> Epoch 96 finished \tANN training loss 0.001408\n",
      ">> Epoch 97 finished \tANN training loss 0.001398\n",
      ">> Epoch 98 finished \tANN training loss 0.001389\n",
      ">> Epoch 99 finished \tANN training loss 0.001379\n",
      ">> Epoch 100 finished \tANN training loss 0.001370\n",
      ">> Epoch 101 finished \tANN training loss 0.001361\n",
      ">> Epoch 102 finished \tANN training loss 0.001352\n",
      ">> Epoch 103 finished \tANN training loss 0.001343\n",
      ">> Epoch 104 finished \tANN training loss 0.001334\n",
      ">> Epoch 105 finished \tANN training loss 0.001325\n",
      ">> Epoch 106 finished \tANN training loss 0.001316\n",
      ">> Epoch 107 finished \tANN training loss 0.001308\n",
      ">> Epoch 108 finished \tANN training loss 0.001299\n",
      ">> Epoch 109 finished \tANN training loss 0.001291\n",
      ">> Epoch 110 finished \tANN training loss 0.001282\n",
      ">> Epoch 111 finished \tANN training loss 0.001274\n",
      ">> Epoch 112 finished \tANN training loss 0.001266\n",
      ">> Epoch 113 finished \tANN training loss 0.001258\n",
      ">> Epoch 114 finished \tANN training loss 0.001250\n",
      ">> Epoch 115 finished \tANN training loss 0.001242\n",
      ">> Epoch 116 finished \tANN training loss 0.001235\n",
      ">> Epoch 117 finished \tANN training loss 0.001227\n",
      ">> Epoch 118 finished \tANN training loss 0.001219\n",
      ">> Epoch 119 finished \tANN training loss 0.001212\n",
      ">> Epoch 120 finished \tANN training loss 0.001205\n",
      ">> Epoch 121 finished \tANN training loss 0.001197\n",
      ">> Epoch 122 finished \tANN training loss 0.001190\n",
      ">> Epoch 123 finished \tANN training loss 0.001183\n",
      ">> Epoch 124 finished \tANN training loss 0.001176\n",
      ">> Epoch 125 finished \tANN training loss 0.001169\n",
      ">> Epoch 126 finished \tANN training loss 0.001162\n",
      ">> Epoch 127 finished \tANN training loss 0.001155\n",
      ">> Epoch 128 finished \tANN training loss 0.001149\n",
      ">> Epoch 129 finished \tANN training loss 0.001142\n",
      ">> Epoch 130 finished \tANN training loss 0.001135\n",
      ">> Epoch 131 finished \tANN training loss 0.001129\n",
      ">> Epoch 132 finished \tANN training loss 0.001122\n",
      ">> Epoch 133 finished \tANN training loss 0.001116\n",
      ">> Epoch 134 finished \tANN training loss 0.001110\n",
      ">> Epoch 135 finished \tANN training loss 0.001103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 136 finished \tANN training loss 0.001097\n",
      ">> Epoch 137 finished \tANN training loss 0.001091\n",
      ">> Epoch 138 finished \tANN training loss 0.001085\n",
      ">> Epoch 139 finished \tANN training loss 0.001079\n",
      ">> Epoch 140 finished \tANN training loss 0.001073\n",
      ">> Epoch 141 finished \tANN training loss 0.001068\n",
      ">> Epoch 142 finished \tANN training loss 0.001062\n",
      ">> Epoch 143 finished \tANN training loss 0.001056\n",
      ">> Epoch 144 finished \tANN training loss 0.001050\n",
      ">> Epoch 145 finished \tANN training loss 0.001045\n",
      ">> Epoch 146 finished \tANN training loss 0.001039\n",
      ">> Epoch 147 finished \tANN training loss 0.001034\n",
      ">> Epoch 148 finished \tANN training loss 0.001029\n",
      ">> Epoch 149 finished \tANN training loss 0.001023\n",
      ">> Epoch 150 finished \tANN training loss 0.001018\n",
      "[END] Fine tuning step\n",
      "############### End Training for ARVINDEQ #####################\n",
      "############### End Training for MGLEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 18.571776\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 18.480438\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 18.386775\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 18.290705\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 18.191922\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 18.090355\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 17.985815\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 17.878055\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 17.766880\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 17.652102\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 17.533511\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 17.410861\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 17.283969\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 17.152441\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 17.016118\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 16.874755\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 16.727896\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 16.575335\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 16.416934\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 16.252157\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 16.080820\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 15.902365\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 15.716632\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 15.523125\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 15.321505\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 15.111619\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 14.893162\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 14.665414\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 14.428461\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 14.181671\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 13.924416\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 13.656986\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 13.378976\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 13.090462\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 12.790727\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 12.479470\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 12.156738\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 11.823413\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 11.478699\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 11.123114\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 10.757727\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 10.381361\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 9.996078\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 9.601129\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 9.198828\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 8.787752\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 8.372274\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 7.952622\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 7.529598\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 7.105081\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 6.681894\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 6.260082\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 5.841708\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 5.427637\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 5.026303\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 4.636757\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 4.257491\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 3.889646\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 3.542308\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 3.207835\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 2.892452\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 2.599003\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 2.328204\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 2.071312\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 1.836945\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 1.622848\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 1.431176\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 1.259528\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 1.108251\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.974616\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.861081\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.759930\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.675145\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.602252\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.540219\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.488119\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.446319\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.413195\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.386702\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.367369\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.353128\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.342605\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.335829\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.332097\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.330761\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.331350\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.333455\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.336517\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.340098\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.345384\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.350614\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.355413\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.361390\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.365662\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.372118\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.378524\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.383785\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.387235\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.392236\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.397296\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.591695\n",
      ">> Epoch 2 finished \tANN training loss 0.538592\n",
      ">> Epoch 3 finished \tANN training loss 0.490344\n",
      ">> Epoch 4 finished \tANN training loss 0.446462\n",
      ">> Epoch 5 finished \tANN training loss 0.406575\n",
      ">> Epoch 6 finished \tANN training loss 0.370295\n",
      ">> Epoch 7 finished \tANN training loss 0.337312\n",
      ">> Epoch 8 finished \tANN training loss 0.307309\n",
      ">> Epoch 9 finished \tANN training loss 0.280057\n",
      ">> Epoch 10 finished \tANN training loss 0.255307\n",
      ">> Epoch 11 finished \tANN training loss 0.232817\n",
      ">> Epoch 12 finished \tANN training loss 0.212383\n",
      ">> Epoch 13 finished \tANN training loss 0.193807\n",
      ">> Epoch 14 finished \tANN training loss 0.176916\n",
      ">> Epoch 15 finished \tANN training loss 0.161561\n",
      ">> Epoch 16 finished \tANN training loss 0.147601\n",
      ">> Epoch 17 finished \tANN training loss 0.134917\n",
      ">> Epoch 18 finished \tANN training loss 0.123382\n",
      ">> Epoch 19 finished \tANN training loss 0.112899\n",
      ">> Epoch 20 finished \tANN training loss 0.103367\n",
      ">> Epoch 21 finished \tANN training loss 0.094699\n",
      ">> Epoch 22 finished \tANN training loss 0.086821\n",
      ">> Epoch 23 finished \tANN training loss 0.079658\n",
      ">> Epoch 24 finished \tANN training loss 0.073145\n",
      ">> Epoch 25 finished \tANN training loss 0.067226\n",
      ">> Epoch 26 finished \tANN training loss 0.061846\n",
      ">> Epoch 27 finished \tANN training loss 0.056953\n",
      ">> Epoch 28 finished \tANN training loss 0.052508\n",
      ">> Epoch 29 finished \tANN training loss 0.048465\n",
      ">> Epoch 30 finished \tANN training loss 0.044790\n",
      ">> Epoch 31 finished \tANN training loss 0.041449\n",
      ">> Epoch 32 finished \tANN training loss 0.038411\n",
      ">> Epoch 33 finished \tANN training loss 0.035651\n",
      ">> Epoch 34 finished \tANN training loss 0.033141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 35 finished \tANN training loss 0.030859\n",
      ">> Epoch 36 finished \tANN training loss 0.028785\n",
      ">> Epoch 37 finished \tANN training loss 0.026901\n",
      ">> Epoch 38 finished \tANN training loss 0.025189\n",
      ">> Epoch 39 finished \tANN training loss 0.023631\n",
      ">> Epoch 40 finished \tANN training loss 0.022215\n",
      ">> Epoch 41 finished \tANN training loss 0.020929\n",
      ">> Epoch 42 finished \tANN training loss 0.019760\n",
      ">> Epoch 43 finished \tANN training loss 0.018697\n",
      ">> Epoch 44 finished \tANN training loss 0.017733\n",
      ">> Epoch 45 finished \tANN training loss 0.016856\n",
      ">> Epoch 46 finished \tANN training loss 0.016057\n",
      ">> Epoch 47 finished \tANN training loss 0.015332\n",
      ">> Epoch 48 finished \tANN training loss 0.014673\n",
      ">> Epoch 49 finished \tANN training loss 0.014075\n",
      ">> Epoch 50 finished \tANN training loss 0.013531\n",
      ">> Epoch 51 finished \tANN training loss 0.013036\n",
      ">> Epoch 52 finished \tANN training loss 0.012586\n",
      ">> Epoch 53 finished \tANN training loss 0.012177\n",
      ">> Epoch 54 finished \tANN training loss 0.011806\n",
      ">> Epoch 55 finished \tANN training loss 0.011468\n",
      ">> Epoch 56 finished \tANN training loss 0.011161\n",
      ">> Epoch 57 finished \tANN training loss 0.010882\n",
      ">> Epoch 58 finished \tANN training loss 0.010628\n",
      ">> Epoch 59 finished \tANN training loss 0.010398\n",
      ">> Epoch 60 finished \tANN training loss 0.010188\n",
      ">> Epoch 61 finished \tANN training loss 0.009997\n",
      ">> Epoch 62 finished \tANN training loss 0.009824\n",
      ">> Epoch 63 finished \tANN training loss 0.009665\n",
      ">> Epoch 64 finished \tANN training loss 0.009522\n",
      ">> Epoch 65 finished \tANN training loss 0.009392\n",
      ">> Epoch 66 finished \tANN training loss 0.009273\n",
      ">> Epoch 67 finished \tANN training loss 0.009165\n",
      ">> Epoch 68 finished \tANN training loss 0.009067\n",
      ">> Epoch 69 finished \tANN training loss 0.008978\n",
      ">> Epoch 70 finished \tANN training loss 0.008897\n",
      ">> Epoch 71 finished \tANN training loss 0.008823\n",
      ">> Epoch 72 finished \tANN training loss 0.008755\n",
      ">> Epoch 73 finished \tANN training loss 0.008694\n",
      ">> Epoch 74 finished \tANN training loss 0.008638\n",
      ">> Epoch 75 finished \tANN training loss 0.008587\n",
      ">> Epoch 76 finished \tANN training loss 0.008541\n",
      ">> Epoch 77 finished \tANN training loss 0.008498\n",
      ">> Epoch 78 finished \tANN training loss 0.008459\n",
      ">> Epoch 79 finished \tANN training loss 0.008424\n",
      ">> Epoch 80 finished \tANN training loss 0.008392\n",
      ">> Epoch 81 finished \tANN training loss 0.008363\n",
      ">> Epoch 82 finished \tANN training loss 0.008336\n",
      ">> Epoch 83 finished \tANN training loss 0.008311\n",
      ">> Epoch 84 finished \tANN training loss 0.008289\n",
      ">> Epoch 85 finished \tANN training loss 0.008269\n",
      ">> Epoch 86 finished \tANN training loss 0.008250\n",
      ">> Epoch 87 finished \tANN training loss 0.008232\n",
      ">> Epoch 88 finished \tANN training loss 0.008217\n",
      ">> Epoch 89 finished \tANN training loss 0.008202\n",
      ">> Epoch 90 finished \tANN training loss 0.008189\n",
      ">> Epoch 91 finished \tANN training loss 0.008177\n",
      ">> Epoch 92 finished \tANN training loss 0.008165\n",
      ">> Epoch 93 finished \tANN training loss 0.008155\n",
      ">> Epoch 94 finished \tANN training loss 0.008145\n",
      ">> Epoch 95 finished \tANN training loss 0.008136\n",
      ">> Epoch 96 finished \tANN training loss 0.008128\n",
      ">> Epoch 97 finished \tANN training loss 0.008120\n",
      ">> Epoch 98 finished \tANN training loss 0.008114\n",
      ">> Epoch 99 finished \tANN training loss 0.008107\n",
      ">> Epoch 100 finished \tANN training loss 0.008101\n",
      ">> Epoch 101 finished \tANN training loss 0.008095\n",
      ">> Epoch 102 finished \tANN training loss 0.008090\n",
      ">> Epoch 103 finished \tANN training loss 0.008085\n",
      ">> Epoch 104 finished \tANN training loss 0.008080\n",
      ">> Epoch 105 finished \tANN training loss 0.008075\n",
      ">> Epoch 106 finished \tANN training loss 0.008071\n",
      ">> Epoch 107 finished \tANN training loss 0.008067\n",
      ">> Epoch 108 finished \tANN training loss 0.008064\n",
      ">> Epoch 109 finished \tANN training loss 0.008060\n",
      ">> Epoch 110 finished \tANN training loss 0.008057\n",
      ">> Epoch 111 finished \tANN training loss 0.008053\n",
      ">> Epoch 112 finished \tANN training loss 0.008050\n",
      ">> Epoch 113 finished \tANN training loss 0.008047\n",
      ">> Epoch 114 finished \tANN training loss 0.008044\n",
      ">> Epoch 115 finished \tANN training loss 0.008042\n",
      ">> Epoch 116 finished \tANN training loss 0.008039\n",
      ">> Epoch 117 finished \tANN training loss 0.008037\n",
      ">> Epoch 118 finished \tANN training loss 0.008034\n",
      ">> Epoch 119 finished \tANN training loss 0.008032\n",
      ">> Epoch 120 finished \tANN training loss 0.008029\n",
      ">> Epoch 121 finished \tANN training loss 0.008027\n",
      ">> Epoch 122 finished \tANN training loss 0.008025\n",
      ">> Epoch 123 finished \tANN training loss 0.008023\n",
      ">> Epoch 124 finished \tANN training loss 0.008020\n",
      ">> Epoch 125 finished \tANN training loss 0.008018\n",
      ">> Epoch 126 finished \tANN training loss 0.008017\n",
      ">> Epoch 127 finished \tANN training loss 0.008014\n",
      ">> Epoch 128 finished \tANN training loss 0.008012\n",
      ">> Epoch 129 finished \tANN training loss 0.008011\n",
      ">> Epoch 130 finished \tANN training loss 0.008009\n",
      ">> Epoch 131 finished \tANN training loss 0.008007\n",
      ">> Epoch 132 finished \tANN training loss 0.008005\n",
      ">> Epoch 133 finished \tANN training loss 0.008003\n",
      ">> Epoch 134 finished \tANN training loss 0.008001\n",
      ">> Epoch 135 finished \tANN training loss 0.007999\n",
      ">> Epoch 136 finished \tANN training loss 0.007997\n",
      ">> Epoch 137 finished \tANN training loss 0.007996\n",
      ">> Epoch 138 finished \tANN training loss 0.007994\n",
      ">> Epoch 139 finished \tANN training loss 0.007992\n",
      ">> Epoch 140 finished \tANN training loss 0.007991\n",
      ">> Epoch 141 finished \tANN training loss 0.007989\n",
      ">> Epoch 142 finished \tANN training loss 0.007987\n",
      ">> Epoch 143 finished \tANN training loss 0.007985\n",
      ">> Epoch 144 finished \tANN training loss 0.007983\n",
      ">> Epoch 145 finished \tANN training loss 0.007982\n",
      ">> Epoch 146 finished \tANN training loss 0.007981\n",
      ">> Epoch 147 finished \tANN training loss 0.007978\n",
      ">> Epoch 148 finished \tANN training loss 0.007977\n",
      ">> Epoch 149 finished \tANN training loss 0.007975\n",
      ">> Epoch 150 finished \tANN training loss 0.007973\n",
      "[END] Fine tuning step\n",
      "############### End Training for MGLEQ #####################\n",
      "############### End Training for GODFRYPHLPEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 1.695676\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 1.669298\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 1.643345\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 1.617735\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 1.592485\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 1.567588\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 1.543015\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 1.518766\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 1.494816\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 1.471113\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 1.447652\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 1.424438\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 1.401474\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 1.378693\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 1.356088\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 1.333637\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 1.311308\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 1.289155\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 1.267139\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 1.245200\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 1.223321\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 1.201570\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 1.179856\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 1.158224\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 1.136622\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 1.115047\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 1.093475\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 1.071992\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 1.050550\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 1.029138\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 1.007760\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 0.986378\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.965092\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.943807\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.922611\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.901561\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.880560\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.859522\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.838685\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.818041\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.797514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 42 finished \tRBM Reconstruction error 0.777154\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.757033\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.737140\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.717352\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.698071\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.678952\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.660133\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.641678\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.623611\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.605905\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.588617\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.571786\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.555379\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.539377\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.524134\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.509014\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.494486\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.480660\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.467211\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.454080\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.441714\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.429870\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.418522\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.407521\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.397017\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.387138\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.377738\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.368688\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.359939\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.351705\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.343894\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.336357\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.329177\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.322342\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.315886\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.309686\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.303868\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.298314\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.293126\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.288025\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.283061\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.278281\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.273682\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.269385\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.265099\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.261181\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.257262\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.253565\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.249801\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.246317\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.242920\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.239566\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.236298\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.233061\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.230140\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.227171\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.224209\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.221290\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.218360\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.087965\n",
      ">> Epoch 2 finished \tANN training loss 0.079791\n",
      ">> Epoch 3 finished \tANN training loss 0.072386\n",
      ">> Epoch 4 finished \tANN training loss 0.065678\n",
      ">> Epoch 5 finished \tANN training loss 0.059614\n",
      ">> Epoch 6 finished \tANN training loss 0.054151\n",
      ">> Epoch 7 finished \tANN training loss 0.049218\n",
      ">> Epoch 8 finished \tANN training loss 0.044752\n",
      ">> Epoch 9 finished \tANN training loss 0.040707\n",
      ">> Epoch 10 finished \tANN training loss 0.037038\n",
      ">> Epoch 11 finished \tANN training loss 0.033709\n",
      ">> Epoch 12 finished \tANN training loss 0.030686\n",
      ">> Epoch 13 finished \tANN training loss 0.027941\n",
      ">> Epoch 14 finished \tANN training loss 0.025448\n",
      ">> Epoch 15 finished \tANN training loss 0.023182\n",
      ">> Epoch 16 finished \tANN training loss 0.021124\n",
      ">> Epoch 17 finished \tANN training loss 0.019252\n",
      ">> Epoch 18 finished \tANN training loss 0.017552\n",
      ">> Epoch 19 finished \tANN training loss 0.016006\n",
      ">> Epoch 20 finished \tANN training loss 0.014601\n",
      ">> Epoch 21 finished \tANN training loss 0.013325\n",
      ">> Epoch 22 finished \tANN training loss 0.012164\n",
      ">> Epoch 23 finished \tANN training loss 0.011109\n",
      ">> Epoch 24 finished \tANN training loss 0.010150\n",
      ">> Epoch 25 finished \tANN training loss 0.009279\n",
      ">> Epoch 26 finished \tANN training loss 0.008486\n",
      ">> Epoch 27 finished \tANN training loss 0.007766\n",
      ">> Epoch 28 finished \tANN training loss 0.007111\n",
      ">> Epoch 29 finished \tANN training loss 0.006517\n",
      ">> Epoch 30 finished \tANN training loss 0.005977\n",
      ">> Epoch 31 finished \tANN training loss 0.005486\n",
      ">> Epoch 32 finished \tANN training loss 0.005040\n",
      ">> Epoch 33 finished \tANN training loss 0.004635\n",
      ">> Epoch 34 finished \tANN training loss 0.004267\n",
      ">> Epoch 35 finished \tANN training loss 0.003933\n",
      ">> Epoch 36 finished \tANN training loss 0.003630\n",
      ">> Epoch 37 finished \tANN training loss 0.003354\n",
      ">> Epoch 38 finished \tANN training loss 0.003104\n",
      ">> Epoch 39 finished \tANN training loss 0.002877\n",
      ">> Epoch 40 finished \tANN training loss 0.002670\n",
      ">> Epoch 41 finished \tANN training loss 0.002483\n",
      ">> Epoch 42 finished \tANN training loss 0.002312\n",
      ">> Epoch 43 finished \tANN training loss 0.002158\n",
      ">> Epoch 44 finished \tANN training loss 0.002017\n",
      ">> Epoch 45 finished \tANN training loss 0.001889\n",
      ">> Epoch 46 finished \tANN training loss 0.001774\n",
      ">> Epoch 47 finished \tANN training loss 0.001668\n",
      ">> Epoch 48 finished \tANN training loss 0.001572\n",
      ">> Epoch 49 finished \tANN training loss 0.001485\n",
      ">> Epoch 50 finished \tANN training loss 0.001406\n",
      ">> Epoch 51 finished \tANN training loss 0.001334\n",
      ">> Epoch 52 finished \tANN training loss 0.001269\n",
      ">> Epoch 53 finished \tANN training loss 0.001209\n",
      ">> Epoch 54 finished \tANN training loss 0.001155\n",
      ">> Epoch 55 finished \tANN training loss 0.001106\n",
      ">> Epoch 56 finished \tANN training loss 0.001061\n",
      ">> Epoch 57 finished \tANN training loss 0.001019\n",
      ">> Epoch 58 finished \tANN training loss 0.000982\n",
      ">> Epoch 59 finished \tANN training loss 0.000948\n",
      ">> Epoch 60 finished \tANN training loss 0.000917\n",
      ">> Epoch 61 finished \tANN training loss 0.000888\n",
      ">> Epoch 62 finished \tANN training loss 0.000862\n",
      ">> Epoch 63 finished \tANN training loss 0.000838\n",
      ">> Epoch 64 finished \tANN training loss 0.000816\n",
      ">> Epoch 65 finished \tANN training loss 0.000796\n",
      ">> Epoch 66 finished \tANN training loss 0.000777\n",
      ">> Epoch 67 finished \tANN training loss 0.000760\n",
      ">> Epoch 68 finished \tANN training loss 0.000745\n",
      ">> Epoch 69 finished \tANN training loss 0.000731\n",
      ">> Epoch 70 finished \tANN training loss 0.000717\n",
      ">> Epoch 71 finished \tANN training loss 0.000705\n",
      ">> Epoch 72 finished \tANN training loss 0.000694\n",
      ">> Epoch 73 finished \tANN training loss 0.000683\n",
      ">> Epoch 74 finished \tANN training loss 0.000674\n",
      ">> Epoch 75 finished \tANN training loss 0.000664\n",
      ">> Epoch 76 finished \tANN training loss 0.000656\n",
      ">> Epoch 77 finished \tANN training loss 0.000648\n",
      ">> Epoch 78 finished \tANN training loss 0.000641\n",
      ">> Epoch 79 finished \tANN training loss 0.000634\n",
      ">> Epoch 80 finished \tANN training loss 0.000628\n",
      ">> Epoch 81 finished \tANN training loss 0.000622\n",
      ">> Epoch 82 finished \tANN training loss 0.000616\n",
      ">> Epoch 83 finished \tANN training loss 0.000611\n",
      ">> Epoch 84 finished \tANN training loss 0.000606\n",
      ">> Epoch 85 finished \tANN training loss 0.000601\n",
      ">> Epoch 86 finished \tANN training loss 0.000597\n",
      ">> Epoch 87 finished \tANN training loss 0.000593\n",
      ">> Epoch 88 finished \tANN training loss 0.000589\n",
      ">> Epoch 89 finished \tANN training loss 0.000585\n",
      ">> Epoch 90 finished \tANN training loss 0.000581\n",
      ">> Epoch 91 finished \tANN training loss 0.000578\n",
      ">> Epoch 92 finished \tANN training loss 0.000574\n",
      ">> Epoch 93 finished \tANN training loss 0.000571\n",
      ">> Epoch 94 finished \tANN training loss 0.000568\n",
      ">> Epoch 95 finished \tANN training loss 0.000565\n",
      ">> Epoch 96 finished \tANN training loss 0.000562\n",
      ">> Epoch 97 finished \tANN training loss 0.000560\n",
      ">> Epoch 98 finished \tANN training loss 0.000557\n",
      ">> Epoch 99 finished \tANN training loss 0.000554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 100 finished \tANN training loss 0.000552\n",
      ">> Epoch 101 finished \tANN training loss 0.000550\n",
      ">> Epoch 102 finished \tANN training loss 0.000547\n",
      ">> Epoch 103 finished \tANN training loss 0.000545\n",
      ">> Epoch 104 finished \tANN training loss 0.000543\n",
      ">> Epoch 105 finished \tANN training loss 0.000541\n",
      ">> Epoch 106 finished \tANN training loss 0.000539\n",
      ">> Epoch 107 finished \tANN training loss 0.000537\n",
      ">> Epoch 108 finished \tANN training loss 0.000535\n",
      ">> Epoch 109 finished \tANN training loss 0.000533\n",
      ">> Epoch 110 finished \tANN training loss 0.000531\n",
      ">> Epoch 111 finished \tANN training loss 0.000529\n",
      ">> Epoch 112 finished \tANN training loss 0.000528\n",
      ">> Epoch 113 finished \tANN training loss 0.000526\n",
      ">> Epoch 114 finished \tANN training loss 0.000524\n",
      ">> Epoch 115 finished \tANN training loss 0.000523\n",
      ">> Epoch 116 finished \tANN training loss 0.000521\n",
      ">> Epoch 117 finished \tANN training loss 0.000519\n",
      ">> Epoch 118 finished \tANN training loss 0.000518\n",
      ">> Epoch 119 finished \tANN training loss 0.000516\n",
      ">> Epoch 120 finished \tANN training loss 0.000515\n",
      ">> Epoch 121 finished \tANN training loss 0.000513\n",
      ">> Epoch 122 finished \tANN training loss 0.000512\n",
      ">> Epoch 123 finished \tANN training loss 0.000511\n",
      ">> Epoch 124 finished \tANN training loss 0.000509\n",
      ">> Epoch 125 finished \tANN training loss 0.000508\n",
      ">> Epoch 126 finished \tANN training loss 0.000507\n",
      ">> Epoch 127 finished \tANN training loss 0.000505\n",
      ">> Epoch 128 finished \tANN training loss 0.000504\n",
      ">> Epoch 129 finished \tANN training loss 0.000503\n",
      ">> Epoch 130 finished \tANN training loss 0.000501\n",
      ">> Epoch 131 finished \tANN training loss 0.000500\n",
      ">> Epoch 132 finished \tANN training loss 0.000499\n",
      ">> Epoch 133 finished \tANN training loss 0.000498\n",
      ">> Epoch 134 finished \tANN training loss 0.000497\n",
      ">> Epoch 135 finished \tANN training loss 0.000496\n",
      ">> Epoch 136 finished \tANN training loss 0.000494\n",
      ">> Epoch 137 finished \tANN training loss 0.000493\n",
      ">> Epoch 138 finished \tANN training loss 0.000492\n",
      ">> Epoch 139 finished \tANN training loss 0.000491\n",
      ">> Epoch 140 finished \tANN training loss 0.000490\n",
      ">> Epoch 141 finished \tANN training loss 0.000489\n",
      ">> Epoch 142 finished \tANN training loss 0.000488\n",
      ">> Epoch 143 finished \tANN training loss 0.000487\n",
      ">> Epoch 144 finished \tANN training loss 0.000486\n",
      ">> Epoch 145 finished \tANN training loss 0.000485\n",
      ">> Epoch 146 finished \tANN training loss 0.000484\n",
      ">> Epoch 147 finished \tANN training loss 0.000483\n",
      ">> Epoch 148 finished \tANN training loss 0.000482\n",
      ">> Epoch 149 finished \tANN training loss 0.000481\n",
      ">> Epoch 150 finished \tANN training loss 0.000480\n",
      "[END] Fine tuning step\n",
      "############### End Training for GODFRYPHLPEQ #####################\n",
      "############### End Training for HEROMOTOCOEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 3.577786\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 3.512762\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 3.447321\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 3.381233\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 3.314238\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 3.246017\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 3.176468\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 3.105355\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 3.032417\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 2.957288\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 2.879763\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 2.799604\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 2.716549\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 2.630379\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 2.540741\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 2.447409\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 2.350492\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 2.249915\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 2.145597\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 2.037933\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 1.927060\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 1.813837\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 1.698579\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 1.582377\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 1.465637\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 1.350596\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 1.237677\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 1.128228\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 1.022893\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 0.923236\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 0.831429\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 0.747055\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.671172\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.603963\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.545020\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.493604\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.448805\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.411706\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.380137\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.353134\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.331655\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.313581\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.297965\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.285286\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.273408\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.263649\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.255007\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.247685\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.241012\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.235026\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.229397\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.224126\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.219336\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.215009\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.210964\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.206837\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.202914\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.199017\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.195353\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.191828\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.188658\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.185240\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.181898\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.178800\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.175754\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.172866\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.169966\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.166976\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.164216\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.161446\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.158706\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.156139\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.153415\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.150818\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.148191\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.145665\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.143280\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.140929\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.138615\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.136286\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.134007\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.131725\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.129572\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.127469\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.125414\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.123297\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.121215\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.119171\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.117163\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.115257\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.113345\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.111489\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.109603\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.107727\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.105828\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.104031\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.102302\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.100642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 99 finished \tRBM Reconstruction error 0.098923\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.097297\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.219306\n",
      ">> Epoch 2 finished \tANN training loss 0.179929\n",
      ">> Epoch 3 finished \tANN training loss 0.147862\n",
      ">> Epoch 4 finished \tANN training loss 0.121774\n",
      ">> Epoch 5 finished \tANN training loss 0.100634\n",
      ">> Epoch 6 finished \tANN training loss 0.083440\n",
      ">> Epoch 7 finished \tANN training loss 0.069386\n",
      ">> Epoch 8 finished \tANN training loss 0.057878\n",
      ">> Epoch 9 finished \tANN training loss 0.048449\n",
      ">> Epoch 10 finished \tANN training loss 0.040717\n",
      ">> Epoch 11 finished \tANN training loss 0.034372\n",
      ">> Epoch 12 finished \tANN training loss 0.029160\n",
      ">> Epoch 13 finished \tANN training loss 0.024874\n",
      ">> Epoch 14 finished \tANN training loss 0.021347\n",
      ">> Epoch 15 finished \tANN training loss 0.018440\n",
      ">> Epoch 16 finished \tANN training loss 0.016042\n",
      ">> Epoch 17 finished \tANN training loss 0.014059\n",
      ">> Epoch 18 finished \tANN training loss 0.012417\n",
      ">> Epoch 19 finished \tANN training loss 0.011054\n",
      ">> Epoch 20 finished \tANN training loss 0.009919\n",
      ">> Epoch 21 finished \tANN training loss 0.008972\n",
      ">> Epoch 22 finished \tANN training loss 0.008178\n",
      ">> Epoch 23 finished \tANN training loss 0.007511\n",
      ">> Epoch 24 finished \tANN training loss 0.006946\n",
      ">> Epoch 25 finished \tANN training loss 0.006466\n",
      ">> Epoch 26 finished \tANN training loss 0.006056\n",
      ">> Epoch 27 finished \tANN training loss 0.005704\n",
      ">> Epoch 28 finished \tANN training loss 0.005398\n",
      ">> Epoch 29 finished \tANN training loss 0.005132\n",
      ">> Epoch 30 finished \tANN training loss 0.004899\n",
      ">> Epoch 31 finished \tANN training loss 0.004692\n",
      ">> Epoch 32 finished \tANN training loss 0.004507\n",
      ">> Epoch 33 finished \tANN training loss 0.004341\n",
      ">> Epoch 34 finished \tANN training loss 0.004191\n",
      ">> Epoch 35 finished \tANN training loss 0.004053\n",
      ">> Epoch 36 finished \tANN training loss 0.003927\n",
      ">> Epoch 37 finished \tANN training loss 0.003810\n",
      ">> Epoch 38 finished \tANN training loss 0.003701\n",
      ">> Epoch 39 finished \tANN training loss 0.003598\n",
      ">> Epoch 40 finished \tANN training loss 0.003502\n",
      ">> Epoch 41 finished \tANN training loss 0.003411\n",
      ">> Epoch 42 finished \tANN training loss 0.003324\n",
      ">> Epoch 43 finished \tANN training loss 0.003242\n",
      ">> Epoch 44 finished \tANN training loss 0.003163\n",
      ">> Epoch 45 finished \tANN training loss 0.003087\n",
      ">> Epoch 46 finished \tANN training loss 0.003014\n",
      ">> Epoch 47 finished \tANN training loss 0.002944\n",
      ">> Epoch 48 finished \tANN training loss 0.002876\n",
      ">> Epoch 49 finished \tANN training loss 0.002811\n",
      ">> Epoch 50 finished \tANN training loss 0.002748\n",
      ">> Epoch 51 finished \tANN training loss 0.002687\n",
      ">> Epoch 52 finished \tANN training loss 0.002627\n",
      ">> Epoch 53 finished \tANN training loss 0.002570\n",
      ">> Epoch 54 finished \tANN training loss 0.002514\n",
      ">> Epoch 55 finished \tANN training loss 0.002460\n",
      ">> Epoch 56 finished \tANN training loss 0.002407\n",
      ">> Epoch 57 finished \tANN training loss 0.002356\n",
      ">> Epoch 58 finished \tANN training loss 0.002306\n",
      ">> Epoch 59 finished \tANN training loss 0.002257\n",
      ">> Epoch 60 finished \tANN training loss 0.002210\n",
      ">> Epoch 61 finished \tANN training loss 0.002164\n",
      ">> Epoch 62 finished \tANN training loss 0.002119\n",
      ">> Epoch 63 finished \tANN training loss 0.002076\n",
      ">> Epoch 64 finished \tANN training loss 0.002033\n",
      ">> Epoch 65 finished \tANN training loss 0.001992\n",
      ">> Epoch 66 finished \tANN training loss 0.001952\n",
      ">> Epoch 67 finished \tANN training loss 0.001913\n",
      ">> Epoch 68 finished \tANN training loss 0.001874\n",
      ">> Epoch 69 finished \tANN training loss 0.001837\n",
      ">> Epoch 70 finished \tANN training loss 0.001801\n",
      ">> Epoch 71 finished \tANN training loss 0.001766\n",
      ">> Epoch 72 finished \tANN training loss 0.001731\n",
      ">> Epoch 73 finished \tANN training loss 0.001698\n",
      ">> Epoch 74 finished \tANN training loss 0.001665\n",
      ">> Epoch 75 finished \tANN training loss 0.001633\n",
      ">> Epoch 76 finished \tANN training loss 0.001602\n",
      ">> Epoch 77 finished \tANN training loss 0.001571\n",
      ">> Epoch 78 finished \tANN training loss 0.001542\n",
      ">> Epoch 79 finished \tANN training loss 0.001513\n",
      ">> Epoch 80 finished \tANN training loss 0.001485\n",
      ">> Epoch 81 finished \tANN training loss 0.001457\n",
      ">> Epoch 82 finished \tANN training loss 0.001430\n",
      ">> Epoch 83 finished \tANN training loss 0.001404\n",
      ">> Epoch 84 finished \tANN training loss 0.001379\n",
      ">> Epoch 85 finished \tANN training loss 0.001354\n",
      ">> Epoch 86 finished \tANN training loss 0.001330\n",
      ">> Epoch 87 finished \tANN training loss 0.001306\n",
      ">> Epoch 88 finished \tANN training loss 0.001283\n",
      ">> Epoch 89 finished \tANN training loss 0.001260\n",
      ">> Epoch 90 finished \tANN training loss 0.001238\n",
      ">> Epoch 91 finished \tANN training loss 0.001217\n",
      ">> Epoch 92 finished \tANN training loss 0.001196\n",
      ">> Epoch 93 finished \tANN training loss 0.001175\n",
      ">> Epoch 94 finished \tANN training loss 0.001155\n",
      ">> Epoch 95 finished \tANN training loss 0.001136\n",
      ">> Epoch 96 finished \tANN training loss 0.001117\n",
      ">> Epoch 97 finished \tANN training loss 0.001098\n",
      ">> Epoch 98 finished \tANN training loss 0.001080\n",
      ">> Epoch 99 finished \tANN training loss 0.001063\n",
      ">> Epoch 100 finished \tANN training loss 0.001045\n",
      ">> Epoch 101 finished \tANN training loss 0.001028\n",
      ">> Epoch 102 finished \tANN training loss 0.001012\n",
      ">> Epoch 103 finished \tANN training loss 0.000996\n",
      ">> Epoch 104 finished \tANN training loss 0.000980\n",
      ">> Epoch 105 finished \tANN training loss 0.000965\n",
      ">> Epoch 106 finished \tANN training loss 0.000950\n",
      ">> Epoch 107 finished \tANN training loss 0.000935\n",
      ">> Epoch 108 finished \tANN training loss 0.000921\n",
      ">> Epoch 109 finished \tANN training loss 0.000907\n",
      ">> Epoch 110 finished \tANN training loss 0.000894\n",
      ">> Epoch 111 finished \tANN training loss 0.000881\n",
      ">> Epoch 112 finished \tANN training loss 0.000868\n",
      ">> Epoch 113 finished \tANN training loss 0.000855\n",
      ">> Epoch 114 finished \tANN training loss 0.000843\n",
      ">> Epoch 115 finished \tANN training loss 0.000831\n",
      ">> Epoch 116 finished \tANN training loss 0.000819\n",
      ">> Epoch 117 finished \tANN training loss 0.000807\n",
      ">> Epoch 118 finished \tANN training loss 0.000796\n",
      ">> Epoch 119 finished \tANN training loss 0.000785\n",
      ">> Epoch 120 finished \tANN training loss 0.000775\n",
      ">> Epoch 121 finished \tANN training loss 0.000764\n",
      ">> Epoch 122 finished \tANN training loss 0.000754\n",
      ">> Epoch 123 finished \tANN training loss 0.000744\n",
      ">> Epoch 124 finished \tANN training loss 0.000734\n",
      ">> Epoch 125 finished \tANN training loss 0.000725\n",
      ">> Epoch 126 finished \tANN training loss 0.000715\n",
      ">> Epoch 127 finished \tANN training loss 0.000706\n",
      ">> Epoch 128 finished \tANN training loss 0.000698\n",
      ">> Epoch 129 finished \tANN training loss 0.000689\n",
      ">> Epoch 130 finished \tANN training loss 0.000681\n",
      ">> Epoch 131 finished \tANN training loss 0.000672\n",
      ">> Epoch 132 finished \tANN training loss 0.000664\n",
      ">> Epoch 133 finished \tANN training loss 0.000656\n",
      ">> Epoch 134 finished \tANN training loss 0.000649\n",
      ">> Epoch 135 finished \tANN training loss 0.000641\n",
      ">> Epoch 136 finished \tANN training loss 0.000634\n",
      ">> Epoch 137 finished \tANN training loss 0.000627\n",
      ">> Epoch 138 finished \tANN training loss 0.000620\n",
      ">> Epoch 139 finished \tANN training loss 0.000613\n",
      ">> Epoch 140 finished \tANN training loss 0.000606\n",
      ">> Epoch 141 finished \tANN training loss 0.000600\n",
      ">> Epoch 142 finished \tANN training loss 0.000594\n",
      ">> Epoch 143 finished \tANN training loss 0.000587\n",
      ">> Epoch 144 finished \tANN training loss 0.000581\n",
      ">> Epoch 145 finished \tANN training loss 0.000575\n",
      ">> Epoch 146 finished \tANN training loss 0.000570\n",
      ">> Epoch 147 finished \tANN training loss 0.000564\n",
      ">> Epoch 148 finished \tANN training loss 0.000559\n",
      ">> Epoch 149 finished \tANN training loss 0.000553\n",
      ">> Epoch 150 finished \tANN training loss 0.000548\n",
      "[END] Fine tuning step\n",
      "############### End Training for HEROMOTOCOEQ #####################\n",
      "############### End Training for TORNTPOWEREQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 6.165930\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 6.001094\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 5.820380\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 5.620856\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 5.398690\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 5.150675\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 4.873422\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 4.563248\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 4.218605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 10 finished \tRBM Reconstruction error 3.839376\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 3.429687\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 2.996818\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 2.552582\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 2.113215\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 1.697926\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 1.322137\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 1.001752\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 0.746821\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 0.556176\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 0.423130\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 0.334820\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 0.282351\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 0.253280\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 0.238721\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 0.232751\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 0.231250\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 0.231938\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 0.232999\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 0.234001\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 0.235718\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 0.235192\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 0.235737\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.235447\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.233934\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.233581\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.231857\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.229813\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.228823\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.226652\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.224225\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.221255\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.219659\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.216421\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.215588\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.215359\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.214662\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.212131\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.209572\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.208187\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.208576\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.207276\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.206833\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.208366\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.206536\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.204708\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.204281\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.204491\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.205127\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.202230\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.201262\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.199223\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.199654\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.198026\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.196655\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.195056\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.195211\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.192807\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.193317\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.192952\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.193728\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.193173\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.193378\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.193509\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.195129\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.195637\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.196571\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.197204\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.196785\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.197022\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.197692\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.197232\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.196579\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.199215\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.197774\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.198726\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.196532\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.195023\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.193895\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.195767\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.194170\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.196285\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.197734\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.197304\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.198489\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.200703\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.200866\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.202091\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.203679\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.205074\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.208020\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.038747\n",
      ">> Epoch 2 finished \tANN training loss 0.028617\n",
      ">> Epoch 3 finished \tANN training loss 0.021880\n",
      ">> Epoch 4 finished \tANN training loss 0.017363\n",
      ">> Epoch 5 finished \tANN training loss 0.014313\n",
      ">> Epoch 6 finished \tANN training loss 0.012234\n",
      ">> Epoch 7 finished \tANN training loss 0.010796\n",
      ">> Epoch 8 finished \tANN training loss 0.009781\n",
      ">> Epoch 9 finished \tANN training loss 0.009050\n",
      ">> Epoch 10 finished \tANN training loss 0.008507\n",
      ">> Epoch 11 finished \tANN training loss 0.008090\n",
      ">> Epoch 12 finished \tANN training loss 0.007760\n",
      ">> Epoch 13 finished \tANN training loss 0.007487\n",
      ">> Epoch 14 finished \tANN training loss 0.007255\n",
      ">> Epoch 15 finished \tANN training loss 0.007051\n",
      ">> Epoch 16 finished \tANN training loss 0.006867\n",
      ">> Epoch 17 finished \tANN training loss 0.006699\n",
      ">> Epoch 18 finished \tANN training loss 0.006542\n",
      ">> Epoch 19 finished \tANN training loss 0.006393\n",
      ">> Epoch 20 finished \tANN training loss 0.006253\n",
      ">> Epoch 21 finished \tANN training loss 0.006118\n",
      ">> Epoch 22 finished \tANN training loss 0.005990\n",
      ">> Epoch 23 finished \tANN training loss 0.005866\n",
      ">> Epoch 24 finished \tANN training loss 0.005746\n",
      ">> Epoch 25 finished \tANN training loss 0.005631\n",
      ">> Epoch 26 finished \tANN training loss 0.005520\n",
      ">> Epoch 27 finished \tANN training loss 0.005412\n",
      ">> Epoch 28 finished \tANN training loss 0.005308\n",
      ">> Epoch 29 finished \tANN training loss 0.005207\n",
      ">> Epoch 30 finished \tANN training loss 0.005109\n",
      ">> Epoch 31 finished \tANN training loss 0.005014\n",
      ">> Epoch 32 finished \tANN training loss 0.004923\n",
      ">> Epoch 33 finished \tANN training loss 0.004834\n",
      ">> Epoch 34 finished \tANN training loss 0.004747\n",
      ">> Epoch 35 finished \tANN training loss 0.004664\n",
      ">> Epoch 36 finished \tANN training loss 0.004583\n",
      ">> Epoch 37 finished \tANN training loss 0.004505\n",
      ">> Epoch 38 finished \tANN training loss 0.004428\n",
      ">> Epoch 39 finished \tANN training loss 0.004355\n",
      ">> Epoch 40 finished \tANN training loss 0.004283\n",
      ">> Epoch 41 finished \tANN training loss 0.004214\n",
      ">> Epoch 42 finished \tANN training loss 0.004147\n",
      ">> Epoch 43 finished \tANN training loss 0.004081\n",
      ">> Epoch 44 finished \tANN training loss 0.004018\n",
      ">> Epoch 45 finished \tANN training loss 0.003957\n",
      ">> Epoch 46 finished \tANN training loss 0.003897\n",
      ">> Epoch 47 finished \tANN training loss 0.003839\n",
      ">> Epoch 48 finished \tANN training loss 0.003783\n",
      ">> Epoch 49 finished \tANN training loss 0.003729\n",
      ">> Epoch 50 finished \tANN training loss 0.003676\n",
      ">> Epoch 51 finished \tANN training loss 0.003625\n",
      ">> Epoch 52 finished \tANN training loss 0.003575\n",
      ">> Epoch 53 finished \tANN training loss 0.003527\n",
      ">> Epoch 54 finished \tANN training loss 0.003480\n",
      ">> Epoch 55 finished \tANN training loss 0.003434\n",
      ">> Epoch 56 finished \tANN training loss 0.003390\n",
      ">> Epoch 57 finished \tANN training loss 0.003348\n",
      ">> Epoch 58 finished \tANN training loss 0.003306\n",
      ">> Epoch 59 finished \tANN training loss 0.003266\n",
      ">> Epoch 60 finished \tANN training loss 0.003226\n",
      ">> Epoch 61 finished \tANN training loss 0.003188\n",
      ">> Epoch 62 finished \tANN training loss 0.003151\n",
      ">> Epoch 63 finished \tANN training loss 0.003116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 64 finished \tANN training loss 0.003081\n",
      ">> Epoch 65 finished \tANN training loss 0.003047\n",
      ">> Epoch 66 finished \tANN training loss 0.003014\n",
      ">> Epoch 67 finished \tANN training loss 0.002982\n",
      ">> Epoch 68 finished \tANN training loss 0.002951\n",
      ">> Epoch 69 finished \tANN training loss 0.002921\n",
      ">> Epoch 70 finished \tANN training loss 0.002892\n",
      ">> Epoch 71 finished \tANN training loss 0.002864\n",
      ">> Epoch 72 finished \tANN training loss 0.002836\n",
      ">> Epoch 73 finished \tANN training loss 0.002809\n",
      ">> Epoch 74 finished \tANN training loss 0.002783\n",
      ">> Epoch 75 finished \tANN training loss 0.002758\n",
      ">> Epoch 76 finished \tANN training loss 0.002733\n",
      ">> Epoch 77 finished \tANN training loss 0.002709\n",
      ">> Epoch 78 finished \tANN training loss 0.002686\n",
      ">> Epoch 79 finished \tANN training loss 0.002663\n",
      ">> Epoch 80 finished \tANN training loss 0.002641\n",
      ">> Epoch 81 finished \tANN training loss 0.002620\n",
      ">> Epoch 82 finished \tANN training loss 0.002599\n",
      ">> Epoch 83 finished \tANN training loss 0.002579\n",
      ">> Epoch 84 finished \tANN training loss 0.002560\n",
      ">> Epoch 85 finished \tANN training loss 0.002540\n",
      ">> Epoch 86 finished \tANN training loss 0.002522\n",
      ">> Epoch 87 finished \tANN training loss 0.002504\n",
      ">> Epoch 88 finished \tANN training loss 0.002486\n",
      ">> Epoch 89 finished \tANN training loss 0.002469\n",
      ">> Epoch 90 finished \tANN training loss 0.002453\n",
      ">> Epoch 91 finished \tANN training loss 0.002436\n",
      ">> Epoch 92 finished \tANN training loss 0.002421\n",
      ">> Epoch 93 finished \tANN training loss 0.002405\n",
      ">> Epoch 94 finished \tANN training loss 0.002390\n",
      ">> Epoch 95 finished \tANN training loss 0.002376\n",
      ">> Epoch 96 finished \tANN training loss 0.002362\n",
      ">> Epoch 97 finished \tANN training loss 0.002348\n",
      ">> Epoch 98 finished \tANN training loss 0.002334\n",
      ">> Epoch 99 finished \tANN training loss 0.002321\n",
      ">> Epoch 100 finished \tANN training loss 0.002309\n",
      ">> Epoch 101 finished \tANN training loss 0.002296\n",
      ">> Epoch 102 finished \tANN training loss 0.002284\n",
      ">> Epoch 103 finished \tANN training loss 0.002272\n",
      ">> Epoch 104 finished \tANN training loss 0.002261\n",
      ">> Epoch 105 finished \tANN training loss 0.002250\n",
      ">> Epoch 106 finished \tANN training loss 0.002239\n",
      ">> Epoch 107 finished \tANN training loss 0.002229\n",
      ">> Epoch 108 finished \tANN training loss 0.002218\n",
      ">> Epoch 109 finished \tANN training loss 0.002208\n",
      ">> Epoch 110 finished \tANN training loss 0.002199\n",
      ">> Epoch 111 finished \tANN training loss 0.002189\n",
      ">> Epoch 112 finished \tANN training loss 0.002180\n",
      ">> Epoch 113 finished \tANN training loss 0.002171\n",
      ">> Epoch 114 finished \tANN training loss 0.002162\n",
      ">> Epoch 115 finished \tANN training loss 0.002154\n",
      ">> Epoch 116 finished \tANN training loss 0.002145\n",
      ">> Epoch 117 finished \tANN training loss 0.002137\n",
      ">> Epoch 118 finished \tANN training loss 0.002130\n",
      ">> Epoch 119 finished \tANN training loss 0.002122\n",
      ">> Epoch 120 finished \tANN training loss 0.002114\n",
      ">> Epoch 121 finished \tANN training loss 0.002107\n",
      ">> Epoch 122 finished \tANN training loss 0.002100\n",
      ">> Epoch 123 finished \tANN training loss 0.002093\n",
      ">> Epoch 124 finished \tANN training loss 0.002086\n",
      ">> Epoch 125 finished \tANN training loss 0.002080\n",
      ">> Epoch 126 finished \tANN training loss 0.002073\n",
      ">> Epoch 127 finished \tANN training loss 0.002067\n",
      ">> Epoch 128 finished \tANN training loss 0.002061\n",
      ">> Epoch 129 finished \tANN training loss 0.002055\n",
      ">> Epoch 130 finished \tANN training loss 0.002049\n",
      ">> Epoch 131 finished \tANN training loss 0.002043\n",
      ">> Epoch 132 finished \tANN training loss 0.002038\n",
      ">> Epoch 133 finished \tANN training loss 0.002032\n",
      ">> Epoch 134 finished \tANN training loss 0.002027\n",
      ">> Epoch 135 finished \tANN training loss 0.002022\n",
      ">> Epoch 136 finished \tANN training loss 0.002017\n",
      ">> Epoch 137 finished \tANN training loss 0.002012\n",
      ">> Epoch 138 finished \tANN training loss 0.002007\n",
      ">> Epoch 139 finished \tANN training loss 0.002002\n",
      ">> Epoch 140 finished \tANN training loss 0.001997\n",
      ">> Epoch 141 finished \tANN training loss 0.001993\n",
      ">> Epoch 142 finished \tANN training loss 0.001988\n",
      ">> Epoch 143 finished \tANN training loss 0.001984\n",
      ">> Epoch 144 finished \tANN training loss 0.001980\n",
      ">> Epoch 145 finished \tANN training loss 0.001976\n",
      ">> Epoch 146 finished \tANN training loss 0.001971\n",
      ">> Epoch 147 finished \tANN training loss 0.001967\n",
      ">> Epoch 148 finished \tANN training loss 0.001963\n",
      ">> Epoch 149 finished \tANN training loss 0.001960\n",
      ">> Epoch 150 finished \tANN training loss 0.001956\n",
      "[END] Fine tuning step\n",
      "############### End Training for TORNTPOWEREQ #####################\n",
      "############### End Training for JUBLFOODEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 5.268444\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 5.203273\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 5.137530\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 5.071200\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 5.004241\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 4.936554\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 4.868162\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 4.798919\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 4.728840\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 4.657747\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 4.585617\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 4.512350\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 4.437893\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 4.362156\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 4.285014\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 4.206476\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 4.126342\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 4.044768\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 3.961536\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 3.876528\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 3.789770\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 3.701117\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 3.610604\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 3.518048\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 3.423528\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 3.327239\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 3.229049\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 3.129191\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 3.027048\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 2.923456\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 2.818118\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 2.711398\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 2.603605\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 2.494694\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 2.384613\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 2.273988\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 2.163138\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 2.053147\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 1.942817\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 1.833156\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 1.725225\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 1.618402\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 1.514462\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 1.412905\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 1.314137\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 1.219430\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 1.127667\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 1.040041\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.957892\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.880089\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.806143\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.737338\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.673327\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.614117\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.560781\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.512214\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.468135\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.428237\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.391924\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.359127\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.330409\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.304536\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.282087\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.262538\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.245955\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.231315\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.218796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 68 finished \tRBM Reconstruction error 0.207495\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.197790\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.188957\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.181657\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.175538\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.169763\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.164876\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.161248\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.157671\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.154980\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.151974\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.149567\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.147313\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.145165\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.143467\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.142069\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.140691\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.139589\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.138627\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.137644\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.136719\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.135889\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.134945\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.134314\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.133689\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.133269\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.132705\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.132324\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.131701\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.131263\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.130892\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.130476\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.129999\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.004979\n",
      ">> Epoch 2 finished \tANN training loss 0.004645\n",
      ">> Epoch 3 finished \tANN training loss 0.004344\n",
      ">> Epoch 4 finished \tANN training loss 0.004072\n",
      ">> Epoch 5 finished \tANN training loss 0.003826\n",
      ">> Epoch 6 finished \tANN training loss 0.003604\n",
      ">> Epoch 7 finished \tANN training loss 0.003404\n",
      ">> Epoch 8 finished \tANN training loss 0.003223\n",
      ">> Epoch 9 finished \tANN training loss 0.003059\n",
      ">> Epoch 10 finished \tANN training loss 0.002912\n",
      ">> Epoch 11 finished \tANN training loss 0.002778\n",
      ">> Epoch 12 finished \tANN training loss 0.002658\n",
      ">> Epoch 13 finished \tANN training loss 0.002549\n",
      ">> Epoch 14 finished \tANN training loss 0.002451\n",
      ">> Epoch 15 finished \tANN training loss 0.002363\n",
      ">> Epoch 16 finished \tANN training loss 0.002283\n",
      ">> Epoch 17 finished \tANN training loss 0.002210\n",
      ">> Epoch 18 finished \tANN training loss 0.002145\n",
      ">> Epoch 19 finished \tANN training loss 0.002086\n",
      ">> Epoch 20 finished \tANN training loss 0.002033\n",
      ">> Epoch 21 finished \tANN training loss 0.001984\n",
      ">> Epoch 22 finished \tANN training loss 0.001941\n",
      ">> Epoch 23 finished \tANN training loss 0.001902\n",
      ">> Epoch 24 finished \tANN training loss 0.001866\n",
      ">> Epoch 25 finished \tANN training loss 0.001834\n",
      ">> Epoch 26 finished \tANN training loss 0.001805\n",
      ">> Epoch 27 finished \tANN training loss 0.001779\n",
      ">> Epoch 28 finished \tANN training loss 0.001755\n",
      ">> Epoch 29 finished \tANN training loss 0.001733\n",
      ">> Epoch 30 finished \tANN training loss 0.001714\n",
      ">> Epoch 31 finished \tANN training loss 0.001696\n",
      ">> Epoch 32 finished \tANN training loss 0.001680\n",
      ">> Epoch 33 finished \tANN training loss 0.001666\n",
      ">> Epoch 34 finished \tANN training loss 0.001653\n",
      ">> Epoch 35 finished \tANN training loss 0.001641\n",
      ">> Epoch 36 finished \tANN training loss 0.001630\n",
      ">> Epoch 37 finished \tANN training loss 0.001621\n",
      ">> Epoch 38 finished \tANN training loss 0.001612\n",
      ">> Epoch 39 finished \tANN training loss 0.001604\n",
      ">> Epoch 40 finished \tANN training loss 0.001596\n",
      ">> Epoch 41 finished \tANN training loss 0.001590\n",
      ">> Epoch 42 finished \tANN training loss 0.001584\n",
      ">> Epoch 43 finished \tANN training loss 0.001578\n",
      ">> Epoch 44 finished \tANN training loss 0.001573\n",
      ">> Epoch 45 finished \tANN training loss 0.001569\n",
      ">> Epoch 46 finished \tANN training loss 0.001565\n",
      ">> Epoch 47 finished \tANN training loss 0.001561\n",
      ">> Epoch 48 finished \tANN training loss 0.001557\n",
      ">> Epoch 49 finished \tANN training loss 0.001554\n",
      ">> Epoch 50 finished \tANN training loss 0.001551\n",
      ">> Epoch 51 finished \tANN training loss 0.001548\n",
      ">> Epoch 52 finished \tANN training loss 0.001546\n",
      ">> Epoch 53 finished \tANN training loss 0.001544\n",
      ">> Epoch 54 finished \tANN training loss 0.001542\n",
      ">> Epoch 55 finished \tANN training loss 0.001540\n",
      ">> Epoch 56 finished \tANN training loss 0.001538\n",
      ">> Epoch 57 finished \tANN training loss 0.001536\n",
      ">> Epoch 58 finished \tANN training loss 0.001535\n",
      ">> Epoch 59 finished \tANN training loss 0.001533\n",
      ">> Epoch 60 finished \tANN training loss 0.001532\n",
      ">> Epoch 61 finished \tANN training loss 0.001531\n",
      ">> Epoch 62 finished \tANN training loss 0.001529\n",
      ">> Epoch 63 finished \tANN training loss 0.001528\n",
      ">> Epoch 64 finished \tANN training loss 0.001527\n",
      ">> Epoch 65 finished \tANN training loss 0.001526\n",
      ">> Epoch 66 finished \tANN training loss 0.001525\n",
      ">> Epoch 67 finished \tANN training loss 0.001524\n",
      ">> Epoch 68 finished \tANN training loss 0.001523\n",
      ">> Epoch 69 finished \tANN training loss 0.001523\n",
      ">> Epoch 70 finished \tANN training loss 0.001522\n",
      ">> Epoch 71 finished \tANN training loss 0.001521\n",
      ">> Epoch 72 finished \tANN training loss 0.001520\n",
      ">> Epoch 73 finished \tANN training loss 0.001520\n",
      ">> Epoch 74 finished \tANN training loss 0.001519\n",
      ">> Epoch 75 finished \tANN training loss 0.001518\n",
      ">> Epoch 76 finished \tANN training loss 0.001518\n",
      ">> Epoch 77 finished \tANN training loss 0.001517\n",
      ">> Epoch 78 finished \tANN training loss 0.001516\n",
      ">> Epoch 79 finished \tANN training loss 0.001516\n",
      ">> Epoch 80 finished \tANN training loss 0.001515\n",
      ">> Epoch 81 finished \tANN training loss 0.001514\n",
      ">> Epoch 82 finished \tANN training loss 0.001514\n",
      ">> Epoch 83 finished \tANN training loss 0.001513\n",
      ">> Epoch 84 finished \tANN training loss 0.001513\n",
      ">> Epoch 85 finished \tANN training loss 0.001512\n",
      ">> Epoch 86 finished \tANN training loss 0.001512\n",
      ">> Epoch 87 finished \tANN training loss 0.001511\n",
      ">> Epoch 88 finished \tANN training loss 0.001511\n",
      ">> Epoch 89 finished \tANN training loss 0.001510\n",
      ">> Epoch 90 finished \tANN training loss 0.001510\n",
      ">> Epoch 91 finished \tANN training loss 0.001509\n",
      ">> Epoch 92 finished \tANN training loss 0.001509\n",
      ">> Epoch 93 finished \tANN training loss 0.001508\n",
      ">> Epoch 94 finished \tANN training loss 0.001508\n",
      ">> Epoch 95 finished \tANN training loss 0.001507\n",
      ">> Epoch 96 finished \tANN training loss 0.001507\n",
      ">> Epoch 97 finished \tANN training loss 0.001506\n",
      ">> Epoch 98 finished \tANN training loss 0.001505\n",
      ">> Epoch 99 finished \tANN training loss 0.001505\n",
      ">> Epoch 100 finished \tANN training loss 0.001505\n",
      ">> Epoch 101 finished \tANN training loss 0.001504\n",
      ">> Epoch 102 finished \tANN training loss 0.001504\n",
      ">> Epoch 103 finished \tANN training loss 0.001503\n",
      ">> Epoch 104 finished \tANN training loss 0.001503\n",
      ">> Epoch 105 finished \tANN training loss 0.001502\n",
      ">> Epoch 106 finished \tANN training loss 0.001502\n",
      ">> Epoch 107 finished \tANN training loss 0.001501\n",
      ">> Epoch 108 finished \tANN training loss 0.001501\n",
      ">> Epoch 109 finished \tANN training loss 0.001500\n",
      ">> Epoch 110 finished \tANN training loss 0.001500\n",
      ">> Epoch 111 finished \tANN training loss 0.001499\n",
      ">> Epoch 112 finished \tANN training loss 0.001499\n",
      ">> Epoch 113 finished \tANN training loss 0.001498\n",
      ">> Epoch 114 finished \tANN training loss 0.001498\n",
      ">> Epoch 115 finished \tANN training loss 0.001497\n",
      ">> Epoch 116 finished \tANN training loss 0.001497\n",
      ">> Epoch 117 finished \tANN training loss 0.001496\n",
      ">> Epoch 118 finished \tANN training loss 0.001496\n",
      ">> Epoch 119 finished \tANN training loss 0.001495\n",
      ">> Epoch 120 finished \tANN training loss 0.001495\n",
      ">> Epoch 121 finished \tANN training loss 0.001495\n",
      ">> Epoch 122 finished \tANN training loss 0.001494\n",
      ">> Epoch 123 finished \tANN training loss 0.001494\n",
      ">> Epoch 124 finished \tANN training loss 0.001493\n",
      ">> Epoch 125 finished \tANN training loss 0.001493\n",
      ">> Epoch 126 finished \tANN training loss 0.001492\n",
      ">> Epoch 127 finished \tANN training loss 0.001492\n",
      ">> Epoch 128 finished \tANN training loss 0.001491\n",
      ">> Epoch 129 finished \tANN training loss 0.001491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 130 finished \tANN training loss 0.001491\n",
      ">> Epoch 131 finished \tANN training loss 0.001490\n",
      ">> Epoch 132 finished \tANN training loss 0.001490\n",
      ">> Epoch 133 finished \tANN training loss 0.001489\n",
      ">> Epoch 134 finished \tANN training loss 0.001489\n",
      ">> Epoch 135 finished \tANN training loss 0.001488\n",
      ">> Epoch 136 finished \tANN training loss 0.001488\n",
      ">> Epoch 137 finished \tANN training loss 0.001487\n",
      ">> Epoch 138 finished \tANN training loss 0.001487\n",
      ">> Epoch 139 finished \tANN training loss 0.001487\n",
      ">> Epoch 140 finished \tANN training loss 0.001486\n",
      ">> Epoch 141 finished \tANN training loss 0.001486\n",
      ">> Epoch 142 finished \tANN training loss 0.001485\n",
      ">> Epoch 143 finished \tANN training loss 0.001485\n",
      ">> Epoch 144 finished \tANN training loss 0.001484\n",
      ">> Epoch 145 finished \tANN training loss 0.001484\n",
      ">> Epoch 146 finished \tANN training loss 0.001484\n",
      ">> Epoch 147 finished \tANN training loss 0.001483\n",
      ">> Epoch 148 finished \tANN training loss 0.001483\n",
      ">> Epoch 149 finished \tANN training loss 0.001482\n",
      ">> Epoch 150 finished \tANN training loss 0.001482\n",
      "[END] Fine tuning step\n",
      "############### End Training for JUBLFOODEQ #####################\n",
      "############### End Training for JINDALSTELEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 9.808657\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 9.576014\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 9.308812\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 8.997736\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 8.631829\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 8.198691\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 7.685389\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 7.080222\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 6.375571\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 5.572843\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 4.690158\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 3.763645\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 2.855035\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 2.030820\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 1.353524\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 0.859060\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 0.541814\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 0.372252\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 0.297135\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 0.280213\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 0.289004\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 0.309349\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 0.331346\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 0.346663\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 0.359213\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 0.367976\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 0.373179\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 0.376995\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 0.378968\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 0.381546\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 0.379373\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 0.380527\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.384254\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.382653\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.379458\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.377934\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.377966\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.375976\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.373413\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.374893\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.377216\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.375212\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.375205\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.377604\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.375060\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.374384\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.375450\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.375511\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.372271\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.370976\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.369587\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.369058\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.368432\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.370596\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.368290\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.364915\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.365773\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.364550\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.368184\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.369387\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.369722\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.368341\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.366422\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.368901\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.375709\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.373678\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.372462\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.371870\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.368458\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.366528\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.370879\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.369748\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.374291\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.375977\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.377452\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.376345\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.377905\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.374483\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.374502\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.373426\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.374566\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.370444\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.375901\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.373630\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.374326\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.367387\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.366036\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.367062\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.371785\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.381982\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.379828\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.381824\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.382399\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.380800\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.383702\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.382196\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.380720\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.382918\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.386268\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.388494\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.542355\n",
      ">> Epoch 2 finished \tANN training loss 0.342966\n",
      ">> Epoch 3 finished \tANN training loss 0.218880\n",
      ">> Epoch 4 finished \tANN training loss 0.140072\n",
      ">> Epoch 5 finished \tANN training loss 0.090076\n",
      ">> Epoch 6 finished \tANN training loss 0.058506\n",
      ">> Epoch 7 finished \tANN training loss 0.038584\n",
      ">> Epoch 8 finished \tANN training loss 0.026010\n",
      ">> Epoch 9 finished \tANN training loss 0.018080\n",
      ">> Epoch 10 finished \tANN training loss 0.013075\n",
      ">> Epoch 11 finished \tANN training loss 0.009918\n",
      ">> Epoch 12 finished \tANN training loss 0.007917\n",
      ">> Epoch 13 finished \tANN training loss 0.006649\n",
      ">> Epoch 14 finished \tANN training loss 0.005840\n",
      ">> Epoch 15 finished \tANN training loss 0.005319\n",
      ">> Epoch 16 finished \tANN training loss 0.004982\n",
      ">> Epoch 17 finished \tANN training loss 0.004759\n",
      ">> Epoch 18 finished \tANN training loss 0.004608\n",
      ">> Epoch 19 finished \tANN training loss 0.004503\n",
      ">> Epoch 20 finished \tANN training loss 0.004426\n",
      ">> Epoch 21 finished \tANN training loss 0.004368\n",
      ">> Epoch 22 finished \tANN training loss 0.004321\n",
      ">> Epoch 23 finished \tANN training loss 0.004281\n",
      ">> Epoch 24 finished \tANN training loss 0.004247\n",
      ">> Epoch 25 finished \tANN training loss 0.004216\n",
      ">> Epoch 26 finished \tANN training loss 0.004186\n",
      ">> Epoch 27 finished \tANN training loss 0.004159\n",
      ">> Epoch 28 finished \tANN training loss 0.004133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 29 finished \tANN training loss 0.004108\n",
      ">> Epoch 30 finished \tANN training loss 0.004083\n",
      ">> Epoch 31 finished \tANN training loss 0.004060\n",
      ">> Epoch 32 finished \tANN training loss 0.004037\n",
      ">> Epoch 33 finished \tANN training loss 0.004014\n",
      ">> Epoch 34 finished \tANN training loss 0.003992\n",
      ">> Epoch 35 finished \tANN training loss 0.003970\n",
      ">> Epoch 36 finished \tANN training loss 0.003949\n",
      ">> Epoch 37 finished \tANN training loss 0.003928\n",
      ">> Epoch 38 finished \tANN training loss 0.003908\n",
      ">> Epoch 39 finished \tANN training loss 0.003888\n",
      ">> Epoch 40 finished \tANN training loss 0.003868\n",
      ">> Epoch 41 finished \tANN training loss 0.003849\n",
      ">> Epoch 42 finished \tANN training loss 0.003830\n",
      ">> Epoch 43 finished \tANN training loss 0.003812\n",
      ">> Epoch 44 finished \tANN training loss 0.003794\n",
      ">> Epoch 45 finished \tANN training loss 0.003776\n",
      ">> Epoch 46 finished \tANN training loss 0.003759\n",
      ">> Epoch 47 finished \tANN training loss 0.003742\n",
      ">> Epoch 48 finished \tANN training loss 0.003725\n",
      ">> Epoch 49 finished \tANN training loss 0.003709\n",
      ">> Epoch 50 finished \tANN training loss 0.003692\n",
      ">> Epoch 51 finished \tANN training loss 0.003677\n",
      ">> Epoch 52 finished \tANN training loss 0.003661\n",
      ">> Epoch 53 finished \tANN training loss 0.003646\n",
      ">> Epoch 54 finished \tANN training loss 0.003631\n",
      ">> Epoch 55 finished \tANN training loss 0.003617\n",
      ">> Epoch 56 finished \tANN training loss 0.003602\n",
      ">> Epoch 57 finished \tANN training loss 0.003588\n",
      ">> Epoch 58 finished \tANN training loss 0.003574\n",
      ">> Epoch 59 finished \tANN training loss 0.003561\n",
      ">> Epoch 60 finished \tANN training loss 0.003548\n",
      ">> Epoch 61 finished \tANN training loss 0.003535\n",
      ">> Epoch 62 finished \tANN training loss 0.003522\n",
      ">> Epoch 63 finished \tANN training loss 0.003509\n",
      ">> Epoch 64 finished \tANN training loss 0.003497\n",
      ">> Epoch 65 finished \tANN training loss 0.003485\n",
      ">> Epoch 66 finished \tANN training loss 0.003473\n",
      ">> Epoch 67 finished \tANN training loss 0.003461\n",
      ">> Epoch 68 finished \tANN training loss 0.003450\n",
      ">> Epoch 69 finished \tANN training loss 0.003439\n",
      ">> Epoch 70 finished \tANN training loss 0.003428\n",
      ">> Epoch 71 finished \tANN training loss 0.003417\n",
      ">> Epoch 72 finished \tANN training loss 0.003406\n",
      ">> Epoch 73 finished \tANN training loss 0.003396\n",
      ">> Epoch 74 finished \tANN training loss 0.003385\n",
      ">> Epoch 75 finished \tANN training loss 0.003375\n",
      ">> Epoch 76 finished \tANN training loss 0.003365\n",
      ">> Epoch 77 finished \tANN training loss 0.003355\n",
      ">> Epoch 78 finished \tANN training loss 0.003346\n",
      ">> Epoch 79 finished \tANN training loss 0.003336\n",
      ">> Epoch 80 finished \tANN training loss 0.003327\n",
      ">> Epoch 81 finished \tANN training loss 0.003318\n",
      ">> Epoch 82 finished \tANN training loss 0.003309\n",
      ">> Epoch 83 finished \tANN training loss 0.003300\n",
      ">> Epoch 84 finished \tANN training loss 0.003292\n",
      ">> Epoch 85 finished \tANN training loss 0.003283\n",
      ">> Epoch 86 finished \tANN training loss 0.003275\n",
      ">> Epoch 87 finished \tANN training loss 0.003267\n",
      ">> Epoch 88 finished \tANN training loss 0.003259\n",
      ">> Epoch 89 finished \tANN training loss 0.003251\n",
      ">> Epoch 90 finished \tANN training loss 0.003243\n",
      ">> Epoch 91 finished \tANN training loss 0.003235\n",
      ">> Epoch 92 finished \tANN training loss 0.003227\n",
      ">> Epoch 93 finished \tANN training loss 0.003220\n",
      ">> Epoch 94 finished \tANN training loss 0.003213\n",
      ">> Epoch 95 finished \tANN training loss 0.003205\n",
      ">> Epoch 96 finished \tANN training loss 0.003198\n",
      ">> Epoch 97 finished \tANN training loss 0.003191\n",
      ">> Epoch 98 finished \tANN training loss 0.003184\n",
      ">> Epoch 99 finished \tANN training loss 0.003178\n",
      ">> Epoch 100 finished \tANN training loss 0.003171\n",
      ">> Epoch 101 finished \tANN training loss 0.003164\n",
      ">> Epoch 102 finished \tANN training loss 0.003158\n",
      ">> Epoch 103 finished \tANN training loss 0.003151\n",
      ">> Epoch 104 finished \tANN training loss 0.003145\n",
      ">> Epoch 105 finished \tANN training loss 0.003139\n",
      ">> Epoch 106 finished \tANN training loss 0.003133\n",
      ">> Epoch 107 finished \tANN training loss 0.003127\n",
      ">> Epoch 108 finished \tANN training loss 0.003121\n",
      ">> Epoch 109 finished \tANN training loss 0.003115\n",
      ">> Epoch 110 finished \tANN training loss 0.003109\n",
      ">> Epoch 111 finished \tANN training loss 0.003104\n",
      ">> Epoch 112 finished \tANN training loss 0.003098\n",
      ">> Epoch 113 finished \tANN training loss 0.003093\n",
      ">> Epoch 114 finished \tANN training loss 0.003087\n",
      ">> Epoch 115 finished \tANN training loss 0.003082\n",
      ">> Epoch 116 finished \tANN training loss 0.003077\n",
      ">> Epoch 117 finished \tANN training loss 0.003071\n",
      ">> Epoch 118 finished \tANN training loss 0.003066\n",
      ">> Epoch 119 finished \tANN training loss 0.003061\n",
      ">> Epoch 120 finished \tANN training loss 0.003056\n",
      ">> Epoch 121 finished \tANN training loss 0.003051\n",
      ">> Epoch 122 finished \tANN training loss 0.003046\n",
      ">> Epoch 123 finished \tANN training loss 0.003041\n",
      ">> Epoch 124 finished \tANN training loss 0.003037\n",
      ">> Epoch 125 finished \tANN training loss 0.003032\n",
      ">> Epoch 126 finished \tANN training loss 0.003027\n",
      ">> Epoch 127 finished \tANN training loss 0.003023\n",
      ">> Epoch 128 finished \tANN training loss 0.003018\n",
      ">> Epoch 129 finished \tANN training loss 0.003014\n",
      ">> Epoch 130 finished \tANN training loss 0.003009\n",
      ">> Epoch 131 finished \tANN training loss 0.003005\n",
      ">> Epoch 132 finished \tANN training loss 0.003001\n",
      ">> Epoch 133 finished \tANN training loss 0.002996\n",
      ">> Epoch 134 finished \tANN training loss 0.002992\n",
      ">> Epoch 135 finished \tANN training loss 0.002988\n",
      ">> Epoch 136 finished \tANN training loss 0.002984\n",
      ">> Epoch 137 finished \tANN training loss 0.002980\n",
      ">> Epoch 138 finished \tANN training loss 0.002976\n",
      ">> Epoch 139 finished \tANN training loss 0.002972\n",
      ">> Epoch 140 finished \tANN training loss 0.002968\n",
      ">> Epoch 141 finished \tANN training loss 0.002964\n",
      ">> Epoch 142 finished \tANN training loss 0.002960\n",
      ">> Epoch 143 finished \tANN training loss 0.002956\n",
      ">> Epoch 144 finished \tANN training loss 0.002952\n",
      ">> Epoch 145 finished \tANN training loss 0.002949\n",
      ">> Epoch 146 finished \tANN training loss 0.002945\n",
      ">> Epoch 147 finished \tANN training loss 0.002941\n",
      ">> Epoch 148 finished \tANN training loss 0.002937\n",
      ">> Epoch 149 finished \tANN training loss 0.002934\n",
      ">> Epoch 150 finished \tANN training loss 0.002930\n",
      "[END] Fine tuning step\n",
      "############### End Training for JINDALSTELEQ #####################\n",
      "############### End Training for TATACOMMEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 5.761958\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 5.612001\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 5.456430\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 5.294079\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 5.123346\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 4.942722\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 4.750471\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 4.544985\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 4.324855\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 4.088377\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 3.834938\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 3.564116\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 3.276687\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 2.974092\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 2.660979\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 2.343647\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 2.028530\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 1.725659\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 1.443080\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 1.187820\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 0.969772\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 0.789542\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 0.646169\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 0.534132\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 0.452381\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 0.394189\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 0.352883\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 0.324778\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 0.303936\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 0.289495\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 0.279653\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 0.271738\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.266087\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.261218\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.257335\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.254482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 37 finished \tRBM Reconstruction error 0.251579\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.249116\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.246984\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.244791\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.242944\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.241190\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.239347\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.237791\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.236171\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.234564\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.233052\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.231683\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.230276\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.228889\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.227475\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.226258\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.224974\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.223672\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.222360\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.221140\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.219887\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.218771\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.217685\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.216493\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.215341\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.214200\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.213170\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.211997\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.210851\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.209721\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.208607\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.207463\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.206435\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.205325\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.204350\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.203247\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.202285\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.201396\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.200392\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.199353\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.198382\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.197388\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.196392\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.195330\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.194262\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.193406\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.192390\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.191432\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.190449\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.189510\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.188615\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.187673\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.186833\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.185869\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.184976\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.184105\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.183250\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.182453\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.181578\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.180722\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.179809\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.179008\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.178127\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.177344\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.132427\n",
      ">> Epoch 2 finished \tANN training loss 0.101515\n",
      ">> Epoch 3 finished \tANN training loss 0.078656\n",
      ">> Epoch 4 finished \tANN training loss 0.061741\n",
      ">> Epoch 5 finished \tANN training loss 0.049205\n",
      ">> Epoch 6 finished \tANN training loss 0.039902\n",
      ">> Epoch 7 finished \tANN training loss 0.032993\n",
      ">> Epoch 8 finished \tANN training loss 0.027849\n",
      ">> Epoch 9 finished \tANN training loss 0.024011\n",
      ">> Epoch 10 finished \tANN training loss 0.021139\n",
      ">> Epoch 11 finished \tANN training loss 0.018983\n",
      ">> Epoch 12 finished \tANN training loss 0.017354\n",
      ">> Epoch 13 finished \tANN training loss 0.016117\n",
      ">> Epoch 14 finished \tANN training loss 0.015172\n",
      ">> Epoch 15 finished \tANN training loss 0.014442\n",
      ">> Epoch 16 finished \tANN training loss 0.013870\n",
      ">> Epoch 17 finished \tANN training loss 0.013415\n",
      ">> Epoch 18 finished \tANN training loss 0.013048\n",
      ">> Epoch 19 finished \tANN training loss 0.012746\n",
      ">> Epoch 20 finished \tANN training loss 0.012492\n",
      ">> Epoch 21 finished \tANN training loss 0.012273\n",
      ">> Epoch 22 finished \tANN training loss 0.012082\n",
      ">> Epoch 23 finished \tANN training loss 0.011912\n",
      ">> Epoch 24 finished \tANN training loss 0.011757\n",
      ">> Epoch 25 finished \tANN training loss 0.011613\n",
      ">> Epoch 26 finished \tANN training loss 0.011479\n",
      ">> Epoch 27 finished \tANN training loss 0.011352\n",
      ">> Epoch 28 finished \tANN training loss 0.011231\n",
      ">> Epoch 29 finished \tANN training loss 0.011114\n",
      ">> Epoch 30 finished \tANN training loss 0.011001\n",
      ">> Epoch 31 finished \tANN training loss 0.010891\n",
      ">> Epoch 32 finished \tANN training loss 0.010784\n",
      ">> Epoch 33 finished \tANN training loss 0.010680\n",
      ">> Epoch 34 finished \tANN training loss 0.010578\n",
      ">> Epoch 35 finished \tANN training loss 0.010478\n",
      ">> Epoch 36 finished \tANN training loss 0.010380\n",
      ">> Epoch 37 finished \tANN training loss 0.010284\n",
      ">> Epoch 38 finished \tANN training loss 0.010189\n",
      ">> Epoch 39 finished \tANN training loss 0.010096\n",
      ">> Epoch 40 finished \tANN training loss 0.010005\n",
      ">> Epoch 41 finished \tANN training loss 0.009915\n",
      ">> Epoch 42 finished \tANN training loss 0.009827\n",
      ">> Epoch 43 finished \tANN training loss 0.009740\n",
      ">> Epoch 44 finished \tANN training loss 0.009654\n",
      ">> Epoch 45 finished \tANN training loss 0.009570\n",
      ">> Epoch 46 finished \tANN training loss 0.009487\n",
      ">> Epoch 47 finished \tANN training loss 0.009405\n",
      ">> Epoch 48 finished \tANN training loss 0.009324\n",
      ">> Epoch 49 finished \tANN training loss 0.009244\n",
      ">> Epoch 50 finished \tANN training loss 0.009166\n",
      ">> Epoch 51 finished \tANN training loss 0.009088\n",
      ">> Epoch 52 finished \tANN training loss 0.009012\n",
      ">> Epoch 53 finished \tANN training loss 0.008936\n",
      ">> Epoch 54 finished \tANN training loss 0.008862\n",
      ">> Epoch 55 finished \tANN training loss 0.008788\n",
      ">> Epoch 56 finished \tANN training loss 0.008716\n",
      ">> Epoch 57 finished \tANN training loss 0.008644\n",
      ">> Epoch 58 finished \tANN training loss 0.008573\n",
      ">> Epoch 59 finished \tANN training loss 0.008503\n",
      ">> Epoch 60 finished \tANN training loss 0.008434\n",
      ">> Epoch 61 finished \tANN training loss 0.008366\n",
      ">> Epoch 62 finished \tANN training loss 0.008298\n",
      ">> Epoch 63 finished \tANN training loss 0.008232\n",
      ">> Epoch 64 finished \tANN training loss 0.008166\n",
      ">> Epoch 65 finished \tANN training loss 0.008101\n",
      ">> Epoch 66 finished \tANN training loss 0.008036\n",
      ">> Epoch 67 finished \tANN training loss 0.007973\n",
      ">> Epoch 68 finished \tANN training loss 0.007910\n",
      ">> Epoch 69 finished \tANN training loss 0.007848\n",
      ">> Epoch 70 finished \tANN training loss 0.007786\n",
      ">> Epoch 71 finished \tANN training loss 0.007726\n",
      ">> Epoch 72 finished \tANN training loss 0.007666\n",
      ">> Epoch 73 finished \tANN training loss 0.007606\n",
      ">> Epoch 74 finished \tANN training loss 0.007548\n",
      ">> Epoch 75 finished \tANN training loss 0.007490\n",
      ">> Epoch 76 finished \tANN training loss 0.007433\n",
      ">> Epoch 77 finished \tANN training loss 0.007376\n",
      ">> Epoch 78 finished \tANN training loss 0.007321\n",
      ">> Epoch 79 finished \tANN training loss 0.007266\n",
      ">> Epoch 80 finished \tANN training loss 0.007211\n",
      ">> Epoch 81 finished \tANN training loss 0.007157\n",
      ">> Epoch 82 finished \tANN training loss 0.007104\n",
      ">> Epoch 83 finished \tANN training loss 0.007052\n",
      ">> Epoch 84 finished \tANN training loss 0.007000\n",
      ">> Epoch 85 finished \tANN training loss 0.006949\n",
      ">> Epoch 86 finished \tANN training loss 0.006898\n",
      ">> Epoch 87 finished \tANN training loss 0.006848\n",
      ">> Epoch 88 finished \tANN training loss 0.006799\n",
      ">> Epoch 89 finished \tANN training loss 0.006750\n",
      ">> Epoch 90 finished \tANN training loss 0.006702\n",
      ">> Epoch 91 finished \tANN training loss 0.006654\n",
      ">> Epoch 92 finished \tANN training loss 0.006607\n",
      ">> Epoch 93 finished \tANN training loss 0.006561\n",
      ">> Epoch 94 finished \tANN training loss 0.006515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 95 finished \tANN training loss 0.006470\n",
      ">> Epoch 96 finished \tANN training loss 0.006426\n",
      ">> Epoch 97 finished \tANN training loss 0.006382\n",
      ">> Epoch 98 finished \tANN training loss 0.006339\n",
      ">> Epoch 99 finished \tANN training loss 0.006296\n",
      ">> Epoch 100 finished \tANN training loss 0.006253\n",
      ">> Epoch 101 finished \tANN training loss 0.006212\n",
      ">> Epoch 102 finished \tANN training loss 0.006170\n",
      ">> Epoch 103 finished \tANN training loss 0.006130\n",
      ">> Epoch 104 finished \tANN training loss 0.006089\n",
      ">> Epoch 105 finished \tANN training loss 0.006050\n",
      ">> Epoch 106 finished \tANN training loss 0.006010\n",
      ">> Epoch 107 finished \tANN training loss 0.005972\n",
      ">> Epoch 108 finished \tANN training loss 0.005933\n",
      ">> Epoch 109 finished \tANN training loss 0.005896\n",
      ">> Epoch 110 finished \tANN training loss 0.005858\n",
      ">> Epoch 111 finished \tANN training loss 0.005821\n",
      ">> Epoch 112 finished \tANN training loss 0.005785\n",
      ">> Epoch 113 finished \tANN training loss 0.005749\n",
      ">> Epoch 114 finished \tANN training loss 0.005713\n",
      ">> Epoch 115 finished \tANN training loss 0.005678\n",
      ">> Epoch 116 finished \tANN training loss 0.005643\n",
      ">> Epoch 117 finished \tANN training loss 0.005609\n",
      ">> Epoch 118 finished \tANN training loss 0.005575\n",
      ">> Epoch 119 finished \tANN training loss 0.005541\n",
      ">> Epoch 120 finished \tANN training loss 0.005508\n",
      ">> Epoch 121 finished \tANN training loss 0.005475\n",
      ">> Epoch 122 finished \tANN training loss 0.005443\n",
      ">> Epoch 123 finished \tANN training loss 0.005411\n",
      ">> Epoch 124 finished \tANN training loss 0.005379\n",
      ">> Epoch 125 finished \tANN training loss 0.005348\n",
      ">> Epoch 126 finished \tANN training loss 0.005317\n",
      ">> Epoch 127 finished \tANN training loss 0.005286\n",
      ">> Epoch 128 finished \tANN training loss 0.005256\n",
      ">> Epoch 129 finished \tANN training loss 0.005226\n",
      ">> Epoch 130 finished \tANN training loss 0.005197\n",
      ">> Epoch 131 finished \tANN training loss 0.005168\n",
      ">> Epoch 132 finished \tANN training loss 0.005139\n",
      ">> Epoch 133 finished \tANN training loss 0.005110\n",
      ">> Epoch 134 finished \tANN training loss 0.005082\n",
      ">> Epoch 135 finished \tANN training loss 0.005054\n",
      ">> Epoch 136 finished \tANN training loss 0.005026\n",
      ">> Epoch 137 finished \tANN training loss 0.004999\n",
      ">> Epoch 138 finished \tANN training loss 0.004972\n",
      ">> Epoch 139 finished \tANN training loss 0.004945\n",
      ">> Epoch 140 finished \tANN training loss 0.004919\n",
      ">> Epoch 141 finished \tANN training loss 0.004893\n",
      ">> Epoch 142 finished \tANN training loss 0.004867\n",
      ">> Epoch 143 finished \tANN training loss 0.004842\n",
      ">> Epoch 144 finished \tANN training loss 0.004816\n",
      ">> Epoch 145 finished \tANN training loss 0.004791\n",
      ">> Epoch 146 finished \tANN training loss 0.004767\n",
      ">> Epoch 147 finished \tANN training loss 0.004742\n",
      ">> Epoch 148 finished \tANN training loss 0.004718\n",
      ">> Epoch 149 finished \tANN training loss 0.004694\n",
      ">> Epoch 150 finished \tANN training loss 0.004671\n",
      "[END] Fine tuning step\n",
      "############### End Training for TATACOMMEQ #####################\n",
      "############### End Training for SIEMENSEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 4.393926\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 4.308974\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 4.221302\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 4.130436\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 4.035764\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 3.936667\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 3.832587\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 3.722754\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 3.606432\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 3.482939\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 3.351562\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 3.211719\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 3.062981\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 2.905348\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 2.738411\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 2.562722\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 2.379534\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 2.190528\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 1.997147\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 1.802650\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 1.610223\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 1.423169\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 1.245689\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 1.081265\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 0.932556\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 0.800251\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 0.686297\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 0.591572\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 0.514140\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 0.451957\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 0.402778\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 0.363972\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.332903\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.309541\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.291376\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.276511\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.264541\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.253867\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.245182\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.237600\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.230774\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.225064\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.219635\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.214659\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.210239\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.205619\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.201490\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.197496\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.193828\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.190123\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.186693\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.183094\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.179919\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.176493\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.173016\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.169951\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.166875\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.164131\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.161261\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.158462\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.155697\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.153021\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.150381\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.147846\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.145386\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.142977\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.140563\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.138171\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.135937\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.133675\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.131438\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.129353\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.127222\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.125115\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.123152\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.121100\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.119150\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.117302\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.115440\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.113606\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.111890\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.110172\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.108460\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.106727\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.105104\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.103546\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.101962\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.100418\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.098853\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.097356\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.095932\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.094495\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.093103\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.091705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 95 finished \tRBM Reconstruction error 0.090429\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.089118\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.087886\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.086644\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.085428\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.084219\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.102403\n",
      ">> Epoch 2 finished \tANN training loss 0.082174\n",
      ">> Epoch 3 finished \tANN training loss 0.066100\n",
      ">> Epoch 4 finished \tANN training loss 0.053330\n",
      ">> Epoch 5 finished \tANN training loss 0.043157\n",
      ">> Epoch 6 finished \tANN training loss 0.035047\n",
      ">> Epoch 7 finished \tANN training loss 0.028579\n",
      ">> Epoch 8 finished \tANN training loss 0.023407\n",
      ">> Epoch 9 finished \tANN training loss 0.019263\n",
      ">> Epoch 10 finished \tANN training loss 0.015937\n",
      ">> Epoch 11 finished \tANN training loss 0.013267\n",
      ">> Epoch 12 finished \tANN training loss 0.011120\n",
      ">> Epoch 13 finished \tANN training loss 0.009393\n",
      ">> Epoch 14 finished \tANN training loss 0.008005\n",
      ">> Epoch 15 finished \tANN training loss 0.006885\n",
      ">> Epoch 16 finished \tANN training loss 0.005983\n",
      ">> Epoch 17 finished \tANN training loss 0.005255\n",
      ">> Epoch 18 finished \tANN training loss 0.004667\n",
      ">> Epoch 19 finished \tANN training loss 0.004189\n",
      ">> Epoch 20 finished \tANN training loss 0.003802\n",
      ">> Epoch 21 finished \tANN training loss 0.003486\n",
      ">> Epoch 22 finished \tANN training loss 0.003228\n",
      ">> Epoch 23 finished \tANN training loss 0.003017\n",
      ">> Epoch 24 finished \tANN training loss 0.002843\n",
      ">> Epoch 25 finished \tANN training loss 0.002698\n",
      ">> Epoch 26 finished \tANN training loss 0.002578\n",
      ">> Epoch 27 finished \tANN training loss 0.002478\n",
      ">> Epoch 28 finished \tANN training loss 0.002392\n",
      ">> Epoch 29 finished \tANN training loss 0.002320\n",
      ">> Epoch 30 finished \tANN training loss 0.002257\n",
      ">> Epoch 31 finished \tANN training loss 0.002203\n",
      ">> Epoch 32 finished \tANN training loss 0.002156\n",
      ">> Epoch 33 finished \tANN training loss 0.002114\n",
      ">> Epoch 34 finished \tANN training loss 0.002076\n",
      ">> Epoch 35 finished \tANN training loss 0.002042\n",
      ">> Epoch 36 finished \tANN training loss 0.002011\n",
      ">> Epoch 37 finished \tANN training loss 0.001983\n",
      ">> Epoch 38 finished \tANN training loss 0.001957\n",
      ">> Epoch 39 finished \tANN training loss 0.001933\n",
      ">> Epoch 40 finished \tANN training loss 0.001910\n",
      ">> Epoch 41 finished \tANN training loss 0.001888\n",
      ">> Epoch 42 finished \tANN training loss 0.001867\n",
      ">> Epoch 43 finished \tANN training loss 0.001848\n",
      ">> Epoch 44 finished \tANN training loss 0.001829\n",
      ">> Epoch 45 finished \tANN training loss 0.001811\n",
      ">> Epoch 46 finished \tANN training loss 0.001794\n",
      ">> Epoch 47 finished \tANN training loss 0.001777\n",
      ">> Epoch 48 finished \tANN training loss 0.001761\n",
      ">> Epoch 49 finished \tANN training loss 0.001746\n",
      ">> Epoch 50 finished \tANN training loss 0.001731\n",
      ">> Epoch 51 finished \tANN training loss 0.001716\n",
      ">> Epoch 52 finished \tANN training loss 0.001702\n",
      ">> Epoch 53 finished \tANN training loss 0.001688\n",
      ">> Epoch 54 finished \tANN training loss 0.001674\n",
      ">> Epoch 55 finished \tANN training loss 0.001661\n",
      ">> Epoch 56 finished \tANN training loss 0.001649\n",
      ">> Epoch 57 finished \tANN training loss 0.001636\n",
      ">> Epoch 58 finished \tANN training loss 0.001624\n",
      ">> Epoch 59 finished \tANN training loss 0.001612\n",
      ">> Epoch 60 finished \tANN training loss 0.001601\n",
      ">> Epoch 61 finished \tANN training loss 0.001590\n",
      ">> Epoch 62 finished \tANN training loss 0.001579\n",
      ">> Epoch 63 finished \tANN training loss 0.001568\n",
      ">> Epoch 64 finished \tANN training loss 0.001558\n",
      ">> Epoch 65 finished \tANN training loss 0.001548\n",
      ">> Epoch 66 finished \tANN training loss 0.001538\n",
      ">> Epoch 67 finished \tANN training loss 0.001528\n",
      ">> Epoch 68 finished \tANN training loss 0.001519\n",
      ">> Epoch 69 finished \tANN training loss 0.001510\n",
      ">> Epoch 70 finished \tANN training loss 0.001501\n",
      ">> Epoch 71 finished \tANN training loss 0.001492\n",
      ">> Epoch 72 finished \tANN training loss 0.001484\n",
      ">> Epoch 73 finished \tANN training loss 0.001476\n",
      ">> Epoch 74 finished \tANN training loss 0.001468\n",
      ">> Epoch 75 finished \tANN training loss 0.001460\n",
      ">> Epoch 76 finished \tANN training loss 0.001452\n",
      ">> Epoch 77 finished \tANN training loss 0.001445\n",
      ">> Epoch 78 finished \tANN training loss 0.001438\n",
      ">> Epoch 79 finished \tANN training loss 0.001430\n",
      ">> Epoch 80 finished \tANN training loss 0.001424\n",
      ">> Epoch 81 finished \tANN training loss 0.001417\n",
      ">> Epoch 82 finished \tANN training loss 0.001410\n",
      ">> Epoch 83 finished \tANN training loss 0.001404\n",
      ">> Epoch 84 finished \tANN training loss 0.001397\n",
      ">> Epoch 85 finished \tANN training loss 0.001391\n",
      ">> Epoch 86 finished \tANN training loss 0.001385\n",
      ">> Epoch 87 finished \tANN training loss 0.001380\n",
      ">> Epoch 88 finished \tANN training loss 0.001374\n",
      ">> Epoch 89 finished \tANN training loss 0.001368\n",
      ">> Epoch 90 finished \tANN training loss 0.001363\n",
      ">> Epoch 91 finished \tANN training loss 0.001358\n",
      ">> Epoch 92 finished \tANN training loss 0.001352\n",
      ">> Epoch 93 finished \tANN training loss 0.001347\n",
      ">> Epoch 94 finished \tANN training loss 0.001343\n",
      ">> Epoch 95 finished \tANN training loss 0.001338\n",
      ">> Epoch 96 finished \tANN training loss 0.001333\n",
      ">> Epoch 97 finished \tANN training loss 0.001328\n",
      ">> Epoch 98 finished \tANN training loss 0.001324\n",
      ">> Epoch 99 finished \tANN training loss 0.001320\n",
      ">> Epoch 100 finished \tANN training loss 0.001315\n",
      ">> Epoch 101 finished \tANN training loss 0.001311\n",
      ">> Epoch 102 finished \tANN training loss 0.001307\n",
      ">> Epoch 103 finished \tANN training loss 0.001303\n",
      ">> Epoch 104 finished \tANN training loss 0.001299\n",
      ">> Epoch 105 finished \tANN training loss 0.001295\n",
      ">> Epoch 106 finished \tANN training loss 0.001292\n",
      ">> Epoch 107 finished \tANN training loss 0.001288\n",
      ">> Epoch 108 finished \tANN training loss 0.001285\n",
      ">> Epoch 109 finished \tANN training loss 0.001281\n",
      ">> Epoch 110 finished \tANN training loss 0.001278\n",
      ">> Epoch 111 finished \tANN training loss 0.001274\n",
      ">> Epoch 112 finished \tANN training loss 0.001271\n",
      ">> Epoch 113 finished \tANN training loss 0.001268\n",
      ">> Epoch 114 finished \tANN training loss 0.001265\n",
      ">> Epoch 115 finished \tANN training loss 0.001262\n",
      ">> Epoch 116 finished \tANN training loss 0.001259\n",
      ">> Epoch 117 finished \tANN training loss 0.001256\n",
      ">> Epoch 118 finished \tANN training loss 0.001253\n",
      ">> Epoch 119 finished \tANN training loss 0.001251\n",
      ">> Epoch 120 finished \tANN training loss 0.001248\n",
      ">> Epoch 121 finished \tANN training loss 0.001245\n",
      ">> Epoch 122 finished \tANN training loss 0.001243\n",
      ">> Epoch 123 finished \tANN training loss 0.001240\n",
      ">> Epoch 124 finished \tANN training loss 0.001238\n",
      ">> Epoch 125 finished \tANN training loss 0.001235\n",
      ">> Epoch 126 finished \tANN training loss 0.001233\n",
      ">> Epoch 127 finished \tANN training loss 0.001231\n",
      ">> Epoch 128 finished \tANN training loss 0.001229\n",
      ">> Epoch 129 finished \tANN training loss 0.001226\n",
      ">> Epoch 130 finished \tANN training loss 0.001224\n",
      ">> Epoch 131 finished \tANN training loss 0.001222\n",
      ">> Epoch 132 finished \tANN training loss 0.001220\n",
      ">> Epoch 133 finished \tANN training loss 0.001218\n",
      ">> Epoch 134 finished \tANN training loss 0.001216\n",
      ">> Epoch 135 finished \tANN training loss 0.001214\n",
      ">> Epoch 136 finished \tANN training loss 0.001212\n",
      ">> Epoch 137 finished \tANN training loss 0.001210\n",
      ">> Epoch 138 finished \tANN training loss 0.001209\n",
      ">> Epoch 139 finished \tANN training loss 0.001207\n",
      ">> Epoch 140 finished \tANN training loss 0.001205\n",
      ">> Epoch 141 finished \tANN training loss 0.001203\n",
      ">> Epoch 142 finished \tANN training loss 0.001202\n",
      ">> Epoch 143 finished \tANN training loss 0.001200\n",
      ">> Epoch 144 finished \tANN training loss 0.001199\n",
      ">> Epoch 145 finished \tANN training loss 0.001197\n",
      ">> Epoch 146 finished \tANN training loss 0.001195\n",
      ">> Epoch 147 finished \tANN training loss 0.001194\n",
      ">> Epoch 148 finished \tANN training loss 0.001192\n",
      ">> Epoch 149 finished \tANN training loss 0.001191\n",
      ">> Epoch 150 finished \tANN training loss 0.001190\n",
      "[END] Fine tuning step\n",
      "############### End Training for SIEMENSEQ #####################\n",
      "############### End Training for HDFCBANKEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 0.717339\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 0.708887\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 0.700620\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 0.692547\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 0.684638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 6 finished \tRBM Reconstruction error 0.676914\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 0.669348\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 0.661960\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 0.654720\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 0.647646\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 0.640722\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 0.633958\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 0.627345\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 0.620863\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 0.614516\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 0.608314\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 0.602244\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 0.596296\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 0.590481\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 0.584781\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 0.579204\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 0.573746\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 0.568389\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 0.563147\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 0.558001\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 0.552954\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 0.547996\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 0.543146\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 0.538402\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 0.533746\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 0.529158\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 0.524661\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.520247\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.515909\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.511653\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.507466\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.503347\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.499304\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.495330\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.491423\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.487575\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.483788\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.480050\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.476376\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.472758\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.469208\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.465699\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.462247\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.458839\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.455480\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.452164\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.448892\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.445674\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.442501\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.439360\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.436272\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.433213\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.430188\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.427226\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.424264\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.421344\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.418461\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.415599\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.412784\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.409977\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.407220\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.404481\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.401749\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.399067\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.396420\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.393810\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.391207\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.388620\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.386062\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.383537\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.381006\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.378482\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.375995\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.373535\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.371097\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.368687\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.366288\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.363900\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.361526\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.359180\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.356850\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.354521\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.352244\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.349973\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.347728\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.345487\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.343244\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.341014\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.338810\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.336626\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.334420\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.332260\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.330100\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.327975\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.325809\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.020319\n",
      ">> Epoch 2 finished \tANN training loss 0.018915\n",
      ">> Epoch 3 finished \tANN training loss 0.017612\n",
      ">> Epoch 4 finished \tANN training loss 0.016402\n",
      ">> Epoch 5 finished \tANN training loss 0.015280\n",
      ">> Epoch 6 finished \tANN training loss 0.014239\n",
      ">> Epoch 7 finished \tANN training loss 0.013273\n",
      ">> Epoch 8 finished \tANN training loss 0.012378\n",
      ">> Epoch 9 finished \tANN training loss 0.011547\n",
      ">> Epoch 10 finished \tANN training loss 0.010777\n",
      ">> Epoch 11 finished \tANN training loss 0.010063\n",
      ">> Epoch 12 finished \tANN training loss 0.009400\n",
      ">> Epoch 13 finished \tANN training loss 0.008786\n",
      ">> Epoch 14 finished \tANN training loss 0.008217\n",
      ">> Epoch 15 finished \tANN training loss 0.007689\n",
      ">> Epoch 16 finished \tANN training loss 0.007199\n",
      ">> Epoch 17 finished \tANN training loss 0.006745\n",
      ">> Epoch 18 finished \tANN training loss 0.006323\n",
      ">> Epoch 19 finished \tANN training loss 0.005932\n",
      ">> Epoch 20 finished \tANN training loss 0.005569\n",
      ">> Epoch 21 finished \tANN training loss 0.005232\n",
      ">> Epoch 22 finished \tANN training loss 0.004919\n",
      ">> Epoch 23 finished \tANN training loss 0.004629\n",
      ">> Epoch 24 finished \tANN training loss 0.004359\n",
      ">> Epoch 25 finished \tANN training loss 0.004108\n",
      ">> Epoch 26 finished \tANN training loss 0.003875\n",
      ">> Epoch 27 finished \tANN training loss 0.003659\n",
      ">> Epoch 28 finished \tANN training loss 0.003458\n",
      ">> Epoch 29 finished \tANN training loss 0.003271\n",
      ">> Epoch 30 finished \tANN training loss 0.003097\n",
      ">> Epoch 31 finished \tANN training loss 0.002935\n",
      ">> Epoch 32 finished \tANN training loss 0.002784\n",
      ">> Epoch 33 finished \tANN training loss 0.002644\n",
      ">> Epoch 34 finished \tANN training loss 0.002514\n",
      ">> Epoch 35 finished \tANN training loss 0.002392\n",
      ">> Epoch 36 finished \tANN training loss 0.002279\n",
      ">> Epoch 37 finished \tANN training loss 0.002173\n",
      ">> Epoch 38 finished \tANN training loss 0.002074\n",
      ">> Epoch 39 finished \tANN training loss 0.001982\n",
      ">> Epoch 40 finished \tANN training loss 0.001896\n",
      ">> Epoch 41 finished \tANN training loss 0.001816\n",
      ">> Epoch 42 finished \tANN training loss 0.001741\n",
      ">> Epoch 43 finished \tANN training loss 0.001671\n",
      ">> Epoch 44 finished \tANN training loss 0.001605\n",
      ">> Epoch 45 finished \tANN training loss 0.001544\n",
      ">> Epoch 46 finished \tANN training loss 0.001486\n",
      ">> Epoch 47 finished \tANN training loss 0.001432\n",
      ">> Epoch 48 finished \tANN training loss 0.001381\n",
      ">> Epoch 49 finished \tANN training loss 0.001334\n",
      ">> Epoch 50 finished \tANN training loss 0.001289\n",
      ">> Epoch 51 finished \tANN training loss 0.001247\n",
      ">> Epoch 52 finished \tANN training loss 0.001208\n",
      ">> Epoch 53 finished \tANN training loss 0.001170\n",
      ">> Epoch 54 finished \tANN training loss 0.001135\n",
      ">> Epoch 55 finished \tANN training loss 0.001102\n",
      ">> Epoch 56 finished \tANN training loss 0.001071\n",
      ">> Epoch 57 finished \tANN training loss 0.001042\n",
      ">> Epoch 58 finished \tANN training loss 0.001014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 59 finished \tANN training loss 0.000987\n",
      ">> Epoch 60 finished \tANN training loss 0.000962\n",
      ">> Epoch 61 finished \tANN training loss 0.000938\n",
      ">> Epoch 62 finished \tANN training loss 0.000916\n",
      ">> Epoch 63 finished \tANN training loss 0.000894\n",
      ">> Epoch 64 finished \tANN training loss 0.000874\n",
      ">> Epoch 65 finished \tANN training loss 0.000854\n",
      ">> Epoch 66 finished \tANN training loss 0.000836\n",
      ">> Epoch 67 finished \tANN training loss 0.000818\n",
      ">> Epoch 68 finished \tANN training loss 0.000801\n",
      ">> Epoch 69 finished \tANN training loss 0.000785\n",
      ">> Epoch 70 finished \tANN training loss 0.000769\n",
      ">> Epoch 71 finished \tANN training loss 0.000755\n",
      ">> Epoch 72 finished \tANN training loss 0.000740\n",
      ">> Epoch 73 finished \tANN training loss 0.000727\n",
      ">> Epoch 74 finished \tANN training loss 0.000713\n",
      ">> Epoch 75 finished \tANN training loss 0.000701\n",
      ">> Epoch 76 finished \tANN training loss 0.000689\n",
      ">> Epoch 77 finished \tANN training loss 0.000677\n",
      ">> Epoch 78 finished \tANN training loss 0.000665\n",
      ">> Epoch 79 finished \tANN training loss 0.000654\n",
      ">> Epoch 80 finished \tANN training loss 0.000644\n",
      ">> Epoch 81 finished \tANN training loss 0.000634\n",
      ">> Epoch 82 finished \tANN training loss 0.000624\n",
      ">> Epoch 83 finished \tANN training loss 0.000614\n",
      ">> Epoch 84 finished \tANN training loss 0.000605\n",
      ">> Epoch 85 finished \tANN training loss 0.000595\n",
      ">> Epoch 86 finished \tANN training loss 0.000587\n",
      ">> Epoch 87 finished \tANN training loss 0.000578\n",
      ">> Epoch 88 finished \tANN training loss 0.000570\n",
      ">> Epoch 89 finished \tANN training loss 0.000562\n",
      ">> Epoch 90 finished \tANN training loss 0.000554\n",
      ">> Epoch 91 finished \tANN training loss 0.000546\n",
      ">> Epoch 92 finished \tANN training loss 0.000538\n",
      ">> Epoch 93 finished \tANN training loss 0.000531\n",
      ">> Epoch 94 finished \tANN training loss 0.000524\n",
      ">> Epoch 95 finished \tANN training loss 0.000517\n",
      ">> Epoch 96 finished \tANN training loss 0.000510\n",
      ">> Epoch 97 finished \tANN training loss 0.000503\n",
      ">> Epoch 98 finished \tANN training loss 0.000497\n",
      ">> Epoch 99 finished \tANN training loss 0.000490\n",
      ">> Epoch 100 finished \tANN training loss 0.000484\n",
      ">> Epoch 101 finished \tANN training loss 0.000478\n",
      ">> Epoch 102 finished \tANN training loss 0.000472\n",
      ">> Epoch 103 finished \tANN training loss 0.000466\n",
      ">> Epoch 104 finished \tANN training loss 0.000460\n",
      ">> Epoch 105 finished \tANN training loss 0.000454\n",
      ">> Epoch 106 finished \tANN training loss 0.000449\n",
      ">> Epoch 107 finished \tANN training loss 0.000443\n",
      ">> Epoch 108 finished \tANN training loss 0.000438\n",
      ">> Epoch 109 finished \tANN training loss 0.000432\n",
      ">> Epoch 110 finished \tANN training loss 0.000427\n",
      ">> Epoch 111 finished \tANN training loss 0.000422\n",
      ">> Epoch 112 finished \tANN training loss 0.000417\n",
      ">> Epoch 113 finished \tANN training loss 0.000412\n",
      ">> Epoch 114 finished \tANN training loss 0.000407\n",
      ">> Epoch 115 finished \tANN training loss 0.000402\n",
      ">> Epoch 116 finished \tANN training loss 0.000398\n",
      ">> Epoch 117 finished \tANN training loss 0.000393\n",
      ">> Epoch 118 finished \tANN training loss 0.000389\n",
      ">> Epoch 119 finished \tANN training loss 0.000384\n",
      ">> Epoch 120 finished \tANN training loss 0.000380\n",
      ">> Epoch 121 finished \tANN training loss 0.000375\n",
      ">> Epoch 122 finished \tANN training loss 0.000371\n",
      ">> Epoch 123 finished \tANN training loss 0.000367\n",
      ">> Epoch 124 finished \tANN training loss 0.000363\n",
      ">> Epoch 125 finished \tANN training loss 0.000359\n",
      ">> Epoch 126 finished \tANN training loss 0.000355\n",
      ">> Epoch 127 finished \tANN training loss 0.000351\n",
      ">> Epoch 128 finished \tANN training loss 0.000347\n",
      ">> Epoch 129 finished \tANN training loss 0.000343\n",
      ">> Epoch 130 finished \tANN training loss 0.000339\n",
      ">> Epoch 131 finished \tANN training loss 0.000336\n",
      ">> Epoch 132 finished \tANN training loss 0.000332\n",
      ">> Epoch 133 finished \tANN training loss 0.000328\n",
      ">> Epoch 134 finished \tANN training loss 0.000325\n",
      ">> Epoch 135 finished \tANN training loss 0.000321\n",
      ">> Epoch 136 finished \tANN training loss 0.000318\n",
      ">> Epoch 137 finished \tANN training loss 0.000314\n",
      ">> Epoch 138 finished \tANN training loss 0.000311\n",
      ">> Epoch 139 finished \tANN training loss 0.000308\n",
      ">> Epoch 140 finished \tANN training loss 0.000305\n",
      ">> Epoch 141 finished \tANN training loss 0.000301\n",
      ">> Epoch 142 finished \tANN training loss 0.000298\n",
      ">> Epoch 143 finished \tANN training loss 0.000295\n",
      ">> Epoch 144 finished \tANN training loss 0.000292\n",
      ">> Epoch 145 finished \tANN training loss 0.000289\n",
      ">> Epoch 146 finished \tANN training loss 0.000286\n",
      ">> Epoch 147 finished \tANN training loss 0.000283\n",
      ">> Epoch 148 finished \tANN training loss 0.000280\n",
      ">> Epoch 149 finished \tANN training loss 0.000277\n",
      ">> Epoch 150 finished \tANN training loss 0.000274\n",
      "[END] Fine tuning step\n",
      "############### End Training for HDFCBANKEQ #####################\n",
      "############### End Training for RECLTDEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 11.726224\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 11.510341\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 11.280737\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 11.034768\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 10.769518\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 10.481977\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 10.168218\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 9.824542\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 9.446560\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 9.030206\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 8.572095\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 8.068438\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 7.518659\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 6.921547\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 6.281430\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 5.605219\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 4.908312\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 4.204913\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 3.516821\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 2.867094\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 2.279052\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 1.770422\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 1.351426\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 1.021990\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 0.771338\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 0.588519\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 0.466116\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 0.381399\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 0.325941\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 0.289885\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 0.266227\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 0.250104\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.239297\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.231398\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.225659\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.221104\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.217483\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.214602\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.212162\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.210090\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.208356\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.206634\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.205383\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.204274\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.203523\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.202698\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.201754\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.201112\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.200323\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.199523\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.199307\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.198882\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.198902\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.198414\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.197869\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.197675\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.197439\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.197174\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.196721\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.196726\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.196380\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.196041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 63 finished \tRBM Reconstruction error 0.195919\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.195623\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.195506\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.195434\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.195282\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.195106\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.194915\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.194471\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.194576\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.193963\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.193936\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.193816\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.193726\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.193566\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.192915\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.192913\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.192639\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.192644\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.192391\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.192232\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.191883\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.191752\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.191709\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.191294\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.191286\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.191223\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.191192\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.190847\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.190537\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.190544\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.190436\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.190233\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.190337\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.189980\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.189372\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.189432\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.189201\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.189619\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.096388\n",
      ">> Epoch 2 finished \tANN training loss 0.074742\n",
      ">> Epoch 3 finished \tANN training loss 0.058289\n",
      ">> Epoch 4 finished \tANN training loss 0.045778\n",
      ">> Epoch 5 finished \tANN training loss 0.036268\n",
      ">> Epoch 6 finished \tANN training loss 0.029037\n",
      ">> Epoch 7 finished \tANN training loss 0.023538\n",
      ">> Epoch 8 finished \tANN training loss 0.019356\n",
      ">> Epoch 9 finished \tANN training loss 0.016177\n",
      ">> Epoch 10 finished \tANN training loss 0.013758\n",
      ">> Epoch 11 finished \tANN training loss 0.011918\n",
      ">> Epoch 12 finished \tANN training loss 0.010519\n",
      ">> Epoch 13 finished \tANN training loss 0.009456\n",
      ">> Epoch 14 finished \tANN training loss 0.008648\n",
      ">> Epoch 15 finished \tANN training loss 0.008032\n",
      ">> Epoch 16 finished \tANN training loss 0.007564\n",
      ">> Epoch 17 finished \tANN training loss 0.007209\n",
      ">> Epoch 18 finished \tANN training loss 0.006937\n",
      ">> Epoch 19 finished \tANN training loss 0.006730\n",
      ">> Epoch 20 finished \tANN training loss 0.006572\n",
      ">> Epoch 21 finished \tANN training loss 0.006450\n",
      ">> Epoch 22 finished \tANN training loss 0.006357\n",
      ">> Epoch 23 finished \tANN training loss 0.006284\n",
      ">> Epoch 24 finished \tANN training loss 0.006228\n",
      ">> Epoch 25 finished \tANN training loss 0.006185\n",
      ">> Epoch 26 finished \tANN training loss 0.006150\n",
      ">> Epoch 27 finished \tANN training loss 0.006123\n",
      ">> Epoch 28 finished \tANN training loss 0.006101\n",
      ">> Epoch 29 finished \tANN training loss 0.006084\n",
      ">> Epoch 30 finished \tANN training loss 0.006069\n",
      ">> Epoch 31 finished \tANN training loss 0.006057\n",
      ">> Epoch 32 finished \tANN training loss 0.006047\n",
      ">> Epoch 33 finished \tANN training loss 0.006038\n",
      ">> Epoch 34 finished \tANN training loss 0.006030\n",
      ">> Epoch 35 finished \tANN training loss 0.006023\n",
      ">> Epoch 36 finished \tANN training loss 0.006017\n",
      ">> Epoch 37 finished \tANN training loss 0.006011\n",
      ">> Epoch 38 finished \tANN training loss 0.006005\n",
      ">> Epoch 39 finished \tANN training loss 0.006000\n",
      ">> Epoch 40 finished \tANN training loss 0.005995\n",
      ">> Epoch 41 finished \tANN training loss 0.005990\n",
      ">> Epoch 42 finished \tANN training loss 0.005985\n",
      ">> Epoch 43 finished \tANN training loss 0.005980\n",
      ">> Epoch 44 finished \tANN training loss 0.005975\n",
      ">> Epoch 45 finished \tANN training loss 0.005971\n",
      ">> Epoch 46 finished \tANN training loss 0.005966\n",
      ">> Epoch 47 finished \tANN training loss 0.005961\n",
      ">> Epoch 48 finished \tANN training loss 0.005957\n",
      ">> Epoch 49 finished \tANN training loss 0.005952\n",
      ">> Epoch 50 finished \tANN training loss 0.005948\n",
      ">> Epoch 51 finished \tANN training loss 0.005943\n",
      ">> Epoch 52 finished \tANN training loss 0.005939\n",
      ">> Epoch 53 finished \tANN training loss 0.005935\n",
      ">> Epoch 54 finished \tANN training loss 0.005930\n",
      ">> Epoch 55 finished \tANN training loss 0.005926\n",
      ">> Epoch 56 finished \tANN training loss 0.005922\n",
      ">> Epoch 57 finished \tANN training loss 0.005917\n",
      ">> Epoch 58 finished \tANN training loss 0.005913\n",
      ">> Epoch 59 finished \tANN training loss 0.005909\n",
      ">> Epoch 60 finished \tANN training loss 0.005904\n",
      ">> Epoch 61 finished \tANN training loss 0.005900\n",
      ">> Epoch 62 finished \tANN training loss 0.005896\n",
      ">> Epoch 63 finished \tANN training loss 0.005892\n",
      ">> Epoch 64 finished \tANN training loss 0.005887\n",
      ">> Epoch 65 finished \tANN training loss 0.005883\n",
      ">> Epoch 66 finished \tANN training loss 0.005879\n",
      ">> Epoch 67 finished \tANN training loss 0.005875\n",
      ">> Epoch 68 finished \tANN training loss 0.005870\n",
      ">> Epoch 69 finished \tANN training loss 0.005866\n",
      ">> Epoch 70 finished \tANN training loss 0.005862\n",
      ">> Epoch 71 finished \tANN training loss 0.005858\n",
      ">> Epoch 72 finished \tANN training loss 0.005853\n",
      ">> Epoch 73 finished \tANN training loss 0.005849\n",
      ">> Epoch 74 finished \tANN training loss 0.005845\n",
      ">> Epoch 75 finished \tANN training loss 0.005841\n",
      ">> Epoch 76 finished \tANN training loss 0.005837\n",
      ">> Epoch 77 finished \tANN training loss 0.005833\n",
      ">> Epoch 78 finished \tANN training loss 0.005829\n",
      ">> Epoch 79 finished \tANN training loss 0.005825\n",
      ">> Epoch 80 finished \tANN training loss 0.005820\n",
      ">> Epoch 81 finished \tANN training loss 0.005816\n",
      ">> Epoch 82 finished \tANN training loss 0.005812\n",
      ">> Epoch 83 finished \tANN training loss 0.005808\n",
      ">> Epoch 84 finished \tANN training loss 0.005804\n",
      ">> Epoch 85 finished \tANN training loss 0.005800\n",
      ">> Epoch 86 finished \tANN training loss 0.005796\n",
      ">> Epoch 87 finished \tANN training loss 0.005792\n",
      ">> Epoch 88 finished \tANN training loss 0.005788\n",
      ">> Epoch 89 finished \tANN training loss 0.005784\n",
      ">> Epoch 90 finished \tANN training loss 0.005780\n",
      ">> Epoch 91 finished \tANN training loss 0.005776\n",
      ">> Epoch 92 finished \tANN training loss 0.005772\n",
      ">> Epoch 93 finished \tANN training loss 0.005768\n",
      ">> Epoch 94 finished \tANN training loss 0.005764\n",
      ">> Epoch 95 finished \tANN training loss 0.005760\n",
      ">> Epoch 96 finished \tANN training loss 0.005756\n",
      ">> Epoch 97 finished \tANN training loss 0.005752\n",
      ">> Epoch 98 finished \tANN training loss 0.005748\n",
      ">> Epoch 99 finished \tANN training loss 0.005744\n",
      ">> Epoch 100 finished \tANN training loss 0.005740\n",
      ">> Epoch 101 finished \tANN training loss 0.005736\n",
      ">> Epoch 102 finished \tANN training loss 0.005732\n",
      ">> Epoch 103 finished \tANN training loss 0.005728\n",
      ">> Epoch 104 finished \tANN training loss 0.005724\n",
      ">> Epoch 105 finished \tANN training loss 0.005720\n",
      ">> Epoch 106 finished \tANN training loss 0.005716\n",
      ">> Epoch 107 finished \tANN training loss 0.005712\n",
      ">> Epoch 108 finished \tANN training loss 0.005708\n",
      ">> Epoch 109 finished \tANN training loss 0.005704\n",
      ">> Epoch 110 finished \tANN training loss 0.005700\n",
      ">> Epoch 111 finished \tANN training loss 0.005697\n",
      ">> Epoch 112 finished \tANN training loss 0.005693\n",
      ">> Epoch 113 finished \tANN training loss 0.005689\n",
      ">> Epoch 114 finished \tANN training loss 0.005685\n",
      ">> Epoch 115 finished \tANN training loss 0.005681\n",
      ">> Epoch 116 finished \tANN training loss 0.005677\n",
      ">> Epoch 117 finished \tANN training loss 0.005673\n",
      ">> Epoch 118 finished \tANN training loss 0.005670\n",
      ">> Epoch 119 finished \tANN training loss 0.005666\n",
      ">> Epoch 120 finished \tANN training loss 0.005662\n",
      ">> Epoch 121 finished \tANN training loss 0.005658\n",
      ">> Epoch 122 finished \tANN training loss 0.005654\n",
      ">> Epoch 123 finished \tANN training loss 0.005650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 124 finished \tANN training loss 0.005647\n",
      ">> Epoch 125 finished \tANN training loss 0.005643\n",
      ">> Epoch 126 finished \tANN training loss 0.005639\n",
      ">> Epoch 127 finished \tANN training loss 0.005635\n",
      ">> Epoch 128 finished \tANN training loss 0.005631\n",
      ">> Epoch 129 finished \tANN training loss 0.005628\n",
      ">> Epoch 130 finished \tANN training loss 0.005624\n",
      ">> Epoch 131 finished \tANN training loss 0.005620\n",
      ">> Epoch 132 finished \tANN training loss 0.005616\n",
      ">> Epoch 133 finished \tANN training loss 0.005613\n",
      ">> Epoch 134 finished \tANN training loss 0.005609\n",
      ">> Epoch 135 finished \tANN training loss 0.005605\n",
      ">> Epoch 136 finished \tANN training loss 0.005601\n",
      ">> Epoch 137 finished \tANN training loss 0.005598\n",
      ">> Epoch 138 finished \tANN training loss 0.005594\n",
      ">> Epoch 139 finished \tANN training loss 0.005590\n",
      ">> Epoch 140 finished \tANN training loss 0.005587\n",
      ">> Epoch 141 finished \tANN training loss 0.005583\n",
      ">> Epoch 142 finished \tANN training loss 0.005579\n",
      ">> Epoch 143 finished \tANN training loss 0.005576\n",
      ">> Epoch 144 finished \tANN training loss 0.005572\n",
      ">> Epoch 145 finished \tANN training loss 0.005568\n",
      ">> Epoch 146 finished \tANN training loss 0.005564\n",
      ">> Epoch 147 finished \tANN training loss 0.005561\n",
      ">> Epoch 148 finished \tANN training loss 0.005557\n",
      ">> Epoch 149 finished \tANN training loss 0.005553\n",
      ">> Epoch 150 finished \tANN training loss 0.005550\n",
      "[END] Fine tuning step\n",
      "############### End Training for RECLTDEQ #####################\n",
      "############### End Training for EXIDEINDEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 3.027794\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 2.979279\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 2.930192\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 2.880461\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 2.829972\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 2.778545\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 2.726064\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 2.672324\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 2.617224\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 2.560656\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 2.502319\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 2.442205\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 2.380059\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 2.315832\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 2.249311\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 2.180465\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 2.109300\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 2.035784\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 1.959692\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 1.881403\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 1.800994\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 1.718255\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 1.633858\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 1.548179\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 1.461164\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 1.373751\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 1.286673\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 1.200409\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 1.115498\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 1.033165\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 0.953329\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 0.877101\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.805121\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.737706\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.675382\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.618262\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.565992\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.519838\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.477864\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.440951\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.408755\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.380299\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.355369\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.333981\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.315682\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.299966\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.285804\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.273168\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.262770\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.253044\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.244246\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.236414\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.229464\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.222615\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.216925\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.211399\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.206237\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.201323\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.196570\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.192144\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.187716\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.183713\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.179653\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.175824\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.172322\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.168850\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.165388\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.161986\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.158617\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.155446\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.152108\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.149171\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.146240\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.143221\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.140423\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.137691\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.134963\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.132286\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.129661\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.127090\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.124579\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.122204\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.119742\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.117443\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.115247\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.112925\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.110638\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.108531\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.106453\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.104237\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.102362\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.100525\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.098515\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.096591\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.094620\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.092933\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.091209\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.089479\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.087888\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.086263\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.003833\n",
      ">> Epoch 2 finished \tANN training loss 0.003707\n",
      ">> Epoch 3 finished \tANN training loss 0.003590\n",
      ">> Epoch 4 finished \tANN training loss 0.003479\n",
      ">> Epoch 5 finished \tANN training loss 0.003376\n",
      ">> Epoch 6 finished \tANN training loss 0.003278\n",
      ">> Epoch 7 finished \tANN training loss 0.003185\n",
      ">> Epoch 8 finished \tANN training loss 0.003097\n",
      ">> Epoch 9 finished \tANN training loss 0.003014\n",
      ">> Epoch 10 finished \tANN training loss 0.002934\n",
      ">> Epoch 11 finished \tANN training loss 0.002858\n",
      ">> Epoch 12 finished \tANN training loss 0.002785\n",
      ">> Epoch 13 finished \tANN training loss 0.002715\n",
      ">> Epoch 14 finished \tANN training loss 0.002648\n",
      ">> Epoch 15 finished \tANN training loss 0.002583\n",
      ">> Epoch 16 finished \tANN training loss 0.002521\n",
      ">> Epoch 17 finished \tANN training loss 0.002460\n",
      ">> Epoch 18 finished \tANN training loss 0.002402\n",
      ">> Epoch 19 finished \tANN training loss 0.002346\n",
      ">> Epoch 20 finished \tANN training loss 0.002292\n",
      ">> Epoch 21 finished \tANN training loss 0.002240\n",
      ">> Epoch 22 finished \tANN training loss 0.002189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 23 finished \tANN training loss 0.002140\n",
      ">> Epoch 24 finished \tANN training loss 0.002093\n",
      ">> Epoch 25 finished \tANN training loss 0.002047\n",
      ">> Epoch 26 finished \tANN training loss 0.002002\n",
      ">> Epoch 27 finished \tANN training loss 0.001959\n",
      ">> Epoch 28 finished \tANN training loss 0.001916\n",
      ">> Epoch 29 finished \tANN training loss 0.001876\n",
      ">> Epoch 30 finished \tANN training loss 0.001836\n",
      ">> Epoch 31 finished \tANN training loss 0.001798\n",
      ">> Epoch 32 finished \tANN training loss 0.001760\n",
      ">> Epoch 33 finished \tANN training loss 0.001724\n",
      ">> Epoch 34 finished \tANN training loss 0.001689\n",
      ">> Epoch 35 finished \tANN training loss 0.001655\n",
      ">> Epoch 36 finished \tANN training loss 0.001621\n",
      ">> Epoch 37 finished \tANN training loss 0.001589\n",
      ">> Epoch 38 finished \tANN training loss 0.001558\n",
      ">> Epoch 39 finished \tANN training loss 0.001527\n",
      ">> Epoch 40 finished \tANN training loss 0.001498\n",
      ">> Epoch 41 finished \tANN training loss 0.001469\n",
      ">> Epoch 42 finished \tANN training loss 0.001441\n",
      ">> Epoch 43 finished \tANN training loss 0.001414\n",
      ">> Epoch 44 finished \tANN training loss 0.001387\n",
      ">> Epoch 45 finished \tANN training loss 0.001362\n",
      ">> Epoch 46 finished \tANN training loss 0.001337\n",
      ">> Epoch 47 finished \tANN training loss 0.001312\n",
      ">> Epoch 48 finished \tANN training loss 0.001289\n",
      ">> Epoch 49 finished \tANN training loss 0.001266\n",
      ">> Epoch 50 finished \tANN training loss 0.001244\n",
      ">> Epoch 51 finished \tANN training loss 0.001222\n",
      ">> Epoch 52 finished \tANN training loss 0.001201\n",
      ">> Epoch 53 finished \tANN training loss 0.001180\n",
      ">> Epoch 54 finished \tANN training loss 0.001161\n",
      ">> Epoch 55 finished \tANN training loss 0.001141\n",
      ">> Epoch 56 finished \tANN training loss 0.001122\n",
      ">> Epoch 57 finished \tANN training loss 0.001104\n",
      ">> Epoch 58 finished \tANN training loss 0.001086\n",
      ">> Epoch 59 finished \tANN training loss 0.001069\n",
      ">> Epoch 60 finished \tANN training loss 0.001052\n",
      ">> Epoch 61 finished \tANN training loss 0.001036\n",
      ">> Epoch 62 finished \tANN training loss 0.001020\n",
      ">> Epoch 63 finished \tANN training loss 0.001004\n",
      ">> Epoch 64 finished \tANN training loss 0.000989\n",
      ">> Epoch 65 finished \tANN training loss 0.000975\n",
      ">> Epoch 66 finished \tANN training loss 0.000961\n",
      ">> Epoch 67 finished \tANN training loss 0.000947\n",
      ">> Epoch 68 finished \tANN training loss 0.000933\n",
      ">> Epoch 69 finished \tANN training loss 0.000920\n",
      ">> Epoch 70 finished \tANN training loss 0.000907\n",
      ">> Epoch 71 finished \tANN training loss 0.000895\n",
      ">> Epoch 72 finished \tANN training loss 0.000883\n",
      ">> Epoch 73 finished \tANN training loss 0.000871\n",
      ">> Epoch 74 finished \tANN training loss 0.000860\n",
      ">> Epoch 75 finished \tANN training loss 0.000849\n",
      ">> Epoch 76 finished \tANN training loss 0.000838\n",
      ">> Epoch 77 finished \tANN training loss 0.000828\n",
      ">> Epoch 78 finished \tANN training loss 0.000818\n",
      ">> Epoch 79 finished \tANN training loss 0.000808\n",
      ">> Epoch 80 finished \tANN training loss 0.000798\n",
      ">> Epoch 81 finished \tANN training loss 0.000789\n",
      ">> Epoch 82 finished \tANN training loss 0.000780\n",
      ">> Epoch 83 finished \tANN training loss 0.000771\n",
      ">> Epoch 84 finished \tANN training loss 0.000762\n",
      ">> Epoch 85 finished \tANN training loss 0.000754\n",
      ">> Epoch 86 finished \tANN training loss 0.000746\n",
      ">> Epoch 87 finished \tANN training loss 0.000738\n",
      ">> Epoch 88 finished \tANN training loss 0.000730\n",
      ">> Epoch 89 finished \tANN training loss 0.000723\n",
      ">> Epoch 90 finished \tANN training loss 0.000715\n",
      ">> Epoch 91 finished \tANN training loss 0.000708\n",
      ">> Epoch 92 finished \tANN training loss 0.000701\n",
      ">> Epoch 93 finished \tANN training loss 0.000695\n",
      ">> Epoch 94 finished \tANN training loss 0.000688\n",
      ">> Epoch 95 finished \tANN training loss 0.000682\n",
      ">> Epoch 96 finished \tANN training loss 0.000676\n",
      ">> Epoch 97 finished \tANN training loss 0.000670\n",
      ">> Epoch 98 finished \tANN training loss 0.000664\n",
      ">> Epoch 99 finished \tANN training loss 0.000658\n",
      ">> Epoch 100 finished \tANN training loss 0.000652\n",
      ">> Epoch 101 finished \tANN training loss 0.000647\n",
      ">> Epoch 102 finished \tANN training loss 0.000642\n",
      ">> Epoch 103 finished \tANN training loss 0.000637\n",
      ">> Epoch 104 finished \tANN training loss 0.000632\n",
      ">> Epoch 105 finished \tANN training loss 0.000627\n",
      ">> Epoch 106 finished \tANN training loss 0.000622\n",
      ">> Epoch 107 finished \tANN training loss 0.000618\n",
      ">> Epoch 108 finished \tANN training loss 0.000613\n",
      ">> Epoch 109 finished \tANN training loss 0.000609\n",
      ">> Epoch 110 finished \tANN training loss 0.000605\n",
      ">> Epoch 111 finished \tANN training loss 0.000601\n",
      ">> Epoch 112 finished \tANN training loss 0.000597\n",
      ">> Epoch 113 finished \tANN training loss 0.000593\n",
      ">> Epoch 114 finished \tANN training loss 0.000589\n",
      ">> Epoch 115 finished \tANN training loss 0.000585\n",
      ">> Epoch 116 finished \tANN training loss 0.000582\n",
      ">> Epoch 117 finished \tANN training loss 0.000578\n",
      ">> Epoch 118 finished \tANN training loss 0.000575\n",
      ">> Epoch 119 finished \tANN training loss 0.000572\n",
      ">> Epoch 120 finished \tANN training loss 0.000569\n",
      ">> Epoch 121 finished \tANN training loss 0.000565\n",
      ">> Epoch 122 finished \tANN training loss 0.000562\n",
      ">> Epoch 123 finished \tANN training loss 0.000559\n",
      ">> Epoch 124 finished \tANN training loss 0.000557\n",
      ">> Epoch 125 finished \tANN training loss 0.000554\n",
      ">> Epoch 126 finished \tANN training loss 0.000551\n",
      ">> Epoch 127 finished \tANN training loss 0.000548\n",
      ">> Epoch 128 finished \tANN training loss 0.000546\n",
      ">> Epoch 129 finished \tANN training loss 0.000543\n",
      ">> Epoch 130 finished \tANN training loss 0.000541\n",
      ">> Epoch 131 finished \tANN training loss 0.000539\n",
      ">> Epoch 132 finished \tANN training loss 0.000536\n",
      ">> Epoch 133 finished \tANN training loss 0.000534\n",
      ">> Epoch 134 finished \tANN training loss 0.000532\n",
      ">> Epoch 135 finished \tANN training loss 0.000530\n",
      ">> Epoch 136 finished \tANN training loss 0.000528\n",
      ">> Epoch 137 finished \tANN training loss 0.000526\n",
      ">> Epoch 138 finished \tANN training loss 0.000524\n",
      ">> Epoch 139 finished \tANN training loss 0.000522\n",
      ">> Epoch 140 finished \tANN training loss 0.000520\n",
      ">> Epoch 141 finished \tANN training loss 0.000518\n",
      ">> Epoch 142 finished \tANN training loss 0.000516\n",
      ">> Epoch 143 finished \tANN training loss 0.000515\n",
      ">> Epoch 144 finished \tANN training loss 0.000513\n",
      ">> Epoch 145 finished \tANN training loss 0.000511\n",
      ">> Epoch 146 finished \tANN training loss 0.000510\n",
      ">> Epoch 147 finished \tANN training loss 0.000508\n",
      ">> Epoch 148 finished \tANN training loss 0.000507\n",
      ">> Epoch 149 finished \tANN training loss 0.000505\n",
      ">> Epoch 150 finished \tANN training loss 0.000504\n",
      "[END] Fine tuning step\n",
      "############### End Training for EXIDEINDEQ #####################\n",
      "############### End Training for SRFEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 0.131755\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 0.130667\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 0.129604\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 0.128569\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 0.127557\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 0.126568\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 0.125605\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 0.124667\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 0.123751\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 0.122855\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 0.121983\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 0.121133\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 0.120307\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 0.119496\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 0.118706\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 0.117940\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 0.117191\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 0.116459\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 0.115744\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 0.115049\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 0.114368\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 0.113707\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 0.113061\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 0.112432\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 0.111821\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 0.111223\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 0.110641\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 0.110074\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 0.109521\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 0.108983\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 0.108456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 32 finished \tRBM Reconstruction error 0.107941\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 0.107443\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 0.106957\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 0.106484\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 0.106024\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 0.105575\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 0.105138\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 0.104711\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 0.104296\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 0.103889\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 0.103491\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 0.103107\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.102733\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.102368\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.102013\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.101664\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.101327\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.100997\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.100679\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.100367\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.100061\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.099765\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.099478\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.099196\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.098922\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.098656\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.098395\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.098142\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.097894\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.097654\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.097420\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.097190\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.096965\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.096749\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.096537\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.096330\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.096128\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.095931\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.095740\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.095554\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.095372\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.095194\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.095022\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.094852\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.094688\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.094528\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.094370\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.094217\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.094068\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.093922\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.093779\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.093639\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.093503\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.093370\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.093241\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.093115\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.092992\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.092871\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.092754\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.092640\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.092528\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.092418\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.092312\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.092207\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.092106\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.092006\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.091909\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.091814\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.091720\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.005792\n",
      ">> Epoch 2 finished \tANN training loss 0.005567\n",
      ">> Epoch 3 finished \tANN training loss 0.005355\n",
      ">> Epoch 4 finished \tANN training loss 0.005156\n",
      ">> Epoch 5 finished \tANN training loss 0.004969\n",
      ">> Epoch 6 finished \tANN training loss 0.004792\n",
      ">> Epoch 7 finished \tANN training loss 0.004626\n",
      ">> Epoch 8 finished \tANN training loss 0.004470\n",
      ">> Epoch 9 finished \tANN training loss 0.004322\n",
      ">> Epoch 10 finished \tANN training loss 0.004184\n",
      ">> Epoch 11 finished \tANN training loss 0.004053\n",
      ">> Epoch 12 finished \tANN training loss 0.003930\n",
      ">> Epoch 13 finished \tANN training loss 0.003814\n",
      ">> Epoch 14 finished \tANN training loss 0.003705\n",
      ">> Epoch 15 finished \tANN training loss 0.003602\n",
      ">> Epoch 16 finished \tANN training loss 0.003506\n",
      ">> Epoch 17 finished \tANN training loss 0.003414\n",
      ">> Epoch 18 finished \tANN training loss 0.003328\n",
      ">> Epoch 19 finished \tANN training loss 0.003247\n",
      ">> Epoch 20 finished \tANN training loss 0.003171\n",
      ">> Epoch 21 finished \tANN training loss 0.003099\n",
      ">> Epoch 22 finished \tANN training loss 0.003031\n",
      ">> Epoch 23 finished \tANN training loss 0.002966\n",
      ">> Epoch 24 finished \tANN training loss 0.002906\n",
      ">> Epoch 25 finished \tANN training loss 0.002849\n",
      ">> Epoch 26 finished \tANN training loss 0.002794\n",
      ">> Epoch 27 finished \tANN training loss 0.002743\n",
      ">> Epoch 28 finished \tANN training loss 0.002695\n",
      ">> Epoch 29 finished \tANN training loss 0.002649\n",
      ">> Epoch 30 finished \tANN training loss 0.002606\n",
      ">> Epoch 31 finished \tANN training loss 0.002565\n",
      ">> Epoch 32 finished \tANN training loss 0.002526\n",
      ">> Epoch 33 finished \tANN training loss 0.002490\n",
      ">> Epoch 34 finished \tANN training loss 0.002455\n",
      ">> Epoch 35 finished \tANN training loss 0.002422\n",
      ">> Epoch 36 finished \tANN training loss 0.002390\n",
      ">> Epoch 37 finished \tANN training loss 0.002361\n",
      ">> Epoch 38 finished \tANN training loss 0.002332\n",
      ">> Epoch 39 finished \tANN training loss 0.002305\n",
      ">> Epoch 40 finished \tANN training loss 0.002279\n",
      ">> Epoch 41 finished \tANN training loss 0.002255\n",
      ">> Epoch 42 finished \tANN training loss 0.002232\n",
      ">> Epoch 43 finished \tANN training loss 0.002209\n",
      ">> Epoch 44 finished \tANN training loss 0.002188\n",
      ">> Epoch 45 finished \tANN training loss 0.002168\n",
      ">> Epoch 46 finished \tANN training loss 0.002148\n",
      ">> Epoch 47 finished \tANN training loss 0.002130\n",
      ">> Epoch 48 finished \tANN training loss 0.002112\n",
      ">> Epoch 49 finished \tANN training loss 0.002095\n",
      ">> Epoch 50 finished \tANN training loss 0.002078\n",
      ">> Epoch 51 finished \tANN training loss 0.002063\n",
      ">> Epoch 52 finished \tANN training loss 0.002048\n",
      ">> Epoch 53 finished \tANN training loss 0.002033\n",
      ">> Epoch 54 finished \tANN training loss 0.002019\n",
      ">> Epoch 55 finished \tANN training loss 0.002005\n",
      ">> Epoch 56 finished \tANN training loss 0.001992\n",
      ">> Epoch 57 finished \tANN training loss 0.001980\n",
      ">> Epoch 58 finished \tANN training loss 0.001968\n",
      ">> Epoch 59 finished \tANN training loss 0.001956\n",
      ">> Epoch 60 finished \tANN training loss 0.001944\n",
      ">> Epoch 61 finished \tANN training loss 0.001933\n",
      ">> Epoch 62 finished \tANN training loss 0.001922\n",
      ">> Epoch 63 finished \tANN training loss 0.001912\n",
      ">> Epoch 64 finished \tANN training loss 0.001902\n",
      ">> Epoch 65 finished \tANN training loss 0.001892\n",
      ">> Epoch 66 finished \tANN training loss 0.001882\n",
      ">> Epoch 67 finished \tANN training loss 0.001873\n",
      ">> Epoch 68 finished \tANN training loss 0.001864\n",
      ">> Epoch 69 finished \tANN training loss 0.001855\n",
      ">> Epoch 70 finished \tANN training loss 0.001846\n",
      ">> Epoch 71 finished \tANN training loss 0.001837\n",
      ">> Epoch 72 finished \tANN training loss 0.001829\n",
      ">> Epoch 73 finished \tANN training loss 0.001821\n",
      ">> Epoch 74 finished \tANN training loss 0.001813\n",
      ">> Epoch 75 finished \tANN training loss 0.001805\n",
      ">> Epoch 76 finished \tANN training loss 0.001797\n",
      ">> Epoch 77 finished \tANN training loss 0.001789\n",
      ">> Epoch 78 finished \tANN training loss 0.001782\n",
      ">> Epoch 79 finished \tANN training loss 0.001775\n",
      ">> Epoch 80 finished \tANN training loss 0.001767\n",
      ">> Epoch 81 finished \tANN training loss 0.001760\n",
      ">> Epoch 82 finished \tANN training loss 0.001753\n",
      ">> Epoch 83 finished \tANN training loss 0.001746\n",
      ">> Epoch 84 finished \tANN training loss 0.001740\n",
      ">> Epoch 85 finished \tANN training loss 0.001733\n",
      ">> Epoch 86 finished \tANN training loss 0.001726\n",
      ">> Epoch 87 finished \tANN training loss 0.001720\n",
      ">> Epoch 88 finished \tANN training loss 0.001713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 89 finished \tANN training loss 0.001707\n",
      ">> Epoch 90 finished \tANN training loss 0.001700\n",
      ">> Epoch 91 finished \tANN training loss 0.001694\n",
      ">> Epoch 92 finished \tANN training loss 0.001688\n",
      ">> Epoch 93 finished \tANN training loss 0.001682\n",
      ">> Epoch 94 finished \tANN training loss 0.001676\n",
      ">> Epoch 95 finished \tANN training loss 0.001670\n",
      ">> Epoch 96 finished \tANN training loss 0.001664\n",
      ">> Epoch 97 finished \tANN training loss 0.001658\n",
      ">> Epoch 98 finished \tANN training loss 0.001652\n",
      ">> Epoch 99 finished \tANN training loss 0.001646\n",
      ">> Epoch 100 finished \tANN training loss 0.001640\n",
      ">> Epoch 101 finished \tANN training loss 0.001635\n",
      ">> Epoch 102 finished \tANN training loss 0.001629\n",
      ">> Epoch 103 finished \tANN training loss 0.001624\n",
      ">> Epoch 104 finished \tANN training loss 0.001618\n",
      ">> Epoch 105 finished \tANN training loss 0.001613\n",
      ">> Epoch 106 finished \tANN training loss 0.001607\n",
      ">> Epoch 107 finished \tANN training loss 0.001602\n",
      ">> Epoch 108 finished \tANN training loss 0.001596\n",
      ">> Epoch 109 finished \tANN training loss 0.001591\n",
      ">> Epoch 110 finished \tANN training loss 0.001586\n",
      ">> Epoch 111 finished \tANN training loss 0.001580\n",
      ">> Epoch 112 finished \tANN training loss 0.001575\n",
      ">> Epoch 113 finished \tANN training loss 0.001570\n",
      ">> Epoch 114 finished \tANN training loss 0.001565\n",
      ">> Epoch 115 finished \tANN training loss 0.001560\n",
      ">> Epoch 116 finished \tANN training loss 0.001555\n",
      ">> Epoch 117 finished \tANN training loss 0.001550\n",
      ">> Epoch 118 finished \tANN training loss 0.001545\n",
      ">> Epoch 119 finished \tANN training loss 0.001540\n",
      ">> Epoch 120 finished \tANN training loss 0.001535\n",
      ">> Epoch 121 finished \tANN training loss 0.001530\n",
      ">> Epoch 122 finished \tANN training loss 0.001526\n",
      ">> Epoch 123 finished \tANN training loss 0.001521\n",
      ">> Epoch 124 finished \tANN training loss 0.001516\n",
      ">> Epoch 125 finished \tANN training loss 0.001511\n",
      ">> Epoch 126 finished \tANN training loss 0.001507\n",
      ">> Epoch 127 finished \tANN training loss 0.001502\n",
      ">> Epoch 128 finished \tANN training loss 0.001498\n",
      ">> Epoch 129 finished \tANN training loss 0.001493\n",
      ">> Epoch 130 finished \tANN training loss 0.001488\n",
      ">> Epoch 131 finished \tANN training loss 0.001484\n",
      ">> Epoch 132 finished \tANN training loss 0.001479\n",
      ">> Epoch 133 finished \tANN training loss 0.001475\n",
      ">> Epoch 134 finished \tANN training loss 0.001470\n",
      ">> Epoch 135 finished \tANN training loss 0.001466\n",
      ">> Epoch 136 finished \tANN training loss 0.001462\n",
      ">> Epoch 137 finished \tANN training loss 0.001457\n",
      ">> Epoch 138 finished \tANN training loss 0.001453\n",
      ">> Epoch 139 finished \tANN training loss 0.001449\n",
      ">> Epoch 140 finished \tANN training loss 0.001445\n",
      ">> Epoch 141 finished \tANN training loss 0.001440\n",
      ">> Epoch 142 finished \tANN training loss 0.001436\n",
      ">> Epoch 143 finished \tANN training loss 0.001432\n",
      ">> Epoch 144 finished \tANN training loss 0.001428\n",
      ">> Epoch 145 finished \tANN training loss 0.001423\n",
      ">> Epoch 146 finished \tANN training loss 0.001419\n",
      ">> Epoch 147 finished \tANN training loss 0.001415\n",
      ">> Epoch 148 finished \tANN training loss 0.001411\n",
      ">> Epoch 149 finished \tANN training loss 0.001407\n",
      ">> Epoch 150 finished \tANN training loss 0.001403\n",
      "[END] Fine tuning step\n",
      "############### End Training for SRFEQ #####################\n",
      "############### End Training for TORNTPHARMEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 26.318328\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 26.304685\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 26.290989\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 26.277254\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 26.263463\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 26.249615\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 26.235721\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 26.221784\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 26.207792\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 26.193761\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 26.179662\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 26.165519\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 26.151327\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 26.137069\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 26.122784\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 26.108429\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 26.094035\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 26.079572\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 26.065067\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 26.050496\n",
      ">> Epoch 21 finished \tRBM Reconstruction error 26.035865\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 26.021197\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 26.006476\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 25.991701\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 25.976872\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 25.961996\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 25.947037\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 25.932029\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 25.916946\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 25.901837\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 25.886632\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 25.871386\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 25.856090\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 25.840698\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 25.825276\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 25.809805\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 25.794264\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 25.778678\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 25.763025\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 25.747265\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 25.731461\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 25.715571\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 25.699625\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 25.683662\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 25.667605\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 25.651498\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 25.635289\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 25.619035\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 25.602698\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 25.586302\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 25.569856\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 25.553311\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 25.536690\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 25.520014\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 25.503264\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 25.486437\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 25.469535\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 25.452602\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 25.435572\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 25.418488\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 25.401331\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 25.384094\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 25.366769\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 25.349360\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 25.331912\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 25.314357\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 25.296746\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 25.279038\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 25.261233\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 25.243394\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 25.225474\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 25.207480\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 25.189367\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 25.171207\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 25.152908\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 25.134541\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 25.116093\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 25.097586\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 25.078961\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 25.060263\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 25.041484\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 25.022644\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 25.003672\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 24.984670\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 24.965560\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 24.946314\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 24.926998\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 24.907596\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 24.888067\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 24.868514\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 24.848854\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 24.829043\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 24.809167\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 24.789233\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 24.769174\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 24.749042\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 24.728812\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 24.708481\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 24.688031\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 24.667540\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.333012\n",
      ">> Epoch 2 finished \tANN training loss 0.331291\n",
      ">> Epoch 3 finished \tANN training loss 0.329570\n",
      ">> Epoch 4 finished \tANN training loss 0.327863\n",
      ">> Epoch 5 finished \tANN training loss 0.326148\n",
      ">> Epoch 6 finished \tANN training loss 0.324434\n",
      ">> Epoch 7 finished \tANN training loss 0.322756\n",
      ">> Epoch 8 finished \tANN training loss 0.321067\n",
      ">> Epoch 9 finished \tANN training loss 0.319382\n",
      ">> Epoch 10 finished \tANN training loss 0.317735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 11 finished \tANN training loss 0.316069\n",
      ">> Epoch 12 finished \tANN training loss 0.314424\n",
      ">> Epoch 13 finished \tANN training loss 0.312782\n",
      ">> Epoch 14 finished \tANN training loss 0.311148\n",
      ">> Epoch 15 finished \tANN training loss 0.309520\n",
      ">> Epoch 16 finished \tANN training loss 0.307893\n",
      ">> Epoch 17 finished \tANN training loss 0.306300\n",
      ">> Epoch 18 finished \tANN training loss 0.304701\n",
      ">> Epoch 19 finished \tANN training loss 0.303088\n",
      ">> Epoch 20 finished \tANN training loss 0.301499\n",
      ">> Epoch 21 finished \tANN training loss 0.299924\n",
      ">> Epoch 22 finished \tANN training loss 0.298355\n",
      ">> Epoch 23 finished \tANN training loss 0.296773\n",
      ">> Epoch 24 finished \tANN training loss 0.295210\n",
      ">> Epoch 25 finished \tANN training loss 0.293634\n",
      ">> Epoch 26 finished \tANN training loss 0.292101\n",
      ">> Epoch 27 finished \tANN training loss 0.290562\n",
      ">> Epoch 28 finished \tANN training loss 0.289028\n",
      ">> Epoch 29 finished \tANN training loss 0.287481\n",
      ">> Epoch 30 finished \tANN training loss 0.285964\n",
      ">> Epoch 31 finished \tANN training loss 0.284458\n",
      ">> Epoch 32 finished \tANN training loss 0.282922\n",
      ">> Epoch 33 finished \tANN training loss 0.281451\n",
      ">> Epoch 34 finished \tANN training loss 0.279948\n",
      ">> Epoch 35 finished \tANN training loss 0.278476\n",
      ">> Epoch 36 finished \tANN training loss 0.277007\n",
      ">> Epoch 37 finished \tANN training loss 0.275540\n",
      ">> Epoch 38 finished \tANN training loss 0.274101\n",
      ">> Epoch 39 finished \tANN training loss 0.272659\n",
      ">> Epoch 40 finished \tANN training loss 0.271235\n",
      ">> Epoch 41 finished \tANN training loss 0.269815\n",
      ">> Epoch 42 finished \tANN training loss 0.268389\n",
      ">> Epoch 43 finished \tANN training loss 0.266986\n",
      ">> Epoch 44 finished \tANN training loss 0.265567\n",
      ">> Epoch 45 finished \tANN training loss 0.264173\n",
      ">> Epoch 46 finished \tANN training loss 0.262787\n",
      ">> Epoch 47 finished \tANN training loss 0.261400\n",
      ">> Epoch 48 finished \tANN training loss 0.260036\n",
      ">> Epoch 49 finished \tANN training loss 0.258646\n",
      ">> Epoch 50 finished \tANN training loss 0.257280\n",
      ">> Epoch 51 finished \tANN training loss 0.255954\n",
      ">> Epoch 52 finished \tANN training loss 0.254604\n",
      ">> Epoch 53 finished \tANN training loss 0.253247\n",
      ">> Epoch 54 finished \tANN training loss 0.251909\n",
      ">> Epoch 55 finished \tANN training loss 0.250585\n",
      ">> Epoch 56 finished \tANN training loss 0.249257\n",
      ">> Epoch 57 finished \tANN training loss 0.247950\n",
      ">> Epoch 58 finished \tANN training loss 0.246653\n",
      ">> Epoch 59 finished \tANN training loss 0.245348\n",
      ">> Epoch 60 finished \tANN training loss 0.244084\n",
      ">> Epoch 61 finished \tANN training loss 0.242792\n",
      ">> Epoch 62 finished \tANN training loss 0.241486\n",
      ">> Epoch 63 finished \tANN training loss 0.240213\n",
      ">> Epoch 64 finished \tANN training loss 0.238944\n",
      ">> Epoch 65 finished \tANN training loss 0.237690\n",
      ">> Epoch 66 finished \tANN training loss 0.236446\n",
      ">> Epoch 67 finished \tANN training loss 0.235204\n",
      ">> Epoch 68 finished \tANN training loss 0.233961\n",
      ">> Epoch 69 finished \tANN training loss 0.232732\n",
      ">> Epoch 70 finished \tANN training loss 0.231505\n",
      ">> Epoch 71 finished \tANN training loss 0.230287\n",
      ">> Epoch 72 finished \tANN training loss 0.229094\n",
      ">> Epoch 73 finished \tANN training loss 0.227874\n",
      ">> Epoch 74 finished \tANN training loss 0.226673\n",
      ">> Epoch 75 finished \tANN training loss 0.225492\n",
      ">> Epoch 76 finished \tANN training loss 0.224311\n",
      ">> Epoch 77 finished \tANN training loss 0.223144\n",
      ">> Epoch 78 finished \tANN training loss 0.221986\n",
      ">> Epoch 79 finished \tANN training loss 0.220835\n",
      ">> Epoch 80 finished \tANN training loss 0.219683\n",
      ">> Epoch 81 finished \tANN training loss 0.218552\n",
      ">> Epoch 82 finished \tANN training loss 0.217422\n",
      ">> Epoch 83 finished \tANN training loss 0.216298\n",
      ">> Epoch 84 finished \tANN training loss 0.215195\n",
      ">> Epoch 85 finished \tANN training loss 0.214076\n",
      ">> Epoch 86 finished \tANN training loss 0.212988\n",
      ">> Epoch 87 finished \tANN training loss 0.211884\n",
      ">> Epoch 88 finished \tANN training loss 0.210808\n",
      ">> Epoch 89 finished \tANN training loss 0.209719\n",
      ">> Epoch 90 finished \tANN training loss 0.208659\n",
      ">> Epoch 91 finished \tANN training loss 0.207594\n",
      ">> Epoch 92 finished \tANN training loss 0.206541\n",
      ">> Epoch 93 finished \tANN training loss 0.205503\n",
      ">> Epoch 94 finished \tANN training loss 0.204458\n",
      ">> Epoch 95 finished \tANN training loss 0.203424\n",
      ">> Epoch 96 finished \tANN training loss 0.202396\n",
      ">> Epoch 97 finished \tANN training loss 0.201377\n",
      ">> Epoch 98 finished \tANN training loss 0.200367\n",
      ">> Epoch 99 finished \tANN training loss 0.199353\n",
      ">> Epoch 100 finished \tANN training loss 0.198362\n",
      ">> Epoch 101 finished \tANN training loss 0.197356\n",
      ">> Epoch 102 finished \tANN training loss 0.196383\n",
      ">> Epoch 103 finished \tANN training loss 0.195376\n",
      ">> Epoch 104 finished \tANN training loss 0.194402\n",
      ">> Epoch 105 finished \tANN training loss 0.193435\n",
      ">> Epoch 106 finished \tANN training loss 0.192479\n",
      ">> Epoch 107 finished \tANN training loss 0.191524\n",
      ">> Epoch 108 finished \tANN training loss 0.190553\n",
      ">> Epoch 109 finished \tANN training loss 0.189616\n",
      ">> Epoch 110 finished \tANN training loss 0.188683\n",
      ">> Epoch 111 finished \tANN training loss 0.187741\n",
      ">> Epoch 112 finished \tANN training loss 0.186815\n",
      ">> Epoch 113 finished \tANN training loss 0.185904\n",
      ">> Epoch 114 finished \tANN training loss 0.184980\n",
      ">> Epoch 115 finished \tANN training loss 0.184069\n",
      ">> Epoch 116 finished \tANN training loss 0.183162\n",
      ">> Epoch 117 finished \tANN training loss 0.182258\n",
      ">> Epoch 118 finished \tANN training loss 0.181362\n",
      ">> Epoch 119 finished \tANN training loss 0.180470\n",
      ">> Epoch 120 finished \tANN training loss 0.179592\n",
      ">> Epoch 121 finished \tANN training loss 0.178711\n",
      ">> Epoch 122 finished \tANN training loss 0.177838\n",
      ">> Epoch 123 finished \tANN training loss 0.176984\n",
      ">> Epoch 124 finished \tANN training loss 0.176090\n",
      ">> Epoch 125 finished \tANN training loss 0.175240\n",
      ">> Epoch 126 finished \tANN training loss 0.174389\n",
      ">> Epoch 127 finished \tANN training loss 0.173540\n",
      ">> Epoch 128 finished \tANN training loss 0.172712\n",
      ">> Epoch 129 finished \tANN training loss 0.171872\n",
      ">> Epoch 130 finished \tANN training loss 0.171034\n",
      ">> Epoch 131 finished \tANN training loss 0.170215\n",
      ">> Epoch 132 finished \tANN training loss 0.169389\n",
      ">> Epoch 133 finished \tANN training loss 0.168572\n",
      ">> Epoch 134 finished \tANN training loss 0.167760\n",
      ">> Epoch 135 finished \tANN training loss 0.166966\n",
      ">> Epoch 136 finished \tANN training loss 0.166148\n",
      ">> Epoch 137 finished \tANN training loss 0.165365\n",
      ">> Epoch 138 finished \tANN training loss 0.164575\n",
      ">> Epoch 139 finished \tANN training loss 0.163792\n",
      ">> Epoch 140 finished \tANN training loss 0.163010\n",
      ">> Epoch 141 finished \tANN training loss 0.162246\n",
      ">> Epoch 142 finished \tANN training loss 0.161470\n",
      ">> Epoch 143 finished \tANN training loss 0.160713\n",
      ">> Epoch 144 finished \tANN training loss 0.159951\n",
      ">> Epoch 145 finished \tANN training loss 0.159197\n",
      ">> Epoch 146 finished \tANN training loss 0.158461\n",
      ">> Epoch 147 finished \tANN training loss 0.157713\n",
      ">> Epoch 148 finished \tANN training loss 0.156957\n",
      ">> Epoch 149 finished \tANN training loss 0.156229\n",
      ">> Epoch 150 finished \tANN training loss 0.155491\n",
      "[END] Fine tuning step\n",
      "############### End Training for TORNTPHARMEQ #####################\n",
      "############### End Training for NMDCEQ #####################\n",
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 5.568149\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 5.502122\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 5.434967\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 5.366534\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 5.296670\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 5.225246\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 5.152137\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 5.077160\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 5.000157\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 4.921086\n",
      ">> Epoch 11 finished \tRBM Reconstruction error 4.839603\n",
      ">> Epoch 12 finished \tRBM Reconstruction error 4.755534\n",
      ">> Epoch 13 finished \tRBM Reconstruction error 4.668819\n",
      ">> Epoch 14 finished \tRBM Reconstruction error 4.579210\n",
      ">> Epoch 15 finished \tRBM Reconstruction error 4.486555\n",
      ">> Epoch 16 finished \tRBM Reconstruction error 4.390652\n",
      ">> Epoch 17 finished \tRBM Reconstruction error 4.291362\n",
      ">> Epoch 18 finished \tRBM Reconstruction error 4.188596\n",
      ">> Epoch 19 finished \tRBM Reconstruction error 4.082244\n",
      ">> Epoch 20 finished \tRBM Reconstruction error 3.972150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 21 finished \tRBM Reconstruction error 3.858533\n",
      ">> Epoch 22 finished \tRBM Reconstruction error 3.740747\n",
      ">> Epoch 23 finished \tRBM Reconstruction error 3.619240\n",
      ">> Epoch 24 finished \tRBM Reconstruction error 3.494075\n",
      ">> Epoch 25 finished \tRBM Reconstruction error 3.364858\n",
      ">> Epoch 26 finished \tRBM Reconstruction error 3.232218\n",
      ">> Epoch 27 finished \tRBM Reconstruction error 3.096498\n",
      ">> Epoch 28 finished \tRBM Reconstruction error 2.957693\n",
      ">> Epoch 29 finished \tRBM Reconstruction error 2.816514\n",
      ">> Epoch 30 finished \tRBM Reconstruction error 2.673697\n",
      ">> Epoch 31 finished \tRBM Reconstruction error 2.529833\n",
      ">> Epoch 32 finished \tRBM Reconstruction error 2.385361\n",
      ">> Epoch 33 finished \tRBM Reconstruction error 2.240590\n",
      ">> Epoch 34 finished \tRBM Reconstruction error 2.097921\n",
      ">> Epoch 35 finished \tRBM Reconstruction error 1.956486\n",
      ">> Epoch 36 finished \tRBM Reconstruction error 1.818938\n",
      ">> Epoch 37 finished \tRBM Reconstruction error 1.685740\n",
      ">> Epoch 38 finished \tRBM Reconstruction error 1.556764\n",
      ">> Epoch 39 finished \tRBM Reconstruction error 1.433747\n",
      ">> Epoch 40 finished \tRBM Reconstruction error 1.317291\n",
      ">> Epoch 41 finished \tRBM Reconstruction error 1.207552\n",
      ">> Epoch 42 finished \tRBM Reconstruction error 1.106315\n",
      ">> Epoch 43 finished \tRBM Reconstruction error 1.013359\n",
      ">> Epoch 44 finished \tRBM Reconstruction error 0.928471\n",
      ">> Epoch 45 finished \tRBM Reconstruction error 0.850368\n",
      ">> Epoch 46 finished \tRBM Reconstruction error 0.781785\n",
      ">> Epoch 47 finished \tRBM Reconstruction error 0.719450\n",
      ">> Epoch 48 finished \tRBM Reconstruction error 0.666054\n",
      ">> Epoch 49 finished \tRBM Reconstruction error 0.619979\n",
      ">> Epoch 50 finished \tRBM Reconstruction error 0.578837\n",
      ">> Epoch 51 finished \tRBM Reconstruction error 0.543604\n",
      ">> Epoch 52 finished \tRBM Reconstruction error 0.512983\n",
      ">> Epoch 53 finished \tRBM Reconstruction error 0.488055\n",
      ">> Epoch 54 finished \tRBM Reconstruction error 0.465363\n",
      ">> Epoch 55 finished \tRBM Reconstruction error 0.446752\n",
      ">> Epoch 56 finished \tRBM Reconstruction error 0.430740\n",
      ">> Epoch 57 finished \tRBM Reconstruction error 0.416996\n",
      ">> Epoch 58 finished \tRBM Reconstruction error 0.405574\n",
      ">> Epoch 59 finished \tRBM Reconstruction error 0.395234\n",
      ">> Epoch 60 finished \tRBM Reconstruction error 0.386734\n",
      ">> Epoch 61 finished \tRBM Reconstruction error 0.379077\n",
      ">> Epoch 62 finished \tRBM Reconstruction error 0.372990\n",
      ">> Epoch 63 finished \tRBM Reconstruction error 0.368080\n",
      ">> Epoch 64 finished \tRBM Reconstruction error 0.364013\n",
      ">> Epoch 65 finished \tRBM Reconstruction error 0.360013\n",
      ">> Epoch 66 finished \tRBM Reconstruction error 0.356368\n",
      ">> Epoch 67 finished \tRBM Reconstruction error 0.353473\n",
      ">> Epoch 68 finished \tRBM Reconstruction error 0.350669\n",
      ">> Epoch 69 finished \tRBM Reconstruction error 0.348156\n",
      ">> Epoch 70 finished \tRBM Reconstruction error 0.345690\n",
      ">> Epoch 71 finished \tRBM Reconstruction error 0.343590\n",
      ">> Epoch 72 finished \tRBM Reconstruction error 0.341538\n",
      ">> Epoch 73 finished \tRBM Reconstruction error 0.339454\n",
      ">> Epoch 74 finished \tRBM Reconstruction error 0.337650\n",
      ">> Epoch 75 finished \tRBM Reconstruction error 0.335991\n",
      ">> Epoch 76 finished \tRBM Reconstruction error 0.334384\n",
      ">> Epoch 77 finished \tRBM Reconstruction error 0.332905\n",
      ">> Epoch 78 finished \tRBM Reconstruction error 0.331493\n",
      ">> Epoch 79 finished \tRBM Reconstruction error 0.330074\n",
      ">> Epoch 80 finished \tRBM Reconstruction error 0.328773\n",
      ">> Epoch 81 finished \tRBM Reconstruction error 0.327522\n",
      ">> Epoch 82 finished \tRBM Reconstruction error 0.326265\n",
      ">> Epoch 83 finished \tRBM Reconstruction error 0.325046\n",
      ">> Epoch 84 finished \tRBM Reconstruction error 0.323841\n",
      ">> Epoch 85 finished \tRBM Reconstruction error 0.322627\n",
      ">> Epoch 86 finished \tRBM Reconstruction error 0.321468\n",
      ">> Epoch 87 finished \tRBM Reconstruction error 0.320323\n",
      ">> Epoch 88 finished \tRBM Reconstruction error 0.319236\n",
      ">> Epoch 89 finished \tRBM Reconstruction error 0.318162\n",
      ">> Epoch 90 finished \tRBM Reconstruction error 0.317086\n",
      ">> Epoch 91 finished \tRBM Reconstruction error 0.316036\n",
      ">> Epoch 92 finished \tRBM Reconstruction error 0.315005\n",
      ">> Epoch 93 finished \tRBM Reconstruction error 0.313977\n",
      ">> Epoch 94 finished \tRBM Reconstruction error 0.312962\n",
      ">> Epoch 95 finished \tRBM Reconstruction error 0.311966\n",
      ">> Epoch 96 finished \tRBM Reconstruction error 0.310972\n",
      ">> Epoch 97 finished \tRBM Reconstruction error 0.310002\n",
      ">> Epoch 98 finished \tRBM Reconstruction error 0.309024\n",
      ">> Epoch 99 finished \tRBM Reconstruction error 0.308070\n",
      ">> Epoch 100 finished \tRBM Reconstruction error 0.307127\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 0.017841\n",
      ">> Epoch 2 finished \tANN training loss 0.016819\n",
      ">> Epoch 3 finished \tANN training loss 0.015915\n",
      ">> Epoch 4 finished \tANN training loss 0.015114\n",
      ">> Epoch 5 finished \tANN training loss 0.014406\n",
      ">> Epoch 6 finished \tANN training loss 0.013779\n",
      ">> Epoch 7 finished \tANN training loss 0.013224\n",
      ">> Epoch 8 finished \tANN training loss 0.012731\n",
      ">> Epoch 9 finished \tANN training loss 0.012293\n",
      ">> Epoch 10 finished \tANN training loss 0.011903\n",
      ">> Epoch 11 finished \tANN training loss 0.011557\n",
      ">> Epoch 12 finished \tANN training loss 0.011248\n",
      ">> Epoch 13 finished \tANN training loss 0.010973\n",
      ">> Epoch 14 finished \tANN training loss 0.010727\n",
      ">> Epoch 15 finished \tANN training loss 0.010507\n",
      ">> Epoch 16 finished \tANN training loss 0.010310\n",
      ">> Epoch 17 finished \tANN training loss 0.010133\n",
      ">> Epoch 18 finished \tANN training loss 0.009974\n",
      ">> Epoch 19 finished \tANN training loss 0.009830\n",
      ">> Epoch 20 finished \tANN training loss 0.009700\n",
      ">> Epoch 21 finished \tANN training loss 0.009582\n",
      ">> Epoch 22 finished \tANN training loss 0.009475\n",
      ">> Epoch 23 finished \tANN training loss 0.009378\n",
      ">> Epoch 24 finished \tANN training loss 0.009288\n",
      ">> Epoch 25 finished \tANN training loss 0.009206\n",
      ">> Epoch 26 finished \tANN training loss 0.009131\n",
      ">> Epoch 27 finished \tANN training loss 0.009061\n",
      ">> Epoch 28 finished \tANN training loss 0.008996\n",
      ">> Epoch 29 finished \tANN training loss 0.008936\n",
      ">> Epoch 30 finished \tANN training loss 0.008880\n",
      ">> Epoch 31 finished \tANN training loss 0.008827\n",
      ">> Epoch 32 finished \tANN training loss 0.008778\n",
      ">> Epoch 33 finished \tANN training loss 0.008731\n",
      ">> Epoch 34 finished \tANN training loss 0.008686\n",
      ">> Epoch 35 finished \tANN training loss 0.008644\n",
      ">> Epoch 36 finished \tANN training loss 0.008604\n",
      ">> Epoch 37 finished \tANN training loss 0.008565\n",
      ">> Epoch 38 finished \tANN training loss 0.008528\n",
      ">> Epoch 39 finished \tANN training loss 0.008492\n",
      ">> Epoch 40 finished \tANN training loss 0.008458\n",
      ">> Epoch 41 finished \tANN training loss 0.008424\n",
      ">> Epoch 42 finished \tANN training loss 0.008392\n",
      ">> Epoch 43 finished \tANN training loss 0.008360\n",
      ">> Epoch 44 finished \tANN training loss 0.008330\n",
      ">> Epoch 45 finished \tANN training loss 0.008300\n",
      ">> Epoch 46 finished \tANN training loss 0.008270\n",
      ">> Epoch 47 finished \tANN training loss 0.008241\n",
      ">> Epoch 48 finished \tANN training loss 0.008213\n",
      ">> Epoch 49 finished \tANN training loss 0.008185\n"
     ]
    }
   ],
   "source": [
    "models_list = []\n",
    "\n",
    "for i in range(len(ticker_list)):\n",
    "    X_train = np.array(X_train_list[i])\n",
    "    y_train = np.array(y_train_list[i])\n",
    "    \n",
    "    model = SupervisedDBNRegression(hidden_layers_structure=[120],\n",
    "                                    learning_rate_rbm=0.0001,\n",
    "                                    learning_rate=0.0001,\n",
    "                                    n_epochs_rbm=100,\n",
    "                                    n_iter_backprop=150,\n",
    "                                    batch_size=32,\n",
    "                                    activation_function='relu')\n",
    "    print('############### End Training for {} #####################'.format(ticker_list[i].split('.')[0]))\n",
    "\n",
    "    model.fit(X_train , y_train)\n",
    "    models_list.append(model)\n",
    "    model.save('./models/{}.pkl'.format(ticker_list[i].split('.')[0]))\n",
    "    \n",
    "    print('############### End Training for {} #####################'.format(ticker_list[i].split('.')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banner-anger",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
